{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Cardiovascular Disease Dataset (Source: https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>bmiclass</th>\n",
       "      <th>MAP</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25283</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15317</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24418</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13764</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  gender  age  bmiclass  MAP  cholesterol  gluc  smoke  alco  \\\n",
       "0      25283       1    3         3    2            1     1      0     0   \n",
       "1      15317       1    5         1    3            1     1      0     0   \n",
       "2       1037       1    3         1    5            1     1      0     0   \n",
       "3      24418       1    2         1    3            1     1      0     0   \n",
       "4      13764       0    5         2    3            1     1      0     0   \n",
       "\n",
       "   active  cardio  \n",
       "0       1       0  \n",
       "1       1       0  \n",
       "2       0       1  \n",
       "3       1       0  \n",
       "4       0       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bf15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop source_id\n",
    "train_df = train_df.drop(columns=[\"source_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"cardio\"\n",
    "SENSITIVE = \"gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "\n",
    "# Identify feature types\n",
    "binary_cols = [\"gender\", \"smoke\", \"alco\", \"active\"]\n",
    "categorical_cols = [\"age\", \"bmiclass\", \"MAP\", \"cholesterol\", \"gluc\"]\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (30000, 28) (11256, 28)\n"
     ]
    }
   ],
   "source": [
    "#ONE-HOT ENCODE CATEGORICALS; KEEP SCALED NUMERICS AS-IS \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train[binary_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test[binary_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.6566275764036958\n",
      "Precision: 0.6507467870788468\n",
      "Recall   : 0.6689876807712909\n",
      "F1 Score : 0.6597411743991548\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.64      0.65      5655\n",
      "           1       0.65      0.67      0.66      5601\n",
      "\n",
      "    accuracy                           0.66     11256\n",
      "   macro avg       0.66      0.66      0.66     11256\n",
      "weighted avg       0.66      0.66      0.66     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3644 2011]\n",
      " [1854 3747]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.6850568585643213\n",
      "Precision: 0.7045364106645444\n",
      "Recall   : 0.6322085341903232\n",
      "F1 Score : 0.6664157335089865\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.70      5655\n",
      "           1       0.70      0.63      0.67      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.68      0.68     11256\n",
      "weighted avg       0.69      0.69      0.68     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4170 1485]\n",
      " [2060 3541]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ef0ed",
   "metadata": {},
   "source": [
    "# Model Evaluation Results\n",
    "\n",
    "## KNN Classifier\n",
    "- **Accuracy:** 0.657  \n",
    "- **Precision:** 0.651  \n",
    "- **Recall:** 0.669  \n",
    "- **F1 Score:** 0.660  \n",
    "\n",
    "### Classification Report\n",
    "| Class | Precision | Recall | F1-score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 0.66      | 0.64   | 0.65     | 5655    |\n",
    "| 1     | 0.65      | 0.67   | 0.66     | 5601    |\n",
    "| **Avg / Total** | **0.66** | **0.66** | **0.66** | **11256** |\n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted 0 | Predicted 1 |\n",
    "|---------------|-------------|-------------|\n",
    "| **Actual 0**  | 3644        | 2011        |\n",
    "| **Actual 1**  | 1854        | 3747        |\n",
    "\n",
    "KNN achieves a balanced performance across both classes, with slightly higher recall than precision. It is reasonably good at identifying positive cases but also misclassifies a fair number of negatives as positives.\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree Classifier\n",
    "- **Accuracy:** 0.685  \n",
    "- **Precision:** 0.705  \n",
    "- **Recall:** 0.632  \n",
    "- **F1 Score:** 0.666  \n",
    "\n",
    "### Classification Report\n",
    "| Class | Precision | Recall | F1-score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| 0     | 0.67      | 0.74   | 0.70     | 5655    |\n",
    "| 1     | 0.70      | 0.63   | 0.67     | 5601    |\n",
    "| **Avg / Total** | **0.69** | **0.68** | **0.68** | **11256** |\n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted 0 | Predicted 1 |\n",
    "|---------------|-------------|-------------|\n",
    "| **Actual 0**  | 4170        | 1485        |\n",
    "| **Actual 1**  | 2060        | 3541        |\n",
    "\n",
    "The Decision Tree has higher precision but lower recall compared to KNN. It is more conservative in predicting positives (reduces false positives), but at the cost of missing more actual positives.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'euclidean', 'n_neighbors': 27, 'weights': 'distance'}\n",
      "Best CV F1: 0.6992184215344929\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.6888770433546553\n",
      "Precision: 0.708606638839197\n",
      "Recall   : 0.6364934833065524\n",
      "F1 Score : 0.6706170052671181\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.74      0.71      5655\n",
      "           1       0.71      0.64      0.67      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.69      0.69     11256\n",
      "weighted avg       0.69      0.69      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4189 1466]\n",
      " [2036 3565]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65dd34f",
   "metadata": {},
   "source": [
    "## KNN (Best Params)\n",
    "\n",
    "### Best Parameters\n",
    "- **Metric:** euclidean  \n",
    "- **Neighbors:** 27  \n",
    "- **Weights:** distance  \n",
    "\n",
    "### Cross-Validation\n",
    "- **Best CV F1 Score:** 0.699  \n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.689  \n",
    "- **Precision:** 0.709  \n",
    "- **Recall:** 0.636  \n",
    "- **F1 Score:** 0.671  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4189         | 1466         |\n",
    "| **Actual: 1** | 2036         | 3565         |\n",
    "\n",
    "- **False negatives:** **2036** (positives missed)  \n",
    "- **False positives:** **1466** (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned KNN achieves **68.9% accuracy** with a solid **precision (0.709)**, but its **recall (0.636)** is lower, meaning it misses a fair number of positives.  \n",
    "This model is more conservative in labeling positives, resulting in fewer false alarms but at the cost of overlooking some actual positive cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 16 | Explained variance retained: 0.953\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.6815031982942431\n",
      "Precision: 0.6855670103092784\n",
      "Recall   : 0.6648812712015711\n",
      "F1 Score : 0.675065711955044\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69      5655\n",
      "           1       0.69      0.66      0.68      5601\n",
      "\n",
      "    accuracy                           0.68     11256\n",
      "   macro avg       0.68      0.68      0.68     11256\n",
      "weighted avg       0.68      0.68      0.68     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3947 1708]\n",
      " [1877 3724]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2272e",
   "metadata": {},
   "source": [
    "# KNN Model Comparison\n",
    "\n",
    "## 1. Baseline KNN\n",
    "- **Accuracy:** 0.657  \n",
    "- **Precision:** 0.651  \n",
    "- **Recall:** 0.669  \n",
    "- **F1 Score:** 0.660  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3644         | 2011         |\n",
    "| **Actual: 1** | 1854         | 3747         |\n",
    "\n",
    "- **False negatives:** 1854  \n",
    "- **False positives:** 2011  \n",
    "\n",
    "**Interpretation:**  \n",
    "Balanced recall and precision, but overall performance is modest. The model misses some positives and misclassifies many negatives.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Tuned KNN (Best Params)\n",
    "- **Best Params:** {metric: euclidean, n_neighbors: 27, weights: distance}  \n",
    "- **Best CV F1:** 0.699  \n",
    "- **Accuracy:** 0.689  \n",
    "- **Precision:** 0.709  \n",
    "- **Recall:** 0.636  \n",
    "- **F1 Score:** 0.671  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4189         | 1466         |\n",
    "| **Actual: 1** | 2036         | 3565         |\n",
    "\n",
    "- **False negatives:** 2036  \n",
    "- **False positives:** 1466  \n",
    "\n",
    "**Interpretation:**  \n",
    "Improved precision but lower recall compared to baseline. More conservative in predicting positives, resulting in fewer false alarms but more missed positives.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. PCA + KNN (16 components, 95.3% variance retained)\n",
    "- **Accuracy:** 0.682  \n",
    "- **Precision:** 0.686  \n",
    "- **Recall:** 0.665  \n",
    "- **F1 Score:** 0.675  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3947         | 1708         |\n",
    "| **Actual: 1** | 1877         | 3724         |\n",
    "\n",
    "- **False negatives:** 1877  \n",
    "- **False positives:** 1708  \n",
    "\n",
    "**Interpretation:**  \n",
    "Performance slightly better than baseline, with more balanced precision and recall. Dimensionality reduction via PCA improves efficiency and stability, while maintaining a good trade-off.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "| Model            | Accuracy | Precision | Recall | F1 Score |\n",
    "|------------------|----------|-----------|--------|----------|\n",
    "| Baseline KNN     | 0.657    | 0.651     | 0.669  | 0.660    |\n",
    "| Tuned KNN        | 0.689    | 0.709     | 0.636  | 0.671    |\n",
    "| PCA + KNN        | 0.682    | 0.686     | 0.665  | 0.675    |\n",
    "\n",
    "- **Baseline KNN:** Balanced but weaker overall.  \n",
    "- **Tuned KNN:** Best precision, higher accuracy, but lower recall (misses positives).  \n",
    "- **PCA + KNN:** Balanced performance, recall higher than tuned KNN, slightly better than baseline, with efficiency gains from reduced dimensions.  \n",
    "\n",
    "---\n",
    "\n",
    "# Final Conclusion\n",
    "The **PCA + KNN** model offers the best **overall trade-off**:  \n",
    "- It retains most variance (95.3%) while reducing dimensionality, making the model more efficient.  \n",
    "- It achieves **balanced precision and recall** (both ~0.67), unlike the tuned KNN which sacrifices recall.  \n",
    "- Although tuned KNN has the highest precision, the drop in recall means it misses too many positives.  \n",
    "\n",
    "**Therefore, PCA + KNN is the preferred version for deployment if balanced detection is the priority.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bf66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned KNN model → knn_best_model.pkl\n",
      "Saved predictions → CVDKaggleData_75M25F_PCAKNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series (not a DataFrame)\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"knn_best_model.pkl\"\n",
    "joblib.dump(pca_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": probs_pca_knn,\n",
    "    \"y_pred\": y_pred_pca_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75M25F_PCAKNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV F1: 0.6584\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7001599147121536\n",
      "Precision: 0.7148648648648649\n",
      "Recall   : 0.6611319407248706\n",
      "F1 Score : 0.6869492625915963\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      5655\n",
      "           1       0.71      0.66      0.69      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4178 1477]\n",
      " [1898 3703]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9019f43",
   "metadata": {},
   "source": [
    "## Decision Tree (Best Params)\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.700  \n",
    "- **Precision:** 0.715  \n",
    "- **Recall:** 0.661  \n",
    "- **F1 Score:** 0.687  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4178         | 1477         |\n",
    "| **Actual: 1** | 1898         | 3703         |\n",
    "\n",
    "- **False negatives:** **1898** (positives missed)  \n",
    "- **False positives:** **1477** (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned Decision Tree reaches **70% accuracy** with a balanced trade-off between **precision (0.715)** and **recall (0.661)**. It is reliable when predicting positives but still misses a notable portion of actual positive cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'entropy', 'max_depth': 6, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.7039333333333333\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.7039\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.7082444918265813\n",
      "Precision: 0.7008843419455523\n",
      "Recall   : 0.7216568469916086\n",
      "F1 Score : 0.711118930330753\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71      5655\n",
      "           1       0.70      0.72      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3930 1725]\n",
      " [1559 4042]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# Stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dde61",
   "metadata": {},
   "source": [
    "## Decision Tree (Tuned & Pruned)\n",
    "\n",
    "### Best Parameters\n",
    "- **Criterion:** entropy  \n",
    "- **Max depth:** 6  \n",
    "- **Min impurity decrease:** 0.001  \n",
    "- **Min samples per leaf:** 2  \n",
    "- **Min samples per split:** 5  \n",
    "- **ccp_alpha (post-pruning):** 0.0  \n",
    "\n",
    "### Cross-Validation\n",
    "- **Best CV Recall (Stage A):** 0.704  \n",
    "- **Best CV Recall (Stage B, with pruning):** 0.704  \n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.708  \n",
    "- **Precision:** 0.701  \n",
    "- **Recall:** **0.722**  \n",
    "- **F1 Score:** 0.711  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3930         | 1725         |\n",
    "| **Actual: 1** | 1559         | 4042         |\n",
    "\n",
    "- **False negatives:** **1559** (positives missed)  \n",
    "- **False positives:** **1725** (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "This tuned and pruned Decision Tree achieves **71% accuracy** with a strong balance between **precision (0.701)** and **recall (0.722)**.  \n",
    "It demonstrates **higher recall**, meaning it catches more positives, though at the cost of slightly more false positives. The pruning (ccp_alpha=0.0) suggests that additional complexity penalty did not improve generalization, so the controlled depth and impurity constraints already provided effective regularization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a300b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 3}, 'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 1.0\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 1.0000\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.4976012793176972\n",
      "Precision: 0.4976012793176972\n",
      "Recall   : 1.0\n",
      "F1 Score : 0.6645310553479267\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5655\n",
      "           1       0.50      1.00      0.66      5601\n",
      "\n",
      "    accuracy                           0.50     11256\n",
      "   macro avg       0.25      0.50      0.33     11256\n",
      "weighted avg       0.25      0.50      0.33     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   0 5655]\n",
      " [   0 5601]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronge push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe9668a",
   "metadata": {},
   "source": [
    "# Decision Tree Model Comparison\n",
    "\n",
    "## 1. Baseline Decision Tree\n",
    "- **Accuracy:** 0.685  \n",
    "- **Precision:** 0.705  \n",
    "- **Recall:** 0.632  \n",
    "- **F1 Score:** 0.666  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4170         | 1485         |\n",
    "| **Actual: 1** | 2060         | 3541         |\n",
    "\n",
    "- **False negatives:** 2060  \n",
    "- **False positives:** 1485  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline Decision Tree shows decent precision but weaker recall. It correctly classifies most negatives but misses a substantial number of positives.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Tuned Decision Tree\n",
    "- **Best Params:** {criterion: gini, max_depth: None, min_samples_leaf: 10, min_samples_split: 2}  \n",
    "- **Best CV F1:** 0.658  \n",
    "- **Accuracy:** 0.700  \n",
    "- **Precision:** 0.715  \n",
    "- **Recall:** 0.661  \n",
    "- **F1 Score:** 0.687  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4178         | 1477         |\n",
    "| **Actual: 1** | 1898         | 3703         |\n",
    "\n",
    "- **False negatives:** 1898  \n",
    "- **False positives:** 1477  \n",
    "\n",
    "**Interpretation:**  \n",
    "This tuned version improves both accuracy and F1 score compared to baseline. It balances precision and recall better, while the constraint on minimum samples per leaf reduces overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Alternative Tuned & Pruned Decision Tree\n",
    "- **Best Params:** {criterion: entropy, max_depth: 6, min_impurity_decrease: 0.001, min_samples_leaf: 2, min_samples_split: 5, ccp_alpha: 0.0}  \n",
    "- **Best CV Recall:** 0.704  \n",
    "- **Accuracy:** 0.708  \n",
    "- **Precision:** 0.701  \n",
    "- **Recall:** 0.722  \n",
    "- **F1 Score:** 0.711  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3930         | 1725         |\n",
    "| **Actual: 1** | 1559         | 4042         |\n",
    "\n",
    "- **False negatives:** 1559  \n",
    "- **False positives:** 1725  \n",
    "\n",
    "**Interpretation:**  \n",
    "This pruned tree achieves the **highest recall (0.722)** and the best overall F1 score. It catches more positives at the cost of slightly more false positives, making it suitable when recall is a priority.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Alternative Tuned & Pruned Decision Tree (Class-weighted)\n",
    "- **Best Params:** {class_weight: {0:1, 1:3}, criterion: gini, max_depth: 4, min_impurity_decrease: 0.0001, min_samples_leaf: 1, min_samples_split: 5, ccp_alpha: 0.0}  \n",
    "- **Best CV Recall:** 1.0  \n",
    "- **Accuracy:** 0.498  \n",
    "- **Precision:** 0.498  \n",
    "- **Recall:** 1.000  \n",
    "- **F1 Score:** 0.665  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 0            | 5655         |\n",
    "| **Actual: 1** | 0            | 5601         |\n",
    "\n",
    "- **False negatives:** 0  \n",
    "- **False positives:** 5655  \n",
    "\n",
    "**Interpretation:**  \n",
    "This extreme class-weighted model predicts **all cases as positive**, leading to perfect recall but unusable performance overall (accuracy below 50%, precision undefined for class 0). It is not practical for deployment.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1 Score |\n",
    "|--------------------------------------|----------|-----------|--------|----------|\n",
    "| Baseline Decision Tree               | 0.685    | 0.705     | 0.632  | 0.666    |\n",
    "| Tuned Decision Tree                  | 0.700    | 0.715     | 0.661  | 0.687    |\n",
    "| Alt. Tuned & Pruned Decision Tree    | 0.708    | 0.701     | 0.722  | 0.711    |\n",
    "| Alt. Class-weighted Decision Tree    | 0.498    | 0.498     | 1.000  | 0.665    |\n",
    "\n",
    "- **Baseline Decision Tree:** Decent precision but limited recall.  \n",
    "- **Tuned Decision Tree:** Improves accuracy and F1 by regularization, more balanced.  \n",
    "- **Alternative Tuned & Pruned DT:** Best overall performance, with **highest recall and F1**, offering the best trade-off.  \n",
    "- **Class-weighted DT:** Overly biased toward the positive class, not useful in practice.  \n",
    "\n",
    "---\n",
    "\n",
    "# Final Conclusion\n",
    "The **Alternative Tuned & Pruned Decision Tree** is the **best-performing model**.  \n",
    "It achieves the highest recall (0.722) and the strongest F1 score (0.711), while maintaining good accuracy (0.708). This makes it the most balanced and reliable option among the Decision Tree versions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf663b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned DT model → tuned_dt_model.pkl\n",
      "Saved predictions → CVDKaggleData_75M25F_DT_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"tuned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "# Use tuned predictions/probabilities from the best estimator\n",
    "y_pred = y_pred_dt\n",
    "y_prob = y_prob_dt\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_dt\": y_pred,\n",
    "    \"y_prob\": y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75M25F_DT_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.6909203980099502\n",
      "Precision: 0.7012518968133535\n",
      "Recall   : 0.6600607034458132\n",
      "F1 Score : 0.6800331095373862\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      5655\n",
      "           1       0.70      0.66      0.68      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.69      0.69     11256\n",
      "weighted avg       0.69      0.69      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4080 1575]\n",
      " [1904 3697]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cd5013",
   "metadata": {},
   "source": [
    "## Random Forest Evaluation\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.691  \n",
    "- **Precision:** 0.701  \n",
    "- **Recall:** 0.660  \n",
    "- **F1 Score:** 0.680  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4080         | 1575         |\n",
    "| **Actual: 1** | 1904         | 3697         |\n",
    "\n",
    "- **False negatives:** 1904 (positives missed)  \n",
    "- **False positives:** 1575 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The Random Forest achieves **69.1% accuracy** with a balanced trade-off between **precision (0.701)** and **recall (0.660)**.  \n",
    "It performs slightly better at identifying negatives (class 0 recall: 0.72) than positives (class 1 recall: 0.66).  \n",
    "The model is fairly balanced overall, with **moderate precision and recall**, making it a stable classifier but still missing a notable portion of positives.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 100\n",
      "max_resources_: 400\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 8\n",
      "n_resources: 100\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 300\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "=== Random Forest (best, halving over n_estimators) Evaluation ===\n",
      "Accuracy : 0.7018479033404407\n",
      "Precision: 0.7114334149557355\n",
      "Recall   : 0.6743438671665773\n",
      "F1 Score : 0.6923923006416132\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      5655\n",
      "           1       0.71      0.67      0.69      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4123 1532]\n",
      " [1824 3777]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # must be first\n",
    "from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1, bootstrap=True)\n",
    "\n",
    "# Do NOT include 'n_estimators' in param_grid; Halving will vary it as the resource.\n",
    "param_grid = {\n",
    "    \"max_depth\": [None, 12],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "search = HalvingGridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    resource=\"n_estimators\",   # use trees as the resource\n",
    "    min_resources=100,         # start small\n",
    "    max_resources=400,         # end at your intended max\n",
    "    factor=3,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "search.fit(Xtr, y_train)\n",
    "best_rf = search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(Xte)\n",
    "y_prob_rf = best_rf.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest (best, halving over n_estimators)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601d270",
   "metadata": {},
   "source": [
    "# Random Forest Model Comparison\n",
    "\n",
    "## 1. Standard Random Forest\n",
    "- **Accuracy:** 0.691  \n",
    "- **Precision:** 0.701  \n",
    "- **Recall:** 0.660  \n",
    "- **F1 Score:** 0.680  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4080         | 1575         |\n",
    "| **Actual: 1** | 1904         | 3697         |\n",
    "\n",
    "- **False negatives:** 1904  \n",
    "- **False positives:** 1575  \n",
    "\n",
    "**Interpretation:**  \n",
    "This baseline Random Forest achieves solid performance with a balanced trade-off. It identifies negatives slightly better than positives, but misses nearly 1900 positives.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Random Forest (Best, Halving over n_estimators)\n",
    "- **Accuracy:** 0.702  \n",
    "- **Precision:** 0.711  \n",
    "- **Recall:** 0.674  \n",
    "- **F1 Score:** 0.692  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4123         | 1532         |\n",
    "| **Actual: 1** | 1824         | 3777         |\n",
    "\n",
    "- **False negatives:** 1824  \n",
    "- **False positives:** 1532  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned Random Forest (via HalvingGridSearchCV) improves **accuracy, precision, recall, and F1** compared to the standard model. It catches more positives (fewer false negatives) while also reducing false positives. This makes it a more balanced and effective version.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1 Score |\n",
    "|--------------------------------------|----------|-----------|--------|----------|\n",
    "| Standard Random Forest               | 0.691    | 0.701     | 0.660  | 0.680    |\n",
    "| RF (Halving over n_estimators, best) | 0.702    | 0.711     | 0.674  | 0.692    |\n",
    "\n",
    "- **Standard RF:** Balanced but slightly weaker on recall and overall score.  \n",
    "- **Halving RF (best):** Stronger across all metrics, with better recall and fewer misclassifications.  \n",
    "\n",
    "**Final Conclusion:**  \n",
    "The **Random Forest tuned via Halving** is the moderate model, offering a consistent improvement in accuracy, precision, recall, and F1 over the standard Random Forest.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned RF model → tuned_rf_model.pkl\n",
      "Saved predictions → CVDKaggleData_75M25F_RF_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned Random Forest Results\n",
    "\n",
    "# Save tuned Random Forest model\n",
    "model_filename = \"tuned_rf_model.pkl\"\n",
    "joblib.dump(best_rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_rf  # from best_rf.predict(X_test_ready)\n",
    "y_prob = y_prob_rf\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_rf_tuned\": y_pred,\n",
    "    \"y_prob\" :y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75M25F_RF_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.6961620469083155\n",
      "Precision: 0.7021316033364227\n",
      "Recall   : 0.6763078021781824\n",
      "F1 Score : 0.6889778101127683\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70      5655\n",
      "           1       0.70      0.68      0.69      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4048 1607]\n",
      " [1813 3788]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ecb99",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Evaluation\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.696  \n",
    "- **Precision:** 0.702  \n",
    "- **Recall:** 0.676  \n",
    "- **F1 Score:** 0.689  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4048         | 1607         |\n",
    "| **Actual: 1** | 1813         | 3788         |\n",
    "\n",
    "- **False negatives:** 1813 (positives missed)  \n",
    "- **False positives:** 1607 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The MLP achieves **69.6% accuracy** with a balanced trade-off between **precision (0.702)** and **recall (0.676)**.  \n",
    "It correctly identifies both negatives and positives at similar rates (class 0 recall: 0.72, class 1 recall: 0.68).  \n",
    "The model slightly favors precision, making it reliable when predicting positives, but it still misses around 1800 true positives.  \n",
    "Overall, the MLP performs comparably to Random Forest and tuned Decision Trees, showing balanced but not standout performance.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b123b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.7133972992181947\n",
      "Precision: 0.7283214766391078\n",
      "Recall   : 0.6763078021781824\n",
      "F1 Score : 0.7013516015552675\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      5655\n",
      "           1       0.73      0.68      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4242 1413]\n",
      " [1813 3788]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39d7bf",
   "metadata": {},
   "source": [
    "## MLP (Adam + EarlyStopping) Evaluation\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.713  \n",
    "- **Precision:** 0.728  \n",
    "- **Recall:** 0.676  \n",
    "- **F1 Score:** 0.701  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4242         | 1413         |\n",
    "| **Actual: 1** | 1813         | 3788         |\n",
    "\n",
    "- **False negatives:** 1813 (positives missed)  \n",
    "- **False positives:** 1413 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The MLP with **Adam optimizer and EarlyStopping** delivers **71.3% accuracy**, the best so far among your neural models.  \n",
    "It achieves **high precision (0.728)**, making it reliable when predicting positives, though recall (0.676) indicates that some positives are still missed.  \n",
    "The model improves over the plain MLP by reducing false positives (1413 vs. 1607 earlier), while maintaining a similar level of false negatives.  \n",
    "Overall, this tuned MLP variant offers the **most balanced performance** among your neural approaches, with strong generalization due to EarlyStopping.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best MLP params: {'learning_rate_init': 0.0003, 'hidden_layer_sizes': (64, 32), 'batch_size': 32, 'alpha': 0.0003, 'activation': 'relu'}\n",
      "Best CV F-beta (β=2): 0.7020\n",
      "=== Best MLP (Adam + ES, fast) Evaluation ===\n",
      "Accuracy : 0.7144633972992182\n",
      "Precision: 0.7250612860644918\n",
      "Recall   : 0.6864845563292269\n",
      "F1 Score : 0.7052457813646368\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      5655\n",
      "           1       0.73      0.69      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.72      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4197 1458]\n",
      " [1756 3845]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTION A — Fastest win: early stopping + single-metric scoring + lighter CV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Keep arrays lean\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # <- stop per-config when val score plateaus\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    max_iter=200,                 # <- much lower; early_stopping will bail sooner\n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Trim the space; focus on what usually matters\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32)],\n",
    "    \"activation\": [\"relu\"],       # 'relu' typically dominates for tabular MLPs\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4],\n",
    "    \"batch_size\": [32, 64, 128],  # larger batch -> faster per-epoch\n",
    "}\n",
    "\n",
    "# Fewer folds = big speedup with little generalization loss\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Use a single scorer that matches your objective (recall-weighted)\n",
    "fbeta2 = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                    # fewer trials; early stop handles over-training\n",
    "    scoring=fbeta2,               # <- single metric speeds everything up\n",
    "    refit=True,                   # refit on full train with best params\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(Xtr, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_mlp.predict(Xte)\n",
    "y_prob = best_mlp.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred, model_name=\"Best MLP (Adam + ES, fast)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1f630",
   "metadata": {},
   "source": [
    "# MLP Model Comparison\n",
    "\n",
    "## 1. Baseline MLP\n",
    "- **Accuracy:** 0.696  \n",
    "- **Precision:** 0.702  \n",
    "- **Recall:** 0.676  \n",
    "- **F1 Score:** 0.689  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4048         | 1607         |\n",
    "| **Actual: 1** | 1813         | 3788         |\n",
    "\n",
    "- **False negatives:** 1813  \n",
    "- **False positives:** 1607  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline MLP shows balanced performance with recall (0.676) slightly higher than precision. It misses about **1,800 positives** and has a moderate number of false alarms.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. MLP (Adam + EarlyStopping)\n",
    "- **Accuracy:** 0.713  \n",
    "- **Precision:** 0.728  \n",
    "- **Recall:** 0.676  \n",
    "- **F1 Score:** 0.701  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4242         | 1413         |\n",
    "| **Actual: 1** | 1813         | 3788         |\n",
    "\n",
    "- **False negatives:** 1813  \n",
    "- **False positives:** 1413  \n",
    "\n",
    "**Interpretation:**  \n",
    "Adding **Adam optimizer with EarlyStopping** boosts **accuracy and precision**. False positives decrease compared to baseline (1413 vs 1607), while recall remains the same. This model is more reliable when predicting positives.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Best MLP (Adam + ES, tuned)\n",
    "- **Best Params:** {learning_rate_init: 0.0003, hidden_layer_sizes: (64, 32), batch_size: 32, alpha: 0.0003, activation: relu}  \n",
    "- **Best CV F-beta (β=2):** 0.702  \n",
    "- **Accuracy:** 0.714  \n",
    "- **Precision:** 0.725  \n",
    "- **Recall:** 0.686  \n",
    "- **F1 Score:** 0.705  \n",
    "- **Support:** 0→5655, 1→5601  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4197         | 1458         |\n",
    "| **Actual: 1** | 1756         | 3845         |\n",
    "\n",
    "- **False negatives:** 1756  \n",
    "- **False positives:** 1458  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned MLP further improves recall (0.686) while keeping strong precision (0.725). It reduces missed positives (1756 vs 1813 earlier) and maintains a balanced trade-off. This is the **best-performing MLP variant** among the three.\n",
    "\n",
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "| Model                      | Accuracy | Precision | Recall | F1 Score |\n",
    "|-----------------------------|----------|-----------|--------|----------|\n",
    "| Baseline MLP               | 0.696    | 0.702     | 0.676  | 0.689    |\n",
    "| MLP (Adam + EarlyStopping) | 0.713    | 0.728     | 0.676  | 0.701    |\n",
    "| Best MLP (Adam + ES, tuned)| 0.714    | 0.725     | 0.686  | 0.705    |\n",
    "\n",
    "- **Baseline MLP:** Solid starting point, balanced precision/recall but lower accuracy.  \n",
    "- **MLP (Adam + ES):** Improves accuracy and precision, reduces false positives, but recall unchanged.  \n",
    "- **Best MLP (Adam + ES, tuned):** Delivers the best balance with improved recall and F1 score, while keeping precision high.  \n",
    "\n",
    "---\n",
    "\n",
    "# Final Conclusion\n",
    "The **Best MLP (Adam + EarlyStopping, tuned)** is the strongest model.  \n",
    "It achieves the **highest recall and F1**, meaning it captures more positives while remaining precise, making it the most reliable choice for deployment.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Adam tuned MLP model → mlp_adamtuned.pkl\n",
      "Saved predictions → CVDKaggleData_75M25F_MLP_adamtuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save MLP model\n",
    "model_filename =  \"mlp_adamtuned.pkl\"\n",
    "joblib.dump(best_mlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = best_mlp.predict(Xte)\n",
    "y_prob = best_mlp.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\" : y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75M25F_MLP_adamtuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Adam tuned MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
