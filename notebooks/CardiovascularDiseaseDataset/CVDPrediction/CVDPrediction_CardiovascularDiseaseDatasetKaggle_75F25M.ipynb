{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Cardiovascular Disease Dataset (Source: https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>bmiclass</th>\n",
       "      <th>MAP</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36155</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34616</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29127</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4008</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33452</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  gender  age  bmiclass  MAP  cholesterol  gluc  smoke  alco  \\\n",
       "0      36155       0    6         2    4            1     1      0     1   \n",
       "1      34616       0    5         2    5            1     1      0     0   \n",
       "2      29127       0    2         3    2            1     1      0     0   \n",
       "3       4008       0    6         1    3            1     1      0     0   \n",
       "4      33452       0    6         2    3            3     3      0     0   \n",
       "\n",
       "   active  cardio  \n",
       "0       1       1  \n",
       "1       1       1  \n",
       "2       0       1  \n",
       "3       0       1  \n",
       "4       1       1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_25M_75F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3bf15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop source_id\n",
    "train_df = train_df.drop(columns=[\"source_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"cardio\"\n",
    "SENSITIVE = \"gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "\n",
    "# Identify feature types\n",
    "binary_cols = [\"gender\", \"smoke\", \"alco\", \"active\"]\n",
    "categorical_cols = [\"age\", \"bmiclass\", \"MAP\", \"cholesterol\", \"gluc\"]\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (30000, 28) (11256, 28)\n"
     ]
    }
   ],
   "source": [
    "#ONE-HOT ENCODE CATEGORICALS; KEEP SCALED NUMERICS AS-IS \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train[binary_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test[binary_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.666133617626155\n",
      "Precision: 0.6652914798206278\n",
      "Recall   : 0.6622031780039279\n",
      "F1 Score : 0.6637437365783823\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67      5655\n",
      "           1       0.67      0.66      0.66      5601\n",
      "\n",
      "    accuracy                           0.67     11256\n",
      "   macro avg       0.67      0.67      0.67     11256\n",
      "weighted avg       0.67      0.67      0.67     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3789 1866]\n",
      " [1892 3709]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.6918976545842217\n",
      "Precision: 0.7151502925156344\n",
      "Recall   : 0.6329226923763613\n",
      "F1 Score : 0.6715286986171624\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71      5655\n",
      "           1       0.72      0.63      0.67      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.69      0.69     11256\n",
      "weighted avg       0.69      0.69      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4243 1412]\n",
      " [2056 3545]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f17b6",
   "metadata": {},
   "source": [
    "# Model Interpretations: KNN and DT\n",
    "\n",
    "## 1. KNN\n",
    "- **Accuracy:** 0.666  \n",
    "- **Precision:** 0.665  \n",
    "- **Recall:** 0.662  \n",
    "- **F1 Score:** 0.664   \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3789         | 1866         |\n",
    "| **Actual: 1** | 1892         | 3709         |\n",
    "\n",
    "- **False negatives:** 1892 (positives missed)  \n",
    "- **False positives:** 1866 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The KNN model shows **balanced precision and recall (~0.66)**, leading to moderate overall performance.  \n",
    "It misses nearly **1900 positives** and misclassifies a similar number of negatives.  \n",
    "The model captures general patterns but struggles with sharper class boundaries.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Decision Tree\n",
    "- **Accuracy:** 0.692  \n",
    "- **Precision:** 0.715  \n",
    "- **Recall:** 0.633  \n",
    "- **F1 Score:** 0.672  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4243         | 1412         |\n",
    "| **Actual: 1** | 2056         | 3545         |\n",
    "\n",
    "- **False negatives:** 2056 (positives missed)  \n",
    "- **False positives:** 1412 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The Decision Tree achieves **higher precision (0.715)** and **accuracy (0.692)** compared to KNN, but with slightly lower recall (0.633).  \n",
    "It identifies negatives more effectively (class 0 recall: 0.75), but misses more positives (2056).  \n",
    "This makes it a **conservative model**: fewer false alarms, but at the cost of overlooking some positive cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'euclidean', 'n_neighbors': 29, 'weights': 'uniform'}\n",
      "Best CV F1: 0.6942235070474742\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.7063788201847904\n",
      "Precision: 0.7087272727272728\n",
      "Recall   : 0.6959471522942332\n",
      "F1 Score : 0.7022790739573012\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      5655\n",
      "           1       0.71      0.70      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4053 1602]\n",
      " [1703 3898]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf213cf",
   "metadata": {},
   "source": [
    "# Tuned KNN - Interpretation:\n",
    "\n",
    "## 1. KNN\n",
    "- **Accuracy:** 0.706  \n",
    "- **Precision:** 0.709  \n",
    "- **Recall:** 0.696  \n",
    "- **F1 Score:** 0.702  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4053         | 1602         |\n",
    "| **Actual: 1** | 1703         | 3898         |\n",
    "\n",
    "- **False negatives:** 1703 (positives missed)  \n",
    "- **False positives:** 1602 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The KNN model demonstrates **balanced performance**, with precision and recall both around **0.70**.  \n",
    "It misses ~1700 positive cases and incorrectly flags ~1600 negatives, showing that errors are fairly evenly distributed.  \n",
    "Overall, the model generalizes well and captures class patterns symmetrically, but in a healthcare context, missing ~30% of positive (disease) cases could be critical.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 16 | Explained variance retained: 0.952\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.6926972281449894\n",
      "Precision: 0.7134316460741331\n",
      "Recall   : 0.6391715765041956\n",
      "F1 Score : 0.6742631132875035\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71      5655\n",
      "           1       0.71      0.64      0.67      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.69      0.69     11256\n",
      "weighted avg       0.69      0.69      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4217 1438]\n",
      " [2021 3580]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e99b9",
   "metadata": {},
   "source": [
    "# Model Interpretations\n",
    "\n",
    "## 1. Baseline KNN\n",
    "- **Accuracy:** 0.666  \n",
    "- **Precision:** 0.665  \n",
    "- **Recall:** 0.662  \n",
    "- **F1 Score:** 0.664  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 3789         | 1866         |\n",
    "| **Actual: 1** | 1892         | 3709         |\n",
    "\n",
    "- **False negatives:** 1892 (positives missed)  \n",
    "- **False positives:** 1866 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline KNN model achieves **balanced but modest performance (~0.66 across all metrics)**.  \n",
    "It misses ~1900 positive cases and misclassifies a similar number of negatives.  \n",
    "The model captures general patterns but lacks refinement, making it a weak starting point.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Optimized KNN (Best Params)\n",
    "- **Accuracy:** 0.706  \n",
    "- **Precision:** 0.709  \n",
    "- **Recall:** 0.696  \n",
    "- **F1 Score:** 0.702  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4053         | 1602         |\n",
    "| **Actual: 1** | 1703         | 3898         |\n",
    "\n",
    "- **False negatives:** 1703 (positives missed)  \n",
    "- **False positives:** 1602 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned KNN model shows **clear improvement** over baseline, with F1 rising from **0.66 → 0.70**.  \n",
    "Errors are more balanced, and the confusion matrix shows fewer missed positives and fewer false alarms.  \n",
    "This indicates that **hyperparameter tuning (n_neighbors=29, Euclidean distance)** significantly boosts model stability and predictive power.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. PCA + KNN (16 components, 95.2% variance)\n",
    "- **Accuracy:** 0.693  \n",
    "- **Precision:** 0.713  \n",
    "- **Recall:** 0.639  \n",
    "- **F1 Score:** 0.674  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4217         | 1438         |\n",
    "| **Actual: 1** | 2021         | 3580         |\n",
    "\n",
    "- **False negatives:** 2021 (positives missed)  \n",
    "- **False positives:** 1438 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "Applying PCA before KNN reduces dimensionality but leads to **imbalanced performance**:  \n",
    "- Precision improves slightly (0.713), meaning fewer false positives.  \n",
    "- Recall drops (0.639), meaning **more positives are missed** (~2000 cases).  \n",
    "\n",
    "This trade-off suggests PCA introduces information loss: while predictions for “no disease” become cleaner, the model sacrifices sensitivity to true positives — which is risky in medical contexts.  \n",
    "\n",
    "---\n",
    "\n",
    "# Summary:\n",
    "- **Baseline KNN:** Balanced but weak (~0.66 F1).  \n",
    "- **Optimized KNN:** Best overall performance (~0.70 F1, balanced precision/recall).  \n",
    "- **PCA + KNN:** Precision gains but recall loss → not ideal for medical use (misses too many cases).  \n",
    "\n",
    "**Best choice:** Optimized KNN with tuned parameters.  \n",
    "PCA + KNN is **not recommended** here due to reduced recall, which increases the number of missed positive (disease) patients.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3bf66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned KNN model → knn_tuned_model.pkl\n",
      "Saved predictions → CVDKaggleData_75F25M__tunedKNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series (not a DataFrame)\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"knn_tuned_model.pkl\"\n",
    "joblib.dump(best_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred_knn = y_pred_knn_best\n",
    "y_prob_knn = y_prob_knn_best\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_knn,\n",
    "    \"y_pred\": y_pred_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75F25M__tunedKNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'gini', 'max_depth': 7, 'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "Best CV F1: 0.6651999999999999\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7112651030561479\n",
      "Precision: 0.709573899090747\n",
      "Recall   : 0.7105873951080164\n",
      "F1 Score : 0.7100802854594113\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      5655\n",
      "           1       0.71      0.71      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4026 1629]\n",
      " [1621 3980]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7df7a7",
   "metadata": {},
   "source": [
    "# Tuned Decision Tree Interpretation\n",
    "\n",
    "## Tuned Decision Tree\n",
    "- **Accuracy:** 0.711  \n",
    "- **Precision:** 0.710  \n",
    "- **Recall:** 0.711  \n",
    "- **F1 Score:** 0.710  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4026         | 1629         |\n",
    "| **Actual: 1** | 1621         | 3980         |\n",
    "\n",
    "- **False negatives:** 1621 (positives missed)  \n",
    "- **False positives:** 1629 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned Decision Tree achieves **balanced and stable performance (~0.71 across all metrics)**, slightly outperforming the optimized KNN model.  \n",
    "- Errors are nearly symmetric, with false negatives and false positives at similar levels.  \n",
    "- Both classes (disease vs. no disease) are treated almost equally, showing no bias toward either group.  \n",
    "- The chosen hyperparameters (`max_depth=7`, `min_samples_leaf=10`) prevent overfitting, yielding consistent results across classes.  \n",
    "\n",
    "Compared to KNN, the Decision Tree offers **slightly higher recall** and **fewer missed positives**, making it more reliable in healthcare scenarios.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.6784666666666668\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.6785\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.7133084577114428\n",
      "Precision: 0.7194085027726432\n",
      "Recall   : 0.6948759150151759\n",
      "F1 Score : 0.7069294342021615\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      5655\n",
      "           1       0.72      0.69      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4137 1518]\n",
      " [1709 3892]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# Stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b99915",
   "metadata": {},
   "source": [
    "# Alternative Decision Tree Interpretation\n",
    "\n",
    "## Tuned & Pruned Decision Tree\n",
    "- **Accuracy:** 0.713  \n",
    "- **Precision:** 0.719  \n",
    "- **Recall:** 0.695  \n",
    "- **F1 Score:** 0.707  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4137         | 1518         |\n",
    "| **Actual: 1** | 1709         | 3892         |\n",
    "\n",
    "- **False negatives:** 1709 (positives missed)  \n",
    "- **False positives:** 1518 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The pruned Decision Tree achieves **solid overall performance (~0.71 across metrics)**, very close to the tuned DT but with subtle differences:  \n",
    "- **Higher precision (0.719)** → fewer false positives compared to the previous tuned DT.  \n",
    "- **Slightly lower recall (0.695)** → more missed positives (~1709 vs. 1621 previously).  \n",
    "- Errors remain fairly balanced, but the model is more conservative in labeling positives.  \n",
    "\n",
    " **Strengths:** Stable accuracy and precision gains. Tree pruning likely improved generalization by reducing overfitting.  \n",
    "**Limitations:** Recall dropped a bit, which means more sick patients are missed compared to the non-pruned DT.  \n",
    "\n",
    "**Conclusio:** This pruned tree is **more precise but slightly less sensitive**. In medical contexts, this trade-off may not be ideal since missing cases (FN) is more costly than flagging extra false positives.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7896dd",
   "metadata": {},
   "source": [
    "# Decision Tree Model Comparisons\n",
    "\n",
    "## 1. Baseline Decision Tree\n",
    "- **Accuracy:** 0.692  \n",
    "- **Precision:** 0.715  \n",
    "- **Recall:** 0.633  \n",
    "- **F1 Score:** 0.672  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4243         | 1412         |\n",
    "| **Actual: 1** | 2056         | 3545         |\n",
    "\n",
    "- **False negatives:** 2056 (positives missed)  \n",
    "- **False positives:** 1412 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline tree shows **high precision but low recall**, meaning it is conservative in predicting positives.  \n",
    "It misses over **2000 true cases**, which is problematic in healthcare contexts.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Tuned Decision Tree\n",
    "- **Accuracy:** 0.711  \n",
    "- **Precision:** 0.710  \n",
    "- **Recall:** 0.711  \n",
    "- **F1 Score:** 0.710  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4026         | 1629         |\n",
    "| **Actual: 1** | 1621         | 3980         |\n",
    "\n",
    "- **False negatives:** 1621  \n",
    "- **False positives:** 1629  \n",
    "\n",
    "**Interpretation:**  \n",
    "Tuning improves **balance across precision and recall**, raising recall substantially compared to baseline.  \n",
    "The model now misses fewer positives while keeping errors evenly distributed.  \n",
    "This is a **clear improvement** over the baseline.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Alternative Tuned & Pruned Decision Tree\n",
    "- **Accuracy:** 0.713  \n",
    "- **Precision:** 0.719  \n",
    "- **Recall:** 0.695  \n",
    "- **F1 Score:** 0.707  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4137         | 1518         |\n",
    "| **Actual: 1** | 1709         | 3892         |\n",
    "\n",
    "- **False negatives:** 1709  \n",
    "- **False positives:** 1518  \n",
    "\n",
    "**Interpretation:**  \n",
    "The pruned tree yields **slightly better accuracy and precision** but a **small drop in recall** compared to the tuned version.  \n",
    "It is more conservative, catching fewer positives but reducing false alarms.  \n",
    "This model is more **stable and generalizable** but less sensitive.  \n",
    "\n",
    "---\n",
    "\n",
    "# Overall Comparison\n",
    "\n",
    "| Model                          | Accuracy | Precision | Recall | F1 Score | Key Behavior |\n",
    "|--------------------------------|----------|-----------|--------|----------|--------------|\n",
    "| **Baseline DT**                | 0.692    | 0.715     | 0.633  | 0.672    | High precision, misses many positives |\n",
    "| **Tuned DT**                   | 0.711    | 0.710     | 0.711  | 0.710    | Balanced, fewer missed positives |\n",
    "| **Alternative Pruned DT**      | 0.713    | 0.719     | 0.695  | 0.707    | More precise, slightly less sensitive |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary:\n",
    "- **Best overall:** Tuned DT → best balance between accuracy, recall, and precision.  \n",
    "- **Most conservative:** Pruned DT → slightly safer predictions, but misses more positives.   \n",
    "- **Worst option:** Baseline DT → too many positives missed.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf663b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned DT model → tuned_dt_model.pkl\n",
      "Saved predictions → CVDKaggleData_75F25M_DT_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"tuned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "# Use tuned predictions/probabilities from the best estimator\n",
    "y_pred = y_pred_dt_best\n",
    "y_prob = y_prob_dt_best\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_dt\": y_pred,\n",
    "    \"y_prob\": y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75F25M_DT_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.6974946695095949\n",
      "Precision: 0.7109104878985786\n",
      "Recall   : 0.6607748616318515\n",
      "F1 Score : 0.6849264365688905\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71      5655\n",
      "           1       0.71      0.66      0.68      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4150 1505]\n",
      " [1900 3701]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff08b2",
   "metadata": {},
   "source": [
    "# Random Forest Interpretation\n",
    "\n",
    "## Random Forest\n",
    "- **Accuracy:** 0.697  \n",
    "- **Precision:** 0.711  \n",
    "- **Recall:** 0.661  \n",
    "- **F1 Score:** 0.685  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4150         | 1505         |\n",
    "| **Actual: 1** | 1900         | 3701         |\n",
    "\n",
    "- **False negatives:** 1900 (positives missed)  \n",
    "- **False positives:** 1505 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The Random Forest model achieves **~70% overall accuracy** with good precision (~0.71), meaning that most predicted positives are correct.  \n",
    "However, recall (~0.66) is lower, showing that the model **misses about one-third of actual positive cases** (~1900 false negatives).  \n",
    "The confusion matrix highlights this imbalance: while predictions for healthy cases (class 0) are fairly strong, the model struggles more with consistently identifying diseased patients (class 1).  \n",
    "\n",
    "**Strengths:** Reliable precision and balanced performance between classes.  \n",
    "**Limitations:** Lower recall reduces sensitivity, which is critical in medical contexts since many positive cases remain undetected.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 100\n",
      "max_resources_: 400\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 8\n",
      "n_resources: 100\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 300\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "=== Random Forest (best, halving over n_estimators) Evaluation ===\n",
      "Accuracy : 0.7075337597725657\n",
      "Precision: 0.7214655668521005\n",
      "Recall   : 0.6714872344224245\n",
      "F1 Score : 0.6955798039578325\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      5655\n",
      "           1       0.72      0.67      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4203 1452]\n",
      " [1840 3761]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # must be first\n",
    "from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1, bootstrap=True)\n",
    "\n",
    "# Do NOT include 'n_estimators' in param_grid; Halving will vary it as the resource.\n",
    "param_grid = {\n",
    "    \"max_depth\": [None, 12],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "search = HalvingGridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    resource=\"n_estimators\",   # use trees as the resource\n",
    "    min_resources=100,         # start small\n",
    "    max_resources=400,         # end at your intended max\n",
    "    factor=3,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "search.fit(Xtr, y_train)\n",
    "best_rf = search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(Xte)\n",
    "y_prob_rf = best_rf.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest (best, halving over n_estimators)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24015820",
   "metadata": {},
   "source": [
    "# Random Forest Comparisons\n",
    "\n",
    "## 1. Baseline Random Forest\n",
    "- **Accuracy:** 0.697  \n",
    "- **Precision:** 0.711  \n",
    "- **Recall:** 0.661  \n",
    "- **F1 Score:** 0.685  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4150         | 1505         |\n",
    "| **Actual: 1** | 1900         | 3701         |\n",
    "\n",
    "- **False negatives:** 1900 (positives missed)  \n",
    "- **False positives:** 1505 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline Random Forest shows **good precision (~0.71)** but **weaker recall (~0.66)**, meaning it misses ~1/3 of true positive cases.  \n",
    "It balances class performance reasonably but under-detects diseased patients.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Optimized Random Forest (Halving Search)\n",
    "- **Accuracy:** 0.708  \n",
    "- **Precision:** 0.721  \n",
    "- **Recall:** 0.671  \n",
    "- **F1 Score:** 0.696  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4203         | 1452         |\n",
    "| **Actual: 1** | 1840         | 3761         |\n",
    "\n",
    "- **False negatives:** 1840 (positives missed)  \n",
    "- **False positives:** 1452 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned Random Forest achieves **better balance** with gains in accuracy, precision, recall, and F1 compared to baseline.  \n",
    "It catches more true positives (lower FN) while also reducing false positives.  \n",
    "Overall, the hyperparameter optimization leads to a **more reliable and generalizable model**.  \n",
    "\n",
    "---\n",
    "\n",
    "# Overall Comparison:\n",
    "\n",
    "| Model                      | Accuracy | Precision | Recall | F1 Score | FN (missed) | FP (flagged) |\n",
    "|-----------------------------|----------|-----------|--------|----------|-------------|--------------|\n",
    "| **Baseline RF**            | 0.697    | 0.711     | 0.661  | 0.685    | 1900        | 1505         |\n",
    "| **Optimized RF (Halving)** | 0.708    | 0.721     | 0.671  | 0.696    | 1840        | 1452         |\n",
    "\n",
    "**Summary:**  \n",
    "- The **optimized RF** improves across all metrics: +1% accuracy, +1% precision, +1% recall, and +1% F1.  \n",
    "- It reduces both **false negatives** and **false positives**, making it better at detecting diseased patients while keeping false alarms in check.  \n",
    "- **Best choice:** Optimized Random Forest.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned RF model → tuned_rf_model.pkl\n",
      "Saved predictions → CVDKaggleData_75F25M_RF_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned Random Forest Results\n",
    "\n",
    "# Save tuned Random Forest model\n",
    "model_filename = \"tuned_rf_model.pkl\"\n",
    "joblib.dump(best_rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_rf  # from best_rf.predict(X_test_ready)\n",
    "y_prob = y_prob_rf\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_rf\": y_pred,\n",
    "    \"y_prob\" :y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75F25M_RF_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.7058457711442786\n",
      "Precision: 0.7175151975683891\n",
      "Recall   : 0.6743438671665773\n",
      "F1 Score : 0.6952600092038657\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      5655\n",
      "           1       0.72      0.67      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4168 1487]\n",
      " [1824 3777]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ab254",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) Interpretation\n",
    "\n",
    "## MLP\n",
    "- **Accuracy:** 0.706  \n",
    "- **Precision:** 0.718  \n",
    "- **Recall:** 0.674  \n",
    "- **F1 Score:** 0.695  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4168         | 1487         |\n",
    "| **Actual: 1** | 1824         | 3777         |\n",
    "\n",
    "- **False negatives:** 1824 (positives missed)  \n",
    "- **False positives:** 1487 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The MLP achieves **~71% accuracy**, with **solid precision (~0.72)** and **moderate recall (~0.67)**.  \n",
    "This means the model is reliable at correctly predicting positives but still misses around **1 in 3 true cases** (~1824 false negatives).  \n",
    "\n",
    "The confusion matrix shows balanced performance:  \n",
    "- Slightly stronger at identifying healthy individuals (class 0).  \n",
    "- Still reasonably effective at detecting diseased patients (class 1), though sensitivity could be improved.  \n",
    "\n",
    "**Strengths:** Good precision and balanced metrics across both classes.  \n",
    "**Limitations:** Recall is lower, meaning a significant number of true positive cases are missed. In a healthcare setting, this could be critical.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b123b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.7107320540156361\n",
      "Precision: 0.713998904909655\n",
      "Recall   : 0.698446705945367\n",
      "F1 Score : 0.7061371841155235\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72      5655\n",
      "           1       0.71      0.70      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4088 1567]\n",
      " [1689 3912]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03620ba3",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (Adam + EarlyStopping) Interpretation\n",
    "\n",
    "## MLP (Adam + EarlyStopping)\n",
    "- **Accuracy:** 0.711  \n",
    "- **Precision:** 0.714  \n",
    "- **Recall:** 0.698  \n",
    "- **F1 Score:** 0.706  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4088         | 1567         |\n",
    "| **Actual: 1** | 1689         | 3912         |\n",
    "\n",
    "- **False negatives:** 1689 (positives missed)  \n",
    "- **False positives:** 1567 (negatives flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "This MLP variant achieves **~71% accuracy**, with **well-balanced precision (0.714) and recall (0.698)**.  \n",
    "Compared to a plain MLP, it benefits from **slightly higher recall**, meaning it identifies more true positives while keeping false positives at a manageable level.  \n",
    "\n",
    "The confusion matrix shows balanced error distribution:  \n",
    "- False negatives (missed positives) and false positives are nearly equal.  \n",
    "- Both classes (healthy and diseased) are treated fairly evenly, with no strong bias.  \n",
    "\n",
    "**Strengths:** Stable training via EarlyStopping, balanced metrics across precision and recall, fewer missed positives than the plain MLP.  \n",
    "**Limitations:** While improved, recall still indicates that ~1 in 3 diseased patients are not detected, which may be critical in medical settings.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best MLP params: {'learning_rate_init': 0.0005, 'hidden_layer_sizes': (128,), 'batch_size': 128, 'alpha': 0.0003, 'activation': 'relu'}\n",
      "Best CV F-beta (β=2): 0.6823\n",
      "=== Best MLP (Adam + ES, fast) Evaluation ===\n",
      "Accuracy : 0.7158848614072495\n",
      "Precision: 0.7413135167704358\n",
      "Recall   : 0.6589894661667559\n",
      "F1 Score : 0.6977315689981096\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      5655\n",
      "           1       0.74      0.66      0.70      5601\n",
      "\n",
      "    accuracy                           0.72     11256\n",
      "   macro avg       0.72      0.72      0.71     11256\n",
      "weighted avg       0.72      0.72      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4367 1288]\n",
      " [1910 3691]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTION A — Fastest win: early stopping + single-metric scoring + lighter CV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Keep arrays lean\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # <- stop per-config when val score plateaus\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    max_iter=200,                 # <- much lower; early_stopping will bail sooner\n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Trim the space; focus on what usually matters\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32)],\n",
    "    \"activation\": [\"relu\"],       # 'relu' typically dominates for tabular MLPs\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4],\n",
    "    \"batch_size\": [32, 64, 128],  # larger batch -> faster per-epoch\n",
    "}\n",
    "\n",
    "# Fewer folds = big speedup with little generalization loss\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Use a single scorer that matches your objective (recall-weighted)\n",
    "fbeta2 = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                    # fewer trials; early stop handles over-training\n",
    "    scoring=fbeta2,               # <- single metric speeds everything up\n",
    "    refit=True,                   # refit on full train with best params\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(Xtr, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_mlp.predict(Xte)\n",
    "y_prob = best_mlp.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred, model_name=\"Best MLP (Adam + ES, fast)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e603903",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) Comparisons\n",
    "\n",
    "## 1. Baseline MLP\n",
    "- **Accuracy:** 0.706  \n",
    "- **Precision:** 0.718  \n",
    "- **Recall:** 0.674  \n",
    "- **F1 Score:** 0.695  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4168         | 1487         |\n",
    "| **Actual: 1** | 1824         | 3777         |\n",
    "\n",
    "- **False negatives:** 1824  \n",
    "- **False positives:** 1487  \n",
    "\n",
    "**Interpretation:**  \n",
    "The baseline MLP achieves balanced performance with **strong precision (~0.72)** but **lower recall (~0.67)**, missing ~1/3 of positive cases.  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. MLP (Adam + EarlyStopping)\n",
    "- **Accuracy:** 0.711  \n",
    "- **Precision:** 0.714  \n",
    "- **Recall:** 0.698  \n",
    "- **F1 Score:** 0.706  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4088         | 1567         |\n",
    "| **Actual: 1** | 1689         | 3912         |\n",
    "\n",
    "- **False negatives:** 1689  \n",
    "- **False positives:** 1567  \n",
    "\n",
    "**Interpretation:**  \n",
    "This variant benefits from **slightly higher recall (~0.70)**, reducing missed positives compared to baseline.  \n",
    "Errors are more balanced between classes, with stable precision and recall.  \n",
    "EarlyStopping likely improved generalization and reduced overfitting.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Best MLP (Adam + ES, tuned params)\n",
    "- **Accuracy:** 0.716  \n",
    "- **Precision:** 0.741  \n",
    "- **Recall:** 0.659  \n",
    "- **F1 Score:** 0.698  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 4367         | 1288         |\n",
    "| **Actual: 1** | 1910         | 3691         |\n",
    "\n",
    "- **False negatives:** 1910  \n",
    "- **False positives:** 1288  \n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned MLP achieves the **highest accuracy (71.6%) and precision (~0.74)**, meaning fewer false alarms.  \n",
    "However, recall drops back down to ~0.66, so it misses more positives (~1910 cases) compared to the EarlyStopping version.  \n",
    "This model prioritizes **precision and overall accuracy** at the cost of sensitivity.  \n",
    "\n",
    "---\n",
    "\n",
    "# Overall Comparison\n",
    "\n",
    "| Model                     | Accuracy | Precision | Recall | F1 Score | FN (missed) | FP (flagged) | Key Trait |\n",
    "|----------------------------|----------|-----------|--------|----------|-------------|--------------|-----------|\n",
    "| **Baseline MLP**          | 0.706    | 0.718     | 0.674  | 0.695    | 1824        | 1487         | Balanced, but moderate recall |\n",
    "| **Adam + EarlyStopping**  | 0.711    | 0.714     | 0.698  | 0.706    | 1689        | 1567         | Best recall, fewer missed positives |\n",
    "| **Best Tuned MLP**        | 0.716    | 0.741     | 0.659  | 0.698    | 1910        | 1288         | Highest accuracy & precision, lower recall |\n",
    "\n",
    "---\n",
    "\n",
    "##  Summary:\n",
    "- **Baseline MLP:** Balanced but weaker recall.  \n",
    "- **Adam + EarlyStopping:** **Best recall**, fewer missed cases — more suitable for healthcare contexts where sensitivity matters.  \n",
    "- **Best Tuned MLP:** **Highest accuracy & precision**, but lower recall, meaning more diseased patients are missed.  \n",
    "\n",
    "The **Adam + EarlyStopping version** offers the most clinically relevant balance (catching more positives), while the tuned model is stronger if minimizing false positives is the priority.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Adam tuned MLP model → mlp_adamtuned.pkl\n",
      "Saved predictions → CVDKaggleData_75F25M_MLP_adamtuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save MLP model\n",
    "model_filename =  \"mlp_adamtuned.pkl\"\n",
    "joblib.dump(adammlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_mlp\n",
    "y_prob = y_prob_mlp\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\" : y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_75F25M_MLP_adamtuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Adam tuned MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
