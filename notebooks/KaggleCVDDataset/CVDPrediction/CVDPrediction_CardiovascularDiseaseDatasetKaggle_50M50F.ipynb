{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Cardiovascular Disease Dataset (Source: https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>bmiclass</th>\n",
       "      <th>MAP</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17997</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24871</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19175</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3585</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13478</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  gender  age  bmiclass  MAP  cholesterol  gluc  smoke  alco  \\\n",
       "0      17997       1    5         2    3            1     1      0     0   \n",
       "1      24871       1    4         1    4            1     1      0     0   \n",
       "2      19175       1    5         1    3            1     1      0     0   \n",
       "3       3585       1    4         2    3            1     1      1     1   \n",
       "4      13478       1    3         1    5            1     1      1     1   \n",
       "\n",
       "   active  cardio  \n",
       "0       1       0  \n",
       "1       1       1  \n",
       "2       1       1  \n",
       "3       1       0  \n",
       "4       1       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_50_50.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3bf15db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop source_id\n",
    "train_df = train_df.drop(columns=[\"source_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"cardio\"\n",
    "SENSITIVE = \"gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "\n",
    "# Identify feature types\n",
    "binary_cols = [\"gender\", \"smoke\", \"alco\", \"active\"]\n",
    "categorical_cols = [\"age\", \"bmiclass\", \"MAP\", \"cholesterol\", \"gluc\"]\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (30000, 28) (11256, 28)\n"
     ]
    }
   ],
   "source": [
    "#ONE-HOT ENCODE CATEGORICALS; KEEP SCALED NUMERICS AS-IS \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train[binary_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test[binary_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.6773276474769012\n",
      "Precision: 0.6840530940362685\n",
      "Recall   : 0.6532762006784503\n",
      "F1 Score : 0.6683105022831051\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69      5655\n",
      "           1       0.68      0.65      0.67      5601\n",
      "\n",
      "    accuracy                           0.68     11256\n",
      "   macro avg       0.68      0.68      0.68     11256\n",
      "weighted avg       0.68      0.68      0.68     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3965 1690]\n",
      " [1942 3659]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.6956289978678039\n",
      "Precision: 0.7148784825133373\n",
      "Recall   : 0.6459560792715586\n",
      "F1 Score : 0.678671918964547\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71      5655\n",
      "           1       0.71      0.65      0.68      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.69     11256\n",
      "weighted avg       0.70      0.70      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4212 1443]\n",
      " [1983 3618]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3196c229",
   "metadata": {},
   "source": [
    "## KNN Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 67.7%  \n",
    "- **Precision**: 68.4%  \n",
    "- **Recall**: 65.3%  \n",
    "- **F1 Score**: 66.8%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 3965         | 1690         |\n",
    "| **Actual: 1** | 1942         | 3659         |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **balanced but modest performance**, with accuracy below 70%.  \n",
    "- **Precision (68.4%)** and **recall (65.3%)** are close, suggesting no strong bias toward precision or sensitivity.  \n",
    "- The confusion matrix shows a substantial number of errors:  \n",
    "  - **1690 false positives** (healthy classified as CVD).  \n",
    "  - **1942 false negatives** (CVD cases missed).  \n",
    "- Overall, this KNN struggles to capture patterns effectively, leading to many misclassifications.  \n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 69.6%  \n",
    "- **Precision**: 71.5%  \n",
    "- **Recall**: 64.6%  \n",
    "- **F1 Score**: 67.9%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 4212         | 1443         |\n",
    "| **Actual: 1** | 1983         | 3618         |\n",
    "\n",
    "### Interpretation\n",
    "- The Decision Tree achieves **slightly higher accuracy (69.6%)** than KNN.  \n",
    "- **Precision is stronger (71.5%)**, indicating positive predictions are more reliable, but **recall remains modest (64.6%)**, with many CVD cases still missed.  \n",
    "- Errors are distributed as:  \n",
    "  - **1443 false positives** (fewer than KNN).  \n",
    "  - **1983 false negatives** (similar to KNN).  \n",
    "- This model is slightly more effective than KNN, with better precision and fewer false positives, but still limited in recall.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "Both models provide **moderate predictive power**, with accuracies below 70%.  \n",
    "- **KNN** shows balanced but weaker performance, with many misclassifications.  \n",
    "- **Decision Tree** performs better, offering **higher precision and fewer false alarms**, though recall remains limited.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'euclidean', 'n_neighbors': 29, 'weights': 'uniform'}\n",
      "Best CV F1: 0.6960630156544079\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.7006929637526652\n",
      "Precision: 0.6962715441435103\n",
      "Recall   : 0.7068380646313158\n",
      "F1 Score : 0.7015150172765128\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70      5655\n",
      "           1       0.70      0.71      0.70      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3928 1727]\n",
      " [1642 3959]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d175a",
   "metadata": {},
   "source": [
    "## KNN (Best Params) Model Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Metric**: Euclidean  \n",
    "- **Neighbors**: 29  \n",
    "- **Weights**: Uniform  \n",
    "- **Best CV F1**: 0.696  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 70.1%  \n",
    "- **Precision**: 69.6%  \n",
    "- **Recall**: 70.7%  \n",
    "- **F1 Score**: 70.2%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 3928         | 1727         |\n",
    "| **Actual: 1** | 1642         | 3959         |\n",
    "\n",
    "### Interpretation\n",
    "- This tuned KNN achieves **balanced performance**, with accuracy and F1 score just above 70%.  \n",
    "- **Precision (69.6%)** and **recall (70.7%)** are closely aligned, meaning the model does not strongly favor either avoiding false alarms or maximizing sensitivity.  \n",
    "- **False negatives** (CVD cases missed): **1642**, improved compared to the baseline KNN.  \n",
    "- **False positives** (healthy misclassified as CVD): **1727**, slightly higher than the baseline.  \n",
    "- Compared to the untuned version, this model provides **a more even trade-off** between precision and recall, at the cost of more false positives.  \n",
    "\n",
    "Overall, the tuned KNN delivers **modest but stable performance**, making it a more reliable option than the baseline, though recall and precision remain limited.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 16 | Explained variance retained: 0.950\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.6916311300639659\n",
      "Precision: 0.7017809776430466\n",
      "Recall   : 0.6613104802713801\n",
      "F1 Score : 0.6809449397922603\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70      5655\n",
      "           1       0.70      0.66      0.68      5601\n",
      "\n",
      "    accuracy                           0.69     11256\n",
      "   macro avg       0.69      0.69      0.69     11256\n",
      "weighted avg       0.69      0.69      0.69     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4081 1574]\n",
      " [1897 3704]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f43738",
   "metadata": {},
   "source": [
    "## KNN Model Versions – Interpretation\n",
    "\n",
    "### Baseline KNN\n",
    "- **Accuracy**: 67.7%  \n",
    "- **Precision**: 68.4%  \n",
    "- **Recall**: 65.3%  \n",
    "- **F1 Score**: 66.8%  \n",
    "- **Confusion Matrix**:  \n",
    "  - False Positives: 1,690  \n",
    "  - False Negatives: 1,942  \n",
    "\n",
    "**Interpretation**:  \n",
    "The baseline KNN shows **modest performance**, with accuracy below 70%. Recall (65.3%) is limited, meaning nearly 2,000 CVD cases are missed. Errors are distributed fairly evenly, suggesting the model struggles to separate classes clearly.  \n",
    "\n",
    "---\n",
    "\n",
    "### Tuned KNN (Best Params)\n",
    "- **Parameters**: Euclidean distance, 29 neighbors, uniform weights  \n",
    "- **Accuracy**: 70.1%  \n",
    "- **Precision**: 69.6%  \n",
    "- **Recall**: 70.7%  \n",
    "- **F1 Score**: 70.2%  \n",
    "- **Confusion Matrix**:  \n",
    "  - False Positives: 1,727  \n",
    "  - False Negatives: 1,642  \n",
    "\n",
    "**Interpretation**:  \n",
    "After tuning, the KNN improves in both **accuracy and recall**, achieving a more balanced performance. The number of missed CVD cases drops from ~1,942 to ~1,642, although false positives increase slightly. This configuration shows the best trade-off between sensitivity and reliability, compared to the baseline.  \n",
    "\n",
    "---\n",
    "\n",
    "### PCA + KNN\n",
    "- **PCA Components**: 16 (95% variance retained)  \n",
    "- **Accuracy**: 69.2%  \n",
    "- **Precision**: 70.2%  \n",
    "- **Recall**: 66.1%  \n",
    "- **F1 Score**: 68.1%  \n",
    "- **Confusion Matrix**:  \n",
    "  - False Positives: 1,574  \n",
    "  - False Negatives: 1,897  \n",
    "\n",
    "**Interpretation**:  \n",
    "Using PCA reduces dimensionality while retaining most variance, leading to **slightly lower recall (66.1%)** compared to the tuned version. While false positives decrease (1,574 vs 1,727), false negatives increase (1,897 missed CVD cases). This makes the model more conservative but less sensitive to detecting true CVD patients.  \n",
    "\n",
    "---\n",
    "\n",
    "### Overall Summary\n",
    "- **Baseline KNN**: Limited predictive ability, balanced but weak across all metrics.  \n",
    "- **Tuned KNN**: Best performing version, with **higher recall and accuracy**, making it the most balanced option.  \n",
    "- **PCA + KNN**: Reduces dimensionality effectively, but at the cost of **lower recall**, leading to more missed CVD cases, though fewer false positives.  \n",
    "\n",
    "The **Tuned KNN** is the most suitable version, as it minimizes missed CVD cases while keeping precision stable.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8055f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned KNN model → knn_tuned_model.pkl\n",
      "Saved predictions → CVDKaggleData_50F50M__tunedKNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series (not a DataFrame)\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"knn_tuned_model.pkl\"\n",
    "joblib.dump(best_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred_knn = y_pred_knn_best\n",
    "y_prob_knn = y_prob_knn_best\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_knn,\n",
    "    \"y_pred\": y_pred_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_50F50M__tunedKNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best CV F1: 0.6532\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7121535181236673\n",
      "Precision: 0.7422532320952185\n",
      "Recall   : 0.6457775397250491\n",
      "F1 Score : 0.6906625930876455\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      5655\n",
      "           1       0.74      0.65      0.69      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.72      0.71      0.71     11256\n",
      "weighted avg       0.72      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4399 1256]\n",
      " [1984 3617]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5614b",
   "metadata": {},
   "source": [
    "## Tuned Decision Tree Model Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Criterion**: Entropy  \n",
    "- **Max Depth**: 7  \n",
    "- **Min Samples Split**: 5  \n",
    "- **Min Samples Leaf**: 1  \n",
    "- **Best CV F1**: 0.6532  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 71.2%  \n",
    "- **Precision**: 74.2%  \n",
    "- **Recall**: 64.6%  \n",
    "- **F1 Score**: 69.1%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 4399         | 1256         |\n",
    "| **Actual: 1** | 1984         | 3617         |\n",
    "\n",
    "### Interpretation\n",
    "- The tuned Decision Tree achieves **accuracy of 71.2%**, showing modest improvement compared to baseline versions.  \n",
    "- **Precision is fairly high (74.2%)**, meaning predicted CVD cases are usually correct.  \n",
    "- **Recall (64.6%)** is weaker, with **1,984 missed CVD patients (false negatives)**, limiting sensitivity.  \n",
    "- Non-CVD patients are detected well (**78% correctly identified**), with **1,256 false positives**.  \n",
    "- The model thus leans toward **precision over recall**, being more conservative in identifying positives but less effective at capturing all true CVD cases.  \n",
    "\n",
    "➡️ Overall, this tuned Decision Tree provides **moderate performance**, but the relatively low recall makes it less suited for medical screening tasks where sensitivity is critical.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.6849333333333332\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.6849\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.7133084577114428\n",
      "Precision: 0.7193274205469328\n",
      "Recall   : 0.6950544545616855\n",
      "F1 Score : 0.7069826568600744\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      5655\n",
      "           1       0.72      0.70      0.71      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4136 1519]\n",
      " [1708 3893]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# Stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85ee082",
   "metadata": {},
   "source": [
    "## Decision Tree Model Comparison\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|--------------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline DT**                      | 0.696    | 0.715     | 0.646  | 0.679    | Balanced start; 1,983 false negatives and 1,443 false positives. |\n",
    "| **Tuned DT (max_depth=7, entropy)**  | 0.712    | 0.742     | 0.646  | 0.691    | Improved precision and accuracy, but recall remains low (1,984 false negatives). |\n",
    "| **Alt. Tuned & Pruned DT (gini, depth=4)** | 0.713 | 0.719     | 0.695  | 0.707    | More balanced trade-off; fewer false negatives (1,708), but slightly higher false positives (1,519). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Baseline DT**: Provides a reasonable baseline with accuracy of 69.6%. Recall (64.6%) is limited, resulting in nearly 2,000 missed CVD cases. Errors are balanced across both false positives and false negatives.  \n",
    "\n",
    "- **Tuned DT (entropy, depth=7)**: Achieves the highest **precision (74.2%)** and improves accuracy to 71.2%. However, recall does not improve (64.6%), still missing ~2,000 CVD cases. This makes it stronger for correct positive predictions but weaker for sensitivity.  \n",
    "\n",
    "- **Alt. Tuned & Pruned DT (gini, depth=4)**: Achieves a **better balance** between precision (71.9%) and recall (69.5%). This reduces missed CVD cases (1,708 false negatives, fewer than both baseline and tuned DT). While false positives rise slightly (1,519), the overall F1 score (70.7%) is the best among the three.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "- **Tuned DT (entropy)** is more precision-oriented, giving more reliable positive predictions but missing many CVD cases.  \n",
    "- **Alt. Tuned & Pruned DT** strikes the best balance, offering **higher recall and the strongest F1 score**, making it the most suitable choice for applications where minimizing missed CVD patients is important.  \n",
    "- The **Baseline DT** is adequate but outperformed by both tuned variants.  \n",
    "\n",
    "**Preferred option**: The **Alt. Tuned & Pruned DT** because it improves recall without sacrificing too much precision, leading to the **lowest number of missed CVD cases** while keeping accuracy stable.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e35d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tunedand pruned DT model → tunedpruned_dt_model.pkl\n",
      "Saved predictions → CVDKaggleData_50F50M_DT_tunedpruned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"tunedpruned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "# Use tuned predictions/probabilities from the best estimator\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_dt\": y_pred_dt,\n",
    "    \"y_prob\": y_prob_dt\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_50F50M_DT_tunedpruned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tunedand pruned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.701137171286425\n",
      "Precision: 0.7164699051674086\n",
      "Recall   : 0.660953401178361\n",
      "F1 Score : 0.687592867756315\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.71      5655\n",
      "           1       0.72      0.66      0.69      5601\n",
      "\n",
      "    accuracy                           0.70     11256\n",
      "   macro avg       0.70      0.70      0.70     11256\n",
      "weighted avg       0.70      0.70      0.70     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4190 1465]\n",
      " [1899 3702]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4328d1a6",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 70.1%  \n",
    "- **Precision**: 71.6%  \n",
    "- **Recall**: 66.1%  \n",
    "- **F1 Score**: 68.8%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 4190         | 1465         |\n",
    "| **Actual: 1** | 1899         | 3702         |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **moderate accuracy (70.1%)**, in line with previous decision tree-based models.  \n",
    "- **Precision (71.6%)** indicates that predicted CVD cases are fairly reliable.  \n",
    "- **Recall (66.1%)** shows the model still misses a notable portion of CVD cases (**1,899 false negatives**).  \n",
    "- For non-CVD cases, **4190 are correctly identified**, but there are **1465 false positives**, where healthy patients were incorrectly flagged as CVD.  \n",
    "- The **F1 score (68.8%)** reflects a fair but not strong balance between precision and recall.  \n",
    "\n",
    "➡️ Overall, this Random Forest provides **stable but modest predictive power**. It reduces variance compared to single decision trees but still struggles with sensitivity, meaning a considerable number of CVD patients remain undetected.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 2\n",
      "n_required_iterations: 2\n",
      "n_possible_iterations: 2\n",
      "min_resources_: 100\n",
      "max_resources_: 400\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 8\n",
      "n_resources: 100\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 3\n",
      "n_resources: 300\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "=== Random Forest (best, halving over n_estimators) Evaluation ===\n",
      "Accuracy : 0.7092217484008528\n",
      "Precision: 0.7220526516596719\n",
      "Recall   : 0.6757721835386538\n",
      "F1 Score : 0.6981462694826155\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72      5655\n",
      "           1       0.72      0.68      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4198 1457]\n",
      " [1816 3785]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv  # must be first\n",
    "from sklearn.model_selection import HalvingGridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=1, bootstrap=True)\n",
    "\n",
    "# Do NOT include 'n_estimators' in param_grid; Halving will vary it as the resource.\n",
    "param_grid = {\n",
    "    \"max_depth\": [None, 12],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"class_weight\": [\"balanced\"],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "search = HalvingGridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    resource=\"n_estimators\",   # use trees as the resource\n",
    "    min_resources=100,         # start small\n",
    "    max_resources=400,         # end at your intended max\n",
    "    factor=3,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    "    return_train_score=False,\n",
    ")\n",
    "\n",
    "search.fit(Xtr, y_train)\n",
    "best_rf = search.best_estimator_\n",
    "y_pred_rf = best_rf.predict(Xte)\n",
    "y_prob_rf = best_rf.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest (best, halving over n_estimators)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddade5b2",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison\n",
    "\n",
    "| Model                           | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|---------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline RF**                 | 0.701    | 0.716     | 0.661  | 0.688    | Solid baseline; 1,899 false negatives, 1,465 false positives. |\n",
    "| **Tuned RF (halving search)**   | 0.709    | 0.722     | 0.676  | 0.698    | Slightly higher accuracy, recall, and F1; fewer false negatives (1,816). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline RF** achieves balanced performance with ~70% accuracy. It performs reasonably on both classes but still misses **1,899 CVD cases** (false negatives).  \n",
    "- **Tuned RF (halving over n_estimators)** improves performance slightly across all metrics:  \n",
    "  - Accuracy increases to **70.9%**.  \n",
    "  - Recall improves to **67.6%**, reducing missed CVD cases to **1,816**.  \n",
    "  - Precision rises slightly to **72.2%**, with a small drop in false positives (1,457 vs. 1,465).  \n",
    "- The F1 score also improves from **68.8% → 69.8%**, showing a better balance between precision and recall.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The **Tuned RF (halving search)** is the stronger variant, as it improves recall and overall balance while keeping precision stable. This leads to **fewer missed CVD cases**, which is especially valuable in medical screening contexts, even if the performance gains over the baseline are modest.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned RF model → tuned_rf_model.pkl\n",
      "Saved predictions → CVDKaggleData_50M50F_RF_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned Random Forest Results\n",
    "\n",
    "# Save tuned Random Forest model\n",
    "model_filename = \"tuned_rf_model.pkl\"\n",
    "joblib.dump(best_rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_rf  # from best_rf.predict(X_test_ready)\n",
    "y_prob = y_prob_rf\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_rf\": y_pred,\n",
    "    \"y_prob\" :y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_50M50F_RF_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.7083333333333334\n",
      "Precision: 0.7230561970746728\n",
      "Recall   : 0.6707730762363864\n",
      "F1 Score : 0.6959340557562286\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      5655\n",
      "           1       0.72      0.67      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.71      0.71      0.71     11256\n",
      "weighted avg       0.71      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4216 1439]\n",
      " [1844 3757]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71f61c",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 70.8%  \n",
    "- **Precision**: 72.3%  \n",
    "- **Recall**: 67.1%  \n",
    "- **F1 Score**: 69.6%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 4216         | 1439         |\n",
    "| **Actual: 1** | 1844         | 3757         |\n",
    "\n",
    "### Interpretation\n",
    "- The MLP reaches **70.8% accuracy**, comparable to tree-based models on this dataset.  \n",
    "- **Precision (72.3%)** indicates that most predicted CVD cases are correct.  \n",
    "- **Recall (67.1%)** shows that sensitivity is still limited, with **1,844 CVD cases missed** (false negatives).  \n",
    "- For non-CVD patients, 4216 are correctly identified, though **1439 false positives** remain.  \n",
    "- With an **F1 score of 69.6%**, the model maintains a fair balance between precision and recall but does not strongly outperform simpler models.  \n",
    "\n",
    "➡️ Overall, this MLP provides **moderate performance with balanced trade-offs**, but its recall remains too low for critical medical screening where minimizing missed CVD cases is a priority.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b123b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.7149964463397299\n",
      "Precision: 0.7269967748055397\n",
      "Recall   : 0.6841635422246027\n",
      "F1 Score : 0.7049300956585725\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72      5655\n",
      "           1       0.73      0.68      0.70      5601\n",
      "\n",
      "    accuracy                           0.71     11256\n",
      "   macro avg       0.72      0.71      0.71     11256\n",
      "weighted avg       0.72      0.71      0.71     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4216 1439]\n",
      " [1769 3832]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24a5d9",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – Adam + EarlyStopping) Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 71.5%  \n",
    "- **Precision**: 72.7%  \n",
    "- **Recall**: 68.4%  \n",
    "- **F1 Score**: 70.5%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 4216         | 1439         |\n",
    "| **Actual: 1** | 1769         | 3832         |\n",
    "\n",
    "### Interpretation\n",
    "- This model achieves **accuracy of 71.5%**, slightly stronger than the baseline MLP.  \n",
    "- **Precision (72.7%)** remains high, meaning most predicted CVD cases are correct.  \n",
    "- **Recall improves to 68.4%**, reducing false negatives to **1,769** (compared to 1,844 in the baseline MLP).  \n",
    "- Non-CVD detection remains stable: 4216 correct, with **1439 false positives**.  \n",
    "- The **F1 score (70.5%)** reflects this better balance, showing that EarlyStopping helps improve generalization.  \n",
    "\n",
    "➡️ Overall, the **Adam + EarlyStopping MLP** offers **more stable and balanced performance** than the plain MLP, with fewer missed CVD cases and stronger generalization, making it the preferable neural network configuration.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (64,), 'batch_size': 32, 'alpha': 1e-05, 'activation': 'relu'}\n",
      "Best CV F-beta (β=2): 0.6899\n",
      "=== Best MLP (Adam + ES, fast) Evaluation ===\n",
      "Accuracy : 0.7160625444207533\n",
      "Precision: 0.7228915662650602\n",
      "Recall   : 0.6963042313872523\n",
      "F1 Score : 0.7093488541287741\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72      5655\n",
      "           1       0.72      0.70      0.71      5601\n",
      "\n",
      "    accuracy                           0.72     11256\n",
      "   macro avg       0.72      0.72      0.72     11256\n",
      "weighted avg       0.72      0.72      0.72     11256\n",
      "\n",
      "Confusion Matrix:\n",
      " [[4160 1495]\n",
      " [1701 3900]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OPTION A — Fastest win: early stopping + single-metric scoring + lighter CV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# Keep arrays lean\n",
    "Xtr = getattr(X_train_ready, \"values\", X_train_ready).astype(\"float32\")\n",
    "Xte = getattr(X_test_ready, \"values\", X_test_ready).astype(\"float32\")\n",
    "\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # <- stop per-config when val score plateaus\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    max_iter=200,                 # <- much lower; early_stopping will bail sooner\n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Trim the space; focus on what usually matters\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32)],\n",
    "    \"activation\": [\"relu\"],       # 'relu' typically dominates for tabular MLPs\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4],\n",
    "    \"batch_size\": [32, 64, 128],  # larger batch -> faster per-epoch\n",
    "}\n",
    "\n",
    "# Fewer folds = big speedup with little generalization loss\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Use a single scorer that matches your objective (recall-weighted)\n",
    "fbeta2 = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                    # fewer trials; early stop handles over-training\n",
    "    scoring=fbeta2,               # <- single metric speeds everything up\n",
    "    refit=True,                   # refit on full train with best params\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(Xtr, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "\n",
    "y_pred = best_mlp.predict(Xte)\n",
    "y_prob = best_mlp.predict_proba(Xte)[:, 1]\n",
    "evaluate_model(y_test, y_pred, model_name=\"Best MLP (Adam + ES, fast)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a350b92e",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison\n",
    "\n",
    "| Model                               | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-------------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline MLP**                    | 0.708    | 0.723     | 0.671  | 0.696    | Balanced, but misses 1,844 CVD cases; 1,439 false positives. |\n",
    "| **MLP (Adam + EarlyStopping)**      | 0.715    | 0.727     | 0.684  | 0.705    | Better recall; 1,769 false negatives (reduced) while keeping 1,439 false positives. |\n",
    "| **Best Tuned MLP (Adam + ES, fast)**| 0.716    | 0.723     | 0.696  | 0.709    | Strongest recall (69.6%); misses only 1,701 CVD cases; slightly higher false positives (1,495). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline MLP**: Provides fair balance (accuracy ~71%), but recall (67.1%) is limited, leading to nearly **1,844 missed CVD patients**. Precision is decent at 72.3%, showing reliable positive predictions.  \n",
    "\n",
    "- **MLP (Adam + EarlyStopping)**: Improves recall to **68.4%**, reducing false negatives to **1,769**. Accuracy also rises slightly (71.5%). It keeps false positives constant at 1,439, showing a more stable and generalizable model.  \n",
    "\n",
    "- **Best Tuned MLP (Adam + ES, fast)**: Achieves the **best recall (69.6%)** and F1 score (70.9%). False negatives are further reduced to **1,701**, though false positives increase slightly (1,495). Accuracy (71.6%) and precision (72.3%) remain strong, making this the most effective version overall.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "- **Baseline MLP** is adequate but limited by lower recall.  \n",
    "- **MLP (Adam + EarlyStopping)** offers a clear improvement, balancing recall and precision more effectively.  \n",
    "- **Best Tuned MLP** is the **strongest performer**, achieving the **highest recall and F1 score**, meaning it misses fewer CVD cases while maintaining reliability in predictions.  \n",
    "\n",
    "➡️ For CVD detection, where missing cases is critical, the **Best Tuned MLP (Adam + ES, fast)** is the preferred choice.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Adam tuned MLP model → mlp_adamtuned.pkl\n",
      "Saved predictions → CVDKaggleData_50M50F_MLP_adamtuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save MLP model\n",
    "model_filename =  \"mlp_adamtuned.pkl\"\n",
    "joblib.dump(best_mlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = best_mlp.predict(Xte)\n",
    "y_prob = best_mlp.predict_proba(Xte)[:, 1]\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\" : y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"CVDKaggleData_50M50F_MLP_adamtuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Adam tuned MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
