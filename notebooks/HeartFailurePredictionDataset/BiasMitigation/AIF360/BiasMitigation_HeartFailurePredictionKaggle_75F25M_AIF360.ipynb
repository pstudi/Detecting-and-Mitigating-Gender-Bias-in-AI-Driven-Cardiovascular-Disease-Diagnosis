{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## Bias Mitigation using AIF360 - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>130.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   33    0              3      100.0        246.0          0           0   \n",
       "1   48    0              1      120.0        284.0          0           0   \n",
       "2   49    0              3      130.0        269.0          0           0   \n",
       "3   62    0              3      140.0        268.0          0           2   \n",
       "4   38    0              3      105.0        236.0          1           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  150.0               1      1.0         1             1  \n",
       "1  120.0               0      0.0         2             0  \n",
       "2  163.0               0      0.0         2             0  \n",
       "3  160.0               0      3.6         0             1  \n",
       "4  166.0               0      2.8         2             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_25M_75F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fe70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e449c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sensitive attribute arrays - after creating X_train_ready and X_test_ready\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()  # 1=Male, 0=Female\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42dd1caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\inFairness\\utils\\ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\inFairness\\utils\\ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "# setup for AIF360\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "from IPython.display import display \n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Config \n",
    "protected_attr = \"Sex\"  # 1=Male, 0=Female\n",
    "PRIV_VALUE = 1          # privileged = Male\n",
    "label_name = \"label\"\n",
    "favorable_label, unfavorable_label = 1, 0\n",
    "privileged_groups   = [{protected_attr: PRIV_VALUE}]\n",
    "unprivileged_groups = [{protected_attr: 1 - PRIV_VALUE}]\n",
    "\n",
    "# Ensure 1-D ints for targets\n",
    "y_train = np.asarray(y_train).astype(int).ravel()\n",
    "y_test  = np.asarray(y_test).astype(int).ravel()\n",
    "\n",
    "# Sensitive attribute arrays\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "\n",
    "def _to_bld(y, A):\n",
    "    y = (y.values if hasattr(y,'values') else np.asarray(y)).ravel()\n",
    "    A = (A.values if hasattr(A,'values') else np.asarray(A)).ravel()\n",
    "    df = pd.DataFrame({\"dummy\": np.zeros(len(y)), label_name: y, protected_attr: A})\n",
    "    return BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "def fair_metrics(y_true, y_pred, A, y_scores=None, absolute=True):\n",
    "    \"\"\"AIF360-based DP and EO (equal opportunity) differences.\"\"\"\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    if y_scores is not None:\n",
    "        p.scores = np.asarray(y_scores).reshape(-1, 1)\n",
    "    cm = ClassificationMetric(\n",
    "        t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.equal_opportunity_difference()\n",
    "    return (abs(dp), abs(eo)) if absolute else (dp, eo)\n",
    "\n",
    "def get_scores(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        z = model.decision_function(X)\n",
    "        return (z - z.min()) / (z.max() - z.min() + 1e-12)\n",
    "    return model.predict(X).astype(float)\n",
    "\n",
    "def selection_rate(y_pred, positive=1):\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    return np.mean(y_pred == positive)\n",
    "\n",
    "def per_group_table(y_true, y_pred, A, positive=1, group_name=\"Sex\"):\n",
    "    \"\"\"Keeps your existing API (positive=...), uses sklearn metrics.\"\"\"\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    A = np.asarray(A).ravel()\n",
    "    rows = []\n",
    "    for g in np.unique(A):\n",
    "        idx = (A == g)\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "        rec = recall_score(yt, yp, pos_label=positive)   # equals TPR for binary\n",
    "        sr  = selection_rate(yp, positive=positive)\n",
    "        acc = accuracy_score(yt, yp)\n",
    "        rows.append({group_name: g, \"TPR\": tpr, \"FPR\": fpr,\n",
    "                     \"Recall\": rec, \"SelectionRate\": sr, \"Accuracy\": acc})\n",
    "    return pd.DataFrame(rows).set_index(group_name)\n",
    "\n",
    "def aif_diffs(y_true, y_pred, A, *, abs_vals=True):\n",
    "    \"\"\"Alternative disparities (AIF360): DP and average odds difference.\"\"\"\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    cm = ClassificationMetric(\n",
    "        t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.average_odds_difference()   # avg of TPR/FPR diffs\n",
    "    if abs_vals:\n",
    "        dp, eo = abs(dp), abs(eo)\n",
    "    return dp, eo\n",
    "\n",
    "def print_row(title, acc, dp, eo, note=\"\"):\n",
    "    print(f\"{title:>24s} | Acc {acc:.4f} | DP {dp:.4f} | EO {eo:.4f} {('|' if note else '')} {note}\")\n",
    "\n",
    "# to print a model cleanly (fixed call sites)\n",
    "def report_model(name, y_true, y_pred, A, scores=None, note=\"\"):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    dp, eo = fair_metrics(y_true, y_pred, A, y_scores=scores, absolute=True)  # no pos_label here\n",
    "    tbl = per_group_table(y_true, y_pred, A, positive=favorable_label, group_name=\"Sex\").round(6)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    display(tbl)\n",
    "    print(f\"Overall -> Accuracy: {acc:.4f} | DP diff: {dp:.4f} | EO diff: {eo:.4f}\"\n",
    "          + (f\" | {note}\" if note else \"\"))\n",
    "    \n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"DP diff\": dp, \"EO diff\": eo}\n",
    "\n",
    "# Pre: compute reweighing weights ONCE on TRAIN\n",
    "_bld_train = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name],\n",
    "    protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label,\n",
    "    unfavorable_label=unfavorable_label\n",
    ")\n",
    "_rw = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                 privileged_groups=privileged_groups).fit(_bld_train)\n",
    "_rw_weights = _rw.transform(_bld_train).instance_weights.ravel()\n",
    "\n",
    "# Turn weights into a resampled training set\n",
    "def resample_by_weights(X, y, A, weights, n_samples=None, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    Xn = np.asarray(X); yn = np.asarray(y).ravel(); An = np.asarray(A).ravel()\n",
    "    w = np.clip(np.asarray(weights, dtype=float), 1e-12, None)\n",
    "    p = w / w.sum()\n",
    "    n = n_samples or len(yn)\n",
    "    idx = rng.choice(len(yn), size=n, replace=True, p=p)\n",
    "    return Xn[idx], yn[idx], An[idx]\n",
    "\n",
    "Xrw, yrw, Arw = resample_by_weights(\n",
    "    X_train_ready, y_train, A_train, _rw_weights,\n",
    "    n_samples=len(y_train), random_state=42\n",
    ")\n",
    "\n",
    "# Post: make a small TRAIN-based calibration split (no test leakage)\n",
    "trn_X, cal_X, trn_y, cal_y, trn_A, cal_A = train_test_split(\n",
    "    X_train_ready, y_train, A_train, test_size=0.12, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# Make types consistent to avoid the PCA warning \n",
    "X_test_np = np.asarray(X_test_ready)\n",
    "trn_X_np  = np.asarray(trn_X)\n",
    "cal_X_np  = np.asarray(cal_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf61beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### PCA-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 11 | Explained variance retained: 0.952\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8315217391304348\n",
      "Precision: 0.9080459770114943\n",
      "Recall   : 0.7745098039215687\n",
      "F1 Score : 0.8359788359788359\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        82\n",
      "           1       0.91      0.77      0.84       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.84      0.84      0.83       184\n",
      "weighted avg       0.84      0.83      0.83       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  8]\n",
      " [23 79]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'entropy', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.9733\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9733\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.8260869565217391\n",
      "Precision: 0.7966101694915254\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8545454545454545\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78        82\n",
      "           1       0.80      0.92      0.85       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.84      0.81      0.82       184\n",
      "weighted avg       0.83      0.83      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58 24]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best CV F1: 0.9566666666666667\n",
      "=== Tuned Random Forest Evaluation ===\n",
      "Accuracy : 0.842391304347826\n",
      "Precision: 0.9010989010989011\n",
      "Recall   : 0.803921568627451\n",
      "F1 Score : 0.8497409326424871\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        82\n",
      "           1       0.90      0.80      0.85       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.85      0.84       184\n",
      "weighted avg       0.85      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [20 82]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "# 1) GridSearchCV over impactful RF params\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",          \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "# 2) Evaluate best RF \n",
    "y_pred = best_rf.predict(X_test_ready)\n",
    "y_prob = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "evaluate_model(y_test, y_pred, \"Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Adam MLP + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.8709677419354839\n",
      "Recall   : 0.7941176470588235\n",
      "F1 Score : 0.8307692307692308\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        82\n",
      "           1       0.87      0.79      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.82      0.82       184\n",
      "weighted avg       0.83      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [21 81]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762eb02",
   "metadata": {},
   "source": [
    "### Bias Mitigation AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e771c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: install AIF360\n",
    "# Uncomment the next line if running locally for the first time\n",
    "#!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3c1689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIF360 version: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "import aif360\n",
    "print(\"AIF360 version:\", aif360.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99a4a6",
   "metadata": {},
   "source": [
    "### Bias Mitigation AIF 360 - KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9616d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - KNN baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.666667  0.03125  0.666667       0.131579  0.921053\n",
       "1    0.781250  0.14000  0.781250       0.561644  0.808219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8315 | DP diff: 0.4301 | EO diff: 0.1146\n",
      "\n",
      "=== KNN pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.595890</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    0.833333  0.125  0.833333       0.236842  0.868421\n",
       "1    0.812500  0.180  0.812500       0.595890  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8261 | DP diff: 0.3590 | EO diff: 0.0208 | resampled by AIF360 weights\n",
      "\n",
      "=== KNN post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.666667  0.03125  0.666667       0.131579  0.921053\n",
       "1    0.781250  0.14000  0.781250       0.561644  0.808219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8315 | DP diff: 0.4301 | EO diff: 0.1146 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn KNN Baseline for AIF360 bias mitigation\n",
    "knn_base = pca_knn\n",
    "\n",
    "yhat_knn_base   = knn_base.predict(X_test_ready)         \n",
    "scores_knn_base = get_scores(knn_base, X_test_ready)\n",
    "\n",
    "res_knn_base = report_model(\"Fairlearn - KNN baseline\", y_test, yhat_knn_base, A_test, scores=scores_knn_base)\n",
    "\n",
    "\n",
    "#Pre (Reweighing)\n",
    "knn_pre        = clone(pca_knn).fit(Xrw, yrw)\n",
    "yhat_knn_pre   = knn_pre.predict(X_test_ready)\n",
    "scores_knn_pre = get_scores(knn_pre, X_test_ready)\n",
    "res_knn_pre    = report_model(\"KNN pre: Reweigh\",\n",
    "                              y_test, yhat_knn_pre, A_test,\n",
    "                              scores=scores_knn_pre,\n",
    "                              note=\"resampled by AIF360 weights\")\n",
    "\n",
    "#Post (Equalized Odds)\n",
    "cal_scores_knn   = get_scores(knn_base, cal_X_np)  # baseline KNN on CAL\n",
    "post_knn = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups)\n",
    "post_knn.fit(_to_bld(cal_y, cal_A),\n",
    "             _to_bld((cal_scores_knn >= 0.5).astype(int), cal_A))\n",
    "\n",
    "pred_knn_post_bld = post_knn.predict(_to_bld((scores_knn_base >= 0.5).astype(int), A_test))\n",
    "yhat_knn_post     = pred_knn_post_bld.labels.ravel().astype(int)\n",
    "\n",
    "res_knn_post = report_model(\"KNN post: EqOdds\",\n",
    "                            y_test, yhat_knn_post, A_test,\n",
    "                            scores=scores_knn_base,\n",
    "                            note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f9b33",
   "metadata": {},
   "source": [
    "## KNN + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8315   | 0.4301  | 0.1146            | 0.5447 |\n",
    "| Pre: Reweigh        | 0.8261   | **0.3590** | **0.0208**     | **0.3798** |\n",
    "| Post: EqualizedOdds | 0.8315   | 0.4301  | 0.1146            | 0.5447 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.132**, 1 **0.562** → large DP gap (**0.430**).  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.781** → EO gap **0.115** (males recalled more).  \n",
    "- **FPR:** 0 **0.031**, 1 **0.140** (males have higher false positives).  \n",
    "- **Note:** Accuracy is good, but fairness disparities remain significant.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.237**, 1 **0.596** → DP improves to **0.359**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.813** → **near-parity recall** (**EO 0.021**, best).  \n",
    "- **FPR:** 0 **0.125**, 1 **0.180** (both ↑).  \n",
    "- **Note:** Achieves the best fairness (lowest DP+EO), but with a modest accuracy drop.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.132**, 1 **0.562** → DP gap **0.430** (unchanged).  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.781** → EO gap unchanged (**0.115**).  \n",
    "- **FPR:** 0 **0.031**, 1 **0.140** (same as baseline).  \n",
    "- **Note:** Results are essentially identical to baseline — no fairness gains.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Pre: Reweigh** — lowest combined disparity (DP+EO ≈ 0.380), by nearly eliminating the recall gap and reducing DP.  \n",
    "- **Baseline** has decent accuracy but strong fairness gaps.  \n",
    "- **Post: EqOdds** fails to improve fairness compared to baseline.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c64ab072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - DT baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.28125  0.833333       0.368421  0.736842\n",
       "1    0.927083  0.30000  0.927083       0.712329  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8261 | DP diff: 0.3439 | EO diff: 0.0938\n",
      "\n",
      "=== DT pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.666667  0.15625  0.666667       0.236842  0.815789\n",
       "1    0.927083  0.26000  0.927083       0.698630  0.863014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8533 | DP diff: 0.4618 | EO diff: 0.2604 | resampled by AIF360 weights\n",
      "\n",
      "=== DT post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.30000</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.34375  0.833333       0.421053  0.684211\n",
       "1    0.927083  0.30000  0.927083       0.712329  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8152 | DP diff: 0.2913 | EO diff: 0.0938 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn DT Baseline for AIF360 bias mitigation\n",
    "dt_base = alt_best_dt\n",
    "\n",
    "yhat_dt_base   = dt_base.predict(X_test_ready)         \n",
    "scores_dt_base = get_scores(dt_base, X_test_ready)\n",
    "\n",
    "res_dt_base = report_model(\"Fairlearn - DT baseline\", y_test, yhat_dt_base, A_test, scores=scores_dt_base)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "dt_pre = clone(alt_best_dt).fit(Xrw, yrw)\n",
    "yhat_dt_pre = dt_pre.predict(X_test_np)\n",
    "scores_dt_pre = get_scores(dt_pre, X_test_np)\n",
    "_ = report_model(\"DT pre: Reweigh\", y_test, yhat_dt_pre, A_test, scores=scores_dt_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_dt = get_scores(dt_base, cal_X_np)\n",
    "post_dt = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_dt.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_dt >= 0.5).astype(int), cal_A))\n",
    "yhat_dt_post = post_dt.predict(_to_bld((scores_dt_base >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"DT post: EqOdds\", y_test, yhat_dt_post, A_test, scores=scores_dt_base,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d907a5",
   "metadata": {},
   "source": [
    "## DT + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8261   | 0.3439  | **0.0938**        | **0.4377** |\n",
    "| Pre: Reweigh        | 0.8533   | 0.4618  | 0.2604            | 0.7222 |\n",
    "| Post: EqualizedOdds | 0.8152   | **0.2913** | **0.0938**     | 0.3851 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.368**, 1 **0.712** → DP gap **0.344**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.927** → EO gap **0.094** (small).  \n",
    "- **FPR:** 0 **0.281**, 1 **0.300** (males slightly higher).  \n",
    "- **Note:** Good accuracy with minimal EO disparity, but a sizeable DP gap.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.237**, 1 **0.699** → DP worsens to **0.462**.  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.927** → EO worsens to **0.260** (large).  \n",
    "- **FPR:** 0 **0.156**, 1 **0.260**.  \n",
    "- **Note:** Accuracy improves (0.853), but fairness degrades strongly (both DP and EO worsen).\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.421**, 1 **0.712** → DP improves to **0.291**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.927** → EO parity remains **0.094**.  \n",
    "- **FPR:** 0 **0.344**, 1 **0.300** (female ↑).  \n",
    "- **Note:** Accuracy slightly lower (0.815), but fairness metrics (DP+EO) are the best overall.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Post: EqOdds**, with the lowest combined gap (DP+EO ≈ 0.385), balancing DP and EO reasonably well.  \n",
    "- **Baseline** performs well on EO (≈0.094) with solid accuracy but suffers from higher DP disparity.  \n",
    "- **Pre: Reweigh** increases accuracy the most but worsens both DP and EO, making it the least fair option.  \n",
    "- **Takeaway:** For DT, post-processing gives the best fairness–performance trade-off, while baseline is competitive due to its strong EO parity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a886023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - RF baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.03125  0.833333       0.157895  0.947368\n",
       "1    0.802083  0.16000  0.802083       0.582192  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4243 | EO diff: 0.0312\n",
      "\n",
      "=== RF pre: Reweigh (sample_weight) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.03125  0.833333       0.157895  0.947368\n",
       "1    0.802083  0.16000  0.802083       0.582192  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4243 | EO diff: 0.0312\n",
      "\n",
      "=== RF post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.16000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.03125  0.833333       0.157895  0.947368\n",
       "1    0.802083  0.16000  0.802083       0.582192  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4243 | EO diff: 0.0312 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RF) with AIF360\n",
    "\n",
    "# -get Fairlearn baseline\n",
    "yhat_rf_base    = best_rf.predict(X_test_ready)\n",
    "scores_rf_base  = get_scores(best_rf, X_test_ready)\n",
    "res_rf_base     = report_model(\"Fairlearn - RF baseline\", y_test, yhat_rf_base, A_test, scores=scores_rf_base)\n",
    "\n",
    "# Pre (Reweighing via sample_weight)\n",
    "rf_pre          = clone(best_rf).fit(X_train_ready, y_train, sample_weight=_rw_weights)\n",
    "yhat_rf_pre     = rf_pre.predict(X_test_ready)\n",
    "scores_rf_pre   = get_scores(rf_pre, X_test_ready)\n",
    "res_rf_pre      = report_model(\"RF pre: Reweigh (sample_weight)\",\n",
    "                               y_test, yhat_rf_pre, A_test, scores=scores_rf_pre)\n",
    "\n",
    "# Post (Equalized Odds) learned on CAL\n",
    "cal_scores_rf   = get_scores(best_rf, cal_X_np)  # baseline rf on calibration split\n",
    "post_rf = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_rf.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_rf >= 0.5).astype(int), cal_A))\n",
    "\n",
    "pred_rf_post_bld = post_rf.predict(_to_bld((scores_rf_base >= 0.5).astype(int), A_test))\n",
    "yhat_rf_post     = pred_rf_post_bld.labels.ravel().astype(int)\n",
    "\n",
    "res_rf_post = report_model(\"RF post: EqOdds\",\n",
    "                           y_test, yhat_rf_post, A_test,\n",
    "                           scores=scores_rf_base,\n",
    "                           note=\"calibrated on held-out TRAIN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d0610",
   "metadata": {},
   "source": [
    "## RF + AIF360 \n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8424   | 0.4243  | **0.0312**        | **0.4555** |\n",
    "| Pre: Reweigh        | 0.8424   | 0.4243  | **0.0312**        | **0.4555** |\n",
    "| Post: EqualizedOdds | 0.8424   | 0.4243  | **0.0312**        | **0.4555** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.158**, 1 **0.582** → DP gap **0.424** (large).  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.802** → EO gap **0.031** (very small).  \n",
    "- **FPR:** 0 **0.031**, 1 **0.160** (males higher).  \n",
    "- **Note:** High accuracy (0.842), excellent EO parity, but strong selection disparity.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate, TPR, FPR:** identical to baseline.  \n",
    "- **Note:** No changes — fairness metrics and accuracy remain the same as baseline.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate, TPR, FPR:** identical to baseline.  \n",
    "- **Note:** Again, no improvement — results are the same as baseline, indicating EqOdds had no effect here.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Baseline** — already strong EO (0.031) with high accuracy.  \n",
    "- **Pre: Reweigh** and **Post: EqOdds** made no difference in this setup.  \n",
    "- **Takeaway:** RF’s baseline model is already optimal in balancing fairness and accuracy, though the DP disparity (0.424) remains a persistent issue.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f76d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - MLP baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.22000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.666667  0.03125  0.666667       0.131579  0.921053\n",
       "1    0.802083  0.22000  0.802083       0.602740  0.794521"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8207 | DP diff: 0.4712 | EO diff: 0.1354\n",
      "\n",
      "=== MLP pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.26000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.780822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.666667  0.09375  0.666667       0.184211  0.868421\n",
       "1    0.802083  0.26000  0.802083       0.616438  0.780822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.7989 | DP diff: 0.4322 | EO diff: 0.1354 | resampled by AIF360 weights\n",
      "\n",
      "=== MLP post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.794521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR     FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                     \n",
       "0    0.833333  0.1875  0.833333       0.289474  0.815789\n",
       "1    0.802083  0.2200  0.802083       0.602740  0.794521"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.7989 | DP diff: 0.3133 | EO diff: 0.0312 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn MLP Baseline for AIF360 bias mitigation\n",
    "mlp_base = adammlp\n",
    "yhat_mlp_base   = mlp_base.predict(X_test_ready)         \n",
    "scores_mlp_base = get_scores(mlp_base, X_test_ready)\n",
    "\n",
    "res_mlp_base = report_model(\"Fairlearn - MLP baseline\", y_test, yhat_mlp_base, A_test, scores=scores_mlp_base)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "mlp_pre = clone(adammlp).fit(Xrw, yrw)\n",
    "yhat_mlp_pre = mlp_pre.predict(X_test_np)\n",
    "scores_mlp_pre = get_scores(mlp_pre, X_test_np)\n",
    "_ = report_model(\"MLP pre: Reweigh\", y_test, yhat_mlp_pre, A_test, scores=scores_mlp_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_mlp = get_scores(mlp_base, cal_X_np)\n",
    "post_mlp = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups)\n",
    "post_mlp.fit(_to_bld(cal_y, cal_A),\n",
    "             _to_bld((cal_scores_mlp >= 0.5).astype(int), cal_A))\n",
    "yhat_mlp_post = post_mlp.predict(_to_bld((scores_mlp_base >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"MLP post: EqOdds\", y_test, yhat_mlp_post, A_test, scores=scores_mlp_base,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712a7a1",
   "metadata": {},
   "source": [
    "## MLP + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8207   | 0.4712  | 0.1354            | 0.6066 |\n",
    "| Pre: Reweigh        | 0.7989   | 0.4322  | 0.1354            | 0.5676 |\n",
    "| Post: EqualizedOdds | 0.7989   | **0.3133** | **0.0312**     | **0.3445** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.132**, 1 **0.603** → DP gap **0.471** (large).  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.802** → EO gap **0.135**.  \n",
    "- **FPR:** 0 **0.031**, 1 **0.220** (much higher for males).  \n",
    "- **Note:** Highest accuracy (0.821) but worst fairness, with both DP and EO disparities evident.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.184**, 1 **0.616** → DP improves slightly to **0.432**.  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.802** → EO gap unchanged (**0.135**).  \n",
    "- **FPR:** 0 **0.094**, 1 **0.260** (↑ vs baseline).  \n",
    "- **Note:** Small DP improvement, EO unchanged, and accuracy drops modestly.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.289**, 1 **0.603** → **best DP** (**0.313**).  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.802** → **best EO** (**0.031**, near parity).  \n",
    "- **FPR:** 0 **0.188** (↑ sharply), 1 **0.220** (≈ baseline).  \n",
    "- **Note:** Strongest fairness improvement (lowest DP+EO), though accuracy falls further to ~0.799.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Post: EqOdds** (DP+EO ≈ 0.345) — drastically reduces both DP and EO, though at the cost of accuracy.  \n",
    "- **Pre: Reweigh** provides only modest DP gains with unchanged EO.  \n",
    "- **Baseline** offers the best accuracy but suffers from the highest disparities.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce511e42",
   "metadata": {},
   "source": [
    "First fairness mitigation: pre- and post-processing was performed on the designated best performing models (KNN, DT, RF, MLP) for CVD prediction.  In addition, these results are compared to a fairness-aware in-processing model - Adversarial Debiasing offered by AIF360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66355777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_29956\\3615687400.py:10: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_29956\\3615687400.py:11: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733708; batch adversarial loss: 0.548406\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683735; batch adversarial loss: 0.593069\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622917; batch adversarial loss: 0.580076\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586533; batch adversarial loss: 0.633904\n",
      "epoch 4; iter: 0; batch classifier loss: 0.504032; batch adversarial loss: 0.540876\n",
      "epoch 5; iter: 0; batch classifier loss: 0.501094; batch adversarial loss: 0.565062\n",
      "epoch 6; iter: 0; batch classifier loss: 0.485903; batch adversarial loss: 0.589199\n",
      "epoch 7; iter: 0; batch classifier loss: 0.452581; batch adversarial loss: 0.565060\n",
      "epoch 8; iter: 0; batch classifier loss: 0.473150; batch adversarial loss: 0.603425\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404911; batch adversarial loss: 0.551220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.386041; batch adversarial loss: 0.599141\n",
      "epoch 11; iter: 0; batch classifier loss: 0.466139; batch adversarial loss: 0.574505\n",
      "epoch 12; iter: 0; batch classifier loss: 0.399129; batch adversarial loss: 0.605983\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347541; batch adversarial loss: 0.606578\n",
      "epoch 14; iter: 0; batch classifier loss: 0.369516; batch adversarial loss: 0.566840\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357345; batch adversarial loss: 0.597157\n",
      "epoch 16; iter: 0; batch classifier loss: 0.323277; batch adversarial loss: 0.622633\n",
      "epoch 17; iter: 0; batch classifier loss: 0.369193; batch adversarial loss: 0.653007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.332822; batch adversarial loss: 0.602631\n",
      "epoch 19; iter: 0; batch classifier loss: 0.277708; batch adversarial loss: 0.555849\n",
      "epoch 20; iter: 0; batch classifier loss: 0.326026; batch adversarial loss: 0.574428\n",
      "epoch 21; iter: 0; batch classifier loss: 0.313420; batch adversarial loss: 0.607203\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348639; batch adversarial loss: 0.601349\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280320; batch adversarial loss: 0.561188\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335760; batch adversarial loss: 0.557163\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384118; batch adversarial loss: 0.616180\n",
      "epoch 26; iter: 0; batch classifier loss: 0.310415; batch adversarial loss: 0.550981\n",
      "epoch 27; iter: 0; batch classifier loss: 0.289635; batch adversarial loss: 0.581339\n",
      "epoch 28; iter: 0; batch classifier loss: 0.317931; batch adversarial loss: 0.604410\n",
      "epoch 29; iter: 0; batch classifier loss: 0.268292; batch adversarial loss: 0.575914\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319060; batch adversarial loss: 0.634008\n",
      "epoch 31; iter: 0; batch classifier loss: 0.308711; batch adversarial loss: 0.575012\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246388; batch adversarial loss: 0.560034\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233351; batch adversarial loss: 0.651215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.221191; batch adversarial loss: 0.610422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.257686; batch adversarial loss: 0.599207\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238043; batch adversarial loss: 0.565942\n",
      "epoch 37; iter: 0; batch classifier loss: 0.235275; batch adversarial loss: 0.575027\n",
      "epoch 38; iter: 0; batch classifier loss: 0.285674; batch adversarial loss: 0.596318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.297440; batch adversarial loss: 0.577757\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223363; batch adversarial loss: 0.617002\n",
      "epoch 41; iter: 0; batch classifier loss: 0.221052; batch adversarial loss: 0.602165\n",
      "epoch 42; iter: 0; batch classifier loss: 0.292944; batch adversarial loss: 0.621914\n",
      "epoch 43; iter: 0; batch classifier loss: 0.245619; batch adversarial loss: 0.608379\n",
      "epoch 44; iter: 0; batch classifier loss: 0.279838; batch adversarial loss: 0.629326\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246534; batch adversarial loss: 0.589840\n",
      "epoch 46; iter: 0; batch classifier loss: 0.241376; batch adversarial loss: 0.582213\n",
      "epoch 47; iter: 0; batch classifier loss: 0.208415; batch adversarial loss: 0.635536\n",
      "epoch 48; iter: 0; batch classifier loss: 0.254219; batch adversarial loss: 0.593424\n",
      "epoch 49; iter: 0; batch classifier loss: 0.220232; batch adversarial loss: 0.578479\n",
      "\n",
      "=== ADV in-proc (AIF360) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR     FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                     \n",
       "0    0.666667  0.0625  0.666667       0.157895  0.894737\n",
       "1    0.864583  0.2400  0.864583       0.650685  0.828767"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4928 | EO diff: 0.1979 | trained on X_train_ready\n"
     ]
    }
   ],
   "source": [
    "#Adversarial Debiasing - In-processing by AIF360\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "    # TF1 graph mode - required by AIF360's implementation \n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "    # Build AIF360 datasets with FEATURES + label + sensitive attribute\n",
    "    bld_tr = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "            pd.Series(y_train, name=label_name),\n",
    "            pd.Series(A_train, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    bld_te = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "            pd.Series(y_test, name=label_name),\n",
    "            pd.Series(A_test, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    # Train + predict inside a TF1 session\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            scope_name=\"adv_debias\",\n",
    "            debias=True,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "\n",
    "        # Extract labels and (if available) scores\n",
    "        yhat_adv = pred_te.labels.ravel().astype(int)\n",
    "        scores_adv = getattr(pred_te, \"scores\", None)\n",
    "        if scores_adv is None:\n",
    "            scores_adv = yhat_adv.astype(float)\n",
    "\n",
    "    # Clean up TF graph\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sess.close()\n",
    "\n",
    "    # Same structured output as other models\n",
    "    _ = report_model(\n",
    "        \"ADV in-proc (AIF360)\",\n",
    "        y_test, yhat_adv, A_test,\n",
    "        scores=scores_adv,\n",
    "        note=\"trained on X_train_ready\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"AdversarialDebiasing skipped:\", type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c7b8",
   "metadata": {},
   "source": [
    "## ADV In-processing (AIF360)\n",
    "\n",
    "### Results overview\n",
    "| Variant        | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|----------------|---------:|--------:|------------------:|------:|\n",
    "| ADV in-proc    | 0.8424   | 0.4928  | 0.1979            | 0.6907 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### ADV in-proc\n",
    "- **Selection rate:** 0 **0.158**, 1 **0.651** → DP gap **0.493** (very large).  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.865** → EO gap **0.198** (notable disparity, males detected more often).  \n",
    "- **FPR:** 0 **0.063**, 1 **0.240** (males much higher).  \n",
    "- **Accuracy:** Female **0.895**, Male **0.829** → stronger performance for females.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **DP disparity is the worst among your ADV runs (0.493)**, showing males are far more frequently selected.  \n",
    "- **EO gap is also higher (0.198)**, reflecting unequal recall between sexes.  \n",
    "- **Accuracy (0.842)** is solid overall, but fairness outcomes are weaker compared to earlier ADV configurations.  \n",
    "- **Interpretation:** This ADV setup improves neither DP nor EO compared to previous runs — fairness worsens, even though accuracy remains competitive.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e29721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.849574; batch adversarial loss: 0.678034\n",
      "epoch 1; iter: 0; batch classifier loss: 0.751289; batch adversarial loss: 0.679811\n",
      "epoch 2; iter: 0; batch classifier loss: 0.687964; batch adversarial loss: 0.705974\n",
      "epoch 3; iter: 0; batch classifier loss: 0.666234; batch adversarial loss: 0.680836\n",
      "epoch 4; iter: 0; batch classifier loss: 0.656251; batch adversarial loss: 0.691837\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569755; batch adversarial loss: 0.664430\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582162; batch adversarial loss: 0.673232\n",
      "epoch 7; iter: 0; batch classifier loss: 0.496106; batch adversarial loss: 0.715469\n",
      "epoch 8; iter: 0; batch classifier loss: 0.465372; batch adversarial loss: 0.695565\n",
      "epoch 9; iter: 0; batch classifier loss: 0.495062; batch adversarial loss: 0.654428\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590101; batch adversarial loss: 0.651189\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490156; batch adversarial loss: 0.663060\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505251; batch adversarial loss: 0.665122\n",
      "epoch 13; iter: 0; batch classifier loss: 0.466851; batch adversarial loss: 0.632741\n",
      "epoch 14; iter: 0; batch classifier loss: 0.518943; batch adversarial loss: 0.620464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.467885; batch adversarial loss: 0.671130\n",
      "epoch 16; iter: 0; batch classifier loss: 0.383128; batch adversarial loss: 0.681093\n",
      "epoch 17; iter: 0; batch classifier loss: 0.457473; batch adversarial loss: 0.626934\n",
      "epoch 18; iter: 0; batch classifier loss: 0.522638; batch adversarial loss: 0.652548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.466487; batch adversarial loss: 0.609487\n",
      "epoch 20; iter: 0; batch classifier loss: 0.370369; batch adversarial loss: 0.676387\n",
      "epoch 21; iter: 0; batch classifier loss: 0.376623; batch adversarial loss: 0.624787\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319990; batch adversarial loss: 0.607207\n",
      "epoch 23; iter: 0; batch classifier loss: 0.391728; batch adversarial loss: 0.642420\n",
      "epoch 24; iter: 0; batch classifier loss: 0.366438; batch adversarial loss: 0.682157\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443272; batch adversarial loss: 0.601214\n",
      "epoch 26; iter: 0; batch classifier loss: 0.469984; batch adversarial loss: 0.631344\n",
      "epoch 27; iter: 0; batch classifier loss: 0.382268; batch adversarial loss: 0.602210\n",
      "epoch 28; iter: 0; batch classifier loss: 0.385378; batch adversarial loss: 0.636170\n",
      "epoch 29; iter: 0; batch classifier loss: 0.414787; batch adversarial loss: 0.670607\n",
      "epoch 30; iter: 0; batch classifier loss: 0.363992; batch adversarial loss: 0.619753\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355430; batch adversarial loss: 0.654897\n",
      "epoch 32; iter: 0; batch classifier loss: 0.395409; batch adversarial loss: 0.627800\n",
      "epoch 33; iter: 0; batch classifier loss: 0.396407; batch adversarial loss: 0.594863\n",
      "epoch 34; iter: 0; batch classifier loss: 0.332287; batch adversarial loss: 0.636648\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256761; batch adversarial loss: 0.567402\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377677; batch adversarial loss: 0.661554\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255061; batch adversarial loss: 0.662789\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434116; batch adversarial loss: 0.637942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401103; batch adversarial loss: 0.618966\n",
      "epoch 0; iter: 0; batch classifier loss: 0.637801; batch adversarial loss: 0.694179\n",
      "epoch 1; iter: 0; batch classifier loss: 0.619164; batch adversarial loss: 0.666924\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607929; batch adversarial loss: 0.680913\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588202; batch adversarial loss: 0.676851\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598559; batch adversarial loss: 0.660575\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552260; batch adversarial loss: 0.660777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471159; batch adversarial loss: 0.651756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.468890; batch adversarial loss: 0.659030\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449276; batch adversarial loss: 0.669937\n",
      "epoch 9; iter: 0; batch classifier loss: 0.491795; batch adversarial loss: 0.643863\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466442; batch adversarial loss: 0.641542\n",
      "epoch 11; iter: 0; batch classifier loss: 0.380367; batch adversarial loss: 0.634264\n",
      "epoch 12; iter: 0; batch classifier loss: 0.361766; batch adversarial loss: 0.636028\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512359; batch adversarial loss: 0.604193\n",
      "epoch 14; iter: 0; batch classifier loss: 0.354118; batch adversarial loss: 0.622267\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377366; batch adversarial loss: 0.627304\n",
      "epoch 16; iter: 0; batch classifier loss: 0.369444; batch adversarial loss: 0.650825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.398533; batch adversarial loss: 0.602811\n",
      "epoch 18; iter: 0; batch classifier loss: 0.366542; batch adversarial loss: 0.621970\n",
      "epoch 19; iter: 0; batch classifier loss: 0.379185; batch adversarial loss: 0.618550\n",
      "epoch 20; iter: 0; batch classifier loss: 0.396563; batch adversarial loss: 0.646221\n",
      "epoch 21; iter: 0; batch classifier loss: 0.414558; batch adversarial loss: 0.581283\n",
      "epoch 22; iter: 0; batch classifier loss: 0.395896; batch adversarial loss: 0.580701\n",
      "epoch 23; iter: 0; batch classifier loss: 0.256392; batch adversarial loss: 0.601409\n",
      "epoch 24; iter: 0; batch classifier loss: 0.251323; batch adversarial loss: 0.601151\n",
      "epoch 25; iter: 0; batch classifier loss: 0.349371; batch adversarial loss: 0.621114\n",
      "epoch 26; iter: 0; batch classifier loss: 0.239606; batch adversarial loss: 0.596531\n",
      "epoch 27; iter: 0; batch classifier loss: 0.254919; batch adversarial loss: 0.598305\n",
      "epoch 28; iter: 0; batch classifier loss: 0.304160; batch adversarial loss: 0.582304\n",
      "epoch 29; iter: 0; batch classifier loss: 0.373945; batch adversarial loss: 0.572277\n",
      "epoch 30; iter: 0; batch classifier loss: 0.239134; batch adversarial loss: 0.596898\n",
      "epoch 31; iter: 0; batch classifier loss: 0.319966; batch adversarial loss: 0.674505\n",
      "epoch 32; iter: 0; batch classifier loss: 0.220108; batch adversarial loss: 0.614140\n",
      "epoch 33; iter: 0; batch classifier loss: 0.277311; batch adversarial loss: 0.577068\n",
      "epoch 34; iter: 0; batch classifier loss: 0.236774; batch adversarial loss: 0.584371\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362324; batch adversarial loss: 0.584002\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231845; batch adversarial loss: 0.565131\n",
      "epoch 37; iter: 0; batch classifier loss: 0.208023; batch adversarial loss: 0.597054\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289748; batch adversarial loss: 0.580929\n",
      "epoch 39; iter: 0; batch classifier loss: 0.174493; batch adversarial loss: 0.586034\n",
      "epoch 0; iter: 0; batch classifier loss: 0.877147; batch adversarial loss: 0.662447\n",
      "epoch 1; iter: 0; batch classifier loss: 0.829917; batch adversarial loss: 0.663580\n",
      "epoch 2; iter: 0; batch classifier loss: 0.828161; batch adversarial loss: 0.673303\n",
      "epoch 3; iter: 0; batch classifier loss: 0.804457; batch adversarial loss: 0.655472\n",
      "epoch 4; iter: 0; batch classifier loss: 0.781294; batch adversarial loss: 0.649910\n",
      "epoch 5; iter: 0; batch classifier loss: 0.729228; batch adversarial loss: 0.664500\n",
      "epoch 6; iter: 0; batch classifier loss: 0.700250; batch adversarial loss: 0.627564\n",
      "epoch 7; iter: 0; batch classifier loss: 0.684611; batch adversarial loss: 0.692757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633779; batch adversarial loss: 0.665328\n",
      "epoch 9; iter: 0; batch classifier loss: 0.676295; batch adversarial loss: 0.631150\n",
      "epoch 10; iter: 0; batch classifier loss: 0.641451; batch adversarial loss: 0.662622\n",
      "epoch 11; iter: 0; batch classifier loss: 0.624132; batch adversarial loss: 0.654081\n",
      "epoch 12; iter: 0; batch classifier loss: 0.619791; batch adversarial loss: 0.655315\n",
      "epoch 13; iter: 0; batch classifier loss: 0.600941; batch adversarial loss: 0.615146\n",
      "epoch 14; iter: 0; batch classifier loss: 0.567530; batch adversarial loss: 0.671882\n",
      "epoch 15; iter: 0; batch classifier loss: 0.587136; batch adversarial loss: 0.648615\n",
      "epoch 16; iter: 0; batch classifier loss: 0.528096; batch adversarial loss: 0.648062\n",
      "epoch 17; iter: 0; batch classifier loss: 0.557320; batch adversarial loss: 0.644119\n",
      "epoch 18; iter: 0; batch classifier loss: 0.570699; batch adversarial loss: 0.608314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.503934; batch adversarial loss: 0.622415\n",
      "epoch 20; iter: 0; batch classifier loss: 0.512881; batch adversarial loss: 0.646577\n",
      "epoch 21; iter: 0; batch classifier loss: 0.498778; batch adversarial loss: 0.617679\n",
      "epoch 22; iter: 0; batch classifier loss: 0.530155; batch adversarial loss: 0.643879\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466451; batch adversarial loss: 0.660317\n",
      "epoch 24; iter: 0; batch classifier loss: 0.495441; batch adversarial loss: 0.630829\n",
      "epoch 25; iter: 0; batch classifier loss: 0.495962; batch adversarial loss: 0.640672\n",
      "epoch 26; iter: 0; batch classifier loss: 0.485451; batch adversarial loss: 0.661978\n",
      "epoch 27; iter: 0; batch classifier loss: 0.495700; batch adversarial loss: 0.619832\n",
      "epoch 28; iter: 0; batch classifier loss: 0.481897; batch adversarial loss: 0.681239\n",
      "epoch 29; iter: 0; batch classifier loss: 0.436486; batch adversarial loss: 0.651802\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405112; batch adversarial loss: 0.678007\n",
      "epoch 31; iter: 0; batch classifier loss: 0.499582; batch adversarial loss: 0.650147\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435103; batch adversarial loss: 0.624212\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427795; batch adversarial loss: 0.667016\n",
      "epoch 34; iter: 0; batch classifier loss: 0.478709; batch adversarial loss: 0.669082\n",
      "epoch 35; iter: 0; batch classifier loss: 0.472788; batch adversarial loss: 0.633899\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430539; batch adversarial loss: 0.666874\n",
      "epoch 37; iter: 0; batch classifier loss: 0.459791; batch adversarial loss: 0.626539\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403059; batch adversarial loss: 0.616487\n",
      "epoch 39; iter: 0; batch classifier loss: 0.409955; batch adversarial loss: 0.601196\n",
      "epoch 0; iter: 0; batch classifier loss: 0.691252; batch adversarial loss: 0.667816\n",
      "epoch 1; iter: 0; batch classifier loss: 0.635983; batch adversarial loss: 0.655570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.644699; batch adversarial loss: 0.664028\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612596; batch adversarial loss: 0.666675\n",
      "epoch 4; iter: 0; batch classifier loss: 0.624075; batch adversarial loss: 0.653267\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562560; batch adversarial loss: 0.648269\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543389; batch adversarial loss: 0.665277\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517324; batch adversarial loss: 0.653995\n",
      "epoch 8; iter: 0; batch classifier loss: 0.536417; batch adversarial loss: 0.665302\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433962; batch adversarial loss: 0.653596\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480205; batch adversarial loss: 0.660000\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457454; batch adversarial loss: 0.654068\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420503; batch adversarial loss: 0.654427\n",
      "epoch 13; iter: 0; batch classifier loss: 0.454101; batch adversarial loss: 0.647230\n",
      "epoch 14; iter: 0; batch classifier loss: 0.429109; batch adversarial loss: 0.642615\n",
      "epoch 15; iter: 0; batch classifier loss: 0.439945; batch adversarial loss: 0.649539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.377472; batch adversarial loss: 0.649044\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417041; batch adversarial loss: 0.645684\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370204; batch adversarial loss: 0.637881\n",
      "epoch 19; iter: 0; batch classifier loss: 0.391726; batch adversarial loss: 0.627713\n",
      "epoch 20; iter: 0; batch classifier loss: 0.404082; batch adversarial loss: 0.644493\n",
      "epoch 21; iter: 0; batch classifier loss: 0.411789; batch adversarial loss: 0.627171\n",
      "epoch 22; iter: 0; batch classifier loss: 0.335835; batch adversarial loss: 0.636711\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380119; batch adversarial loss: 0.618164\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388379; batch adversarial loss: 0.620614\n",
      "epoch 25; iter: 0; batch classifier loss: 0.337362; batch adversarial loss: 0.644492\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400257; batch adversarial loss: 0.643391\n",
      "epoch 27; iter: 0; batch classifier loss: 0.381220; batch adversarial loss: 0.626146\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350710; batch adversarial loss: 0.642193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.361918; batch adversarial loss: 0.644094\n",
      "epoch 30; iter: 0; batch classifier loss: 0.349745; batch adversarial loss: 0.643525\n",
      "epoch 31; iter: 0; batch classifier loss: 0.377544; batch adversarial loss: 0.610222\n",
      "epoch 32; iter: 0; batch classifier loss: 0.349612; batch adversarial loss: 0.627622\n",
      "epoch 33; iter: 0; batch classifier loss: 0.319844; batch adversarial loss: 0.610184\n",
      "epoch 34; iter: 0; batch classifier loss: 0.313785; batch adversarial loss: 0.617797\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358468; batch adversarial loss: 0.629176\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353273; batch adversarial loss: 0.612693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.361167; batch adversarial loss: 0.604879\n",
      "epoch 38; iter: 0; batch classifier loss: 0.391820; batch adversarial loss: 0.606251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.345231; batch adversarial loss: 0.633413\n",
      "epoch 0; iter: 0; batch classifier loss: 0.626748; batch adversarial loss: 0.593236\n",
      "epoch 1; iter: 0; batch classifier loss: 0.725362; batch adversarial loss: 0.553052\n",
      "epoch 2; iter: 0; batch classifier loss: 0.530426; batch adversarial loss: 0.580276\n",
      "epoch 3; iter: 0; batch classifier loss: 0.556719; batch adversarial loss: 0.601065\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557716; batch adversarial loss: 0.545821\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508239; batch adversarial loss: 0.569259\n",
      "epoch 6; iter: 0; batch classifier loss: 0.464521; batch adversarial loss: 0.556512\n",
      "epoch 7; iter: 0; batch classifier loss: 0.417399; batch adversarial loss: 0.592388\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497618; batch adversarial loss: 0.551733\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445244; batch adversarial loss: 0.572098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.347533; batch adversarial loss: 0.610784\n",
      "epoch 11; iter: 0; batch classifier loss: 0.390510; batch adversarial loss: 0.607780\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329419; batch adversarial loss: 0.596875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.416631; batch adversarial loss: 0.596661\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310634; batch adversarial loss: 0.605416\n",
      "epoch 15; iter: 0; batch classifier loss: 0.310472; batch adversarial loss: 0.590077\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399269; batch adversarial loss: 0.673366\n",
      "epoch 17; iter: 0; batch classifier loss: 0.429189; batch adversarial loss: 0.528021\n",
      "epoch 18; iter: 0; batch classifier loss: 0.352641; batch adversarial loss: 0.633008\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459043; batch adversarial loss: 0.563961\n",
      "epoch 20; iter: 0; batch classifier loss: 0.397033; batch adversarial loss: 0.573960\n",
      "epoch 21; iter: 0; batch classifier loss: 0.307382; batch adversarial loss: 0.695207\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316032; batch adversarial loss: 0.638286\n",
      "epoch 23; iter: 0; batch classifier loss: 0.343073; batch adversarial loss: 0.515919\n",
      "epoch 24; iter: 0; batch classifier loss: 0.441151; batch adversarial loss: 0.518135\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423712; batch adversarial loss: 0.594327\n",
      "epoch 26; iter: 0; batch classifier loss: 0.389743; batch adversarial loss: 0.617453\n",
      "epoch 27; iter: 0; batch classifier loss: 0.342301; batch adversarial loss: 0.598363\n",
      "epoch 28; iter: 0; batch classifier loss: 0.275583; batch adversarial loss: 0.566282\n",
      "epoch 29; iter: 0; batch classifier loss: 0.277963; batch adversarial loss: 0.536349\n",
      "epoch 30; iter: 0; batch classifier loss: 0.256832; batch adversarial loss: 0.618465\n",
      "epoch 31; iter: 0; batch classifier loss: 0.364075; batch adversarial loss: 0.591593\n",
      "epoch 32; iter: 0; batch classifier loss: 0.342307; batch adversarial loss: 0.556253\n",
      "epoch 33; iter: 0; batch classifier loss: 0.251759; batch adversarial loss: 0.567416\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284688; batch adversarial loss: 0.560320\n",
      "epoch 35; iter: 0; batch classifier loss: 0.254624; batch adversarial loss: 0.665562\n",
      "epoch 36; iter: 0; batch classifier loss: 0.271876; batch adversarial loss: 0.568932\n",
      "epoch 37; iter: 0; batch classifier loss: 0.281956; batch adversarial loss: 0.646998\n",
      "epoch 38; iter: 0; batch classifier loss: 0.248478; batch adversarial loss: 0.660999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310005; batch adversarial loss: 0.577022\n",
      "epoch 40; iter: 0; batch classifier loss: 0.281319; batch adversarial loss: 0.558619\n",
      "epoch 41; iter: 0; batch classifier loss: 0.295449; batch adversarial loss: 0.586562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.245825; batch adversarial loss: 0.508221\n",
      "epoch 43; iter: 0; batch classifier loss: 0.281095; batch adversarial loss: 0.587770\n",
      "epoch 44; iter: 0; batch classifier loss: 0.410594; batch adversarial loss: 0.625515\n",
      "epoch 45; iter: 0; batch classifier loss: 0.241551; batch adversarial loss: 0.543270\n",
      "epoch 46; iter: 0; batch classifier loss: 0.200252; batch adversarial loss: 0.522383\n",
      "epoch 47; iter: 0; batch classifier loss: 0.281609; batch adversarial loss: 0.565996\n",
      "epoch 48; iter: 0; batch classifier loss: 0.302424; batch adversarial loss: 0.573897\n",
      "epoch 49; iter: 0; batch classifier loss: 0.250870; batch adversarial loss: 0.568289\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215375; batch adversarial loss: 0.592032\n",
      "epoch 51; iter: 0; batch classifier loss: 0.279362; batch adversarial loss: 0.667701\n",
      "epoch 52; iter: 0; batch classifier loss: 0.231601; batch adversarial loss: 0.650138\n",
      "epoch 53; iter: 0; batch classifier loss: 0.191052; batch adversarial loss: 0.678119\n",
      "epoch 54; iter: 0; batch classifier loss: 0.331347; batch adversarial loss: 0.526256\n",
      "epoch 55; iter: 0; batch classifier loss: 0.309789; batch adversarial loss: 0.624117\n",
      "epoch 56; iter: 0; batch classifier loss: 0.295276; batch adversarial loss: 0.473204\n",
      "epoch 57; iter: 0; batch classifier loss: 0.297730; batch adversarial loss: 0.455561\n",
      "epoch 58; iter: 0; batch classifier loss: 0.201008; batch adversarial loss: 0.629538\n",
      "epoch 59; iter: 0; batch classifier loss: 0.269440; batch adversarial loss: 0.507543\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769379; batch adversarial loss: 0.698289\n",
      "epoch 1; iter: 0; batch classifier loss: 0.688577; batch adversarial loss: 0.652861\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621734; batch adversarial loss: 0.630635\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652213; batch adversarial loss: 0.652850\n",
      "epoch 4; iter: 0; batch classifier loss: 0.556495; batch adversarial loss: 0.676053\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536817; batch adversarial loss: 0.678548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.460320; batch adversarial loss: 0.618285\n",
      "epoch 7; iter: 0; batch classifier loss: 0.416831; batch adversarial loss: 0.641537\n",
      "epoch 8; iter: 0; batch classifier loss: 0.444361; batch adversarial loss: 0.669842\n",
      "epoch 9; iter: 0; batch classifier loss: 0.464872; batch adversarial loss: 0.682772\n",
      "epoch 10; iter: 0; batch classifier loss: 0.353927; batch adversarial loss: 0.589313\n",
      "epoch 11; iter: 0; batch classifier loss: 0.331308; batch adversarial loss: 0.618073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.411931; batch adversarial loss: 0.588952\n",
      "epoch 13; iter: 0; batch classifier loss: 0.394344; batch adversarial loss: 0.616175\n",
      "epoch 14; iter: 0; batch classifier loss: 0.429495; batch adversarial loss: 0.583840\n",
      "epoch 15; iter: 0; batch classifier loss: 0.402284; batch adversarial loss: 0.599968\n",
      "epoch 16; iter: 0; batch classifier loss: 0.336045; batch adversarial loss: 0.629208\n",
      "epoch 17; iter: 0; batch classifier loss: 0.320750; batch adversarial loss: 0.599221\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355316; batch adversarial loss: 0.599492\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316292; batch adversarial loss: 0.567925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.410376; batch adversarial loss: 0.651898\n",
      "epoch 21; iter: 0; batch classifier loss: 0.359825; batch adversarial loss: 0.630398\n",
      "epoch 22; iter: 0; batch classifier loss: 0.390478; batch adversarial loss: 0.595887\n",
      "epoch 23; iter: 0; batch classifier loss: 0.319829; batch adversarial loss: 0.629208\n",
      "epoch 24; iter: 0; batch classifier loss: 0.345740; batch adversarial loss: 0.647895\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342113; batch adversarial loss: 0.530202\n",
      "epoch 26; iter: 0; batch classifier loss: 0.346534; batch adversarial loss: 0.566946\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293485; batch adversarial loss: 0.690413\n",
      "epoch 28; iter: 0; batch classifier loss: 0.291987; batch adversarial loss: 0.708696\n",
      "epoch 29; iter: 0; batch classifier loss: 0.295827; batch adversarial loss: 0.580137\n",
      "epoch 30; iter: 0; batch classifier loss: 0.376419; batch adversarial loss: 0.625192\n",
      "epoch 31; iter: 0; batch classifier loss: 0.270943; batch adversarial loss: 0.594042\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238570; batch adversarial loss: 0.588173\n",
      "epoch 33; iter: 0; batch classifier loss: 0.283384; batch adversarial loss: 0.667016\n",
      "epoch 34; iter: 0; batch classifier loss: 0.276350; batch adversarial loss: 0.625300\n",
      "epoch 35; iter: 0; batch classifier loss: 0.316312; batch adversarial loss: 0.574550\n",
      "epoch 36; iter: 0; batch classifier loss: 0.236619; batch adversarial loss: 0.525436\n",
      "epoch 37; iter: 0; batch classifier loss: 0.304138; batch adversarial loss: 0.572106\n",
      "epoch 38; iter: 0; batch classifier loss: 0.241898; batch adversarial loss: 0.644433\n",
      "epoch 39; iter: 0; batch classifier loss: 0.235899; batch adversarial loss: 0.616458\n",
      "epoch 40; iter: 0; batch classifier loss: 0.270495; batch adversarial loss: 0.525812\n",
      "epoch 41; iter: 0; batch classifier loss: 0.202679; batch adversarial loss: 0.526635\n",
      "epoch 42; iter: 0; batch classifier loss: 0.250922; batch adversarial loss: 0.638143\n",
      "epoch 43; iter: 0; batch classifier loss: 0.181411; batch adversarial loss: 0.508188\n",
      "epoch 44; iter: 0; batch classifier loss: 0.224844; batch adversarial loss: 0.653314\n",
      "epoch 45; iter: 0; batch classifier loss: 0.239124; batch adversarial loss: 0.527180\n",
      "epoch 46; iter: 0; batch classifier loss: 0.182131; batch adversarial loss: 0.618500\n",
      "epoch 47; iter: 0; batch classifier loss: 0.259201; batch adversarial loss: 0.622494\n",
      "epoch 48; iter: 0; batch classifier loss: 0.208576; batch adversarial loss: 0.705224\n",
      "epoch 49; iter: 0; batch classifier loss: 0.226372; batch adversarial loss: 0.540232\n",
      "epoch 50; iter: 0; batch classifier loss: 0.234350; batch adversarial loss: 0.564282\n",
      "epoch 51; iter: 0; batch classifier loss: 0.215712; batch adversarial loss: 0.603352\n",
      "epoch 52; iter: 0; batch classifier loss: 0.201006; batch adversarial loss: 0.633639\n",
      "epoch 53; iter: 0; batch classifier loss: 0.177688; batch adversarial loss: 0.543812\n",
      "epoch 54; iter: 0; batch classifier loss: 0.228780; batch adversarial loss: 0.550885\n",
      "epoch 55; iter: 0; batch classifier loss: 0.270720; batch adversarial loss: 0.581677\n",
      "epoch 56; iter: 0; batch classifier loss: 0.193806; batch adversarial loss: 0.517067\n",
      "epoch 57; iter: 0; batch classifier loss: 0.170245; batch adversarial loss: 0.523767\n",
      "epoch 58; iter: 0; batch classifier loss: 0.165790; batch adversarial loss: 0.674871\n",
      "epoch 59; iter: 0; batch classifier loss: 0.231315; batch adversarial loss: 0.598398\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702990; batch adversarial loss: 0.711320\n",
      "epoch 1; iter: 0; batch classifier loss: 0.706735; batch adversarial loss: 0.710639\n",
      "epoch 2; iter: 0; batch classifier loss: 0.674404; batch adversarial loss: 0.707850\n",
      "epoch 3; iter: 0; batch classifier loss: 0.660803; batch adversarial loss: 0.703604\n",
      "epoch 4; iter: 0; batch classifier loss: 0.643768; batch adversarial loss: 0.704629\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601204; batch adversarial loss: 0.704123\n",
      "epoch 6; iter: 0; batch classifier loss: 0.601244; batch adversarial loss: 0.699363\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602525; batch adversarial loss: 0.697500\n",
      "epoch 8; iter: 0; batch classifier loss: 0.545496; batch adversarial loss: 0.695561\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529463; batch adversarial loss: 0.694678\n",
      "epoch 10; iter: 0; batch classifier loss: 0.515241; batch adversarial loss: 0.691341\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528249; batch adversarial loss: 0.690570\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468424; batch adversarial loss: 0.686692\n",
      "epoch 13; iter: 0; batch classifier loss: 0.506635; batch adversarial loss: 0.685447\n",
      "epoch 14; iter: 0; batch classifier loss: 0.473659; batch adversarial loss: 0.685491\n",
      "epoch 15; iter: 0; batch classifier loss: 0.511025; batch adversarial loss: 0.685318\n",
      "epoch 16; iter: 0; batch classifier loss: 0.468762; batch adversarial loss: 0.683913\n",
      "epoch 17; iter: 0; batch classifier loss: 0.450416; batch adversarial loss: 0.677520\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511468; batch adversarial loss: 0.674548\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440105; batch adversarial loss: 0.679892\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474877; batch adversarial loss: 0.673006\n",
      "epoch 21; iter: 0; batch classifier loss: 0.438469; batch adversarial loss: 0.671722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439912; batch adversarial loss: 0.671823\n",
      "epoch 23; iter: 0; batch classifier loss: 0.452550; batch adversarial loss: 0.666081\n",
      "epoch 24; iter: 0; batch classifier loss: 0.443565; batch adversarial loss: 0.661476\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422917; batch adversarial loss: 0.670087\n",
      "epoch 26; iter: 0; batch classifier loss: 0.396874; batch adversarial loss: 0.663987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389108; batch adversarial loss: 0.654404\n",
      "epoch 28; iter: 0; batch classifier loss: 0.431892; batch adversarial loss: 0.659490\n",
      "epoch 29; iter: 0; batch classifier loss: 0.426236; batch adversarial loss: 0.669053\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419007; batch adversarial loss: 0.658850\n",
      "epoch 31; iter: 0; batch classifier loss: 0.450938; batch adversarial loss: 0.655041\n",
      "epoch 32; iter: 0; batch classifier loss: 0.392125; batch adversarial loss: 0.664202\n",
      "epoch 33; iter: 0; batch classifier loss: 0.357373; batch adversarial loss: 0.654854\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390621; batch adversarial loss: 0.648451\n",
      "epoch 35; iter: 0; batch classifier loss: 0.378830; batch adversarial loss: 0.646598\n",
      "epoch 36; iter: 0; batch classifier loss: 0.426851; batch adversarial loss: 0.651865\n",
      "epoch 37; iter: 0; batch classifier loss: 0.375558; batch adversarial loss: 0.645202\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372024; batch adversarial loss: 0.626318\n",
      "epoch 39; iter: 0; batch classifier loss: 0.368326; batch adversarial loss: 0.649263\n",
      "epoch 40; iter: 0; batch classifier loss: 0.375087; batch adversarial loss: 0.641081\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384438; batch adversarial loss: 0.637248\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355624; batch adversarial loss: 0.643984\n",
      "epoch 43; iter: 0; batch classifier loss: 0.407490; batch adversarial loss: 0.643140\n",
      "epoch 44; iter: 0; batch classifier loss: 0.344613; batch adversarial loss: 0.646822\n",
      "epoch 45; iter: 0; batch classifier loss: 0.423463; batch adversarial loss: 0.625841\n",
      "epoch 46; iter: 0; batch classifier loss: 0.353096; batch adversarial loss: 0.625453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.324512; batch adversarial loss: 0.626880\n",
      "epoch 48; iter: 0; batch classifier loss: 0.340100; batch adversarial loss: 0.626479\n",
      "epoch 49; iter: 0; batch classifier loss: 0.319730; batch adversarial loss: 0.649054\n",
      "epoch 50; iter: 0; batch classifier loss: 0.314207; batch adversarial loss: 0.637624\n",
      "epoch 51; iter: 0; batch classifier loss: 0.341869; batch adversarial loss: 0.634759\n",
      "epoch 52; iter: 0; batch classifier loss: 0.310540; batch adversarial loss: 0.638904\n",
      "epoch 53; iter: 0; batch classifier loss: 0.421423; batch adversarial loss: 0.630428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.351807; batch adversarial loss: 0.625375\n",
      "epoch 55; iter: 0; batch classifier loss: 0.375171; batch adversarial loss: 0.623204\n",
      "epoch 56; iter: 0; batch classifier loss: 0.352119; batch adversarial loss: 0.626659\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325184; batch adversarial loss: 0.651306\n",
      "epoch 58; iter: 0; batch classifier loss: 0.294058; batch adversarial loss: 0.599293\n",
      "epoch 59; iter: 0; batch classifier loss: 0.345441; batch adversarial loss: 0.611999\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697246; batch adversarial loss: 0.728501\n",
      "epoch 1; iter: 0; batch classifier loss: 0.683076; batch adversarial loss: 0.740860\n",
      "epoch 2; iter: 0; batch classifier loss: 0.615713; batch adversarial loss: 0.723842\n",
      "epoch 3; iter: 0; batch classifier loss: 0.588719; batch adversarial loss: 0.723523\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566478; batch adversarial loss: 0.720021\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552615; batch adversarial loss: 0.717132\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552578; batch adversarial loss: 0.712385\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516179; batch adversarial loss: 0.701995\n",
      "epoch 8; iter: 0; batch classifier loss: 0.484590; batch adversarial loss: 0.706539\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496513; batch adversarial loss: 0.707453\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449570; batch adversarial loss: 0.698650\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440618; batch adversarial loss: 0.696744\n",
      "epoch 12; iter: 0; batch classifier loss: 0.439917; batch adversarial loss: 0.691988\n",
      "epoch 13; iter: 0; batch classifier loss: 0.470383; batch adversarial loss: 0.700289\n",
      "epoch 14; iter: 0; batch classifier loss: 0.386656; batch adversarial loss: 0.686982\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422580; batch adversarial loss: 0.696079\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487928; batch adversarial loss: 0.694587\n",
      "epoch 17; iter: 0; batch classifier loss: 0.417776; batch adversarial loss: 0.675028\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398312; batch adversarial loss: 0.670564\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400630; batch adversarial loss: 0.678467\n",
      "epoch 20; iter: 0; batch classifier loss: 0.397555; batch adversarial loss: 0.671826\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504384; batch adversarial loss: 0.686138\n",
      "epoch 22; iter: 0; batch classifier loss: 0.405278; batch adversarial loss: 0.681025\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456100; batch adversarial loss: 0.694140\n",
      "epoch 24; iter: 0; batch classifier loss: 0.436873; batch adversarial loss: 0.672592\n",
      "epoch 25; iter: 0; batch classifier loss: 0.420650; batch adversarial loss: 0.669707\n",
      "epoch 26; iter: 0; batch classifier loss: 0.452753; batch adversarial loss: 0.681226\n",
      "epoch 27; iter: 0; batch classifier loss: 0.391887; batch adversarial loss: 0.664551\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382540; batch adversarial loss: 0.654034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.391828; batch adversarial loss: 0.671950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.408021; batch adversarial loss: 0.668393\n",
      "epoch 31; iter: 0; batch classifier loss: 0.350067; batch adversarial loss: 0.666072\n",
      "epoch 32; iter: 0; batch classifier loss: 0.366401; batch adversarial loss: 0.661661\n",
      "epoch 33; iter: 0; batch classifier loss: 0.384272; batch adversarial loss: 0.656895\n",
      "epoch 34; iter: 0; batch classifier loss: 0.373937; batch adversarial loss: 0.644423\n",
      "epoch 35; iter: 0; batch classifier loss: 0.364996; batch adversarial loss: 0.663550\n",
      "epoch 36; iter: 0; batch classifier loss: 0.403576; batch adversarial loss: 0.667290\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387748; batch adversarial loss: 0.653949\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308151; batch adversarial loss: 0.648330\n",
      "epoch 39; iter: 0; batch classifier loss: 0.339743; batch adversarial loss: 0.652599\n",
      "epoch 40; iter: 0; batch classifier loss: 0.324023; batch adversarial loss: 0.630554\n",
      "epoch 41; iter: 0; batch classifier loss: 0.261677; batch adversarial loss: 0.656693\n",
      "epoch 42; iter: 0; batch classifier loss: 0.318503; batch adversarial loss: 0.644955\n",
      "epoch 43; iter: 0; batch classifier loss: 0.312247; batch adversarial loss: 0.620335\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336520; batch adversarial loss: 0.635679\n",
      "epoch 45; iter: 0; batch classifier loss: 0.275967; batch adversarial loss: 0.627416\n",
      "epoch 46; iter: 0; batch classifier loss: 0.272126; batch adversarial loss: 0.614357\n",
      "epoch 47; iter: 0; batch classifier loss: 0.316098; batch adversarial loss: 0.652741\n",
      "epoch 48; iter: 0; batch classifier loss: 0.301526; batch adversarial loss: 0.640244\n",
      "epoch 49; iter: 0; batch classifier loss: 0.298634; batch adversarial loss: 0.653230\n",
      "epoch 50; iter: 0; batch classifier loss: 0.344660; batch adversarial loss: 0.625369\n",
      "epoch 51; iter: 0; batch classifier loss: 0.322533; batch adversarial loss: 0.634513\n",
      "epoch 52; iter: 0; batch classifier loss: 0.421844; batch adversarial loss: 0.643663\n",
      "epoch 53; iter: 0; batch classifier loss: 0.244987; batch adversarial loss: 0.612818\n",
      "epoch 54; iter: 0; batch classifier loss: 0.302082; batch adversarial loss: 0.615731\n",
      "epoch 55; iter: 0; batch classifier loss: 0.286836; batch adversarial loss: 0.608627\n",
      "epoch 56; iter: 0; batch classifier loss: 0.330154; batch adversarial loss: 0.591522\n",
      "epoch 57; iter: 0; batch classifier loss: 0.259157; batch adversarial loss: 0.631363\n",
      "epoch 58; iter: 0; batch classifier loss: 0.222142; batch adversarial loss: 0.646600\n",
      "epoch 59; iter: 0; batch classifier loss: 0.235715; batch adversarial loss: 0.623745\n",
      "epoch 0; iter: 0; batch classifier loss: 0.750160; batch adversarial loss: 0.696379\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671659; batch adversarial loss: 0.721946\n",
      "epoch 2; iter: 0; batch classifier loss: 0.586377; batch adversarial loss: 0.663124\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548752; batch adversarial loss: 0.686803\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520479; batch adversarial loss: 0.640901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.572547; batch adversarial loss: 0.678781\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577633; batch adversarial loss: 0.598020\n",
      "epoch 7; iter: 0; batch classifier loss: 0.523295; batch adversarial loss: 0.569837\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503661; batch adversarial loss: 0.602623\n",
      "epoch 9; iter: 0; batch classifier loss: 0.431759; batch adversarial loss: 0.634733\n",
      "epoch 10; iter: 0; batch classifier loss: 0.516686; batch adversarial loss: 0.627842\n",
      "epoch 11; iter: 0; batch classifier loss: 0.403310; batch adversarial loss: 0.683868\n",
      "epoch 12; iter: 0; batch classifier loss: 0.471237; batch adversarial loss: 0.655435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408622; batch adversarial loss: 0.593525\n",
      "epoch 14; iter: 0; batch classifier loss: 0.402411; batch adversarial loss: 0.628068\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545398; batch adversarial loss: 0.686926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.403639; batch adversarial loss: 0.626775\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441277; batch adversarial loss: 0.618552\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384313; batch adversarial loss: 0.588880\n",
      "epoch 19; iter: 0; batch classifier loss: 0.340315; batch adversarial loss: 0.589399\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475691; batch adversarial loss: 0.673728\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408560; batch adversarial loss: 0.629483\n",
      "epoch 22; iter: 0; batch classifier loss: 0.348654; batch adversarial loss: 0.667644\n",
      "epoch 23; iter: 0; batch classifier loss: 0.374240; batch adversarial loss: 0.621230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.353293; batch adversarial loss: 0.669950\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452011; batch adversarial loss: 0.495293\n",
      "epoch 26; iter: 0; batch classifier loss: 0.361909; batch adversarial loss: 0.580863\n",
      "epoch 27; iter: 0; batch classifier loss: 0.348484; batch adversarial loss: 0.630040\n",
      "epoch 28; iter: 0; batch classifier loss: 0.217868; batch adversarial loss: 0.598696\n",
      "epoch 29; iter: 0; batch classifier loss: 0.294130; batch adversarial loss: 0.590809\n",
      "epoch 30; iter: 0; batch classifier loss: 0.479998; batch adversarial loss: 0.576995\n",
      "epoch 31; iter: 0; batch classifier loss: 0.358946; batch adversarial loss: 0.509626\n",
      "epoch 32; iter: 0; batch classifier loss: 0.340396; batch adversarial loss: 0.604799\n",
      "epoch 33; iter: 0; batch classifier loss: 0.351666; batch adversarial loss: 0.644953\n",
      "epoch 34; iter: 0; batch classifier loss: 0.286628; batch adversarial loss: 0.616533\n",
      "epoch 35; iter: 0; batch classifier loss: 0.293091; batch adversarial loss: 0.633391\n",
      "epoch 36; iter: 0; batch classifier loss: 0.355822; batch adversarial loss: 0.641958\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296299; batch adversarial loss: 0.521193\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259004; batch adversarial loss: 0.640031\n",
      "epoch 39; iter: 0; batch classifier loss: 0.301296; batch adversarial loss: 0.506200\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260522; batch adversarial loss: 0.756145\n",
      "epoch 41; iter: 0; batch classifier loss: 0.402856; batch adversarial loss: 0.704203\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364196; batch adversarial loss: 0.620841\n",
      "epoch 43; iter: 0; batch classifier loss: 0.243008; batch adversarial loss: 0.551753\n",
      "epoch 44; iter: 0; batch classifier loss: 0.288359; batch adversarial loss: 0.617114\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433635; batch adversarial loss: 0.612356\n",
      "epoch 46; iter: 0; batch classifier loss: 0.168449; batch adversarial loss: 0.622791\n",
      "epoch 47; iter: 0; batch classifier loss: 0.296738; batch adversarial loss: 0.620567\n",
      "epoch 48; iter: 0; batch classifier loss: 0.193098; batch adversarial loss: 0.652908\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219364; batch adversarial loss: 0.559506\n",
      "epoch 50; iter: 0; batch classifier loss: 0.283956; batch adversarial loss: 0.514752\n",
      "epoch 51; iter: 0; batch classifier loss: 0.349163; batch adversarial loss: 0.566287\n",
      "epoch 52; iter: 0; batch classifier loss: 0.210601; batch adversarial loss: 0.604590\n",
      "epoch 53; iter: 0; batch classifier loss: 0.314583; batch adversarial loss: 0.557428\n",
      "epoch 54; iter: 0; batch classifier loss: 0.247497; batch adversarial loss: 0.572108\n",
      "epoch 55; iter: 0; batch classifier loss: 0.275680; batch adversarial loss: 0.477050\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.611272\n",
      "epoch 57; iter: 0; batch classifier loss: 0.281501; batch adversarial loss: 0.678704\n",
      "epoch 58; iter: 0; batch classifier loss: 0.280248; batch adversarial loss: 0.640254\n",
      "epoch 59; iter: 0; batch classifier loss: 0.271975; batch adversarial loss: 0.540680\n",
      "epoch 60; iter: 0; batch classifier loss: 0.298494; batch adversarial loss: 0.614861\n",
      "epoch 61; iter: 0; batch classifier loss: 0.158930; batch adversarial loss: 0.594298\n",
      "epoch 62; iter: 0; batch classifier loss: 0.299749; batch adversarial loss: 0.533704\n",
      "epoch 63; iter: 0; batch classifier loss: 0.256277; batch adversarial loss: 0.589752\n",
      "epoch 64; iter: 0; batch classifier loss: 0.166063; batch adversarial loss: 0.573486\n",
      "epoch 65; iter: 0; batch classifier loss: 0.238469; batch adversarial loss: 0.643867\n",
      "epoch 66; iter: 0; batch classifier loss: 0.210068; batch adversarial loss: 0.631385\n",
      "epoch 67; iter: 0; batch classifier loss: 0.274649; batch adversarial loss: 0.498515\n",
      "epoch 68; iter: 0; batch classifier loss: 0.315350; batch adversarial loss: 0.618916\n",
      "epoch 69; iter: 0; batch classifier loss: 0.267196; batch adversarial loss: 0.591239\n",
      "epoch 70; iter: 0; batch classifier loss: 0.296522; batch adversarial loss: 0.578995\n",
      "epoch 71; iter: 0; batch classifier loss: 0.308605; batch adversarial loss: 0.535771\n",
      "epoch 72; iter: 0; batch classifier loss: 0.298072; batch adversarial loss: 0.638792\n",
      "epoch 73; iter: 0; batch classifier loss: 0.305115; batch adversarial loss: 0.537370\n",
      "epoch 74; iter: 0; batch classifier loss: 0.171130; batch adversarial loss: 0.573726\n",
      "epoch 75; iter: 0; batch classifier loss: 0.263470; batch adversarial loss: 0.555620\n",
      "epoch 76; iter: 0; batch classifier loss: 0.317099; batch adversarial loss: 0.532081\n",
      "epoch 77; iter: 0; batch classifier loss: 0.180947; batch adversarial loss: 0.548199\n",
      "epoch 78; iter: 0; batch classifier loss: 0.282676; batch adversarial loss: 0.544295\n",
      "epoch 79; iter: 0; batch classifier loss: 0.310057; batch adversarial loss: 0.625892\n",
      "epoch 0; iter: 0; batch classifier loss: 0.757088; batch adversarial loss: 0.811879\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682944; batch adversarial loss: 0.765602\n",
      "epoch 2; iter: 0; batch classifier loss: 0.625847; batch adversarial loss: 0.786665\n",
      "epoch 3; iter: 0; batch classifier loss: 0.537451; batch adversarial loss: 0.799803\n",
      "epoch 4; iter: 0; batch classifier loss: 0.618619; batch adversarial loss: 0.819303\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520914; batch adversarial loss: 0.755707\n",
      "epoch 6; iter: 0; batch classifier loss: 0.506655; batch adversarial loss: 0.808410\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466818; batch adversarial loss: 0.750132\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416347; batch adversarial loss: 0.715833\n",
      "epoch 9; iter: 0; batch classifier loss: 0.434943; batch adversarial loss: 0.731099\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463679; batch adversarial loss: 0.757462\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437300; batch adversarial loss: 0.745073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.445344; batch adversarial loss: 0.753229\n",
      "epoch 13; iter: 0; batch classifier loss: 0.362937; batch adversarial loss: 0.709410\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359794; batch adversarial loss: 0.757418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.388730; batch adversarial loss: 0.794896\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381898; batch adversarial loss: 0.689251\n",
      "epoch 17; iter: 0; batch classifier loss: 0.329297; batch adversarial loss: 0.780598\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346353; batch adversarial loss: 0.733228\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350862; batch adversarial loss: 0.745322\n",
      "epoch 20; iter: 0; batch classifier loss: 0.354524; batch adversarial loss: 0.728962\n",
      "epoch 21; iter: 0; batch classifier loss: 0.358923; batch adversarial loss: 0.713730\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316268; batch adversarial loss: 0.751965\n",
      "epoch 23; iter: 0; batch classifier loss: 0.338845; batch adversarial loss: 0.697762\n",
      "epoch 24; iter: 0; batch classifier loss: 0.363024; batch adversarial loss: 0.700900\n",
      "epoch 25; iter: 0; batch classifier loss: 0.336194; batch adversarial loss: 0.723294\n",
      "epoch 26; iter: 0; batch classifier loss: 0.281373; batch adversarial loss: 0.705055\n",
      "epoch 27; iter: 0; batch classifier loss: 0.314119; batch adversarial loss: 0.679597\n",
      "epoch 28; iter: 0; batch classifier loss: 0.285563; batch adversarial loss: 0.718021\n",
      "epoch 29; iter: 0; batch classifier loss: 0.286818; batch adversarial loss: 0.715974\n",
      "epoch 30; iter: 0; batch classifier loss: 0.350010; batch adversarial loss: 0.691277\n",
      "epoch 31; iter: 0; batch classifier loss: 0.234237; batch adversarial loss: 0.675441\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291734; batch adversarial loss: 0.694599\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312909; batch adversarial loss: 0.696276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.302636; batch adversarial loss: 0.671651\n",
      "epoch 35; iter: 0; batch classifier loss: 0.393768; batch adversarial loss: 0.701255\n",
      "epoch 36; iter: 0; batch classifier loss: 0.263536; batch adversarial loss: 0.670337\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255124; batch adversarial loss: 0.664019\n",
      "epoch 38; iter: 0; batch classifier loss: 0.252260; batch adversarial loss: 0.667663\n",
      "epoch 39; iter: 0; batch classifier loss: 0.251345; batch adversarial loss: 0.671631\n",
      "epoch 40; iter: 0; batch classifier loss: 0.303999; batch adversarial loss: 0.686515\n",
      "epoch 41; iter: 0; batch classifier loss: 0.316747; batch adversarial loss: 0.667400\n",
      "epoch 42; iter: 0; batch classifier loss: 0.281215; batch adversarial loss: 0.640935\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258171; batch adversarial loss: 0.647902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263334; batch adversarial loss: 0.653906\n",
      "epoch 45; iter: 0; batch classifier loss: 0.242133; batch adversarial loss: 0.669323\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196565; batch adversarial loss: 0.649088\n",
      "epoch 47; iter: 0; batch classifier loss: 0.319074; batch adversarial loss: 0.649800\n",
      "epoch 48; iter: 0; batch classifier loss: 0.252327; batch adversarial loss: 0.663547\n",
      "epoch 49; iter: 0; batch classifier loss: 0.250716; batch adversarial loss: 0.626802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.298571; batch adversarial loss: 0.606032\n",
      "epoch 51; iter: 0; batch classifier loss: 0.239646; batch adversarial loss: 0.624804\n",
      "epoch 52; iter: 0; batch classifier loss: 0.231857; batch adversarial loss: 0.641353\n",
      "epoch 53; iter: 0; batch classifier loss: 0.195349; batch adversarial loss: 0.623690\n",
      "epoch 54; iter: 0; batch classifier loss: 0.325006; batch adversarial loss: 0.641015\n",
      "epoch 55; iter: 0; batch classifier loss: 0.374537; batch adversarial loss: 0.647038\n",
      "epoch 56; iter: 0; batch classifier loss: 0.234022; batch adversarial loss: 0.622337\n",
      "epoch 57; iter: 0; batch classifier loss: 0.186871; batch adversarial loss: 0.607846\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180252; batch adversarial loss: 0.605565\n",
      "epoch 59; iter: 0; batch classifier loss: 0.162317; batch adversarial loss: 0.589324\n",
      "epoch 60; iter: 0; batch classifier loss: 0.209977; batch adversarial loss: 0.607727\n",
      "epoch 61; iter: 0; batch classifier loss: 0.191831; batch adversarial loss: 0.638730\n",
      "epoch 62; iter: 0; batch classifier loss: 0.203478; batch adversarial loss: 0.647473\n",
      "epoch 63; iter: 0; batch classifier loss: 0.262108; batch adversarial loss: 0.620064\n",
      "epoch 64; iter: 0; batch classifier loss: 0.199366; batch adversarial loss: 0.601861\n",
      "epoch 65; iter: 0; batch classifier loss: 0.269945; batch adversarial loss: 0.596123\n",
      "epoch 66; iter: 0; batch classifier loss: 0.208152; batch adversarial loss: 0.626387\n",
      "epoch 67; iter: 0; batch classifier loss: 0.139902; batch adversarial loss: 0.608755\n",
      "epoch 68; iter: 0; batch classifier loss: 0.218700; batch adversarial loss: 0.598981\n",
      "epoch 69; iter: 0; batch classifier loss: 0.160609; batch adversarial loss: 0.604600\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194248; batch adversarial loss: 0.571543\n",
      "epoch 71; iter: 0; batch classifier loss: 0.214425; batch adversarial loss: 0.624451\n",
      "epoch 72; iter: 0; batch classifier loss: 0.224506; batch adversarial loss: 0.594075\n",
      "epoch 73; iter: 0; batch classifier loss: 0.185063; batch adversarial loss: 0.610341\n",
      "epoch 74; iter: 0; batch classifier loss: 0.150598; batch adversarial loss: 0.612318\n",
      "epoch 75; iter: 0; batch classifier loss: 0.175390; batch adversarial loss: 0.608042\n",
      "epoch 76; iter: 0; batch classifier loss: 0.199418; batch adversarial loss: 0.619881\n",
      "epoch 77; iter: 0; batch classifier loss: 0.334150; batch adversarial loss: 0.613112\n",
      "epoch 78; iter: 0; batch classifier loss: 0.213130; batch adversarial loss: 0.611092\n",
      "epoch 79; iter: 0; batch classifier loss: 0.114623; batch adversarial loss: 0.603017\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670454; batch adversarial loss: 0.945762\n",
      "epoch 1; iter: 0; batch classifier loss: 0.679686; batch adversarial loss: 0.929392\n",
      "epoch 2; iter: 0; batch classifier loss: 0.662314; batch adversarial loss: 0.928049\n",
      "epoch 3; iter: 0; batch classifier loss: 0.648668; batch adversarial loss: 0.940097\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614192; batch adversarial loss: 0.912019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.581596; batch adversarial loss: 0.896238\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574100; batch adversarial loss: 0.935702\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544828; batch adversarial loss: 0.936328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512896; batch adversarial loss: 0.986588\n",
      "epoch 9; iter: 0; batch classifier loss: 0.553678; batch adversarial loss: 0.953036\n",
      "epoch 10; iter: 0; batch classifier loss: 0.529016; batch adversarial loss: 0.986344\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489182; batch adversarial loss: 0.957568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535715; batch adversarial loss: 0.954252\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483307; batch adversarial loss: 0.978050\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470193; batch adversarial loss: 0.923476\n",
      "epoch 15; iter: 0; batch classifier loss: 0.475083; batch adversarial loss: 0.953314\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481631; batch adversarial loss: 0.935404\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459386; batch adversarial loss: 0.951823\n",
      "epoch 18; iter: 0; batch classifier loss: 0.429059; batch adversarial loss: 0.910976\n",
      "epoch 19; iter: 0; batch classifier loss: 0.438164; batch adversarial loss: 0.926157\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436475; batch adversarial loss: 0.906768\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439655; batch adversarial loss: 0.921239\n",
      "epoch 22; iter: 0; batch classifier loss: 0.464160; batch adversarial loss: 0.921487\n",
      "epoch 23; iter: 0; batch classifier loss: 0.400665; batch adversarial loss: 0.970290\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445926; batch adversarial loss: 0.950415\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441961; batch adversarial loss: 0.890800\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428926; batch adversarial loss: 0.932787\n",
      "epoch 27; iter: 0; batch classifier loss: 0.387721; batch adversarial loss: 0.877157\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397883; batch adversarial loss: 0.854535\n",
      "epoch 29; iter: 0; batch classifier loss: 0.396783; batch adversarial loss: 0.916596\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385954; batch adversarial loss: 0.920184\n",
      "epoch 31; iter: 0; batch classifier loss: 0.384184; batch adversarial loss: 0.913587\n",
      "epoch 32; iter: 0; batch classifier loss: 0.444523; batch adversarial loss: 0.923820\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412376; batch adversarial loss: 0.908403\n",
      "epoch 34; iter: 0; batch classifier loss: 0.433027; batch adversarial loss: 0.892683\n",
      "epoch 35; iter: 0; batch classifier loss: 0.411583; batch adversarial loss: 0.933193\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377516; batch adversarial loss: 0.941012\n",
      "epoch 37; iter: 0; batch classifier loss: 0.457234; batch adversarial loss: 0.871901\n",
      "epoch 38; iter: 0; batch classifier loss: 0.375729; batch adversarial loss: 0.873163\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401690; batch adversarial loss: 0.852814\n",
      "epoch 40; iter: 0; batch classifier loss: 0.347054; batch adversarial loss: 0.870712\n",
      "epoch 41; iter: 0; batch classifier loss: 0.372954; batch adversarial loss: 0.877297\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363700; batch adversarial loss: 0.849916\n",
      "epoch 43; iter: 0; batch classifier loss: 0.368616; batch adversarial loss: 0.820061\n",
      "epoch 44; iter: 0; batch classifier loss: 0.360524; batch adversarial loss: 0.912279\n",
      "epoch 45; iter: 0; batch classifier loss: 0.399474; batch adversarial loss: 0.794474\n",
      "epoch 46; iter: 0; batch classifier loss: 0.348385; batch adversarial loss: 0.859503\n",
      "epoch 47; iter: 0; batch classifier loss: 0.359441; batch adversarial loss: 0.881439\n",
      "epoch 48; iter: 0; batch classifier loss: 0.350620; batch adversarial loss: 0.835076\n",
      "epoch 49; iter: 0; batch classifier loss: 0.353706; batch adversarial loss: 0.855204\n",
      "epoch 50; iter: 0; batch classifier loss: 0.273136; batch adversarial loss: 0.867059\n",
      "epoch 51; iter: 0; batch classifier loss: 0.325163; batch adversarial loss: 0.866592\n",
      "epoch 52; iter: 0; batch classifier loss: 0.432513; batch adversarial loss: 0.872913\n",
      "epoch 53; iter: 0; batch classifier loss: 0.384594; batch adversarial loss: 0.820507\n",
      "epoch 54; iter: 0; batch classifier loss: 0.319713; batch adversarial loss: 0.846924\n",
      "epoch 55; iter: 0; batch classifier loss: 0.298178; batch adversarial loss: 0.889362\n",
      "epoch 56; iter: 0; batch classifier loss: 0.272055; batch adversarial loss: 0.816801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.321682; batch adversarial loss: 0.796161\n",
      "epoch 58; iter: 0; batch classifier loss: 0.325323; batch adversarial loss: 0.840326\n",
      "epoch 59; iter: 0; batch classifier loss: 0.288498; batch adversarial loss: 0.836320\n",
      "epoch 60; iter: 0; batch classifier loss: 0.310944; batch adversarial loss: 0.819938\n",
      "epoch 61; iter: 0; batch classifier loss: 0.343771; batch adversarial loss: 0.785020\n",
      "epoch 62; iter: 0; batch classifier loss: 0.320529; batch adversarial loss: 0.837078\n",
      "epoch 63; iter: 0; batch classifier loss: 0.284062; batch adversarial loss: 0.812162\n",
      "epoch 64; iter: 0; batch classifier loss: 0.314195; batch adversarial loss: 0.808644\n",
      "epoch 65; iter: 0; batch classifier loss: 0.335678; batch adversarial loss: 0.742223\n",
      "epoch 66; iter: 0; batch classifier loss: 0.343580; batch adversarial loss: 0.809493\n",
      "epoch 67; iter: 0; batch classifier loss: 0.332668; batch adversarial loss: 0.802450\n",
      "epoch 68; iter: 0; batch classifier loss: 0.414018; batch adversarial loss: 0.819986\n",
      "epoch 69; iter: 0; batch classifier loss: 0.342124; batch adversarial loss: 0.794870\n",
      "epoch 70; iter: 0; batch classifier loss: 0.347946; batch adversarial loss: 0.798659\n",
      "epoch 71; iter: 0; batch classifier loss: 0.285385; batch adversarial loss: 0.786607\n",
      "epoch 72; iter: 0; batch classifier loss: 0.342096; batch adversarial loss: 0.761638\n",
      "epoch 73; iter: 0; batch classifier loss: 0.272373; batch adversarial loss: 0.758050\n",
      "epoch 74; iter: 0; batch classifier loss: 0.289025; batch adversarial loss: 0.765268\n",
      "epoch 75; iter: 0; batch classifier loss: 0.244705; batch adversarial loss: 0.751558\n",
      "epoch 76; iter: 0; batch classifier loss: 0.289615; batch adversarial loss: 0.785109\n",
      "epoch 77; iter: 0; batch classifier loss: 0.305456; batch adversarial loss: 0.806075\n",
      "epoch 78; iter: 0; batch classifier loss: 0.317510; batch adversarial loss: 0.784866\n",
      "epoch 79; iter: 0; batch classifier loss: 0.306320; batch adversarial loss: 0.773969\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747722; batch adversarial loss: 0.725920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.694660; batch adversarial loss: 0.727363\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647600; batch adversarial loss: 0.734395\n",
      "epoch 3; iter: 0; batch classifier loss: 0.639210; batch adversarial loss: 0.724178\n",
      "epoch 4; iter: 0; batch classifier loss: 0.597430; batch adversarial loss: 0.712934\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575512; batch adversarial loss: 0.723322\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585092; batch adversarial loss: 0.723224\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528785; batch adversarial loss: 0.712576\n",
      "epoch 8; iter: 0; batch classifier loss: 0.523900; batch adversarial loss: 0.708940\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472635; batch adversarial loss: 0.714825\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485328; batch adversarial loss: 0.706682\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437603; batch adversarial loss: 0.706612\n",
      "epoch 12; iter: 0; batch classifier loss: 0.438495; batch adversarial loss: 0.698762\n",
      "epoch 13; iter: 0; batch classifier loss: 0.496816; batch adversarial loss: 0.705393\n",
      "epoch 14; iter: 0; batch classifier loss: 0.498024; batch adversarial loss: 0.704398\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432470; batch adversarial loss: 0.702193\n",
      "epoch 16; iter: 0; batch classifier loss: 0.387974; batch adversarial loss: 0.689219\n",
      "epoch 17; iter: 0; batch classifier loss: 0.406461; batch adversarial loss: 0.694538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.393305; batch adversarial loss: 0.693006\n",
      "epoch 19; iter: 0; batch classifier loss: 0.376049; batch adversarial loss: 0.694203\n",
      "epoch 20; iter: 0; batch classifier loss: 0.374229; batch adversarial loss: 0.688807\n",
      "epoch 21; iter: 0; batch classifier loss: 0.432301; batch adversarial loss: 0.684699\n",
      "epoch 22; iter: 0; batch classifier loss: 0.401450; batch adversarial loss: 0.689839\n",
      "epoch 23; iter: 0; batch classifier loss: 0.427155; batch adversarial loss: 0.686665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.368868; batch adversarial loss: 0.676916\n",
      "epoch 25; iter: 0; batch classifier loss: 0.370326; batch adversarial loss: 0.677188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404362; batch adversarial loss: 0.678696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362684; batch adversarial loss: 0.678558\n",
      "epoch 28; iter: 0; batch classifier loss: 0.412529; batch adversarial loss: 0.673936\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350611; batch adversarial loss: 0.665004\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410062; batch adversarial loss: 0.667851\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355476; batch adversarial loss: 0.655273\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333611; batch adversarial loss: 0.654785\n",
      "epoch 33; iter: 0; batch classifier loss: 0.379718; batch adversarial loss: 0.676708\n",
      "epoch 34; iter: 0; batch classifier loss: 0.264775; batch adversarial loss: 0.658662\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370427; batch adversarial loss: 0.660675\n",
      "epoch 36; iter: 0; batch classifier loss: 0.325032; batch adversarial loss: 0.654551\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385974; batch adversarial loss: 0.665696\n",
      "epoch 38; iter: 0; batch classifier loss: 0.283516; batch adversarial loss: 0.644102\n",
      "epoch 39; iter: 0; batch classifier loss: 0.306428; batch adversarial loss: 0.647654\n",
      "epoch 40; iter: 0; batch classifier loss: 0.297179; batch adversarial loss: 0.653919\n",
      "epoch 41; iter: 0; batch classifier loss: 0.342717; batch adversarial loss: 0.641881\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356646; batch adversarial loss: 0.657312\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270932; batch adversarial loss: 0.642650\n",
      "epoch 44; iter: 0; batch classifier loss: 0.333477; batch adversarial loss: 0.647442\n",
      "epoch 45; iter: 0; batch classifier loss: 0.279445; batch adversarial loss: 0.652756\n",
      "epoch 46; iter: 0; batch classifier loss: 0.330237; batch adversarial loss: 0.614316\n",
      "epoch 47; iter: 0; batch classifier loss: 0.267665; batch adversarial loss: 0.647807\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347576; batch adversarial loss: 0.622277\n",
      "epoch 49; iter: 0; batch classifier loss: 0.265842; batch adversarial loss: 0.642179\n",
      "epoch 50; iter: 0; batch classifier loss: 0.278562; batch adversarial loss: 0.641688\n",
      "epoch 51; iter: 0; batch classifier loss: 0.251297; batch adversarial loss: 0.623466\n",
      "epoch 52; iter: 0; batch classifier loss: 0.311816; batch adversarial loss: 0.628977\n",
      "epoch 53; iter: 0; batch classifier loss: 0.300422; batch adversarial loss: 0.640295\n",
      "epoch 54; iter: 0; batch classifier loss: 0.324745; batch adversarial loss: 0.613312\n",
      "epoch 55; iter: 0; batch classifier loss: 0.256240; batch adversarial loss: 0.627021\n",
      "epoch 56; iter: 0; batch classifier loss: 0.268586; batch adversarial loss: 0.639032\n",
      "epoch 57; iter: 0; batch classifier loss: 0.358714; batch adversarial loss: 0.636235\n",
      "epoch 58; iter: 0; batch classifier loss: 0.331444; batch adversarial loss: 0.618275\n",
      "epoch 59; iter: 0; batch classifier loss: 0.276615; batch adversarial loss: 0.645055\n",
      "epoch 60; iter: 0; batch classifier loss: 0.307674; batch adversarial loss: 0.609893\n",
      "epoch 61; iter: 0; batch classifier loss: 0.303707; batch adversarial loss: 0.621639\n",
      "epoch 62; iter: 0; batch classifier loss: 0.247507; batch adversarial loss: 0.621623\n",
      "epoch 63; iter: 0; batch classifier loss: 0.259821; batch adversarial loss: 0.611807\n",
      "epoch 64; iter: 0; batch classifier loss: 0.230365; batch adversarial loss: 0.626846\n",
      "epoch 65; iter: 0; batch classifier loss: 0.233559; batch adversarial loss: 0.606376\n",
      "epoch 66; iter: 0; batch classifier loss: 0.294317; batch adversarial loss: 0.603270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.237911; batch adversarial loss: 0.592178\n",
      "epoch 68; iter: 0; batch classifier loss: 0.248765; batch adversarial loss: 0.606649\n",
      "epoch 69; iter: 0; batch classifier loss: 0.284701; batch adversarial loss: 0.610440\n",
      "epoch 70; iter: 0; batch classifier loss: 0.347174; batch adversarial loss: 0.633191\n",
      "epoch 71; iter: 0; batch classifier loss: 0.265374; batch adversarial loss: 0.619228\n",
      "epoch 72; iter: 0; batch classifier loss: 0.275721; batch adversarial loss: 0.609538\n",
      "epoch 73; iter: 0; batch classifier loss: 0.292420; batch adversarial loss: 0.623427\n",
      "epoch 74; iter: 0; batch classifier loss: 0.256761; batch adversarial loss: 0.604568\n",
      "epoch 75; iter: 0; batch classifier loss: 0.247500; batch adversarial loss: 0.628341\n",
      "epoch 76; iter: 0; batch classifier loss: 0.197684; batch adversarial loss: 0.619483\n",
      "epoch 77; iter: 0; batch classifier loss: 0.224603; batch adversarial loss: 0.605604\n",
      "epoch 78; iter: 0; batch classifier loss: 0.254175; batch adversarial loss: 0.619798\n",
      "epoch 79; iter: 0; batch classifier loss: 0.256956; batch adversarial loss: 0.607574\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770240; batch adversarial loss: 0.772556\n",
      "epoch 1; iter: 0; batch classifier loss: 0.657283; batch adversarial loss: 0.770206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.639153; batch adversarial loss: 0.743034\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586995; batch adversarial loss: 0.708582\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586558; batch adversarial loss: 0.746994\n",
      "epoch 5; iter: 0; batch classifier loss: 0.588138; batch adversarial loss: 0.725671\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518399; batch adversarial loss: 0.706329\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544081; batch adversarial loss: 0.676671\n",
      "epoch 8; iter: 0; batch classifier loss: 0.454716; batch adversarial loss: 0.672802\n",
      "epoch 9; iter: 0; batch classifier loss: 0.483646; batch adversarial loss: 0.644806\n",
      "epoch 10; iter: 0; batch classifier loss: 0.495800; batch adversarial loss: 0.683886\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470104; batch adversarial loss: 0.705532\n",
      "epoch 12; iter: 0; batch classifier loss: 0.466738; batch adversarial loss: 0.730812\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562477; batch adversarial loss: 0.684345\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390087; batch adversarial loss: 0.666671\n",
      "epoch 15; iter: 0; batch classifier loss: 0.418892; batch adversarial loss: 0.671487\n",
      "epoch 16; iter: 0; batch classifier loss: 0.398250; batch adversarial loss: 0.656548\n",
      "epoch 17; iter: 0; batch classifier loss: 0.353907; batch adversarial loss: 0.693540\n",
      "epoch 18; iter: 0; batch classifier loss: 0.373971; batch adversarial loss: 0.653094\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424346; batch adversarial loss: 0.636073\n",
      "epoch 20; iter: 0; batch classifier loss: 0.452357; batch adversarial loss: 0.660968\n",
      "epoch 21; iter: 0; batch classifier loss: 0.456156; batch adversarial loss: 0.714529\n",
      "epoch 22; iter: 0; batch classifier loss: 0.408421; batch adversarial loss: 0.640935\n",
      "epoch 23; iter: 0; batch classifier loss: 0.328203; batch adversarial loss: 0.564351\n",
      "epoch 24; iter: 0; batch classifier loss: 0.404945; batch adversarial loss: 0.635684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.341065; batch adversarial loss: 0.646476\n",
      "epoch 26; iter: 0; batch classifier loss: 0.387272; batch adversarial loss: 0.655987\n",
      "epoch 27; iter: 0; batch classifier loss: 0.434180; batch adversarial loss: 0.679563\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364652; batch adversarial loss: 0.620763\n",
      "epoch 29; iter: 0; batch classifier loss: 0.342886; batch adversarial loss: 0.685711\n",
      "epoch 30; iter: 0; batch classifier loss: 0.379132; batch adversarial loss: 0.582858\n",
      "epoch 31; iter: 0; batch classifier loss: 0.383251; batch adversarial loss: 0.616335\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320771; batch adversarial loss: 0.617605\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387243; batch adversarial loss: 0.648289\n",
      "epoch 34; iter: 0; batch classifier loss: 0.224351; batch adversarial loss: 0.624373\n",
      "epoch 35; iter: 0; batch classifier loss: 0.377346; batch adversarial loss: 0.629639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328354; batch adversarial loss: 0.612290\n",
      "epoch 37; iter: 0; batch classifier loss: 0.372739; batch adversarial loss: 0.640014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324197; batch adversarial loss: 0.553704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.290469; batch adversarial loss: 0.575577\n",
      "epoch 0; iter: 0; batch classifier loss: 0.693142; batch adversarial loss: 0.824042\n",
      "epoch 1; iter: 0; batch classifier loss: 0.717926; batch adversarial loss: 0.808847\n",
      "epoch 2; iter: 0; batch classifier loss: 0.685815; batch adversarial loss: 0.829649\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558620; batch adversarial loss: 0.870162\n",
      "epoch 4; iter: 0; batch classifier loss: 0.542783; batch adversarial loss: 0.829752\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506674; batch adversarial loss: 0.873953\n",
      "epoch 6; iter: 0; batch classifier loss: 0.491664; batch adversarial loss: 0.840416\n",
      "epoch 7; iter: 0; batch classifier loss: 0.464779; batch adversarial loss: 0.841883\n",
      "epoch 8; iter: 0; batch classifier loss: 0.441918; batch adversarial loss: 0.877417\n",
      "epoch 9; iter: 0; batch classifier loss: 0.425397; batch adversarial loss: 0.803710\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477211; batch adversarial loss: 0.830780\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413550; batch adversarial loss: 0.853961\n",
      "epoch 12; iter: 0; batch classifier loss: 0.369574; batch adversarial loss: 0.779049\n",
      "epoch 13; iter: 0; batch classifier loss: 0.347272; batch adversarial loss: 0.809998\n",
      "epoch 14; iter: 0; batch classifier loss: 0.346204; batch adversarial loss: 0.774974\n",
      "epoch 15; iter: 0; batch classifier loss: 0.396049; batch adversarial loss: 0.834711\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311335; batch adversarial loss: 0.749631\n",
      "epoch 17; iter: 0; batch classifier loss: 0.434383; batch adversarial loss: 0.770136\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465410; batch adversarial loss: 0.725309\n",
      "epoch 19; iter: 0; batch classifier loss: 0.350312; batch adversarial loss: 0.781505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.279806; batch adversarial loss: 0.780530\n",
      "epoch 21; iter: 0; batch classifier loss: 0.359082; batch adversarial loss: 0.744860\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355158; batch adversarial loss: 0.781814\n",
      "epoch 23; iter: 0; batch classifier loss: 0.433351; batch adversarial loss: 0.698540\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362289; batch adversarial loss: 0.707299\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326734; batch adversarial loss: 0.738834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.345223; batch adversarial loss: 0.701223\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269958; batch adversarial loss: 0.733362\n",
      "epoch 28; iter: 0; batch classifier loss: 0.234404; batch adversarial loss: 0.745060\n",
      "epoch 29; iter: 0; batch classifier loss: 0.276166; batch adversarial loss: 0.673623\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324993; batch adversarial loss: 0.693560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.269521; batch adversarial loss: 0.731027\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368914; batch adversarial loss: 0.682181\n",
      "epoch 33; iter: 0; batch classifier loss: 0.309034; batch adversarial loss: 0.689627\n",
      "epoch 34; iter: 0; batch classifier loss: 0.297292; batch adversarial loss: 0.697322\n",
      "epoch 35; iter: 0; batch classifier loss: 0.180109; batch adversarial loss: 0.674564\n",
      "epoch 36; iter: 0; batch classifier loss: 0.261385; batch adversarial loss: 0.712706\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271278; batch adversarial loss: 0.677168\n",
      "epoch 38; iter: 0; batch classifier loss: 0.258001; batch adversarial loss: 0.684567\n",
      "epoch 39; iter: 0; batch classifier loss: 0.243826; batch adversarial loss: 0.707767\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673428; batch adversarial loss: 0.702093\n",
      "epoch 1; iter: 0; batch classifier loss: 0.669787; batch adversarial loss: 0.704865\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657998; batch adversarial loss: 0.697863\n",
      "epoch 3; iter: 0; batch classifier loss: 0.625311; batch adversarial loss: 0.695236\n",
      "epoch 4; iter: 0; batch classifier loss: 0.628869; batch adversarial loss: 0.703666\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614955; batch adversarial loss: 0.689719\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625772; batch adversarial loss: 0.684861\n",
      "epoch 7; iter: 0; batch classifier loss: 0.583113; batch adversarial loss: 0.701895\n",
      "epoch 8; iter: 0; batch classifier loss: 0.625002; batch adversarial loss: 0.691519\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585907; batch adversarial loss: 0.696918\n",
      "epoch 10; iter: 0; batch classifier loss: 0.590463; batch adversarial loss: 0.689632\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567442; batch adversarial loss: 0.671553\n",
      "epoch 12; iter: 0; batch classifier loss: 0.514250; batch adversarial loss: 0.691582\n",
      "epoch 13; iter: 0; batch classifier loss: 0.561099; batch adversarial loss: 0.660533\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515886; batch adversarial loss: 0.682032\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508728; batch adversarial loss: 0.680156\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495364; batch adversarial loss: 0.670557\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505514; batch adversarial loss: 0.672982\n",
      "epoch 18; iter: 0; batch classifier loss: 0.511410; batch adversarial loss: 0.655973\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488427; batch adversarial loss: 0.671319\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468155; batch adversarial loss: 0.664525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.447870; batch adversarial loss: 0.682151\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407100; batch adversarial loss: 0.685370\n",
      "epoch 23; iter: 0; batch classifier loss: 0.438473; batch adversarial loss: 0.674468\n",
      "epoch 24; iter: 0; batch classifier loss: 0.451981; batch adversarial loss: 0.662072\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381384; batch adversarial loss: 0.656958\n",
      "epoch 26; iter: 0; batch classifier loss: 0.436296; batch adversarial loss: 0.664864\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480039; batch adversarial loss: 0.646665\n",
      "epoch 28; iter: 0; batch classifier loss: 0.467478; batch adversarial loss: 0.655927\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376867; batch adversarial loss: 0.667985\n",
      "epoch 30; iter: 0; batch classifier loss: 0.453936; batch adversarial loss: 0.639503\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464087; batch adversarial loss: 0.648622\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368481; batch adversarial loss: 0.656371\n",
      "epoch 33; iter: 0; batch classifier loss: 0.388478; batch adversarial loss: 0.646308\n",
      "epoch 34; iter: 0; batch classifier loss: 0.375026; batch adversarial loss: 0.675812\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423489; batch adversarial loss: 0.649543\n",
      "epoch 36; iter: 0; batch classifier loss: 0.439213; batch adversarial loss: 0.640487\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363852; batch adversarial loss: 0.648509\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382133; batch adversarial loss: 0.635557\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385351; batch adversarial loss: 0.646343\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713242; batch adversarial loss: 0.738382\n",
      "epoch 1; iter: 0; batch classifier loss: 0.680094; batch adversarial loss: 0.724302\n",
      "epoch 2; iter: 0; batch classifier loss: 0.630940; batch adversarial loss: 0.747891\n",
      "epoch 3; iter: 0; batch classifier loss: 0.609978; batch adversarial loss: 0.735132\n",
      "epoch 4; iter: 0; batch classifier loss: 0.577897; batch adversarial loss: 0.734599\n",
      "epoch 5; iter: 0; batch classifier loss: 0.546258; batch adversarial loss: 0.736887\n",
      "epoch 6; iter: 0; batch classifier loss: 0.541072; batch adversarial loss: 0.738340\n",
      "epoch 7; iter: 0; batch classifier loss: 0.550399; batch adversarial loss: 0.738477\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525705; batch adversarial loss: 0.737723\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517856; batch adversarial loss: 0.752124\n",
      "epoch 10; iter: 0; batch classifier loss: 0.508011; batch adversarial loss: 0.730529\n",
      "epoch 11; iter: 0; batch classifier loss: 0.475563; batch adversarial loss: 0.743368\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484035; batch adversarial loss: 0.720797\n",
      "epoch 13; iter: 0; batch classifier loss: 0.472096; batch adversarial loss: 0.726085\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459268; batch adversarial loss: 0.719599\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442989; batch adversarial loss: 0.715414\n",
      "epoch 16; iter: 0; batch classifier loss: 0.449730; batch adversarial loss: 0.700944\n",
      "epoch 17; iter: 0; batch classifier loss: 0.471258; batch adversarial loss: 0.713032\n",
      "epoch 18; iter: 0; batch classifier loss: 0.430226; batch adversarial loss: 0.727833\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414552; batch adversarial loss: 0.717819\n",
      "epoch 20; iter: 0; batch classifier loss: 0.392982; batch adversarial loss: 0.719263\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462438; batch adversarial loss: 0.700492\n",
      "epoch 22; iter: 0; batch classifier loss: 0.459362; batch adversarial loss: 0.720165\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340351; batch adversarial loss: 0.712784\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370987; batch adversarial loss: 0.704593\n",
      "epoch 25; iter: 0; batch classifier loss: 0.403195; batch adversarial loss: 0.705215\n",
      "epoch 26; iter: 0; batch classifier loss: 0.385372; batch adversarial loss: 0.698578\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374622; batch adversarial loss: 0.704981\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348928; batch adversarial loss: 0.693534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301371; batch adversarial loss: 0.693434\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399635; batch adversarial loss: 0.700636\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379758; batch adversarial loss: 0.692312\n",
      "epoch 32; iter: 0; batch classifier loss: 0.331192; batch adversarial loss: 0.691639\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416596; batch adversarial loss: 0.700378\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381625; batch adversarial loss: 0.688101\n",
      "epoch 35; iter: 0; batch classifier loss: 0.364145; batch adversarial loss: 0.698652\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383299; batch adversarial loss: 0.685962\n",
      "epoch 37; iter: 0; batch classifier loss: 0.380925; batch adversarial loss: 0.690006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.402860; batch adversarial loss: 0.670259\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340087; batch adversarial loss: 0.690768\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748983; batch adversarial loss: 0.753823\n",
      "epoch 1; iter: 0; batch classifier loss: 0.748996; batch adversarial loss: 0.792193\n",
      "epoch 2; iter: 0; batch classifier loss: 0.715738; batch adversarial loss: 0.802676\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620146; batch adversarial loss: 0.740834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614661; batch adversarial loss: 0.751284\n",
      "epoch 5; iter: 0; batch classifier loss: 0.480228; batch adversarial loss: 0.715291\n",
      "epoch 6; iter: 0; batch classifier loss: 0.571986; batch adversarial loss: 0.740426\n",
      "epoch 7; iter: 0; batch classifier loss: 0.492375; batch adversarial loss: 0.749728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.508577; batch adversarial loss: 0.747272\n",
      "epoch 9; iter: 0; batch classifier loss: 0.531649; batch adversarial loss: 0.746265\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453896; batch adversarial loss: 0.714240\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492627; batch adversarial loss: 0.714790\n",
      "epoch 12; iter: 0; batch classifier loss: 0.389996; batch adversarial loss: 0.706604\n",
      "epoch 13; iter: 0; batch classifier loss: 0.407619; batch adversarial loss: 0.703386\n",
      "epoch 14; iter: 0; batch classifier loss: 0.393562; batch adversarial loss: 0.701399\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502860; batch adversarial loss: 0.727060\n",
      "epoch 16; iter: 0; batch classifier loss: 0.421981; batch adversarial loss: 0.705946\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459142; batch adversarial loss: 0.691432\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446632; batch adversarial loss: 0.689888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.525664; batch adversarial loss: 0.693430\n",
      "epoch 20; iter: 0; batch classifier loss: 0.349612; batch adversarial loss: 0.679034\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292365; batch adversarial loss: 0.642002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407052; batch adversarial loss: 0.663008\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412669; batch adversarial loss: 0.665393\n",
      "epoch 24; iter: 0; batch classifier loss: 0.367981; batch adversarial loss: 0.660743\n",
      "epoch 25; iter: 0; batch classifier loss: 0.389403; batch adversarial loss: 0.644483\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403333; batch adversarial loss: 0.667046\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396886; batch adversarial loss: 0.643424\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286144; batch adversarial loss: 0.640303\n",
      "epoch 29; iter: 0; batch classifier loss: 0.350000; batch adversarial loss: 0.622962\n",
      "epoch 30; iter: 0; batch classifier loss: 0.282509; batch adversarial loss: 0.659702\n",
      "epoch 31; iter: 0; batch classifier loss: 0.304108; batch adversarial loss: 0.620647\n",
      "epoch 32; iter: 0; batch classifier loss: 0.339512; batch adversarial loss: 0.624871\n",
      "epoch 33; iter: 0; batch classifier loss: 0.485473; batch adversarial loss: 0.626963\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432065; batch adversarial loss: 0.629422\n",
      "epoch 35; iter: 0; batch classifier loss: 0.425891; batch adversarial loss: 0.657998\n",
      "epoch 36; iter: 0; batch classifier loss: 0.302202; batch adversarial loss: 0.616262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346286; batch adversarial loss: 0.634065\n",
      "epoch 38; iter: 0; batch classifier loss: 0.330068; batch adversarial loss: 0.613392\n",
      "epoch 39; iter: 0; batch classifier loss: 0.271241; batch adversarial loss: 0.611175\n",
      "epoch 40; iter: 0; batch classifier loss: 0.240391; batch adversarial loss: 0.609186\n",
      "epoch 41; iter: 0; batch classifier loss: 0.356329; batch adversarial loss: 0.632279\n",
      "epoch 42; iter: 0; batch classifier loss: 0.333148; batch adversarial loss: 0.600339\n",
      "epoch 43; iter: 0; batch classifier loss: 0.308446; batch adversarial loss: 0.572785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.271833; batch adversarial loss: 0.570811\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381040; batch adversarial loss: 0.555155\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354253; batch adversarial loss: 0.559769\n",
      "epoch 47; iter: 0; batch classifier loss: 0.313427; batch adversarial loss: 0.601851\n",
      "epoch 48; iter: 0; batch classifier loss: 0.293156; batch adversarial loss: 0.592613\n",
      "epoch 49; iter: 0; batch classifier loss: 0.325847; batch adversarial loss: 0.595730\n",
      "epoch 50; iter: 0; batch classifier loss: 0.209920; batch adversarial loss: 0.580784\n",
      "epoch 51; iter: 0; batch classifier loss: 0.320750; batch adversarial loss: 0.613294\n",
      "epoch 52; iter: 0; batch classifier loss: 0.278778; batch adversarial loss: 0.557512\n",
      "epoch 53; iter: 0; batch classifier loss: 0.462203; batch adversarial loss: 0.632585\n",
      "epoch 54; iter: 0; batch classifier loss: 0.416180; batch adversarial loss: 0.605683\n",
      "epoch 55; iter: 0; batch classifier loss: 0.238963; batch adversarial loss: 0.618658\n",
      "epoch 56; iter: 0; batch classifier loss: 0.261194; batch adversarial loss: 0.560630\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386000; batch adversarial loss: 0.619671\n",
      "epoch 58; iter: 0; batch classifier loss: 0.290501; batch adversarial loss: 0.601086\n",
      "epoch 59; iter: 0; batch classifier loss: 0.238982; batch adversarial loss: 0.572384\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720973; batch adversarial loss: 0.642771\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670285; batch adversarial loss: 0.657612\n",
      "epoch 2; iter: 0; batch classifier loss: 0.659773; batch adversarial loss: 0.658313\n",
      "epoch 3; iter: 0; batch classifier loss: 0.557996; batch adversarial loss: 0.648189\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567708; batch adversarial loss: 0.677640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.506607; batch adversarial loss: 0.683514\n",
      "epoch 6; iter: 0; batch classifier loss: 0.441967; batch adversarial loss: 0.578474\n",
      "epoch 7; iter: 0; batch classifier loss: 0.484628; batch adversarial loss: 0.632802\n",
      "epoch 8; iter: 0; batch classifier loss: 0.417996; batch adversarial loss: 0.598218\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420834; batch adversarial loss: 0.674467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.390159; batch adversarial loss: 0.617520\n",
      "epoch 11; iter: 0; batch classifier loss: 0.503825; batch adversarial loss: 0.629299\n",
      "epoch 12; iter: 0; batch classifier loss: 0.388593; batch adversarial loss: 0.610183\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411952; batch adversarial loss: 0.679581\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350253; batch adversarial loss: 0.672940\n",
      "epoch 15; iter: 0; batch classifier loss: 0.324706; batch adversarial loss: 0.583539\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469567; batch adversarial loss: 0.661497\n",
      "epoch 17; iter: 0; batch classifier loss: 0.414032; batch adversarial loss: 0.602749\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375066; batch adversarial loss: 0.567969\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338117; batch adversarial loss: 0.618779\n",
      "epoch 20; iter: 0; batch classifier loss: 0.225603; batch adversarial loss: 0.587410\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336394; batch adversarial loss: 0.658418\n",
      "epoch 22; iter: 0; batch classifier loss: 0.299841; batch adversarial loss: 0.647232\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342867; batch adversarial loss: 0.641512\n",
      "epoch 24; iter: 0; batch classifier loss: 0.342460; batch adversarial loss: 0.626218\n",
      "epoch 25; iter: 0; batch classifier loss: 0.330063; batch adversarial loss: 0.714292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403500; batch adversarial loss: 0.519495\n",
      "epoch 27; iter: 0; batch classifier loss: 0.322038; batch adversarial loss: 0.627051\n",
      "epoch 28; iter: 0; batch classifier loss: 0.303800; batch adversarial loss: 0.651780\n",
      "epoch 29; iter: 0; batch classifier loss: 0.240975; batch adversarial loss: 0.689988\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269257; batch adversarial loss: 0.600684\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355428; batch adversarial loss: 0.608210\n",
      "epoch 32; iter: 0; batch classifier loss: 0.197496; batch adversarial loss: 0.633535\n",
      "epoch 33; iter: 0; batch classifier loss: 0.277554; batch adversarial loss: 0.605466\n",
      "epoch 34; iter: 0; batch classifier loss: 0.299411; batch adversarial loss: 0.643978\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337722; batch adversarial loss: 0.592806\n",
      "epoch 36; iter: 0; batch classifier loss: 0.315728; batch adversarial loss: 0.595719\n",
      "epoch 37; iter: 0; batch classifier loss: 0.214995; batch adversarial loss: 0.575250\n",
      "epoch 38; iter: 0; batch classifier loss: 0.184954; batch adversarial loss: 0.678942\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291872; batch adversarial loss: 0.562087\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315262; batch adversarial loss: 0.554372\n",
      "epoch 41; iter: 0; batch classifier loss: 0.251807; batch adversarial loss: 0.586005\n",
      "epoch 42; iter: 0; batch classifier loss: 0.274892; batch adversarial loss: 0.592838\n",
      "epoch 43; iter: 0; batch classifier loss: 0.189756; batch adversarial loss: 0.622548\n",
      "epoch 44; iter: 0; batch classifier loss: 0.231595; batch adversarial loss: 0.563216\n",
      "epoch 45; iter: 0; batch classifier loss: 0.266464; batch adversarial loss: 0.565696\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266669; batch adversarial loss: 0.576319\n",
      "epoch 47; iter: 0; batch classifier loss: 0.275176; batch adversarial loss: 0.645144\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262864; batch adversarial loss: 0.541382\n",
      "epoch 49; iter: 0; batch classifier loss: 0.176056; batch adversarial loss: 0.653656\n",
      "epoch 50; iter: 0; batch classifier loss: 0.254814; batch adversarial loss: 0.607009\n",
      "epoch 51; iter: 0; batch classifier loss: 0.257964; batch adversarial loss: 0.570551\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161975; batch adversarial loss: 0.653866\n",
      "epoch 53; iter: 0; batch classifier loss: 0.225783; batch adversarial loss: 0.642249\n",
      "epoch 54; iter: 0; batch classifier loss: 0.227828; batch adversarial loss: 0.611543\n",
      "epoch 55; iter: 0; batch classifier loss: 0.215770; batch adversarial loss: 0.547938\n",
      "epoch 56; iter: 0; batch classifier loss: 0.185114; batch adversarial loss: 0.600385\n",
      "epoch 57; iter: 0; batch classifier loss: 0.113695; batch adversarial loss: 0.521866\n",
      "epoch 58; iter: 0; batch classifier loss: 0.178958; batch adversarial loss: 0.564073\n",
      "epoch 59; iter: 0; batch classifier loss: 0.212914; batch adversarial loss: 0.596467\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733767; batch adversarial loss: 0.647220\n",
      "epoch 1; iter: 0; batch classifier loss: 0.698973; batch adversarial loss: 0.658072\n",
      "epoch 2; iter: 0; batch classifier loss: 0.685905; batch adversarial loss: 0.628830\n",
      "epoch 3; iter: 0; batch classifier loss: 0.664632; batch adversarial loss: 0.649998\n",
      "epoch 4; iter: 0; batch classifier loss: 0.652286; batch adversarial loss: 0.661899\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568446; batch adversarial loss: 0.690406\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557434; batch adversarial loss: 0.591727\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545326; batch adversarial loss: 0.703638\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566998; batch adversarial loss: 0.596958\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548736; batch adversarial loss: 0.606743\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565889; batch adversarial loss: 0.624753\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526938; batch adversarial loss: 0.612193\n",
      "epoch 12; iter: 0; batch classifier loss: 0.535371; batch adversarial loss: 0.665435\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476950; batch adversarial loss: 0.686300\n",
      "epoch 14; iter: 0; batch classifier loss: 0.519498; batch adversarial loss: 0.593560\n",
      "epoch 15; iter: 0; batch classifier loss: 0.504724; batch adversarial loss: 0.601707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518003; batch adversarial loss: 0.596819\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481345; batch adversarial loss: 0.645222\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473465; batch adversarial loss: 0.659615\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458664; batch adversarial loss: 0.621646\n",
      "epoch 20; iter: 0; batch classifier loss: 0.421923; batch adversarial loss: 0.678883\n",
      "epoch 21; iter: 0; batch classifier loss: 0.503891; batch adversarial loss: 0.632943\n",
      "epoch 22; iter: 0; batch classifier loss: 0.458832; batch adversarial loss: 0.677036\n",
      "epoch 23; iter: 0; batch classifier loss: 0.451809; batch adversarial loss: 0.731156\n",
      "epoch 24; iter: 0; batch classifier loss: 0.475137; batch adversarial loss: 0.694652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417539; batch adversarial loss: 0.722794\n",
      "epoch 26; iter: 0; batch classifier loss: 0.402043; batch adversarial loss: 0.699682\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442994; batch adversarial loss: 0.694999\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413672; batch adversarial loss: 0.629143\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407555; batch adversarial loss: 0.735412\n",
      "epoch 30; iter: 0; batch classifier loss: 0.452330; batch adversarial loss: 0.673250\n",
      "epoch 31; iter: 0; batch classifier loss: 0.408518; batch adversarial loss: 0.639510\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445877; batch adversarial loss: 0.668259\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400700; batch adversarial loss: 0.647470\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423696; batch adversarial loss: 0.675016\n",
      "epoch 35; iter: 0; batch classifier loss: 0.384923; batch adversarial loss: 0.684040\n",
      "epoch 36; iter: 0; batch classifier loss: 0.430788; batch adversarial loss: 0.713139\n",
      "epoch 37; iter: 0; batch classifier loss: 0.393973; batch adversarial loss: 0.615541\n",
      "epoch 38; iter: 0; batch classifier loss: 0.343118; batch adversarial loss: 0.710409\n",
      "epoch 39; iter: 0; batch classifier loss: 0.401392; batch adversarial loss: 0.636655\n",
      "epoch 40; iter: 0; batch classifier loss: 0.441401; batch adversarial loss: 0.698932\n",
      "epoch 41; iter: 0; batch classifier loss: 0.360241; batch adversarial loss: 0.680738\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390360; batch adversarial loss: 0.646631\n",
      "epoch 43; iter: 0; batch classifier loss: 0.344815; batch adversarial loss: 0.685887\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376980; batch adversarial loss: 0.620246\n",
      "epoch 45; iter: 0; batch classifier loss: 0.361645; batch adversarial loss: 0.705989\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357929; batch adversarial loss: 0.607852\n",
      "epoch 47; iter: 0; batch classifier loss: 0.367102; batch adversarial loss: 0.719853\n",
      "epoch 48; iter: 0; batch classifier loss: 0.340363; batch adversarial loss: 0.616803\n",
      "epoch 49; iter: 0; batch classifier loss: 0.311673; batch adversarial loss: 0.733634\n",
      "epoch 50; iter: 0; batch classifier loss: 0.347929; batch adversarial loss: 0.628829\n",
      "epoch 51; iter: 0; batch classifier loss: 0.347786; batch adversarial loss: 0.672465\n",
      "epoch 52; iter: 0; batch classifier loss: 0.344893; batch adversarial loss: 0.609015\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375855; batch adversarial loss: 0.657274\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399831; batch adversarial loss: 0.679447\n",
      "epoch 55; iter: 0; batch classifier loss: 0.344696; batch adversarial loss: 0.690695\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383225; batch adversarial loss: 0.700836\n",
      "epoch 57; iter: 0; batch classifier loss: 0.322526; batch adversarial loss: 0.531215\n",
      "epoch 58; iter: 0; batch classifier loss: 0.292259; batch adversarial loss: 0.628367\n",
      "epoch 59; iter: 0; batch classifier loss: 0.313117; batch adversarial loss: 0.722069\n",
      "epoch 0; iter: 0; batch classifier loss: 0.669956; batch adversarial loss: 0.590108\n",
      "epoch 1; iter: 0; batch classifier loss: 0.656748; batch adversarial loss: 0.564447\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594071; batch adversarial loss: 0.581569\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582901; batch adversarial loss: 0.544915\n",
      "epoch 4; iter: 0; batch classifier loss: 0.539379; batch adversarial loss: 0.547503\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541530; batch adversarial loss: 0.589211\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499692; batch adversarial loss: 0.550490\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517438; batch adversarial loss: 0.603184\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468409; batch adversarial loss: 0.552687\n",
      "epoch 9; iter: 0; batch classifier loss: 0.509874; batch adversarial loss: 0.565310\n",
      "epoch 10; iter: 0; batch classifier loss: 0.466326; batch adversarial loss: 0.575968\n",
      "epoch 11; iter: 0; batch classifier loss: 0.416106; batch adversarial loss: 0.563767\n",
      "epoch 12; iter: 0; batch classifier loss: 0.469801; batch adversarial loss: 0.639761\n",
      "epoch 13; iter: 0; batch classifier loss: 0.415647; batch adversarial loss: 0.594778\n",
      "epoch 14; iter: 0; batch classifier loss: 0.449165; batch adversarial loss: 0.545123\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398048; batch adversarial loss: 0.563486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.401294; batch adversarial loss: 0.580627\n",
      "epoch 17; iter: 0; batch classifier loss: 0.433491; batch adversarial loss: 0.555841\n",
      "epoch 18; iter: 0; batch classifier loss: 0.439606; batch adversarial loss: 0.541474\n",
      "epoch 19; iter: 0; batch classifier loss: 0.389100; batch adversarial loss: 0.543652\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463700; batch adversarial loss: 0.595703\n",
      "epoch 21; iter: 0; batch classifier loss: 0.429710; batch adversarial loss: 0.598894\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392257; batch adversarial loss: 0.598259\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396614; batch adversarial loss: 0.541915\n",
      "epoch 24; iter: 0; batch classifier loss: 0.403572; batch adversarial loss: 0.597377\n",
      "epoch 25; iter: 0; batch classifier loss: 0.353351; batch adversarial loss: 0.577449\n",
      "epoch 26; iter: 0; batch classifier loss: 0.371312; batch adversarial loss: 0.586018\n",
      "epoch 27; iter: 0; batch classifier loss: 0.341564; batch adversarial loss: 0.633361\n",
      "epoch 28; iter: 0; batch classifier loss: 0.353600; batch adversarial loss: 0.564802\n",
      "epoch 29; iter: 0; batch classifier loss: 0.319986; batch adversarial loss: 0.593160\n",
      "epoch 30; iter: 0; batch classifier loss: 0.356059; batch adversarial loss: 0.564313\n",
      "epoch 31; iter: 0; batch classifier loss: 0.318512; batch adversarial loss: 0.525730\n",
      "epoch 32; iter: 0; batch classifier loss: 0.323069; batch adversarial loss: 0.599537\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320402; batch adversarial loss: 0.621871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.365910; batch adversarial loss: 0.569081\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396925; batch adversarial loss: 0.604625\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341043; batch adversarial loss: 0.590999\n",
      "epoch 37; iter: 0; batch classifier loss: 0.389673; batch adversarial loss: 0.577853\n",
      "epoch 38; iter: 0; batch classifier loss: 0.309142; batch adversarial loss: 0.593673\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291673; batch adversarial loss: 0.579397\n",
      "epoch 40; iter: 0; batch classifier loss: 0.326113; batch adversarial loss: 0.657061\n",
      "epoch 41; iter: 0; batch classifier loss: 0.245388; batch adversarial loss: 0.536044\n",
      "epoch 42; iter: 0; batch classifier loss: 0.371506; batch adversarial loss: 0.630648\n",
      "epoch 43; iter: 0; batch classifier loss: 0.304565; batch adversarial loss: 0.560847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.267632; batch adversarial loss: 0.614342\n",
      "epoch 45; iter: 0; batch classifier loss: 0.281557; batch adversarial loss: 0.571557\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378852; batch adversarial loss: 0.545410\n",
      "epoch 47; iter: 0; batch classifier loss: 0.254713; batch adversarial loss: 0.584473\n",
      "epoch 48; iter: 0; batch classifier loss: 0.315474; batch adversarial loss: 0.546735\n",
      "epoch 49; iter: 0; batch classifier loss: 0.217593; batch adversarial loss: 0.559151\n",
      "epoch 50; iter: 0; batch classifier loss: 0.327595; batch adversarial loss: 0.579104\n",
      "epoch 51; iter: 0; batch classifier loss: 0.295505; batch adversarial loss: 0.589685\n",
      "epoch 52; iter: 0; batch classifier loss: 0.261384; batch adversarial loss: 0.571033\n",
      "epoch 53; iter: 0; batch classifier loss: 0.281697; batch adversarial loss: 0.581399\n",
      "epoch 54; iter: 0; batch classifier loss: 0.223458; batch adversarial loss: 0.559923\n",
      "epoch 55; iter: 0; batch classifier loss: 0.268972; batch adversarial loss: 0.633131\n",
      "epoch 56; iter: 0; batch classifier loss: 0.286990; batch adversarial loss: 0.587770\n",
      "epoch 57; iter: 0; batch classifier loss: 0.354902; batch adversarial loss: 0.561237\n",
      "epoch 58; iter: 0; batch classifier loss: 0.273074; batch adversarial loss: 0.630691\n",
      "epoch 59; iter: 0; batch classifier loss: 0.298050; batch adversarial loss: 0.571868\n",
      "epoch 0; iter: 0; batch classifier loss: 0.608231; batch adversarial loss: 0.604081\n",
      "epoch 1; iter: 0; batch classifier loss: 0.558621; batch adversarial loss: 0.655146\n",
      "epoch 2; iter: 0; batch classifier loss: 0.526231; batch adversarial loss: 0.632025\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562921; batch adversarial loss: 0.621925\n",
      "epoch 4; iter: 0; batch classifier loss: 0.518717; batch adversarial loss: 0.636273\n",
      "epoch 5; iter: 0; batch classifier loss: 0.470000; batch adversarial loss: 0.614383\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521063; batch adversarial loss: 0.614553\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518516; batch adversarial loss: 0.674066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.482159; batch adversarial loss: 0.643193\n",
      "epoch 9; iter: 0; batch classifier loss: 0.404749; batch adversarial loss: 0.646089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.357349; batch adversarial loss: 0.613921\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440677; batch adversarial loss: 0.620619\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376305; batch adversarial loss: 0.655380\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457983; batch adversarial loss: 0.634863\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389566; batch adversarial loss: 0.633591\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366222; batch adversarial loss: 0.569583\n",
      "epoch 16; iter: 0; batch classifier loss: 0.415440; batch adversarial loss: 0.591693\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357851; batch adversarial loss: 0.637099\n",
      "epoch 18; iter: 0; batch classifier loss: 0.320669; batch adversarial loss: 0.703558\n",
      "epoch 19; iter: 0; batch classifier loss: 0.450201; batch adversarial loss: 0.640571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.288359; batch adversarial loss: 0.665153\n",
      "epoch 21; iter: 0; batch classifier loss: 0.272324; batch adversarial loss: 0.557533\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399524; batch adversarial loss: 0.585946\n",
      "epoch 23; iter: 0; batch classifier loss: 0.342258; batch adversarial loss: 0.587395\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324017; batch adversarial loss: 0.613980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.404993; batch adversarial loss: 0.592247\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365433; batch adversarial loss: 0.568712\n",
      "epoch 27; iter: 0; batch classifier loss: 0.360291; batch adversarial loss: 0.652608\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461659; batch adversarial loss: 0.592586\n",
      "epoch 29; iter: 0; batch classifier loss: 0.313633; batch adversarial loss: 0.569927\n",
      "epoch 30; iter: 0; batch classifier loss: 0.353581; batch adversarial loss: 0.548920\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390926; batch adversarial loss: 0.645364\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311819; batch adversarial loss: 0.683893\n",
      "epoch 33; iter: 0; batch classifier loss: 0.333619; batch adversarial loss: 0.666306\n",
      "epoch 34; iter: 0; batch classifier loss: 0.346965; batch adversarial loss: 0.580459\n",
      "epoch 35; iter: 0; batch classifier loss: 0.235380; batch adversarial loss: 0.615861\n",
      "epoch 36; iter: 0; batch classifier loss: 0.339286; batch adversarial loss: 0.587331\n",
      "epoch 37; iter: 0; batch classifier loss: 0.353545; batch adversarial loss: 0.547029\n",
      "epoch 38; iter: 0; batch classifier loss: 0.367103; batch adversarial loss: 0.631906\n",
      "epoch 39; iter: 0; batch classifier loss: 0.329500; batch adversarial loss: 0.592694\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344847; batch adversarial loss: 0.610523\n",
      "epoch 41; iter: 0; batch classifier loss: 0.296125; batch adversarial loss: 0.603904\n",
      "epoch 42; iter: 0; batch classifier loss: 0.247869; batch adversarial loss: 0.658581\n",
      "epoch 43; iter: 0; batch classifier loss: 0.272670; batch adversarial loss: 0.596024\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247604; batch adversarial loss: 0.661716\n",
      "epoch 45; iter: 0; batch classifier loss: 0.242577; batch adversarial loss: 0.528482\n",
      "epoch 46; iter: 0; batch classifier loss: 0.287516; batch adversarial loss: 0.620624\n",
      "epoch 47; iter: 0; batch classifier loss: 0.261630; batch adversarial loss: 0.612414\n",
      "epoch 48; iter: 0; batch classifier loss: 0.325516; batch adversarial loss: 0.651423\n",
      "epoch 49; iter: 0; batch classifier loss: 0.258929; batch adversarial loss: 0.610534\n",
      "epoch 50; iter: 0; batch classifier loss: 0.270634; batch adversarial loss: 0.526431\n",
      "epoch 51; iter: 0; batch classifier loss: 0.248729; batch adversarial loss: 0.590971\n",
      "epoch 52; iter: 0; batch classifier loss: 0.241459; batch adversarial loss: 0.586559\n",
      "epoch 53; iter: 0; batch classifier loss: 0.281901; batch adversarial loss: 0.660616\n",
      "epoch 54; iter: 0; batch classifier loss: 0.333168; batch adversarial loss: 0.583471\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212666; batch adversarial loss: 0.622138\n",
      "epoch 56; iter: 0; batch classifier loss: 0.251064; batch adversarial loss: 0.524003\n",
      "epoch 57; iter: 0; batch classifier loss: 0.185517; batch adversarial loss: 0.568516\n",
      "epoch 58; iter: 0; batch classifier loss: 0.293217; batch adversarial loss: 0.560524\n",
      "epoch 59; iter: 0; batch classifier loss: 0.254175; batch adversarial loss: 0.538821\n",
      "epoch 60; iter: 0; batch classifier loss: 0.313951; batch adversarial loss: 0.615403\n",
      "epoch 61; iter: 0; batch classifier loss: 0.208863; batch adversarial loss: 0.591533\n",
      "epoch 62; iter: 0; batch classifier loss: 0.189840; batch adversarial loss: 0.485927\n",
      "epoch 63; iter: 0; batch classifier loss: 0.334507; batch adversarial loss: 0.614248\n",
      "epoch 64; iter: 0; batch classifier loss: 0.238642; batch adversarial loss: 0.541675\n",
      "epoch 65; iter: 0; batch classifier loss: 0.241872; batch adversarial loss: 0.551808\n",
      "epoch 66; iter: 0; batch classifier loss: 0.374932; batch adversarial loss: 0.717080\n",
      "epoch 67; iter: 0; batch classifier loss: 0.261361; batch adversarial loss: 0.513424\n",
      "epoch 68; iter: 0; batch classifier loss: 0.314781; batch adversarial loss: 0.593097\n",
      "epoch 69; iter: 0; batch classifier loss: 0.282596; batch adversarial loss: 0.535117\n",
      "epoch 70; iter: 0; batch classifier loss: 0.330910; batch adversarial loss: 0.538552\n",
      "epoch 71; iter: 0; batch classifier loss: 0.277314; batch adversarial loss: 0.523907\n",
      "epoch 72; iter: 0; batch classifier loss: 0.207582; batch adversarial loss: 0.606689\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386991; batch adversarial loss: 0.631589\n",
      "epoch 74; iter: 0; batch classifier loss: 0.252272; batch adversarial loss: 0.503970\n",
      "epoch 75; iter: 0; batch classifier loss: 0.268846; batch adversarial loss: 0.623242\n",
      "epoch 76; iter: 0; batch classifier loss: 0.195676; batch adversarial loss: 0.516762\n",
      "epoch 77; iter: 0; batch classifier loss: 0.210255; batch adversarial loss: 0.501625\n",
      "epoch 78; iter: 0; batch classifier loss: 0.198158; batch adversarial loss: 0.562724\n",
      "epoch 79; iter: 0; batch classifier loss: 0.242400; batch adversarial loss: 0.605945\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718173; batch adversarial loss: 0.648985\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627112; batch adversarial loss: 0.664864\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629553; batch adversarial loss: 0.610212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559096; batch adversarial loss: 0.598886\n",
      "epoch 4; iter: 0; batch classifier loss: 0.498138; batch adversarial loss: 0.801987\n",
      "epoch 5; iter: 0; batch classifier loss: 0.504180; batch adversarial loss: 0.691035\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482745; batch adversarial loss: 0.672133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.401950; batch adversarial loss: 0.589979\n",
      "epoch 8; iter: 0; batch classifier loss: 0.379488; batch adversarial loss: 0.659676\n",
      "epoch 9; iter: 0; batch classifier loss: 0.450305; batch adversarial loss: 0.560049\n",
      "epoch 10; iter: 0; batch classifier loss: 0.339593; batch adversarial loss: 0.542146\n",
      "epoch 11; iter: 0; batch classifier loss: 0.421057; batch adversarial loss: 0.562145\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413705; batch adversarial loss: 0.689833\n",
      "epoch 13; iter: 0; batch classifier loss: 0.335405; batch adversarial loss: 0.626038\n",
      "epoch 14; iter: 0; batch classifier loss: 0.421308; batch adversarial loss: 0.613634\n",
      "epoch 15; iter: 0; batch classifier loss: 0.287494; batch adversarial loss: 0.625991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.274698; batch adversarial loss: 0.598797\n",
      "epoch 17; iter: 0; batch classifier loss: 0.326203; batch adversarial loss: 0.556601\n",
      "epoch 18; iter: 0; batch classifier loss: 0.298493; batch adversarial loss: 0.602417\n",
      "epoch 19; iter: 0; batch classifier loss: 0.348590; batch adversarial loss: 0.562117\n",
      "epoch 20; iter: 0; batch classifier loss: 0.328524; batch adversarial loss: 0.566143\n",
      "epoch 21; iter: 0; batch classifier loss: 0.308083; batch adversarial loss: 0.699819\n",
      "epoch 22; iter: 0; batch classifier loss: 0.262756; batch adversarial loss: 0.659059\n",
      "epoch 23; iter: 0; batch classifier loss: 0.285652; batch adversarial loss: 0.634141\n",
      "epoch 24; iter: 0; batch classifier loss: 0.284416; batch adversarial loss: 0.661542\n",
      "epoch 25; iter: 0; batch classifier loss: 0.326169; batch adversarial loss: 0.607468\n",
      "epoch 26; iter: 0; batch classifier loss: 0.244766; batch adversarial loss: 0.647917\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293529; batch adversarial loss: 0.634098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.321386; batch adversarial loss: 0.567890\n",
      "epoch 29; iter: 0; batch classifier loss: 0.309877; batch adversarial loss: 0.590666\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261921; batch adversarial loss: 0.643340\n",
      "epoch 31; iter: 0; batch classifier loss: 0.225161; batch adversarial loss: 0.589308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.246853; batch adversarial loss: 0.505958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.287442; batch adversarial loss: 0.563742\n",
      "epoch 34; iter: 0; batch classifier loss: 0.237177; batch adversarial loss: 0.627423\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319062; batch adversarial loss: 0.747125\n",
      "epoch 36; iter: 0; batch classifier loss: 0.304864; batch adversarial loss: 0.577128\n",
      "epoch 37; iter: 0; batch classifier loss: 0.190067; batch adversarial loss: 0.612698\n",
      "epoch 38; iter: 0; batch classifier loss: 0.191186; batch adversarial loss: 0.541428\n",
      "epoch 39; iter: 0; batch classifier loss: 0.184157; batch adversarial loss: 0.573384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.317619; batch adversarial loss: 0.564047\n",
      "epoch 41; iter: 0; batch classifier loss: 0.316338; batch adversarial loss: 0.631032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.216796; batch adversarial loss: 0.551573\n",
      "epoch 43; iter: 0; batch classifier loss: 0.223576; batch adversarial loss: 0.614116\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237877; batch adversarial loss: 0.599952\n",
      "epoch 45; iter: 0; batch classifier loss: 0.263706; batch adversarial loss: 0.620989\n",
      "epoch 46; iter: 0; batch classifier loss: 0.220398; batch adversarial loss: 0.482563\n",
      "epoch 47; iter: 0; batch classifier loss: 0.183294; batch adversarial loss: 0.631725\n",
      "epoch 48; iter: 0; batch classifier loss: 0.240339; batch adversarial loss: 0.636187\n",
      "epoch 49; iter: 0; batch classifier loss: 0.216161; batch adversarial loss: 0.636038\n",
      "epoch 50; iter: 0; batch classifier loss: 0.223774; batch adversarial loss: 0.648243\n",
      "epoch 51; iter: 0; batch classifier loss: 0.238079; batch adversarial loss: 0.706678\n",
      "epoch 52; iter: 0; batch classifier loss: 0.280332; batch adversarial loss: 0.603392\n",
      "epoch 53; iter: 0; batch classifier loss: 0.272508; batch adversarial loss: 0.549060\n",
      "epoch 54; iter: 0; batch classifier loss: 0.171553; batch adversarial loss: 0.563442\n",
      "epoch 55; iter: 0; batch classifier loss: 0.166900; batch adversarial loss: 0.650647\n",
      "epoch 56; iter: 0; batch classifier loss: 0.128345; batch adversarial loss: 0.546262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.116172; batch adversarial loss: 0.673345\n",
      "epoch 58; iter: 0; batch classifier loss: 0.151895; batch adversarial loss: 0.529093\n",
      "epoch 59; iter: 0; batch classifier loss: 0.161293; batch adversarial loss: 0.703849\n",
      "epoch 60; iter: 0; batch classifier loss: 0.184516; batch adversarial loss: 0.571683\n",
      "epoch 61; iter: 0; batch classifier loss: 0.185646; batch adversarial loss: 0.524390\n",
      "epoch 62; iter: 0; batch classifier loss: 0.305561; batch adversarial loss: 0.542237\n",
      "epoch 63; iter: 0; batch classifier loss: 0.201797; batch adversarial loss: 0.669198\n",
      "epoch 64; iter: 0; batch classifier loss: 0.201749; batch adversarial loss: 0.543488\n",
      "epoch 65; iter: 0; batch classifier loss: 0.246949; batch adversarial loss: 0.595583\n",
      "epoch 66; iter: 0; batch classifier loss: 0.254303; batch adversarial loss: 0.586149\n",
      "epoch 67; iter: 0; batch classifier loss: 0.162406; batch adversarial loss: 0.585707\n",
      "epoch 68; iter: 0; batch classifier loss: 0.309721; batch adversarial loss: 0.620669\n",
      "epoch 69; iter: 0; batch classifier loss: 0.198062; batch adversarial loss: 0.553728\n",
      "epoch 70; iter: 0; batch classifier loss: 0.214395; batch adversarial loss: 0.585768\n",
      "epoch 71; iter: 0; batch classifier loss: 0.234399; batch adversarial loss: 0.605975\n",
      "epoch 72; iter: 0; batch classifier loss: 0.187538; batch adversarial loss: 0.576566\n",
      "epoch 73; iter: 0; batch classifier loss: 0.148416; batch adversarial loss: 0.622615\n",
      "epoch 74; iter: 0; batch classifier loss: 0.160960; batch adversarial loss: 0.551548\n",
      "epoch 75; iter: 0; batch classifier loss: 0.269889; batch adversarial loss: 0.531122\n",
      "epoch 76; iter: 0; batch classifier loss: 0.190123; batch adversarial loss: 0.593256\n",
      "epoch 77; iter: 0; batch classifier loss: 0.153471; batch adversarial loss: 0.572080\n",
      "epoch 78; iter: 0; batch classifier loss: 0.224304; batch adversarial loss: 0.627681\n",
      "epoch 79; iter: 0; batch classifier loss: 0.209185; batch adversarial loss: 0.561811\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738132; batch adversarial loss: 0.768141\n",
      "epoch 1; iter: 0; batch classifier loss: 0.678680; batch adversarial loss: 0.761719\n",
      "epoch 2; iter: 0; batch classifier loss: 0.664294; batch adversarial loss: 0.765427\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677588; batch adversarial loss: 0.744157\n",
      "epoch 4; iter: 0; batch classifier loss: 0.602824; batch adversarial loss: 0.747277\n",
      "epoch 5; iter: 0; batch classifier loss: 0.628474; batch adversarial loss: 0.738764\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591478; batch adversarial loss: 0.736182\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606752; batch adversarial loss: 0.735506\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572422; batch adversarial loss: 0.757977\n",
      "epoch 9; iter: 0; batch classifier loss: 0.581564; batch adversarial loss: 0.726066\n",
      "epoch 10; iter: 0; batch classifier loss: 0.592799; batch adversarial loss: 0.735732\n",
      "epoch 11; iter: 0; batch classifier loss: 0.541442; batch adversarial loss: 0.730065\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483370; batch adversarial loss: 0.734821\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498388; batch adversarial loss: 0.750610\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528498; batch adversarial loss: 0.722987\n",
      "epoch 15; iter: 0; batch classifier loss: 0.476842; batch adversarial loss: 0.726982\n",
      "epoch 16; iter: 0; batch classifier loss: 0.505097; batch adversarial loss: 0.734270\n",
      "epoch 17; iter: 0; batch classifier loss: 0.428753; batch adversarial loss: 0.732033\n",
      "epoch 18; iter: 0; batch classifier loss: 0.442920; batch adversarial loss: 0.727124\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459665; batch adversarial loss: 0.727187\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456932; batch adversarial loss: 0.719788\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419652; batch adversarial loss: 0.710509\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431778; batch adversarial loss: 0.711140\n",
      "epoch 23; iter: 0; batch classifier loss: 0.460986; batch adversarial loss: 0.721756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.442118; batch adversarial loss: 0.708047\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451930; batch adversarial loss: 0.708131\n",
      "epoch 26; iter: 0; batch classifier loss: 0.459611; batch adversarial loss: 0.709027\n",
      "epoch 27; iter: 0; batch classifier loss: 0.358382; batch adversarial loss: 0.706154\n",
      "epoch 28; iter: 0; batch classifier loss: 0.475748; batch adversarial loss: 0.711433\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429965; batch adversarial loss: 0.703152\n",
      "epoch 30; iter: 0; batch classifier loss: 0.371445; batch adversarial loss: 0.693868\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431331; batch adversarial loss: 0.694013\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426011; batch adversarial loss: 0.694401\n",
      "epoch 33; iter: 0; batch classifier loss: 0.440660; batch adversarial loss: 0.688234\n",
      "epoch 34; iter: 0; batch classifier loss: 0.420104; batch adversarial loss: 0.697858\n",
      "epoch 35; iter: 0; batch classifier loss: 0.444793; batch adversarial loss: 0.689873\n",
      "epoch 36; iter: 0; batch classifier loss: 0.482820; batch adversarial loss: 0.689840\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445671; batch adversarial loss: 0.682147\n",
      "epoch 38; iter: 0; batch classifier loss: 0.363888; batch adversarial loss: 0.683581\n",
      "epoch 39; iter: 0; batch classifier loss: 0.440549; batch adversarial loss: 0.680471\n",
      "epoch 40; iter: 0; batch classifier loss: 0.304660; batch adversarial loss: 0.678564\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343747; batch adversarial loss: 0.680236\n",
      "epoch 42; iter: 0; batch classifier loss: 0.344989; batch adversarial loss: 0.678154\n",
      "epoch 43; iter: 0; batch classifier loss: 0.350550; batch adversarial loss: 0.676365\n",
      "epoch 44; iter: 0; batch classifier loss: 0.332993; batch adversarial loss: 0.674516\n",
      "epoch 45; iter: 0; batch classifier loss: 0.430534; batch adversarial loss: 0.666718\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314262; batch adversarial loss: 0.674307\n",
      "epoch 47; iter: 0; batch classifier loss: 0.374143; batch adversarial loss: 0.670671\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421685; batch adversarial loss: 0.670119\n",
      "epoch 49; iter: 0; batch classifier loss: 0.314406; batch adversarial loss: 0.665124\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403923; batch adversarial loss: 0.669449\n",
      "epoch 51; iter: 0; batch classifier loss: 0.441787; batch adversarial loss: 0.660802\n",
      "epoch 52; iter: 0; batch classifier loss: 0.356579; batch adversarial loss: 0.663066\n",
      "epoch 53; iter: 0; batch classifier loss: 0.396480; batch adversarial loss: 0.666081\n",
      "epoch 54; iter: 0; batch classifier loss: 0.428541; batch adversarial loss: 0.649163\n",
      "epoch 55; iter: 0; batch classifier loss: 0.313944; batch adversarial loss: 0.658316\n",
      "epoch 56; iter: 0; batch classifier loss: 0.408592; batch adversarial loss: 0.650384\n",
      "epoch 57; iter: 0; batch classifier loss: 0.402801; batch adversarial loss: 0.655375\n",
      "epoch 58; iter: 0; batch classifier loss: 0.352332; batch adversarial loss: 0.663585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.376854; batch adversarial loss: 0.661174\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355278; batch adversarial loss: 0.656736\n",
      "epoch 61; iter: 0; batch classifier loss: 0.290965; batch adversarial loss: 0.655635\n",
      "epoch 62; iter: 0; batch classifier loss: 0.293694; batch adversarial loss: 0.651143\n",
      "epoch 63; iter: 0; batch classifier loss: 0.369078; batch adversarial loss: 0.654616\n",
      "epoch 64; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.652584\n",
      "epoch 65; iter: 0; batch classifier loss: 0.313702; batch adversarial loss: 0.648077\n",
      "epoch 66; iter: 0; batch classifier loss: 0.340340; batch adversarial loss: 0.661475\n",
      "epoch 67; iter: 0; batch classifier loss: 0.332344; batch adversarial loss: 0.651936\n",
      "epoch 68; iter: 0; batch classifier loss: 0.343414; batch adversarial loss: 0.644135\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409038; batch adversarial loss: 0.636931\n",
      "epoch 70; iter: 0; batch classifier loss: 0.330969; batch adversarial loss: 0.651091\n",
      "epoch 71; iter: 0; batch classifier loss: 0.372953; batch adversarial loss: 0.654049\n",
      "epoch 72; iter: 0; batch classifier loss: 0.303271; batch adversarial loss: 0.632924\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378097; batch adversarial loss: 0.656133\n",
      "epoch 74; iter: 0; batch classifier loss: 0.406978; batch adversarial loss: 0.658189\n",
      "epoch 75; iter: 0; batch classifier loss: 0.271971; batch adversarial loss: 0.636255\n",
      "epoch 76; iter: 0; batch classifier loss: 0.379430; batch adversarial loss: 0.634076\n",
      "epoch 77; iter: 0; batch classifier loss: 0.309130; batch adversarial loss: 0.651658\n",
      "epoch 78; iter: 0; batch classifier loss: 0.386430; batch adversarial loss: 0.627385\n",
      "epoch 79; iter: 0; batch classifier loss: 0.307798; batch adversarial loss: 0.642161\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700775; batch adversarial loss: 0.739663\n",
      "epoch 1; iter: 0; batch classifier loss: 0.685692; batch adversarial loss: 0.729934\n",
      "epoch 2; iter: 0; batch classifier loss: 0.619142; batch adversarial loss: 0.737672\n",
      "epoch 3; iter: 0; batch classifier loss: 0.600788; batch adversarial loss: 0.736933\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584889; batch adversarial loss: 0.749016\n",
      "epoch 5; iter: 0; batch classifier loss: 0.558438; batch adversarial loss: 0.730618\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520040; batch adversarial loss: 0.727418\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501258; batch adversarial loss: 0.711968\n",
      "epoch 8; iter: 0; batch classifier loss: 0.509308; batch adversarial loss: 0.715649\n",
      "epoch 9; iter: 0; batch classifier loss: 0.503503; batch adversarial loss: 0.724529\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468844; batch adversarial loss: 0.720236\n",
      "epoch 11; iter: 0; batch classifier loss: 0.462005; batch adversarial loss: 0.721527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412595; batch adversarial loss: 0.708043\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452527; batch adversarial loss: 0.702642\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442958; batch adversarial loss: 0.707392\n",
      "epoch 15; iter: 0; batch classifier loss: 0.440551; batch adversarial loss: 0.700252\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423148; batch adversarial loss: 0.702173\n",
      "epoch 17; iter: 0; batch classifier loss: 0.378465; batch adversarial loss: 0.691361\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466115; batch adversarial loss: 0.703219\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406674; batch adversarial loss: 0.699024\n",
      "epoch 20; iter: 0; batch classifier loss: 0.398335; batch adversarial loss: 0.694576\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415822; batch adversarial loss: 0.698352\n",
      "epoch 22; iter: 0; batch classifier loss: 0.406456; batch adversarial loss: 0.688835\n",
      "epoch 23; iter: 0; batch classifier loss: 0.440184; batch adversarial loss: 0.691794\n",
      "epoch 24; iter: 0; batch classifier loss: 0.372961; batch adversarial loss: 0.671253\n",
      "epoch 25; iter: 0; batch classifier loss: 0.384135; batch adversarial loss: 0.687855\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394957; batch adversarial loss: 0.674349\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.680648\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362010; batch adversarial loss: 0.669087\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324749; batch adversarial loss: 0.674917\n",
      "epoch 30; iter: 0; batch classifier loss: 0.337454; batch adversarial loss: 0.661019\n",
      "epoch 31; iter: 0; batch classifier loss: 0.399271; batch adversarial loss: 0.685392\n",
      "epoch 32; iter: 0; batch classifier loss: 0.391533; batch adversarial loss: 0.666607\n",
      "epoch 33; iter: 0; batch classifier loss: 0.330814; batch adversarial loss: 0.658003\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334418; batch adversarial loss: 0.651452\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386163; batch adversarial loss: 0.668317\n",
      "epoch 36; iter: 0; batch classifier loss: 0.334947; batch adversarial loss: 0.662011\n",
      "epoch 37; iter: 0; batch classifier loss: 0.281511; batch adversarial loss: 0.641355\n",
      "epoch 38; iter: 0; batch classifier loss: 0.344187; batch adversarial loss: 0.661377\n",
      "epoch 39; iter: 0; batch classifier loss: 0.303437; batch adversarial loss: 0.641333\n",
      "epoch 40; iter: 0; batch classifier loss: 0.317583; batch adversarial loss: 0.636934\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343183; batch adversarial loss: 0.652661\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350646; batch adversarial loss: 0.646990\n",
      "epoch 43; iter: 0; batch classifier loss: 0.337044; batch adversarial loss: 0.660081\n",
      "epoch 44; iter: 0; batch classifier loss: 0.360403; batch adversarial loss: 0.652729\n",
      "epoch 45; iter: 0; batch classifier loss: 0.366322; batch adversarial loss: 0.645045\n",
      "epoch 46; iter: 0; batch classifier loss: 0.306590; batch adversarial loss: 0.641629\n",
      "epoch 47; iter: 0; batch classifier loss: 0.350093; batch adversarial loss: 0.648816\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207308; batch adversarial loss: 0.616363\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374762; batch adversarial loss: 0.628197\n",
      "epoch 50; iter: 0; batch classifier loss: 0.312037; batch adversarial loss: 0.649702\n",
      "epoch 51; iter: 0; batch classifier loss: 0.306165; batch adversarial loss: 0.617486\n",
      "epoch 52; iter: 0; batch classifier loss: 0.357527; batch adversarial loss: 0.626776\n",
      "epoch 53; iter: 0; batch classifier loss: 0.304485; batch adversarial loss: 0.630701\n",
      "epoch 54; iter: 0; batch classifier loss: 0.282732; batch adversarial loss: 0.626153\n",
      "epoch 55; iter: 0; batch classifier loss: 0.321183; batch adversarial loss: 0.630561\n",
      "epoch 56; iter: 0; batch classifier loss: 0.312370; batch adversarial loss: 0.645368\n",
      "epoch 57; iter: 0; batch classifier loss: 0.322293; batch adversarial loss: 0.627929\n",
      "epoch 58; iter: 0; batch classifier loss: 0.263374; batch adversarial loss: 0.644652\n",
      "epoch 59; iter: 0; batch classifier loss: 0.299436; batch adversarial loss: 0.620437\n",
      "epoch 60; iter: 0; batch classifier loss: 0.252260; batch adversarial loss: 0.600509\n",
      "epoch 61; iter: 0; batch classifier loss: 0.258166; batch adversarial loss: 0.623464\n",
      "epoch 62; iter: 0; batch classifier loss: 0.261490; batch adversarial loss: 0.634000\n",
      "epoch 63; iter: 0; batch classifier loss: 0.225143; batch adversarial loss: 0.612819\n",
      "epoch 64; iter: 0; batch classifier loss: 0.251507; batch adversarial loss: 0.640452\n",
      "epoch 65; iter: 0; batch classifier loss: 0.332899; batch adversarial loss: 0.614907\n",
      "epoch 66; iter: 0; batch classifier loss: 0.330778; batch adversarial loss: 0.606221\n",
      "epoch 67; iter: 0; batch classifier loss: 0.279218; batch adversarial loss: 0.622336\n",
      "epoch 68; iter: 0; batch classifier loss: 0.289335; batch adversarial loss: 0.635826\n",
      "epoch 69; iter: 0; batch classifier loss: 0.260006; batch adversarial loss: 0.628847\n",
      "epoch 70; iter: 0; batch classifier loss: 0.194572; batch adversarial loss: 0.617594\n",
      "epoch 71; iter: 0; batch classifier loss: 0.261857; batch adversarial loss: 0.617064\n",
      "epoch 72; iter: 0; batch classifier loss: 0.253174; batch adversarial loss: 0.639680\n",
      "epoch 73; iter: 0; batch classifier loss: 0.269089; batch adversarial loss: 0.636550\n",
      "epoch 74; iter: 0; batch classifier loss: 0.278744; batch adversarial loss: 0.602770\n",
      "epoch 75; iter: 0; batch classifier loss: 0.271315; batch adversarial loss: 0.630681\n",
      "epoch 76; iter: 0; batch classifier loss: 0.224216; batch adversarial loss: 0.595275\n",
      "epoch 77; iter: 0; batch classifier loss: 0.205880; batch adversarial loss: 0.655191\n",
      "epoch 78; iter: 0; batch classifier loss: 0.248733; batch adversarial loss: 0.651243\n",
      "epoch 79; iter: 0; batch classifier loss: 0.252347; batch adversarial loss: 0.615065\n",
      "epoch 0; iter: 0; batch classifier loss: 0.699019; batch adversarial loss: 0.722219\n",
      "epoch 1; iter: 0; batch classifier loss: 0.667487; batch adversarial loss: 0.718662\n",
      "epoch 2; iter: 0; batch classifier loss: 0.640295; batch adversarial loss: 0.683068\n",
      "epoch 3; iter: 0; batch classifier loss: 0.586973; batch adversarial loss: 0.706346\n",
      "epoch 4; iter: 0; batch classifier loss: 0.591138; batch adversarial loss: 0.704857\n",
      "epoch 5; iter: 0; batch classifier loss: 0.500512; batch adversarial loss: 0.712072\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501525; batch adversarial loss: 0.708623\n",
      "epoch 7; iter: 0; batch classifier loss: 0.504934; batch adversarial loss: 0.679727\n",
      "epoch 8; iter: 0; batch classifier loss: 0.518525; batch adversarial loss: 0.686596\n",
      "epoch 9; iter: 0; batch classifier loss: 0.459551; batch adversarial loss: 0.684689\n",
      "epoch 10; iter: 0; batch classifier loss: 0.477758; batch adversarial loss: 0.669402\n",
      "epoch 11; iter: 0; batch classifier loss: 0.418627; batch adversarial loss: 0.676802\n",
      "epoch 12; iter: 0; batch classifier loss: 0.404766; batch adversarial loss: 0.670999\n",
      "epoch 13; iter: 0; batch classifier loss: 0.353190; batch adversarial loss: 0.668554\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397079; batch adversarial loss: 0.683244\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380912; batch adversarial loss: 0.657548\n",
      "epoch 16; iter: 0; batch classifier loss: 0.490464; batch adversarial loss: 0.658632\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365043; batch adversarial loss: 0.643981\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286384; batch adversarial loss: 0.648758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343721; batch adversarial loss: 0.654078\n",
      "epoch 20; iter: 0; batch classifier loss: 0.561172; batch adversarial loss: 0.673777\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372230; batch adversarial loss: 0.681533\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487911; batch adversarial loss: 0.620354\n",
      "epoch 23; iter: 0; batch classifier loss: 0.381808; batch adversarial loss: 0.627119\n",
      "epoch 24; iter: 0; batch classifier loss: 0.369921; batch adversarial loss: 0.643308\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304442; batch adversarial loss: 0.648753\n",
      "epoch 26; iter: 0; batch classifier loss: 0.257133; batch adversarial loss: 0.635316\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337229; batch adversarial loss: 0.665199\n",
      "epoch 28; iter: 0; batch classifier loss: 0.313335; batch adversarial loss: 0.625744\n",
      "epoch 29; iter: 0; batch classifier loss: 0.373906; batch adversarial loss: 0.637002\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449117; batch adversarial loss: 0.619266\n",
      "epoch 31; iter: 0; batch classifier loss: 0.254395; batch adversarial loss: 0.653396\n",
      "epoch 32; iter: 0; batch classifier loss: 0.289308; batch adversarial loss: 0.638080\n",
      "epoch 33; iter: 0; batch classifier loss: 0.216218; batch adversarial loss: 0.600681\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284622; batch adversarial loss: 0.663518\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239941; batch adversarial loss: 0.614491\n",
      "epoch 36; iter: 0; batch classifier loss: 0.312556; batch adversarial loss: 0.657276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.275903; batch adversarial loss: 0.603213\n",
      "epoch 38; iter: 0; batch classifier loss: 0.270327; batch adversarial loss: 0.606556\n",
      "epoch 39; iter: 0; batch classifier loss: 0.340002; batch adversarial loss: 0.602283\n",
      "epoch 0; iter: 0; batch classifier loss: 0.713528; batch adversarial loss: 0.894817\n",
      "epoch 1; iter: 0; batch classifier loss: 0.651196; batch adversarial loss: 0.975551\n",
      "epoch 2; iter: 0; batch classifier loss: 0.587255; batch adversarial loss: 1.071679\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593119; batch adversarial loss: 0.926958\n",
      "epoch 4; iter: 0; batch classifier loss: 0.540464; batch adversarial loss: 0.906889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.467903; batch adversarial loss: 1.053371\n",
      "epoch 6; iter: 0; batch classifier loss: 0.450189; batch adversarial loss: 0.881387\n",
      "epoch 7; iter: 0; batch classifier loss: 0.417417; batch adversarial loss: 0.970489\n",
      "epoch 8; iter: 0; batch classifier loss: 0.405384; batch adversarial loss: 1.035282\n",
      "epoch 9; iter: 0; batch classifier loss: 0.358847; batch adversarial loss: 1.056703\n",
      "epoch 10; iter: 0; batch classifier loss: 0.371665; batch adversarial loss: 0.896275\n",
      "epoch 11; iter: 0; batch classifier loss: 0.356594; batch adversarial loss: 0.875795\n",
      "epoch 12; iter: 0; batch classifier loss: 0.342631; batch adversarial loss: 0.880200\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339892; batch adversarial loss: 0.991812\n",
      "epoch 14; iter: 0; batch classifier loss: 0.261893; batch adversarial loss: 0.983429\n",
      "epoch 15; iter: 0; batch classifier loss: 0.358331; batch adversarial loss: 0.849388\n",
      "epoch 16; iter: 0; batch classifier loss: 0.351951; batch adversarial loss: 0.828522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.307962; batch adversarial loss: 0.856336\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360102; batch adversarial loss: 0.902494\n",
      "epoch 19; iter: 0; batch classifier loss: 0.403801; batch adversarial loss: 0.925898\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361551; batch adversarial loss: 0.869991\n",
      "epoch 21; iter: 0; batch classifier loss: 0.391139; batch adversarial loss: 0.873888\n",
      "epoch 22; iter: 0; batch classifier loss: 0.280659; batch adversarial loss: 0.858595\n",
      "epoch 23; iter: 0; batch classifier loss: 0.320919; batch adversarial loss: 0.809693\n",
      "epoch 24; iter: 0; batch classifier loss: 0.273981; batch adversarial loss: 0.835457\n",
      "epoch 25; iter: 0; batch classifier loss: 0.325816; batch adversarial loss: 0.841546\n",
      "epoch 26; iter: 0; batch classifier loss: 0.342397; batch adversarial loss: 0.909975\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277682; batch adversarial loss: 0.853281\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241035; batch adversarial loss: 0.906254\n",
      "epoch 29; iter: 0; batch classifier loss: 0.272848; batch adversarial loss: 0.860277\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319555; batch adversarial loss: 0.825675\n",
      "epoch 31; iter: 0; batch classifier loss: 0.201899; batch adversarial loss: 0.789169\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267477; batch adversarial loss: 0.802676\n",
      "epoch 33; iter: 0; batch classifier loss: 0.320198; batch adversarial loss: 0.785836\n",
      "epoch 34; iter: 0; batch classifier loss: 0.210086; batch adversarial loss: 0.874240\n",
      "epoch 35; iter: 0; batch classifier loss: 0.232207; batch adversarial loss: 0.824586\n",
      "epoch 36; iter: 0; batch classifier loss: 0.264700; batch adversarial loss: 0.712906\n",
      "epoch 37; iter: 0; batch classifier loss: 0.246234; batch adversarial loss: 0.799865\n",
      "epoch 38; iter: 0; batch classifier loss: 0.218253; batch adversarial loss: 0.828629\n",
      "epoch 39; iter: 0; batch classifier loss: 0.193806; batch adversarial loss: 0.793610\n",
      "epoch 0; iter: 0; batch classifier loss: 0.748887; batch adversarial loss: 0.676832\n",
      "epoch 1; iter: 0; batch classifier loss: 0.724135; batch adversarial loss: 0.689011\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676099; batch adversarial loss: 0.710223\n",
      "epoch 3; iter: 0; batch classifier loss: 0.756056; batch adversarial loss: 0.664026\n",
      "epoch 4; iter: 0; batch classifier loss: 0.697382; batch adversarial loss: 0.667686\n",
      "epoch 5; iter: 0; batch classifier loss: 0.678648; batch adversarial loss: 0.702323\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656533; batch adversarial loss: 0.715303\n",
      "epoch 7; iter: 0; batch classifier loss: 0.666671; batch adversarial loss: 0.704706\n",
      "epoch 8; iter: 0; batch classifier loss: 0.637778; batch adversarial loss: 0.668680\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589990; batch adversarial loss: 0.681238\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574790; batch adversarial loss: 0.681798\n",
      "epoch 11; iter: 0; batch classifier loss: 0.582387; batch adversarial loss: 0.656310\n",
      "epoch 12; iter: 0; batch classifier loss: 0.607269; batch adversarial loss: 0.673830\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558977; batch adversarial loss: 0.696329\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542606; batch adversarial loss: 0.692410\n",
      "epoch 15; iter: 0; batch classifier loss: 0.528509; batch adversarial loss: 0.685210\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519226; batch adversarial loss: 0.703522\n",
      "epoch 17; iter: 0; batch classifier loss: 0.515653; batch adversarial loss: 0.696286\n",
      "epoch 18; iter: 0; batch classifier loss: 0.512607; batch adversarial loss: 0.681137\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485432; batch adversarial loss: 0.676591\n",
      "epoch 20; iter: 0; batch classifier loss: 0.534993; batch adversarial loss: 0.670946\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473582; batch adversarial loss: 0.693382\n",
      "epoch 22; iter: 0; batch classifier loss: 0.555446; batch adversarial loss: 0.667794\n",
      "epoch 23; iter: 0; batch classifier loss: 0.518077; batch adversarial loss: 0.665396\n",
      "epoch 24; iter: 0; batch classifier loss: 0.458050; batch adversarial loss: 0.673501\n",
      "epoch 25; iter: 0; batch classifier loss: 0.456970; batch adversarial loss: 0.639839\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457042; batch adversarial loss: 0.662605\n",
      "epoch 27; iter: 0; batch classifier loss: 0.428915; batch adversarial loss: 0.655899\n",
      "epoch 28; iter: 0; batch classifier loss: 0.355067; batch adversarial loss: 0.656095\n",
      "epoch 29; iter: 0; batch classifier loss: 0.399064; batch adversarial loss: 0.659747\n",
      "epoch 30; iter: 0; batch classifier loss: 0.428951; batch adversarial loss: 0.673749\n",
      "epoch 31; iter: 0; batch classifier loss: 0.403923; batch adversarial loss: 0.684179\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420205; batch adversarial loss: 0.651792\n",
      "epoch 33; iter: 0; batch classifier loss: 0.447963; batch adversarial loss: 0.676701\n",
      "epoch 34; iter: 0; batch classifier loss: 0.324937; batch adversarial loss: 0.682158\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436986; batch adversarial loss: 0.642008\n",
      "epoch 36; iter: 0; batch classifier loss: 0.423487; batch adversarial loss: 0.638251\n",
      "epoch 37; iter: 0; batch classifier loss: 0.437961; batch adversarial loss: 0.629795\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380341; batch adversarial loss: 0.649243\n",
      "epoch 39; iter: 0; batch classifier loss: 0.429949; batch adversarial loss: 0.650736\n",
      "epoch 0; iter: 0; batch classifier loss: 0.792308; batch adversarial loss: 0.913872\n",
      "epoch 1; iter: 0; batch classifier loss: 0.757672; batch adversarial loss: 0.952315\n",
      "epoch 2; iter: 0; batch classifier loss: 0.717582; batch adversarial loss: 0.879572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.704619; batch adversarial loss: 0.926923\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640845; batch adversarial loss: 0.906373\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633438; batch adversarial loss: 0.880623\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606631; batch adversarial loss: 0.914347\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587879; batch adversarial loss: 0.926878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.586011; batch adversarial loss: 0.893598\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528085; batch adversarial loss: 0.877599\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500569; batch adversarial loss: 0.901033\n",
      "epoch 11; iter: 0; batch classifier loss: 0.563061; batch adversarial loss: 0.893803\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529025; batch adversarial loss: 0.909232\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489071; batch adversarial loss: 0.917193\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475190; batch adversarial loss: 0.914483\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480303; batch adversarial loss: 0.918063\n",
      "epoch 16; iter: 0; batch classifier loss: 0.454321; batch adversarial loss: 0.816138\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420677; batch adversarial loss: 0.887657\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452588; batch adversarial loss: 0.899861\n",
      "epoch 19; iter: 0; batch classifier loss: 0.400428; batch adversarial loss: 0.812133\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429802; batch adversarial loss: 0.864767\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366264; batch adversarial loss: 0.842469\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392777; batch adversarial loss: 0.883359\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414604; batch adversarial loss: 0.864662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360325; batch adversarial loss: 0.820652\n",
      "epoch 25; iter: 0; batch classifier loss: 0.373537; batch adversarial loss: 0.851949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378037; batch adversarial loss: 0.853437\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397791; batch adversarial loss: 0.841567\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375838; batch adversarial loss: 0.887396\n",
      "epoch 29; iter: 0; batch classifier loss: 0.300333; batch adversarial loss: 0.860106\n",
      "epoch 30; iter: 0; batch classifier loss: 0.353989; batch adversarial loss: 0.846719\n",
      "epoch 31; iter: 0; batch classifier loss: 0.340222; batch adversarial loss: 0.839158\n",
      "epoch 32; iter: 0; batch classifier loss: 0.430866; batch adversarial loss: 0.821452\n",
      "epoch 33; iter: 0; batch classifier loss: 0.378665; batch adversarial loss: 0.828397\n",
      "epoch 34; iter: 0; batch classifier loss: 0.309206; batch adversarial loss: 0.879594\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421859; batch adversarial loss: 0.781032\n",
      "epoch 36; iter: 0; batch classifier loss: 0.324256; batch adversarial loss: 0.811184\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346595; batch adversarial loss: 0.830532\n",
      "epoch 38; iter: 0; batch classifier loss: 0.332735; batch adversarial loss: 0.837841\n",
      "epoch 39; iter: 0; batch classifier loss: 0.373862; batch adversarial loss: 0.808308\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695357; batch adversarial loss: 1.033492\n",
      "epoch 1; iter: 0; batch classifier loss: 0.649323; batch adversarial loss: 1.048561\n",
      "epoch 2; iter: 0; batch classifier loss: 0.582429; batch adversarial loss: 0.994091\n",
      "epoch 3; iter: 0; batch classifier loss: 0.548883; batch adversarial loss: 1.039635\n",
      "epoch 4; iter: 0; batch classifier loss: 0.572273; batch adversarial loss: 1.015263\n",
      "epoch 5; iter: 0; batch classifier loss: 0.464967; batch adversarial loss: 0.979481\n",
      "epoch 6; iter: 0; batch classifier loss: 0.562538; batch adversarial loss: 0.974465\n",
      "epoch 7; iter: 0; batch classifier loss: 0.450170; batch adversarial loss: 0.956886\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499922; batch adversarial loss: 1.016514\n",
      "epoch 9; iter: 0; batch classifier loss: 0.519094; batch adversarial loss: 0.895079\n",
      "epoch 10; iter: 0; batch classifier loss: 0.449331; batch adversarial loss: 0.992100\n",
      "epoch 11; iter: 0; batch classifier loss: 0.532534; batch adversarial loss: 1.010279\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488354; batch adversarial loss: 0.873526\n",
      "epoch 13; iter: 0; batch classifier loss: 0.576441; batch adversarial loss: 0.940966\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503682; batch adversarial loss: 0.935508\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382684; batch adversarial loss: 0.923948\n",
      "epoch 16; iter: 0; batch classifier loss: 0.552954; batch adversarial loss: 0.944031\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487693; batch adversarial loss: 0.907047\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398386; batch adversarial loss: 0.840482\n",
      "epoch 19; iter: 0; batch classifier loss: 0.426110; batch adversarial loss: 0.874859\n",
      "epoch 20; iter: 0; batch classifier loss: 0.338718; batch adversarial loss: 0.846805\n",
      "epoch 21; iter: 0; batch classifier loss: 0.230226; batch adversarial loss: 0.881748\n",
      "epoch 22; iter: 0; batch classifier loss: 0.431535; batch adversarial loss: 0.897378\n",
      "epoch 23; iter: 0; batch classifier loss: 0.397945; batch adversarial loss: 0.851077\n",
      "epoch 24; iter: 0; batch classifier loss: 0.401172; batch adversarial loss: 0.884177\n",
      "epoch 25; iter: 0; batch classifier loss: 0.441579; batch adversarial loss: 0.834292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372915; batch adversarial loss: 0.910298\n",
      "epoch 27; iter: 0; batch classifier loss: 0.436189; batch adversarial loss: 0.881557\n",
      "epoch 28; iter: 0; batch classifier loss: 0.463010; batch adversarial loss: 0.825558\n",
      "epoch 29; iter: 0; batch classifier loss: 0.246363; batch adversarial loss: 0.808151\n",
      "epoch 30; iter: 0; batch classifier loss: 0.446546; batch adversarial loss: 0.826183\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413683; batch adversarial loss: 0.813494\n",
      "epoch 32; iter: 0; batch classifier loss: 0.391108; batch adversarial loss: 0.801353\n",
      "epoch 33; iter: 0; batch classifier loss: 0.446295; batch adversarial loss: 0.781690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.315578; batch adversarial loss: 0.799046\n",
      "epoch 35; iter: 0; batch classifier loss: 0.342269; batch adversarial loss: 0.782949\n",
      "epoch 36; iter: 0; batch classifier loss: 0.349008; batch adversarial loss: 0.783254\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426915; batch adversarial loss: 0.756609\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419325; batch adversarial loss: 0.758258\n",
      "epoch 39; iter: 0; batch classifier loss: 0.329775; batch adversarial loss: 0.750186\n",
      "epoch 40; iter: 0; batch classifier loss: 0.411785; batch adversarial loss: 0.766390\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340086; batch adversarial loss: 0.761720\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404232; batch adversarial loss: 0.770396\n",
      "epoch 43; iter: 0; batch classifier loss: 0.389317; batch adversarial loss: 0.756760\n",
      "epoch 44; iter: 0; batch classifier loss: 0.502446; batch adversarial loss: 0.730631\n",
      "epoch 45; iter: 0; batch classifier loss: 0.458383; batch adversarial loss: 0.753077\n",
      "epoch 46; iter: 0; batch classifier loss: 0.347652; batch adversarial loss: 0.727253\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346013; batch adversarial loss: 0.722117\n",
      "epoch 48; iter: 0; batch classifier loss: 0.421983; batch adversarial loss: 0.686764\n",
      "epoch 49; iter: 0; batch classifier loss: 0.507398; batch adversarial loss: 0.724089\n",
      "epoch 50; iter: 0; batch classifier loss: 0.325879; batch adversarial loss: 0.718524\n",
      "epoch 51; iter: 0; batch classifier loss: 0.495809; batch adversarial loss: 0.715532\n",
      "epoch 52; iter: 0; batch classifier loss: 0.438133; batch adversarial loss: 0.706905\n",
      "epoch 53; iter: 0; batch classifier loss: 0.460796; batch adversarial loss: 0.711300\n",
      "epoch 54; iter: 0; batch classifier loss: 0.396341; batch adversarial loss: 0.691403\n",
      "epoch 55; iter: 0; batch classifier loss: 0.305624; batch adversarial loss: 0.686079\n",
      "epoch 56; iter: 0; batch classifier loss: 0.225178; batch adversarial loss: 0.655592\n",
      "epoch 57; iter: 0; batch classifier loss: 0.468352; batch adversarial loss: 0.694544\n",
      "epoch 58; iter: 0; batch classifier loss: 0.414110; batch adversarial loss: 0.709828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.450853; batch adversarial loss: 0.715775\n",
      "epoch 0; iter: 0; batch classifier loss: 0.672557; batch adversarial loss: 0.603384\n",
      "epoch 1; iter: 0; batch classifier loss: 0.625880; batch adversarial loss: 0.613581\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589873; batch adversarial loss: 0.574107\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582680; batch adversarial loss: 0.618000\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520622; batch adversarial loss: 0.648079\n",
      "epoch 5; iter: 0; batch classifier loss: 0.503219; batch adversarial loss: 0.612777\n",
      "epoch 6; iter: 0; batch classifier loss: 0.458598; batch adversarial loss: 0.567160\n",
      "epoch 7; iter: 0; batch classifier loss: 0.362650; batch adversarial loss: 0.556760\n",
      "epoch 8; iter: 0; batch classifier loss: 0.407870; batch adversarial loss: 0.627736\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320261; batch adversarial loss: 0.732211\n",
      "epoch 10; iter: 0; batch classifier loss: 0.408171; batch adversarial loss: 0.678915\n",
      "epoch 11; iter: 0; batch classifier loss: 0.309194; batch adversarial loss: 0.636425\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461290; batch adversarial loss: 0.644344\n",
      "epoch 13; iter: 0; batch classifier loss: 0.446662; batch adversarial loss: 0.644730\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413237; batch adversarial loss: 0.599279\n",
      "epoch 15; iter: 0; batch classifier loss: 0.284028; batch adversarial loss: 0.539989\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382925; batch adversarial loss: 0.583639\n",
      "epoch 17; iter: 0; batch classifier loss: 0.275404; batch adversarial loss: 0.608542\n",
      "epoch 18; iter: 0; batch classifier loss: 0.385969; batch adversarial loss: 0.600176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.362782; batch adversarial loss: 0.619144\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282617; batch adversarial loss: 0.600168\n",
      "epoch 21; iter: 0; batch classifier loss: 0.443524; batch adversarial loss: 0.573809\n",
      "epoch 22; iter: 0; batch classifier loss: 0.286501; batch adversarial loss: 0.599725\n",
      "epoch 23; iter: 0; batch classifier loss: 0.405096; batch adversarial loss: 0.577819\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351878; batch adversarial loss: 0.556035\n",
      "epoch 25; iter: 0; batch classifier loss: 0.295686; batch adversarial loss: 0.567888\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264104; batch adversarial loss: 0.695534\n",
      "epoch 27; iter: 0; batch classifier loss: 0.290995; batch adversarial loss: 0.633905\n",
      "epoch 28; iter: 0; batch classifier loss: 0.265258; batch adversarial loss: 0.601765\n",
      "epoch 29; iter: 0; batch classifier loss: 0.217145; batch adversarial loss: 0.531125\n",
      "epoch 30; iter: 0; batch classifier loss: 0.264850; batch adversarial loss: 0.458129\n",
      "epoch 31; iter: 0; batch classifier loss: 0.264512; batch adversarial loss: 0.566283\n",
      "epoch 32; iter: 0; batch classifier loss: 0.287958; batch adversarial loss: 0.554653\n",
      "epoch 33; iter: 0; batch classifier loss: 0.366204; batch adversarial loss: 0.584167\n",
      "epoch 34; iter: 0; batch classifier loss: 0.318567; batch adversarial loss: 0.625326\n",
      "epoch 35; iter: 0; batch classifier loss: 0.290368; batch adversarial loss: 0.635253\n",
      "epoch 36; iter: 0; batch classifier loss: 0.238483; batch adversarial loss: 0.600778\n",
      "epoch 37; iter: 0; batch classifier loss: 0.189720; batch adversarial loss: 0.633154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.296766; batch adversarial loss: 0.679817\n",
      "epoch 39; iter: 0; batch classifier loss: 0.228967; batch adversarial loss: 0.592639\n",
      "epoch 40; iter: 0; batch classifier loss: 0.186331; batch adversarial loss: 0.616270\n",
      "epoch 41; iter: 0; batch classifier loss: 0.271679; batch adversarial loss: 0.599444\n",
      "epoch 42; iter: 0; batch classifier loss: 0.196318; batch adversarial loss: 0.587213\n",
      "epoch 43; iter: 0; batch classifier loss: 0.325664; batch adversarial loss: 0.538039\n",
      "epoch 44; iter: 0; batch classifier loss: 0.275798; batch adversarial loss: 0.551998\n",
      "epoch 45; iter: 0; batch classifier loss: 0.293014; batch adversarial loss: 0.599329\n",
      "epoch 46; iter: 0; batch classifier loss: 0.242019; batch adversarial loss: 0.554281\n",
      "epoch 47; iter: 0; batch classifier loss: 0.241070; batch adversarial loss: 0.654983\n",
      "epoch 48; iter: 0; batch classifier loss: 0.246278; batch adversarial loss: 0.435520\n",
      "epoch 49; iter: 0; batch classifier loss: 0.243416; batch adversarial loss: 0.720667\n",
      "epoch 50; iter: 0; batch classifier loss: 0.300157; batch adversarial loss: 0.561778\n",
      "epoch 51; iter: 0; batch classifier loss: 0.189103; batch adversarial loss: 0.618571\n",
      "epoch 52; iter: 0; batch classifier loss: 0.161750; batch adversarial loss: 0.609170\n",
      "epoch 53; iter: 0; batch classifier loss: 0.238717; batch adversarial loss: 0.650763\n",
      "epoch 54; iter: 0; batch classifier loss: 0.273784; batch adversarial loss: 0.560266\n",
      "epoch 55; iter: 0; batch classifier loss: 0.154412; batch adversarial loss: 0.593121\n",
      "epoch 56; iter: 0; batch classifier loss: 0.184659; batch adversarial loss: 0.535244\n",
      "epoch 57; iter: 0; batch classifier loss: 0.139057; batch adversarial loss: 0.589048\n",
      "epoch 58; iter: 0; batch classifier loss: 0.180136; batch adversarial loss: 0.572114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.170591; batch adversarial loss: 0.646529\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735096; batch adversarial loss: 0.743396\n",
      "epoch 1; iter: 0; batch classifier loss: 0.718567; batch adversarial loss: 0.726065\n",
      "epoch 2; iter: 0; batch classifier loss: 0.719222; batch adversarial loss: 0.729114\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673535; batch adversarial loss: 0.722132\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676763; batch adversarial loss: 0.746181\n",
      "epoch 5; iter: 0; batch classifier loss: 0.680955; batch adversarial loss: 0.717839\n",
      "epoch 6; iter: 0; batch classifier loss: 0.585580; batch adversarial loss: 0.722811\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629444; batch adversarial loss: 0.697906\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579237; batch adversarial loss: 0.719311\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587377; batch adversarial loss: 0.729878\n",
      "epoch 10; iter: 0; batch classifier loss: 0.561260; batch adversarial loss: 0.723778\n",
      "epoch 11; iter: 0; batch classifier loss: 0.578120; batch adversarial loss: 0.716202\n",
      "epoch 12; iter: 0; batch classifier loss: 0.568676; batch adversarial loss: 0.706546\n",
      "epoch 13; iter: 0; batch classifier loss: 0.525132; batch adversarial loss: 0.718435\n",
      "epoch 14; iter: 0; batch classifier loss: 0.559327; batch adversarial loss: 0.687656\n",
      "epoch 15; iter: 0; batch classifier loss: 0.574361; batch adversarial loss: 0.702976\n",
      "epoch 16; iter: 0; batch classifier loss: 0.575157; batch adversarial loss: 0.704760\n",
      "epoch 17; iter: 0; batch classifier loss: 0.539347; batch adversarial loss: 0.724475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.552411; batch adversarial loss: 0.711564\n",
      "epoch 19; iter: 0; batch classifier loss: 0.492906; batch adversarial loss: 0.700434\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506779; batch adversarial loss: 0.704591\n",
      "epoch 21; iter: 0; batch classifier loss: 0.502238; batch adversarial loss: 0.706852\n",
      "epoch 22; iter: 0; batch classifier loss: 0.519094; batch adversarial loss: 0.693622\n",
      "epoch 23; iter: 0; batch classifier loss: 0.475268; batch adversarial loss: 0.702823\n",
      "epoch 24; iter: 0; batch classifier loss: 0.483022; batch adversarial loss: 0.707441\n",
      "epoch 25; iter: 0; batch classifier loss: 0.444421; batch adversarial loss: 0.708363\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472154; batch adversarial loss: 0.681553\n",
      "epoch 27; iter: 0; batch classifier loss: 0.462875; batch adversarial loss: 0.700901\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461125; batch adversarial loss: 0.705896\n",
      "epoch 29; iter: 0; batch classifier loss: 0.450773; batch adversarial loss: 0.698816\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407693; batch adversarial loss: 0.683383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430936; batch adversarial loss: 0.683921\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420103; batch adversarial loss: 0.693570\n",
      "epoch 33; iter: 0; batch classifier loss: 0.408100; batch adversarial loss: 0.700303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.401873; batch adversarial loss: 0.687182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.404009; batch adversarial loss: 0.687517\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421359; batch adversarial loss: 0.684377\n",
      "epoch 37; iter: 0; batch classifier loss: 0.361990; batch adversarial loss: 0.684893\n",
      "epoch 38; iter: 0; batch classifier loss: 0.406928; batch adversarial loss: 0.688152\n",
      "epoch 39; iter: 0; batch classifier loss: 0.436187; batch adversarial loss: 0.676135\n",
      "epoch 40; iter: 0; batch classifier loss: 0.418239; batch adversarial loss: 0.702183\n",
      "epoch 41; iter: 0; batch classifier loss: 0.347979; batch adversarial loss: 0.690597\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404646; batch adversarial loss: 0.681153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.391533; batch adversarial loss: 0.674207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.403126; batch adversarial loss: 0.663339\n",
      "epoch 45; iter: 0; batch classifier loss: 0.377358; batch adversarial loss: 0.668780\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392700; batch adversarial loss: 0.678764\n",
      "epoch 47; iter: 0; batch classifier loss: 0.385179; batch adversarial loss: 0.664509\n",
      "epoch 48; iter: 0; batch classifier loss: 0.418235; batch adversarial loss: 0.663120\n",
      "epoch 49; iter: 0; batch classifier loss: 0.429444; batch adversarial loss: 0.644161\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358692; batch adversarial loss: 0.661301\n",
      "epoch 51; iter: 0; batch classifier loss: 0.386492; batch adversarial loss: 0.656666\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375237; batch adversarial loss: 0.658392\n",
      "epoch 53; iter: 0; batch classifier loss: 0.332792; batch adversarial loss: 0.668997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.333897; batch adversarial loss: 0.660718\n",
      "epoch 55; iter: 0; batch classifier loss: 0.368214; batch adversarial loss: 0.648677\n",
      "epoch 56; iter: 0; batch classifier loss: 0.365234; batch adversarial loss: 0.658323\n",
      "epoch 57; iter: 0; batch classifier loss: 0.332835; batch adversarial loss: 0.655006\n",
      "epoch 58; iter: 0; batch classifier loss: 0.346505; batch adversarial loss: 0.634283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.383957; batch adversarial loss: 0.651209\n",
      "epoch 0; iter: 0; batch classifier loss: 0.868433; batch adversarial loss: 0.641116\n",
      "epoch 1; iter: 0; batch classifier loss: 0.786829; batch adversarial loss: 0.619665\n",
      "epoch 2; iter: 0; batch classifier loss: 0.760236; batch adversarial loss: 0.637430\n",
      "epoch 3; iter: 0; batch classifier loss: 0.725622; batch adversarial loss: 0.633538\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676228; batch adversarial loss: 0.629194\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643292; batch adversarial loss: 0.640523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.649759; batch adversarial loss: 0.634526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.626306; batch adversarial loss: 0.600953\n",
      "epoch 8; iter: 0; batch classifier loss: 0.567906; batch adversarial loss: 0.658885\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575348; batch adversarial loss: 0.671025\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522830; batch adversarial loss: 0.684406\n",
      "epoch 11; iter: 0; batch classifier loss: 0.524717; batch adversarial loss: 0.634919\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505243; batch adversarial loss: 0.625418\n",
      "epoch 13; iter: 0; batch classifier loss: 0.514744; batch adversarial loss: 0.637714\n",
      "epoch 14; iter: 0; batch classifier loss: 0.497883; batch adversarial loss: 0.587025\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433974; batch adversarial loss: 0.611632\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482134; batch adversarial loss: 0.643253\n",
      "epoch 17; iter: 0; batch classifier loss: 0.465279; batch adversarial loss: 0.649589\n",
      "epoch 18; iter: 0; batch classifier loss: 0.457647; batch adversarial loss: 0.599139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.504492; batch adversarial loss: 0.616676\n",
      "epoch 20; iter: 0; batch classifier loss: 0.428451; batch adversarial loss: 0.672079\n",
      "epoch 21; iter: 0; batch classifier loss: 0.458027; batch adversarial loss: 0.679085\n",
      "epoch 22; iter: 0; batch classifier loss: 0.404952; batch adversarial loss: 0.664238\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396872; batch adversarial loss: 0.590319\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424591; batch adversarial loss: 0.616306\n",
      "epoch 25; iter: 0; batch classifier loss: 0.450402; batch adversarial loss: 0.594097\n",
      "epoch 26; iter: 0; batch classifier loss: 0.344836; batch adversarial loss: 0.662470\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395820; batch adversarial loss: 0.620251\n",
      "epoch 28; iter: 0; batch classifier loss: 0.379426; batch adversarial loss: 0.654074\n",
      "epoch 29; iter: 0; batch classifier loss: 0.400579; batch adversarial loss: 0.619322\n",
      "epoch 30; iter: 0; batch classifier loss: 0.336386; batch adversarial loss: 0.708692\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366641; batch adversarial loss: 0.646241\n",
      "epoch 32; iter: 0; batch classifier loss: 0.328447; batch adversarial loss: 0.686613\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429648; batch adversarial loss: 0.645654\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389788; batch adversarial loss: 0.649557\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421191; batch adversarial loss: 0.623986\n",
      "epoch 36; iter: 0; batch classifier loss: 0.345742; batch adversarial loss: 0.641776\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387555; batch adversarial loss: 0.706154\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394812; batch adversarial loss: 0.577734\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328734; batch adversarial loss: 0.663181\n",
      "epoch 40; iter: 0; batch classifier loss: 0.320987; batch adversarial loss: 0.527600\n",
      "epoch 41; iter: 0; batch classifier loss: 0.401258; batch adversarial loss: 0.603150\n",
      "epoch 42; iter: 0; batch classifier loss: 0.300491; batch adversarial loss: 0.622664\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258656; batch adversarial loss: 0.637897\n",
      "epoch 44; iter: 0; batch classifier loss: 0.369562; batch adversarial loss: 0.641670\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376492; batch adversarial loss: 0.645674\n",
      "epoch 46; iter: 0; batch classifier loss: 0.332569; batch adversarial loss: 0.616265\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375607; batch adversarial loss: 0.695389\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412837; batch adversarial loss: 0.651642\n",
      "epoch 49; iter: 0; batch classifier loss: 0.318135; batch adversarial loss: 0.595455\n",
      "epoch 50; iter: 0; batch classifier loss: 0.317656; batch adversarial loss: 0.695812\n",
      "epoch 51; iter: 0; batch classifier loss: 0.375548; batch adversarial loss: 0.560954\n",
      "epoch 52; iter: 0; batch classifier loss: 0.307564; batch adversarial loss: 0.600702\n",
      "epoch 53; iter: 0; batch classifier loss: 0.293746; batch adversarial loss: 0.648818\n",
      "epoch 54; iter: 0; batch classifier loss: 0.302938; batch adversarial loss: 0.594828\n",
      "epoch 55; iter: 0; batch classifier loss: 0.319200; batch adversarial loss: 0.666757\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361804; batch adversarial loss: 0.669615\n",
      "epoch 57; iter: 0; batch classifier loss: 0.263615; batch adversarial loss: 0.702639\n",
      "epoch 58; iter: 0; batch classifier loss: 0.280864; batch adversarial loss: 0.691808\n",
      "epoch 59; iter: 0; batch classifier loss: 0.304268; batch adversarial loss: 0.627671\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758289; batch adversarial loss: 0.670159\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844517; batch adversarial loss: 0.681485\n",
      "epoch 2; iter: 0; batch classifier loss: 0.760183; batch adversarial loss: 0.679321\n",
      "epoch 3; iter: 0; batch classifier loss: 0.698242; batch adversarial loss: 0.663858\n",
      "epoch 4; iter: 0; batch classifier loss: 0.725949; batch adversarial loss: 0.674802\n",
      "epoch 5; iter: 0; batch classifier loss: 0.673511; batch adversarial loss: 0.654882\n",
      "epoch 6; iter: 0; batch classifier loss: 0.631475; batch adversarial loss: 0.643604\n",
      "epoch 7; iter: 0; batch classifier loss: 0.606729; batch adversarial loss: 0.674171\n",
      "epoch 8; iter: 0; batch classifier loss: 0.619157; batch adversarial loss: 0.646460\n",
      "epoch 9; iter: 0; batch classifier loss: 0.535787; batch adversarial loss: 0.645077\n",
      "epoch 10; iter: 0; batch classifier loss: 0.464229; batch adversarial loss: 0.640332\n",
      "epoch 11; iter: 0; batch classifier loss: 0.487562; batch adversarial loss: 0.665792\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457871; batch adversarial loss: 0.664548\n",
      "epoch 13; iter: 0; batch classifier loss: 0.494394; batch adversarial loss: 0.627131\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469073; batch adversarial loss: 0.632192\n",
      "epoch 15; iter: 0; batch classifier loss: 0.354639; batch adversarial loss: 0.613798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442841; batch adversarial loss: 0.644355\n",
      "epoch 17; iter: 0; batch classifier loss: 0.355687; batch adversarial loss: 0.615733\n",
      "epoch 18; iter: 0; batch classifier loss: 0.465503; batch adversarial loss: 0.635270\n",
      "epoch 19; iter: 0; batch classifier loss: 0.458726; batch adversarial loss: 0.644588\n",
      "epoch 20; iter: 0; batch classifier loss: 0.348766; batch adversarial loss: 0.640025\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477650; batch adversarial loss: 0.599044\n",
      "epoch 22; iter: 0; batch classifier loss: 0.441034; batch adversarial loss: 0.608507\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284339; batch adversarial loss: 0.612809\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439237; batch adversarial loss: 0.629421\n",
      "epoch 25; iter: 0; batch classifier loss: 0.262589; batch adversarial loss: 0.627830\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380161; batch adversarial loss: 0.602292\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442930; batch adversarial loss: 0.608341\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370510; batch adversarial loss: 0.607545\n",
      "epoch 29; iter: 0; batch classifier loss: 0.304695; batch adversarial loss: 0.603895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.279037; batch adversarial loss: 0.627782\n",
      "epoch 31; iter: 0; batch classifier loss: 0.347174; batch adversarial loss: 0.637126\n",
      "epoch 32; iter: 0; batch classifier loss: 0.341929; batch adversarial loss: 0.632103\n",
      "epoch 33; iter: 0; batch classifier loss: 0.347034; batch adversarial loss: 0.601635\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290963; batch adversarial loss: 0.583398\n",
      "epoch 35; iter: 0; batch classifier loss: 0.290215; batch adversarial loss: 0.591052\n",
      "epoch 36; iter: 0; batch classifier loss: 0.308781; batch adversarial loss: 0.571268\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222884; batch adversarial loss: 0.585833\n",
      "epoch 38; iter: 0; batch classifier loss: 0.289065; batch adversarial loss: 0.578504\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289195; batch adversarial loss: 0.541220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260555; batch adversarial loss: 0.550126\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252391; batch adversarial loss: 0.618615\n",
      "epoch 42; iter: 0; batch classifier loss: 0.243661; batch adversarial loss: 0.624762\n",
      "epoch 43; iter: 0; batch classifier loss: 0.212160; batch adversarial loss: 0.553785\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211816; batch adversarial loss: 0.619883\n",
      "epoch 45; iter: 0; batch classifier loss: 0.274098; batch adversarial loss: 0.568184\n",
      "epoch 46; iter: 0; batch classifier loss: 0.196883; batch adversarial loss: 0.605776\n",
      "epoch 47; iter: 0; batch classifier loss: 0.281210; batch adversarial loss: 0.591990\n",
      "epoch 48; iter: 0; batch classifier loss: 0.378095; batch adversarial loss: 0.593253\n",
      "epoch 49; iter: 0; batch classifier loss: 0.209330; batch adversarial loss: 0.552192\n",
      "epoch 50; iter: 0; batch classifier loss: 0.269684; batch adversarial loss: 0.571341\n",
      "epoch 51; iter: 0; batch classifier loss: 0.337595; batch adversarial loss: 0.560581\n",
      "epoch 52; iter: 0; batch classifier loss: 0.255874; batch adversarial loss: 0.548887\n",
      "epoch 53; iter: 0; batch classifier loss: 0.222103; batch adversarial loss: 0.586459\n",
      "epoch 54; iter: 0; batch classifier loss: 0.354000; batch adversarial loss: 0.553090\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223404; batch adversarial loss: 0.639753\n",
      "epoch 56; iter: 0; batch classifier loss: 0.373828; batch adversarial loss: 0.615903\n",
      "epoch 57; iter: 0; batch classifier loss: 0.242091; batch adversarial loss: 0.581806\n",
      "epoch 58; iter: 0; batch classifier loss: 0.309709; batch adversarial loss: 0.568511\n",
      "epoch 59; iter: 0; batch classifier loss: 0.215087; batch adversarial loss: 0.547134\n",
      "epoch 60; iter: 0; batch classifier loss: 0.220700; batch adversarial loss: 0.498048\n",
      "epoch 61; iter: 0; batch classifier loss: 0.199052; batch adversarial loss: 0.544142\n",
      "epoch 62; iter: 0; batch classifier loss: 0.183740; batch adversarial loss: 0.614338\n",
      "epoch 63; iter: 0; batch classifier loss: 0.196662; batch adversarial loss: 0.513230\n",
      "epoch 64; iter: 0; batch classifier loss: 0.254128; batch adversarial loss: 0.544050\n",
      "epoch 65; iter: 0; batch classifier loss: 0.244056; batch adversarial loss: 0.565730\n",
      "epoch 66; iter: 0; batch classifier loss: 0.269319; batch adversarial loss: 0.566650\n",
      "epoch 67; iter: 0; batch classifier loss: 0.233317; batch adversarial loss: 0.586337\n",
      "epoch 68; iter: 0; batch classifier loss: 0.221886; batch adversarial loss: 0.480413\n",
      "epoch 69; iter: 0; batch classifier loss: 0.214360; batch adversarial loss: 0.622390\n",
      "epoch 70; iter: 0; batch classifier loss: 0.317346; batch adversarial loss: 0.614635\n",
      "epoch 71; iter: 0; batch classifier loss: 0.217679; batch adversarial loss: 0.623187\n",
      "epoch 72; iter: 0; batch classifier loss: 0.248975; batch adversarial loss: 0.520250\n",
      "epoch 73; iter: 0; batch classifier loss: 0.217030; batch adversarial loss: 0.526254\n",
      "epoch 74; iter: 0; batch classifier loss: 0.250803; batch adversarial loss: 0.619545\n",
      "epoch 75; iter: 0; batch classifier loss: 0.278224; batch adversarial loss: 0.572244\n",
      "epoch 76; iter: 0; batch classifier loss: 0.149293; batch adversarial loss: 0.616797\n",
      "epoch 77; iter: 0; batch classifier loss: 0.209724; batch adversarial loss: 0.554176\n",
      "epoch 78; iter: 0; batch classifier loss: 0.270638; batch adversarial loss: 0.568154\n",
      "epoch 79; iter: 0; batch classifier loss: 0.224103; batch adversarial loss: 0.527770\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683717; batch adversarial loss: 0.699893\n",
      "epoch 1; iter: 0; batch classifier loss: 0.615579; batch adversarial loss: 0.698448\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563953; batch adversarial loss: 0.688666\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601790; batch adversarial loss: 0.672764\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541142; batch adversarial loss: 0.674076\n",
      "epoch 5; iter: 0; batch classifier loss: 0.489806; batch adversarial loss: 0.683828\n",
      "epoch 6; iter: 0; batch classifier loss: 0.453667; batch adversarial loss: 0.675756\n",
      "epoch 7; iter: 0; batch classifier loss: 0.394656; batch adversarial loss: 0.683227\n",
      "epoch 8; iter: 0; batch classifier loss: 0.439161; batch adversarial loss: 0.655887\n",
      "epoch 9; iter: 0; batch classifier loss: 0.386305; batch adversarial loss: 0.664224\n",
      "epoch 10; iter: 0; batch classifier loss: 0.456779; batch adversarial loss: 0.641522\n",
      "epoch 11; iter: 0; batch classifier loss: 0.535588; batch adversarial loss: 0.642456\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448140; batch adversarial loss: 0.662757\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457143; batch adversarial loss: 0.631126\n",
      "epoch 14; iter: 0; batch classifier loss: 0.325838; batch adversarial loss: 0.658524\n",
      "epoch 15; iter: 0; batch classifier loss: 0.380694; batch adversarial loss: 0.648462\n",
      "epoch 16; iter: 0; batch classifier loss: 0.354721; batch adversarial loss: 0.666432\n",
      "epoch 17; iter: 0; batch classifier loss: 0.294795; batch adversarial loss: 0.645386\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397068; batch adversarial loss: 0.621481\n",
      "epoch 19; iter: 0; batch classifier loss: 0.424446; batch adversarial loss: 0.618396\n",
      "epoch 20; iter: 0; batch classifier loss: 0.438738; batch adversarial loss: 0.600794\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355876; batch adversarial loss: 0.631564\n",
      "epoch 22; iter: 0; batch classifier loss: 0.370134; batch adversarial loss: 0.626235\n",
      "epoch 23; iter: 0; batch classifier loss: 0.329606; batch adversarial loss: 0.597799\n",
      "epoch 24; iter: 0; batch classifier loss: 0.317074; batch adversarial loss: 0.628414\n",
      "epoch 25; iter: 0; batch classifier loss: 0.271475; batch adversarial loss: 0.608877\n",
      "epoch 26; iter: 0; batch classifier loss: 0.353580; batch adversarial loss: 0.594613\n",
      "epoch 27; iter: 0; batch classifier loss: 0.274806; batch adversarial loss: 0.603521\n",
      "epoch 28; iter: 0; batch classifier loss: 0.290272; batch adversarial loss: 0.649320\n",
      "epoch 29; iter: 0; batch classifier loss: 0.271012; batch adversarial loss: 0.597574\n",
      "epoch 30; iter: 0; batch classifier loss: 0.280852; batch adversarial loss: 0.595594\n",
      "epoch 31; iter: 0; batch classifier loss: 0.223999; batch adversarial loss: 0.594901\n",
      "epoch 32; iter: 0; batch classifier loss: 0.272770; batch adversarial loss: 0.567115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.262866; batch adversarial loss: 0.596247\n",
      "epoch 34; iter: 0; batch classifier loss: 0.313557; batch adversarial loss: 0.602555\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312895; batch adversarial loss: 0.593082\n",
      "epoch 36; iter: 0; batch classifier loss: 0.309297; batch adversarial loss: 0.600343\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255586; batch adversarial loss: 0.608746\n",
      "epoch 38; iter: 0; batch classifier loss: 0.217282; batch adversarial loss: 0.640364\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310652; batch adversarial loss: 0.626254\n",
      "epoch 40; iter: 0; batch classifier loss: 0.228951; batch adversarial loss: 0.564772\n",
      "epoch 41; iter: 0; batch classifier loss: 0.253016; batch adversarial loss: 0.577264\n",
      "epoch 42; iter: 0; batch classifier loss: 0.215360; batch adversarial loss: 0.623855\n",
      "epoch 43; iter: 0; batch classifier loss: 0.211707; batch adversarial loss: 0.591730\n",
      "epoch 44; iter: 0; batch classifier loss: 0.176184; batch adversarial loss: 0.545051\n",
      "epoch 45; iter: 0; batch classifier loss: 0.300590; batch adversarial loss: 0.550715\n",
      "epoch 46; iter: 0; batch classifier loss: 0.293399; batch adversarial loss: 0.572662\n",
      "epoch 47; iter: 0; batch classifier loss: 0.253169; batch adversarial loss: 0.579893\n",
      "epoch 48; iter: 0; batch classifier loss: 0.262786; batch adversarial loss: 0.585048\n",
      "epoch 49; iter: 0; batch classifier loss: 0.208416; batch adversarial loss: 0.576065\n",
      "epoch 50; iter: 0; batch classifier loss: 0.226575; batch adversarial loss: 0.586339\n",
      "epoch 51; iter: 0; batch classifier loss: 0.178101; batch adversarial loss: 0.621822\n",
      "epoch 52; iter: 0; batch classifier loss: 0.235449; batch adversarial loss: 0.578611\n",
      "epoch 53; iter: 0; batch classifier loss: 0.193577; batch adversarial loss: 0.631329\n",
      "epoch 54; iter: 0; batch classifier loss: 0.227833; batch adversarial loss: 0.562244\n",
      "epoch 55; iter: 0; batch classifier loss: 0.188619; batch adversarial loss: 0.612007\n",
      "epoch 56; iter: 0; batch classifier loss: 0.189334; batch adversarial loss: 0.632750\n",
      "epoch 57; iter: 0; batch classifier loss: 0.217008; batch adversarial loss: 0.601687\n",
      "epoch 58; iter: 0; batch classifier loss: 0.200434; batch adversarial loss: 0.555375\n",
      "epoch 59; iter: 0; batch classifier loss: 0.167447; batch adversarial loss: 0.632452\n",
      "epoch 60; iter: 0; batch classifier loss: 0.212071; batch adversarial loss: 0.594650\n",
      "epoch 61; iter: 0; batch classifier loss: 0.172080; batch adversarial loss: 0.575688\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131509; batch adversarial loss: 0.575271\n",
      "epoch 63; iter: 0; batch classifier loss: 0.173353; batch adversarial loss: 0.629115\n",
      "epoch 64; iter: 0; batch classifier loss: 0.380528; batch adversarial loss: 0.659980\n",
      "epoch 65; iter: 0; batch classifier loss: 0.266413; batch adversarial loss: 0.525503\n",
      "epoch 66; iter: 0; batch classifier loss: 0.259213; batch adversarial loss: 0.595346\n",
      "epoch 67; iter: 0; batch classifier loss: 0.252774; batch adversarial loss: 0.542680\n",
      "epoch 68; iter: 0; batch classifier loss: 0.192136; batch adversarial loss: 0.563559\n",
      "epoch 69; iter: 0; batch classifier loss: 0.190838; batch adversarial loss: 0.621104\n",
      "epoch 70; iter: 0; batch classifier loss: 0.109149; batch adversarial loss: 0.609511\n",
      "epoch 71; iter: 0; batch classifier loss: 0.192307; batch adversarial loss: 0.582618\n",
      "epoch 72; iter: 0; batch classifier loss: 0.172282; batch adversarial loss: 0.517336\n",
      "epoch 73; iter: 0; batch classifier loss: 0.229480; batch adversarial loss: 0.582640\n",
      "epoch 74; iter: 0; batch classifier loss: 0.161289; batch adversarial loss: 0.518395\n",
      "epoch 75; iter: 0; batch classifier loss: 0.136001; batch adversarial loss: 0.589806\n",
      "epoch 76; iter: 0; batch classifier loss: 0.162829; batch adversarial loss: 0.596997\n",
      "epoch 77; iter: 0; batch classifier loss: 0.170381; batch adversarial loss: 0.569869\n",
      "epoch 78; iter: 0; batch classifier loss: 0.139064; batch adversarial loss: 0.529918\n",
      "epoch 79; iter: 0; batch classifier loss: 0.170224; batch adversarial loss: 0.554711\n",
      "epoch 0; iter: 0; batch classifier loss: 0.667180; batch adversarial loss: 0.812345\n",
      "epoch 1; iter: 0; batch classifier loss: 0.679852; batch adversarial loss: 0.849872\n",
      "epoch 2; iter: 0; batch classifier loss: 0.640765; batch adversarial loss: 0.863603\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607236; batch adversarial loss: 0.789612\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646839; batch adversarial loss: 0.840030\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621208; batch adversarial loss: 0.854204\n",
      "epoch 6; iter: 0; batch classifier loss: 0.595312; batch adversarial loss: 0.841445\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611262; batch adversarial loss: 0.848780\n",
      "epoch 8; iter: 0; batch classifier loss: 0.621637; batch adversarial loss: 0.919488\n",
      "epoch 9; iter: 0; batch classifier loss: 0.624369; batch adversarial loss: 0.870904\n",
      "epoch 10; iter: 0; batch classifier loss: 0.661141; batch adversarial loss: 0.928613\n",
      "epoch 11; iter: 0; batch classifier loss: 0.566163; batch adversarial loss: 0.867069\n",
      "epoch 12; iter: 0; batch classifier loss: 0.599434; batch adversarial loss: 0.851467\n",
      "epoch 13; iter: 0; batch classifier loss: 0.583152; batch adversarial loss: 0.824634\n",
      "epoch 14; iter: 0; batch classifier loss: 0.560998; batch adversarial loss: 0.844342\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556935; batch adversarial loss: 0.828099\n",
      "epoch 16; iter: 0; batch classifier loss: 0.608404; batch adversarial loss: 0.836131\n",
      "epoch 17; iter: 0; batch classifier loss: 0.566207; batch adversarial loss: 0.869581\n",
      "epoch 18; iter: 0; batch classifier loss: 0.529222; batch adversarial loss: 0.818923\n",
      "epoch 19; iter: 0; batch classifier loss: 0.563857; batch adversarial loss: 0.842379\n",
      "epoch 20; iter: 0; batch classifier loss: 0.582005; batch adversarial loss: 0.855038\n",
      "epoch 21; iter: 0; batch classifier loss: 0.622677; batch adversarial loss: 0.888062\n",
      "epoch 22; iter: 0; batch classifier loss: 0.569742; batch adversarial loss: 0.868932\n",
      "epoch 23; iter: 0; batch classifier loss: 0.608935; batch adversarial loss: 0.871187\n",
      "epoch 24; iter: 0; batch classifier loss: 0.543183; batch adversarial loss: 0.840746\n",
      "epoch 25; iter: 0; batch classifier loss: 0.574548; batch adversarial loss: 0.798598\n",
      "epoch 26; iter: 0; batch classifier loss: 0.563439; batch adversarial loss: 0.815202\n",
      "epoch 27; iter: 0; batch classifier loss: 0.588731; batch adversarial loss: 0.773712\n",
      "epoch 28; iter: 0; batch classifier loss: 0.579456; batch adversarial loss: 0.817114\n",
      "epoch 29; iter: 0; batch classifier loss: 0.604364; batch adversarial loss: 0.809698\n",
      "epoch 30; iter: 0; batch classifier loss: 0.592756; batch adversarial loss: 0.824232\n",
      "epoch 31; iter: 0; batch classifier loss: 0.605065; batch adversarial loss: 0.838413\n",
      "epoch 32; iter: 0; batch classifier loss: 0.578711; batch adversarial loss: 0.796355\n",
      "epoch 33; iter: 0; batch classifier loss: 0.533740; batch adversarial loss: 0.788000\n",
      "epoch 34; iter: 0; batch classifier loss: 0.568092; batch adversarial loss: 0.826363\n",
      "epoch 35; iter: 0; batch classifier loss: 0.565679; batch adversarial loss: 0.812046\n",
      "epoch 36; iter: 0; batch classifier loss: 0.503919; batch adversarial loss: 0.789812\n",
      "epoch 37; iter: 0; batch classifier loss: 0.549343; batch adversarial loss: 0.764675\n",
      "epoch 38; iter: 0; batch classifier loss: 0.556840; batch adversarial loss: 0.786569\n",
      "epoch 39; iter: 0; batch classifier loss: 0.530074; batch adversarial loss: 0.782335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.662815; batch adversarial loss: 0.841852\n",
      "epoch 41; iter: 0; batch classifier loss: 0.632427; batch adversarial loss: 0.818243\n",
      "epoch 42; iter: 0; batch classifier loss: 0.605363; batch adversarial loss: 0.796126\n",
      "epoch 43; iter: 0; batch classifier loss: 0.555062; batch adversarial loss: 0.827301\n",
      "epoch 44; iter: 0; batch classifier loss: 0.554623; batch adversarial loss: 0.769756\n",
      "epoch 45; iter: 0; batch classifier loss: 0.593524; batch adversarial loss: 0.791178\n",
      "epoch 46; iter: 0; batch classifier loss: 0.598213; batch adversarial loss: 0.844763\n",
      "epoch 47; iter: 0; batch classifier loss: 0.539033; batch adversarial loss: 0.770814\n",
      "epoch 48; iter: 0; batch classifier loss: 0.538340; batch adversarial loss: 0.759372\n",
      "epoch 49; iter: 0; batch classifier loss: 0.525586; batch adversarial loss: 0.786969\n",
      "epoch 50; iter: 0; batch classifier loss: 0.599597; batch adversarial loss: 0.787514\n",
      "epoch 51; iter: 0; batch classifier loss: 0.659278; batch adversarial loss: 0.834125\n",
      "epoch 52; iter: 0; batch classifier loss: 0.599712; batch adversarial loss: 0.764423\n",
      "epoch 53; iter: 0; batch classifier loss: 0.498455; batch adversarial loss: 0.720469\n",
      "epoch 54; iter: 0; batch classifier loss: 0.565368; batch adversarial loss: 0.735772\n",
      "epoch 55; iter: 0; batch classifier loss: 0.605696; batch adversarial loss: 0.785238\n",
      "epoch 56; iter: 0; batch classifier loss: 0.576470; batch adversarial loss: 0.789325\n",
      "epoch 57; iter: 0; batch classifier loss: 0.545523; batch adversarial loss: 0.764254\n",
      "epoch 58; iter: 0; batch classifier loss: 0.578139; batch adversarial loss: 0.777559\n",
      "epoch 59; iter: 0; batch classifier loss: 0.516413; batch adversarial loss: 0.728697\n",
      "epoch 60; iter: 0; batch classifier loss: 0.582464; batch adversarial loss: 0.745985\n",
      "epoch 61; iter: 0; batch classifier loss: 0.547345; batch adversarial loss: 0.713965\n",
      "epoch 62; iter: 0; batch classifier loss: 0.608055; batch adversarial loss: 0.804739\n",
      "epoch 63; iter: 0; batch classifier loss: 0.546751; batch adversarial loss: 0.715312\n",
      "epoch 64; iter: 0; batch classifier loss: 0.567449; batch adversarial loss: 0.746982\n",
      "epoch 65; iter: 0; batch classifier loss: 0.615649; batch adversarial loss: 0.777594\n",
      "epoch 66; iter: 0; batch classifier loss: 0.506305; batch adversarial loss: 0.725628\n",
      "epoch 67; iter: 0; batch classifier loss: 0.602897; batch adversarial loss: 0.749005\n",
      "epoch 68; iter: 0; batch classifier loss: 0.475189; batch adversarial loss: 0.745665\n",
      "epoch 69; iter: 0; batch classifier loss: 0.562285; batch adversarial loss: 0.744455\n",
      "epoch 70; iter: 0; batch classifier loss: 0.626985; batch adversarial loss: 0.801470\n",
      "epoch 71; iter: 0; batch classifier loss: 0.577004; batch adversarial loss: 0.775469\n",
      "epoch 72; iter: 0; batch classifier loss: 0.596493; batch adversarial loss: 0.789806\n",
      "epoch 73; iter: 0; batch classifier loss: 0.550909; batch adversarial loss: 0.736116\n",
      "epoch 74; iter: 0; batch classifier loss: 0.530954; batch adversarial loss: 0.704468\n",
      "epoch 75; iter: 0; batch classifier loss: 0.553222; batch adversarial loss: 0.701375\n",
      "epoch 76; iter: 0; batch classifier loss: 0.553022; batch adversarial loss: 0.750448\n",
      "epoch 77; iter: 0; batch classifier loss: 0.573825; batch adversarial loss: 0.773771\n",
      "epoch 78; iter: 0; batch classifier loss: 0.557788; batch adversarial loss: 0.733688\n",
      "epoch 79; iter: 0; batch classifier loss: 0.584550; batch adversarial loss: 0.756596\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731598; batch adversarial loss: 0.566519\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691851; batch adversarial loss: 0.591989\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649905; batch adversarial loss: 0.603533\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623235; batch adversarial loss: 0.624076\n",
      "epoch 4; iter: 0; batch classifier loss: 0.632516; batch adversarial loss: 0.637652\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570149; batch adversarial loss: 0.599113\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554773; batch adversarial loss: 0.612358\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512966; batch adversarial loss: 0.617989\n",
      "epoch 8; iter: 0; batch classifier loss: 0.521318; batch adversarial loss: 0.676211\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460531; batch adversarial loss: 0.634076\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455778; batch adversarial loss: 0.603206\n",
      "epoch 11; iter: 0; batch classifier loss: 0.459544; batch adversarial loss: 0.633439\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417731; batch adversarial loss: 0.604390\n",
      "epoch 13; iter: 0; batch classifier loss: 0.478464; batch adversarial loss: 0.629385\n",
      "epoch 14; iter: 0; batch classifier loss: 0.460029; batch adversarial loss: 0.632551\n",
      "epoch 15; iter: 0; batch classifier loss: 0.462301; batch adversarial loss: 0.618931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483069; batch adversarial loss: 0.608980\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441523; batch adversarial loss: 0.577561\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452617; batch adversarial loss: 0.616600\n",
      "epoch 19; iter: 0; batch classifier loss: 0.394134; batch adversarial loss: 0.617767\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342481; batch adversarial loss: 0.654176\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424772; batch adversarial loss: 0.633732\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446356; batch adversarial loss: 0.601255\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335758; batch adversarial loss: 0.624781\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384759; batch adversarial loss: 0.609590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.383986; batch adversarial loss: 0.628871\n",
      "epoch 26; iter: 0; batch classifier loss: 0.394670; batch adversarial loss: 0.635484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.396256; batch adversarial loss: 0.605946\n",
      "epoch 28; iter: 0; batch classifier loss: 0.399857; batch adversarial loss: 0.611639\n",
      "epoch 29; iter: 0; batch classifier loss: 0.314520; batch adversarial loss: 0.611239\n",
      "epoch 30; iter: 0; batch classifier loss: 0.372757; batch adversarial loss: 0.608761\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368041; batch adversarial loss: 0.619734\n",
      "epoch 32; iter: 0; batch classifier loss: 0.425845; batch adversarial loss: 0.565850\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370398; batch adversarial loss: 0.601028\n",
      "epoch 34; iter: 0; batch classifier loss: 0.333586; batch adversarial loss: 0.612682\n",
      "epoch 35; iter: 0; batch classifier loss: 0.304170; batch adversarial loss: 0.597731\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280185; batch adversarial loss: 0.625177\n",
      "epoch 37; iter: 0; batch classifier loss: 0.325279; batch adversarial loss: 0.633531\n",
      "epoch 38; iter: 0; batch classifier loss: 0.283815; batch adversarial loss: 0.601451\n",
      "epoch 39; iter: 0; batch classifier loss: 0.285551; batch adversarial loss: 0.629390\n",
      "epoch 40; iter: 0; batch classifier loss: 0.332285; batch adversarial loss: 0.555926\n",
      "epoch 41; iter: 0; batch classifier loss: 0.305756; batch adversarial loss: 0.629229\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306785; batch adversarial loss: 0.636284\n",
      "epoch 43; iter: 0; batch classifier loss: 0.346761; batch adversarial loss: 0.602000\n",
      "epoch 44; iter: 0; batch classifier loss: 0.379268; batch adversarial loss: 0.606495\n",
      "epoch 45; iter: 0; batch classifier loss: 0.323265; batch adversarial loss: 0.578694\n",
      "epoch 46; iter: 0; batch classifier loss: 0.367786; batch adversarial loss: 0.596536\n",
      "epoch 47; iter: 0; batch classifier loss: 0.335298; batch adversarial loss: 0.610915\n",
      "epoch 48; iter: 0; batch classifier loss: 0.282536; batch adversarial loss: 0.592760\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369142; batch adversarial loss: 0.592404\n",
      "epoch 50; iter: 0; batch classifier loss: 0.312614; batch adversarial loss: 0.606483\n",
      "epoch 51; iter: 0; batch classifier loss: 0.306576; batch adversarial loss: 0.615648\n",
      "epoch 52; iter: 0; batch classifier loss: 0.274925; batch adversarial loss: 0.625589\n",
      "epoch 53; iter: 0; batch classifier loss: 0.277344; batch adversarial loss: 0.601882\n",
      "epoch 54; iter: 0; batch classifier loss: 0.349021; batch adversarial loss: 0.625534\n",
      "epoch 55; iter: 0; batch classifier loss: 0.267963; batch adversarial loss: 0.603482\n",
      "epoch 56; iter: 0; batch classifier loss: 0.318972; batch adversarial loss: 0.670378\n",
      "epoch 57; iter: 0; batch classifier loss: 0.291436; batch adversarial loss: 0.616341\n",
      "epoch 58; iter: 0; batch classifier loss: 0.247050; batch adversarial loss: 0.615678\n",
      "epoch 59; iter: 0; batch classifier loss: 0.264887; batch adversarial loss: 0.615712\n",
      "epoch 60; iter: 0; batch classifier loss: 0.263232; batch adversarial loss: 0.615500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.281736; batch adversarial loss: 0.569996\n",
      "epoch 62; iter: 0; batch classifier loss: 0.274886; batch adversarial loss: 0.624447\n",
      "epoch 63; iter: 0; batch classifier loss: 0.317939; batch adversarial loss: 0.623096\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348136; batch adversarial loss: 0.632763\n",
      "epoch 65; iter: 0; batch classifier loss: 0.266124; batch adversarial loss: 0.644994\n",
      "epoch 66; iter: 0; batch classifier loss: 0.309821; batch adversarial loss: 0.568603\n",
      "epoch 67; iter: 0; batch classifier loss: 0.276445; batch adversarial loss: 0.627713\n",
      "epoch 68; iter: 0; batch classifier loss: 0.261896; batch adversarial loss: 0.597424\n",
      "epoch 69; iter: 0; batch classifier loss: 0.275667; batch adversarial loss: 0.621122\n",
      "epoch 70; iter: 0; batch classifier loss: 0.261659; batch adversarial loss: 0.614892\n",
      "epoch 71; iter: 0; batch classifier loss: 0.268860; batch adversarial loss: 0.631029\n",
      "epoch 72; iter: 0; batch classifier loss: 0.262468; batch adversarial loss: 0.589055\n",
      "epoch 73; iter: 0; batch classifier loss: 0.265516; batch adversarial loss: 0.644637\n",
      "epoch 74; iter: 0; batch classifier loss: 0.240637; batch adversarial loss: 0.597496\n",
      "epoch 75; iter: 0; batch classifier loss: 0.324294; batch adversarial loss: 0.678793\n",
      "epoch 76; iter: 0; batch classifier loss: 0.245943; batch adversarial loss: 0.658607\n",
      "epoch 77; iter: 0; batch classifier loss: 0.262047; batch adversarial loss: 0.580521\n",
      "epoch 78; iter: 0; batch classifier loss: 0.260798; batch adversarial loss: 0.590590\n",
      "epoch 79; iter: 0; batch classifier loss: 0.357405; batch adversarial loss: 0.677382\n",
      "epoch 0; iter: 0; batch classifier loss: 0.764693; batch adversarial loss: 0.782618\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682042; batch adversarial loss: 0.784419\n",
      "epoch 2; iter: 0; batch classifier loss: 0.627996; batch adversarial loss: 0.738957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.555102; batch adversarial loss: 0.685672\n",
      "epoch 4; iter: 0; batch classifier loss: 0.613217; batch adversarial loss: 0.742586\n",
      "epoch 5; iter: 0; batch classifier loss: 0.535696; batch adversarial loss: 0.706104\n",
      "epoch 6; iter: 0; batch classifier loss: 0.522239; batch adversarial loss: 0.741952\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564242; batch adversarial loss: 0.766153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.503605; batch adversarial loss: 0.655717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616756; batch adversarial loss: 0.700817\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498845; batch adversarial loss: 0.745307\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555630; batch adversarial loss: 0.737406\n",
      "epoch 12; iter: 0; batch classifier loss: 0.547907; batch adversarial loss: 0.707998\n",
      "epoch 13; iter: 0; batch classifier loss: 0.475930; batch adversarial loss: 0.703828\n",
      "epoch 14; iter: 0; batch classifier loss: 0.409265; batch adversarial loss: 0.695554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446317; batch adversarial loss: 0.716973\n",
      "epoch 16; iter: 0; batch classifier loss: 0.588978; batch adversarial loss: 0.647870\n",
      "epoch 17; iter: 0; batch classifier loss: 0.576085; batch adversarial loss: 0.738174\n",
      "epoch 18; iter: 0; batch classifier loss: 0.425750; batch adversarial loss: 0.652892\n",
      "epoch 19; iter: 0; batch classifier loss: 0.541105; batch adversarial loss: 0.733301\n",
      "epoch 20; iter: 0; batch classifier loss: 0.494626; batch adversarial loss: 0.722104\n",
      "epoch 21; iter: 0; batch classifier loss: 0.539490; batch adversarial loss: 0.686576\n",
      "epoch 22; iter: 0; batch classifier loss: 0.380067; batch adversarial loss: 0.678722\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441237; batch adversarial loss: 0.690616\n",
      "epoch 24; iter: 0; batch classifier loss: 0.439341; batch adversarial loss: 0.657521\n",
      "epoch 25; iter: 0; batch classifier loss: 0.471213; batch adversarial loss: 0.724146\n",
      "epoch 26; iter: 0; batch classifier loss: 0.473393; batch adversarial loss: 0.587275\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352784; batch adversarial loss: 0.609837\n",
      "epoch 28; iter: 0; batch classifier loss: 0.364479; batch adversarial loss: 0.686979\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371505; batch adversarial loss: 0.761577\n",
      "epoch 30; iter: 0; batch classifier loss: 0.335746; batch adversarial loss: 0.638439\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410323; batch adversarial loss: 0.679039\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379473; batch adversarial loss: 0.641066\n",
      "epoch 33; iter: 0; batch classifier loss: 0.343183; batch adversarial loss: 0.614871\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306714; batch adversarial loss: 0.622303\n",
      "epoch 35; iter: 0; batch classifier loss: 0.329817; batch adversarial loss: 0.548195\n",
      "epoch 36; iter: 0; batch classifier loss: 0.304065; batch adversarial loss: 0.645169\n",
      "epoch 37; iter: 0; batch classifier loss: 0.279593; batch adversarial loss: 0.623582\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381593; batch adversarial loss: 0.610431\n",
      "epoch 39; iter: 0; batch classifier loss: 0.320097; batch adversarial loss: 0.626479\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719214; batch adversarial loss: 0.784469\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647842; batch adversarial loss: 0.763400\n",
      "epoch 2; iter: 0; batch classifier loss: 0.594003; batch adversarial loss: 0.756105\n",
      "epoch 3; iter: 0; batch classifier loss: 0.589100; batch adversarial loss: 0.789383\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501102; batch adversarial loss: 0.816405\n",
      "epoch 5; iter: 0; batch classifier loss: 0.523666; batch adversarial loss: 0.746122\n",
      "epoch 6; iter: 0; batch classifier loss: 0.471294; batch adversarial loss: 0.738250\n",
      "epoch 7; iter: 0; batch classifier loss: 0.456965; batch adversarial loss: 0.724757\n",
      "epoch 8; iter: 0; batch classifier loss: 0.435007; batch adversarial loss: 0.776534\n",
      "epoch 9; iter: 0; batch classifier loss: 0.409157; batch adversarial loss: 0.749804\n",
      "epoch 10; iter: 0; batch classifier loss: 0.425496; batch adversarial loss: 0.738037\n",
      "epoch 11; iter: 0; batch classifier loss: 0.451150; batch adversarial loss: 0.728522\n",
      "epoch 12; iter: 0; batch classifier loss: 0.420884; batch adversarial loss: 0.696929\n",
      "epoch 13; iter: 0; batch classifier loss: 0.388858; batch adversarial loss: 0.742280\n",
      "epoch 14; iter: 0; batch classifier loss: 0.408088; batch adversarial loss: 0.740704\n",
      "epoch 15; iter: 0; batch classifier loss: 0.375785; batch adversarial loss: 0.715542\n",
      "epoch 16; iter: 0; batch classifier loss: 0.364891; batch adversarial loss: 0.725267\n",
      "epoch 17; iter: 0; batch classifier loss: 0.325356; batch adversarial loss: 0.761867\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346914; batch adversarial loss: 0.722552\n",
      "epoch 19; iter: 0; batch classifier loss: 0.422725; batch adversarial loss: 0.705942\n",
      "epoch 20; iter: 0; batch classifier loss: 0.368926; batch adversarial loss: 0.680125\n",
      "epoch 21; iter: 0; batch classifier loss: 0.306436; batch adversarial loss: 0.711988\n",
      "epoch 22; iter: 0; batch classifier loss: 0.275591; batch adversarial loss: 0.714003\n",
      "epoch 23; iter: 0; batch classifier loss: 0.317016; batch adversarial loss: 0.680955\n",
      "epoch 24; iter: 0; batch classifier loss: 0.292591; batch adversarial loss: 0.690992\n",
      "epoch 25; iter: 0; batch classifier loss: 0.268660; batch adversarial loss: 0.671584\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388177; batch adversarial loss: 0.693347\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277647; batch adversarial loss: 0.681174\n",
      "epoch 28; iter: 0; batch classifier loss: 0.241963; batch adversarial loss: 0.688308\n",
      "epoch 29; iter: 0; batch classifier loss: 0.333248; batch adversarial loss: 0.678230\n",
      "epoch 30; iter: 0; batch classifier loss: 0.262514; batch adversarial loss: 0.690037\n",
      "epoch 31; iter: 0; batch classifier loss: 0.205993; batch adversarial loss: 0.671004\n",
      "epoch 32; iter: 0; batch classifier loss: 0.284029; batch adversarial loss: 0.639145\n",
      "epoch 33; iter: 0; batch classifier loss: 0.207704; batch adversarial loss: 0.656214\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266923; batch adversarial loss: 0.649309\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370870; batch adversarial loss: 0.644545\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323850; batch adversarial loss: 0.647037\n",
      "epoch 37; iter: 0; batch classifier loss: 0.277876; batch adversarial loss: 0.647745\n",
      "epoch 38; iter: 0; batch classifier loss: 0.227020; batch adversarial loss: 0.618887\n",
      "epoch 39; iter: 0; batch classifier loss: 0.215511; batch adversarial loss: 0.643257\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767373; batch adversarial loss: 0.802686\n",
      "epoch 1; iter: 0; batch classifier loss: 0.721524; batch adversarial loss: 0.764287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.703212; batch adversarial loss: 0.812700\n",
      "epoch 3; iter: 0; batch classifier loss: 0.690228; batch adversarial loss: 0.771943\n",
      "epoch 4; iter: 0; batch classifier loss: 0.664725; batch adversarial loss: 0.734883\n",
      "epoch 5; iter: 0; batch classifier loss: 0.634278; batch adversarial loss: 0.776548\n",
      "epoch 6; iter: 0; batch classifier loss: 0.626918; batch adversarial loss: 0.757021\n",
      "epoch 7; iter: 0; batch classifier loss: 0.614643; batch adversarial loss: 0.760973\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618000; batch adversarial loss: 0.748954\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574810; batch adversarial loss: 0.770220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.576607; batch adversarial loss: 0.790547\n",
      "epoch 11; iter: 0; batch classifier loss: 0.575098; batch adversarial loss: 0.756799\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566697; batch adversarial loss: 0.757367\n",
      "epoch 13; iter: 0; batch classifier loss: 0.594830; batch adversarial loss: 0.801888\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547314; batch adversarial loss: 0.758236\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554102; batch adversarial loss: 0.745072\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502042; batch adversarial loss: 0.753378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.573533; batch adversarial loss: 0.703627\n",
      "epoch 18; iter: 0; batch classifier loss: 0.558721; batch adversarial loss: 0.734110\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513164; batch adversarial loss: 0.759658\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468099; batch adversarial loss: 0.783980\n",
      "epoch 21; iter: 0; batch classifier loss: 0.458330; batch adversarial loss: 0.762064\n",
      "epoch 22; iter: 0; batch classifier loss: 0.465357; batch adversarial loss: 0.752517\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420606; batch adversarial loss: 0.744848\n",
      "epoch 24; iter: 0; batch classifier loss: 0.402576; batch adversarial loss: 0.782302\n",
      "epoch 25; iter: 0; batch classifier loss: 0.451903; batch adversarial loss: 0.717715\n",
      "epoch 26; iter: 0; batch classifier loss: 0.462532; batch adversarial loss: 0.742293\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437281; batch adversarial loss: 0.763335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.484679; batch adversarial loss: 0.741226\n",
      "epoch 29; iter: 0; batch classifier loss: 0.452003; batch adversarial loss: 0.737133\n",
      "epoch 30; iter: 0; batch classifier loss: 0.416051; batch adversarial loss: 0.720230\n",
      "epoch 31; iter: 0; batch classifier loss: 0.421400; batch adversarial loss: 0.743887\n",
      "epoch 32; iter: 0; batch classifier loss: 0.449432; batch adversarial loss: 0.742077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.438235; batch adversarial loss: 0.733939\n",
      "epoch 34; iter: 0; batch classifier loss: 0.426883; batch adversarial loss: 0.736104\n",
      "epoch 35; iter: 0; batch classifier loss: 0.421490; batch adversarial loss: 0.798674\n",
      "epoch 36; iter: 0; batch classifier loss: 0.409989; batch adversarial loss: 0.762747\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413184; batch adversarial loss: 0.761313\n",
      "epoch 38; iter: 0; batch classifier loss: 0.404164; batch adversarial loss: 0.727835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380563; batch adversarial loss: 0.720423\n",
      "epoch 0; iter: 0; batch classifier loss: 0.611601; batch adversarial loss: 0.776245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.583437; batch adversarial loss: 0.737855\n",
      "epoch 2; iter: 0; batch classifier loss: 0.626113; batch adversarial loss: 0.779561\n",
      "epoch 3; iter: 0; batch classifier loss: 0.603229; batch adversarial loss: 0.749322\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568404; batch adversarial loss: 0.769145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567330; batch adversarial loss: 0.766891\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598448; batch adversarial loss: 0.779702\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553648; batch adversarial loss: 0.745153\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519394; batch adversarial loss: 0.763598\n",
      "epoch 9; iter: 0; batch classifier loss: 0.583142; batch adversarial loss: 0.753450\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521425; batch adversarial loss: 0.755166\n",
      "epoch 11; iter: 0; batch classifier loss: 0.488346; batch adversarial loss: 0.725007\n",
      "epoch 12; iter: 0; batch classifier loss: 0.562004; batch adversarial loss: 0.773307\n",
      "epoch 13; iter: 0; batch classifier loss: 0.505689; batch adversarial loss: 0.753146\n",
      "epoch 14; iter: 0; batch classifier loss: 0.576742; batch adversarial loss: 0.754334\n",
      "epoch 15; iter: 0; batch classifier loss: 0.570893; batch adversarial loss: 0.753934\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510895; batch adversarial loss: 0.760211\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486726; batch adversarial loss: 0.739653\n",
      "epoch 18; iter: 0; batch classifier loss: 0.535216; batch adversarial loss: 0.747502\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537773; batch adversarial loss: 0.758032\n",
      "epoch 20; iter: 0; batch classifier loss: 0.563019; batch adversarial loss: 0.754212\n",
      "epoch 21; iter: 0; batch classifier loss: 0.448513; batch adversarial loss: 0.726861\n",
      "epoch 22; iter: 0; batch classifier loss: 0.450403; batch adversarial loss: 0.707384\n",
      "epoch 23; iter: 0; batch classifier loss: 0.542926; batch adversarial loss: 0.729946\n",
      "epoch 24; iter: 0; batch classifier loss: 0.533191; batch adversarial loss: 0.721268\n",
      "epoch 25; iter: 0; batch classifier loss: 0.521987; batch adversarial loss: 0.735493\n",
      "epoch 26; iter: 0; batch classifier loss: 0.546337; batch adversarial loss: 0.729132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.569504; batch adversarial loss: 0.732793\n",
      "epoch 28; iter: 0; batch classifier loss: 0.538832; batch adversarial loss: 0.740468\n",
      "epoch 29; iter: 0; batch classifier loss: 0.506095; batch adversarial loss: 0.698772\n",
      "epoch 30; iter: 0; batch classifier loss: 0.494892; batch adversarial loss: 0.700189\n",
      "epoch 31; iter: 0; batch classifier loss: 0.513055; batch adversarial loss: 0.721421\n",
      "epoch 32; iter: 0; batch classifier loss: 0.497719; batch adversarial loss: 0.733279\n",
      "epoch 33; iter: 0; batch classifier loss: 0.619574; batch adversarial loss: 0.754264\n",
      "epoch 34; iter: 0; batch classifier loss: 0.460703; batch adversarial loss: 0.702751\n",
      "epoch 35; iter: 0; batch classifier loss: 0.490638; batch adversarial loss: 0.693213\n",
      "epoch 36; iter: 0; batch classifier loss: 0.589095; batch adversarial loss: 0.723134\n",
      "epoch 37; iter: 0; batch classifier loss: 0.514076; batch adversarial loss: 0.699086\n",
      "epoch 38; iter: 0; batch classifier loss: 0.580136; batch adversarial loss: 0.706178\n",
      "epoch 39; iter: 0; batch classifier loss: 0.501864; batch adversarial loss: 0.708174\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673709; batch adversarial loss: 0.599739\n",
      "epoch 1; iter: 0; batch classifier loss: 0.671215; batch adversarial loss: 0.671883\n",
      "epoch 2; iter: 0; batch classifier loss: 0.581645; batch adversarial loss: 0.634176\n",
      "epoch 3; iter: 0; batch classifier loss: 0.558795; batch adversarial loss: 0.626586\n",
      "epoch 4; iter: 0; batch classifier loss: 0.541865; batch adversarial loss: 0.655849\n",
      "epoch 5; iter: 0; batch classifier loss: 0.553892; batch adversarial loss: 0.611893\n",
      "epoch 6; iter: 0; batch classifier loss: 0.503399; batch adversarial loss: 0.636048\n",
      "epoch 7; iter: 0; batch classifier loss: 0.418709; batch adversarial loss: 0.630476\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476399; batch adversarial loss: 0.620681\n",
      "epoch 9; iter: 0; batch classifier loss: 0.472266; batch adversarial loss: 0.586673\n",
      "epoch 10; iter: 0; batch classifier loss: 0.398804; batch adversarial loss: 0.647627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440910; batch adversarial loss: 0.621012\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347268; batch adversarial loss: 0.657174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.475319; batch adversarial loss: 0.619783\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469509; batch adversarial loss: 0.608277\n",
      "epoch 15; iter: 0; batch classifier loss: 0.387420; batch adversarial loss: 0.650117\n",
      "epoch 16; iter: 0; batch classifier loss: 0.384214; batch adversarial loss: 0.597256\n",
      "epoch 17; iter: 0; batch classifier loss: 0.310444; batch adversarial loss: 0.695956\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362753; batch adversarial loss: 0.577291\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331001; batch adversarial loss: 0.624398\n",
      "epoch 20; iter: 0; batch classifier loss: 0.376018; batch adversarial loss: 0.574860\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300685; batch adversarial loss: 0.615525\n",
      "epoch 22; iter: 0; batch classifier loss: 0.277846; batch adversarial loss: 0.614583\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390397; batch adversarial loss: 0.655490\n",
      "epoch 24; iter: 0; batch classifier loss: 0.297511; batch adversarial loss: 0.526083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338862; batch adversarial loss: 0.573276\n",
      "epoch 26; iter: 0; batch classifier loss: 0.382733; batch adversarial loss: 0.555818\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313346; batch adversarial loss: 0.607279\n",
      "epoch 28; iter: 0; batch classifier loss: 0.401305; batch adversarial loss: 0.597248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.319441; batch adversarial loss: 0.594542\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382962; batch adversarial loss: 0.617792\n",
      "epoch 31; iter: 0; batch classifier loss: 0.268139; batch adversarial loss: 0.617063\n",
      "epoch 32; iter: 0; batch classifier loss: 0.420401; batch adversarial loss: 0.595277\n",
      "epoch 33; iter: 0; batch classifier loss: 0.427636; batch adversarial loss: 0.602317\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393480; batch adversarial loss: 0.605460\n",
      "epoch 35; iter: 0; batch classifier loss: 0.358909; batch adversarial loss: 0.580740\n",
      "epoch 36; iter: 0; batch classifier loss: 0.330549; batch adversarial loss: 0.573289\n",
      "epoch 37; iter: 0; batch classifier loss: 0.366634; batch adversarial loss: 0.548025\n",
      "epoch 38; iter: 0; batch classifier loss: 0.371686; batch adversarial loss: 0.577062\n",
      "epoch 39; iter: 0; batch classifier loss: 0.188104; batch adversarial loss: 0.565588\n",
      "epoch 40; iter: 0; batch classifier loss: 0.284581; batch adversarial loss: 0.618752\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293635; batch adversarial loss: 0.680724\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302471; batch adversarial loss: 0.602195\n",
      "epoch 43; iter: 0; batch classifier loss: 0.266346; batch adversarial loss: 0.602808\n",
      "epoch 44; iter: 0; batch classifier loss: 0.292439; batch adversarial loss: 0.610777\n",
      "epoch 45; iter: 0; batch classifier loss: 0.290761; batch adversarial loss: 0.594381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.299987; batch adversarial loss: 0.530021\n",
      "epoch 47; iter: 0; batch classifier loss: 0.337674; batch adversarial loss: 0.647161\n",
      "epoch 48; iter: 0; batch classifier loss: 0.148335; batch adversarial loss: 0.542563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.234754; batch adversarial loss: 0.575470\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255820; batch adversarial loss: 0.561570\n",
      "epoch 51; iter: 0; batch classifier loss: 0.276779; batch adversarial loss: 0.649583\n",
      "epoch 52; iter: 0; batch classifier loss: 0.313531; batch adversarial loss: 0.590208\n",
      "epoch 53; iter: 0; batch classifier loss: 0.248713; batch adversarial loss: 0.676719\n",
      "epoch 54; iter: 0; batch classifier loss: 0.220357; batch adversarial loss: 0.680691\n",
      "epoch 55; iter: 0; batch classifier loss: 0.268337; batch adversarial loss: 0.630339\n",
      "epoch 56; iter: 0; batch classifier loss: 0.205732; batch adversarial loss: 0.570111\n",
      "epoch 57; iter: 0; batch classifier loss: 0.232696; batch adversarial loss: 0.610341\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262538; batch adversarial loss: 0.567360\n",
      "epoch 59; iter: 0; batch classifier loss: 0.169091; batch adversarial loss: 0.616109\n",
      "epoch 0; iter: 0; batch classifier loss: 0.660561; batch adversarial loss: 0.669633\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605269; batch adversarial loss: 0.706053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.608230; batch adversarial loss: 0.695068\n",
      "epoch 3; iter: 0; batch classifier loss: 0.633299; batch adversarial loss: 0.724029\n",
      "epoch 4; iter: 0; batch classifier loss: 0.571324; batch adversarial loss: 0.738513\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556422; batch adversarial loss: 0.707456\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454356; batch adversarial loss: 0.648698\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494484; batch adversarial loss: 0.676575\n",
      "epoch 8; iter: 0; batch classifier loss: 0.478817; batch adversarial loss: 0.725250\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462891; batch adversarial loss: 0.602016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.426601; batch adversarial loss: 0.677190\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366615; batch adversarial loss: 0.625710\n",
      "epoch 12; iter: 0; batch classifier loss: 0.334300; batch adversarial loss: 0.623771\n",
      "epoch 13; iter: 0; batch classifier loss: 0.464629; batch adversarial loss: 0.661032\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339421; batch adversarial loss: 0.638730\n",
      "epoch 15; iter: 0; batch classifier loss: 0.411863; batch adversarial loss: 0.584257\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356685; batch adversarial loss: 0.636714\n",
      "epoch 17; iter: 0; batch classifier loss: 0.367036; batch adversarial loss: 0.641640\n",
      "epoch 18; iter: 0; batch classifier loss: 0.453974; batch adversarial loss: 0.591068\n",
      "epoch 19; iter: 0; batch classifier loss: 0.412156; batch adversarial loss: 0.613388\n",
      "epoch 20; iter: 0; batch classifier loss: 0.358082; batch adversarial loss: 0.623044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342607; batch adversarial loss: 0.589722\n",
      "epoch 22; iter: 0; batch classifier loss: 0.302911; batch adversarial loss: 0.659361\n",
      "epoch 23; iter: 0; batch classifier loss: 0.278831; batch adversarial loss: 0.635059\n",
      "epoch 24; iter: 0; batch classifier loss: 0.335424; batch adversarial loss: 0.588162\n",
      "epoch 25; iter: 0; batch classifier loss: 0.280350; batch adversarial loss: 0.665442\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352702; batch adversarial loss: 0.612198\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278024; batch adversarial loss: 0.567017\n",
      "epoch 28; iter: 0; batch classifier loss: 0.295904; batch adversarial loss: 0.594947\n",
      "epoch 29; iter: 0; batch classifier loss: 0.358748; batch adversarial loss: 0.571343\n",
      "epoch 30; iter: 0; batch classifier loss: 0.170802; batch adversarial loss: 0.651016\n",
      "epoch 31; iter: 0; batch classifier loss: 0.196862; batch adversarial loss: 0.578985\n",
      "epoch 32; iter: 0; batch classifier loss: 0.270847; batch adversarial loss: 0.617505\n",
      "epoch 33; iter: 0; batch classifier loss: 0.267473; batch adversarial loss: 0.662501\n",
      "epoch 34; iter: 0; batch classifier loss: 0.309629; batch adversarial loss: 0.598857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.317233; batch adversarial loss: 0.569186\n",
      "epoch 36; iter: 0; batch classifier loss: 0.226629; batch adversarial loss: 0.580142\n",
      "epoch 37; iter: 0; batch classifier loss: 0.215828; batch adversarial loss: 0.585329\n",
      "epoch 38; iter: 0; batch classifier loss: 0.300522; batch adversarial loss: 0.632721\n",
      "epoch 39; iter: 0; batch classifier loss: 0.244985; batch adversarial loss: 0.528560\n",
      "epoch 40; iter: 0; batch classifier loss: 0.246139; batch adversarial loss: 0.587181\n",
      "epoch 41; iter: 0; batch classifier loss: 0.287957; batch adversarial loss: 0.598081\n",
      "epoch 42; iter: 0; batch classifier loss: 0.254885; batch adversarial loss: 0.647855\n",
      "epoch 43; iter: 0; batch classifier loss: 0.290646; batch adversarial loss: 0.576033\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263304; batch adversarial loss: 0.565182\n",
      "epoch 45; iter: 0; batch classifier loss: 0.197245; batch adversarial loss: 0.664640\n",
      "epoch 46; iter: 0; batch classifier loss: 0.239804; batch adversarial loss: 0.574622\n",
      "epoch 47; iter: 0; batch classifier loss: 0.144253; batch adversarial loss: 0.558014\n",
      "epoch 48; iter: 0; batch classifier loss: 0.234166; batch adversarial loss: 0.558374\n",
      "epoch 49; iter: 0; batch classifier loss: 0.241962; batch adversarial loss: 0.636095\n",
      "epoch 50; iter: 0; batch classifier loss: 0.203306; batch adversarial loss: 0.630969\n",
      "epoch 51; iter: 0; batch classifier loss: 0.295648; batch adversarial loss: 0.582544\n",
      "epoch 52; iter: 0; batch classifier loss: 0.225524; batch adversarial loss: 0.695523\n",
      "epoch 53; iter: 0; batch classifier loss: 0.262833; batch adversarial loss: 0.563430\n",
      "epoch 54; iter: 0; batch classifier loss: 0.248011; batch adversarial loss: 0.530755\n",
      "epoch 55; iter: 0; batch classifier loss: 0.237961; batch adversarial loss: 0.674381\n",
      "epoch 56; iter: 0; batch classifier loss: 0.262762; batch adversarial loss: 0.576621\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211930; batch adversarial loss: 0.611737\n",
      "epoch 58; iter: 0; batch classifier loss: 0.282004; batch adversarial loss: 0.669327\n",
      "epoch 59; iter: 0; batch classifier loss: 0.252482; batch adversarial loss: 0.615369\n",
      "epoch 0; iter: 0; batch classifier loss: 0.682813; batch adversarial loss: 0.622125\n",
      "epoch 1; iter: 0; batch classifier loss: 0.638114; batch adversarial loss: 0.610572\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621001; batch adversarial loss: 0.611395\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659470; batch adversarial loss: 0.622540\n",
      "epoch 4; iter: 0; batch classifier loss: 0.560235; batch adversarial loss: 0.653982\n",
      "epoch 5; iter: 0; batch classifier loss: 0.619734; batch adversarial loss: 0.625010\n",
      "epoch 6; iter: 0; batch classifier loss: 0.625342; batch adversarial loss: 0.606631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.559957; batch adversarial loss: 0.617552\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575177; batch adversarial loss: 0.625092\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540784; batch adversarial loss: 0.682526\n",
      "epoch 10; iter: 0; batch classifier loss: 0.539087; batch adversarial loss: 0.616351\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514905; batch adversarial loss: 0.682576\n",
      "epoch 12; iter: 0; batch classifier loss: 0.524872; batch adversarial loss: 0.647994\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536115; batch adversarial loss: 0.612459\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544702; batch adversarial loss: 0.623712\n",
      "epoch 15; iter: 0; batch classifier loss: 0.518378; batch adversarial loss: 0.643483\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518062; batch adversarial loss: 0.637380\n",
      "epoch 17; iter: 0; batch classifier loss: 0.491755; batch adversarial loss: 0.686511\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499852; batch adversarial loss: 0.608665\n",
      "epoch 19; iter: 0; batch classifier loss: 0.447198; batch adversarial loss: 0.635703\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437048; batch adversarial loss: 0.669807\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487411; batch adversarial loss: 0.591530\n",
      "epoch 22; iter: 0; batch classifier loss: 0.520346; batch adversarial loss: 0.669415\n",
      "epoch 23; iter: 0; batch classifier loss: 0.364344; batch adversarial loss: 0.594745\n",
      "epoch 24; iter: 0; batch classifier loss: 0.377911; batch adversarial loss: 0.678112\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457837; batch adversarial loss: 0.620747\n",
      "epoch 26; iter: 0; batch classifier loss: 0.427401; batch adversarial loss: 0.588884\n",
      "epoch 27; iter: 0; batch classifier loss: 0.410392; batch adversarial loss: 0.574302\n",
      "epoch 28; iter: 0; batch classifier loss: 0.405738; batch adversarial loss: 0.565855\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405801; batch adversarial loss: 0.575582\n",
      "epoch 30; iter: 0; batch classifier loss: 0.389880; batch adversarial loss: 0.672961\n",
      "epoch 31; iter: 0; batch classifier loss: 0.371871; batch adversarial loss: 0.623966\n",
      "epoch 32; iter: 0; batch classifier loss: 0.365858; batch adversarial loss: 0.619349\n",
      "epoch 33; iter: 0; batch classifier loss: 0.460525; batch adversarial loss: 0.599753\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394410; batch adversarial loss: 0.602335\n",
      "epoch 35; iter: 0; batch classifier loss: 0.375174; batch adversarial loss: 0.635241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.404919; batch adversarial loss: 0.666608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.362044; batch adversarial loss: 0.623191\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392378; batch adversarial loss: 0.596583\n",
      "epoch 39; iter: 0; batch classifier loss: 0.430642; batch adversarial loss: 0.602037\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403982; batch adversarial loss: 0.647881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.324597; batch adversarial loss: 0.636229\n",
      "epoch 42; iter: 0; batch classifier loss: 0.401307; batch adversarial loss: 0.572318\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378709; batch adversarial loss: 0.685582\n",
      "epoch 44; iter: 0; batch classifier loss: 0.338610; batch adversarial loss: 0.640030\n",
      "epoch 45; iter: 0; batch classifier loss: 0.400288; batch adversarial loss: 0.613353\n",
      "epoch 46; iter: 0; batch classifier loss: 0.443198; batch adversarial loss: 0.658694\n",
      "epoch 47; iter: 0; batch classifier loss: 0.352531; batch adversarial loss: 0.669780\n",
      "epoch 48; iter: 0; batch classifier loss: 0.346985; batch adversarial loss: 0.647257\n",
      "epoch 49; iter: 0; batch classifier loss: 0.337480; batch adversarial loss: 0.628829\n",
      "epoch 50; iter: 0; batch classifier loss: 0.326955; batch adversarial loss: 0.644976\n",
      "epoch 51; iter: 0; batch classifier loss: 0.360372; batch adversarial loss: 0.580497\n",
      "epoch 52; iter: 0; batch classifier loss: 0.385683; batch adversarial loss: 0.566908\n",
      "epoch 53; iter: 0; batch classifier loss: 0.293389; batch adversarial loss: 0.605997\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391723; batch adversarial loss: 0.628634\n",
      "epoch 55; iter: 0; batch classifier loss: 0.326876; batch adversarial loss: 0.633246\n",
      "epoch 56; iter: 0; batch classifier loss: 0.262486; batch adversarial loss: 0.707617\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364022; batch adversarial loss: 0.655617\n",
      "epoch 58; iter: 0; batch classifier loss: 0.340071; batch adversarial loss: 0.595050\n",
      "epoch 59; iter: 0; batch classifier loss: 0.414410; batch adversarial loss: 0.664905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.659241; batch adversarial loss: 0.662303\n",
      "epoch 1; iter: 0; batch classifier loss: 0.605283; batch adversarial loss: 0.637071\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589428; batch adversarial loss: 0.625287\n",
      "epoch 3; iter: 0; batch classifier loss: 0.552533; batch adversarial loss: 0.640563\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548852; batch adversarial loss: 0.617640\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575109; batch adversarial loss: 0.599012\n",
      "epoch 6; iter: 0; batch classifier loss: 0.537938; batch adversarial loss: 0.670056\n",
      "epoch 7; iter: 0; batch classifier loss: 0.469232; batch adversarial loss: 0.626218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.456304; batch adversarial loss: 0.616244\n",
      "epoch 9; iter: 0; batch classifier loss: 0.461812; batch adversarial loss: 0.590431\n",
      "epoch 10; iter: 0; batch classifier loss: 0.517446; batch adversarial loss: 0.592212\n",
      "epoch 11; iter: 0; batch classifier loss: 0.447582; batch adversarial loss: 0.600714\n",
      "epoch 12; iter: 0; batch classifier loss: 0.415161; batch adversarial loss: 0.657277\n",
      "epoch 13; iter: 0; batch classifier loss: 0.481948; batch adversarial loss: 0.611561\n",
      "epoch 14; iter: 0; batch classifier loss: 0.419919; batch adversarial loss: 0.604061\n",
      "epoch 15; iter: 0; batch classifier loss: 0.433879; batch adversarial loss: 0.600021\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451081; batch adversarial loss: 0.583179\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446332; batch adversarial loss: 0.589424\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410477; batch adversarial loss: 0.599065\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441732; batch adversarial loss: 0.621499\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417904; batch adversarial loss: 0.622625\n",
      "epoch 21; iter: 0; batch classifier loss: 0.404577; batch adversarial loss: 0.546910\n",
      "epoch 22; iter: 0; batch classifier loss: 0.412845; batch adversarial loss: 0.613121\n",
      "epoch 23; iter: 0; batch classifier loss: 0.384850; batch adversarial loss: 0.619917\n",
      "epoch 24; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.608621\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399024; batch adversarial loss: 0.602567\n",
      "epoch 26; iter: 0; batch classifier loss: 0.357550; batch adversarial loss: 0.613129\n",
      "epoch 27; iter: 0; batch classifier loss: 0.350121; batch adversarial loss: 0.581235\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342185; batch adversarial loss: 0.650015\n",
      "epoch 29; iter: 0; batch classifier loss: 0.359479; batch adversarial loss: 0.610165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.320917; batch adversarial loss: 0.646812\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387211; batch adversarial loss: 0.668614\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356152; batch adversarial loss: 0.582912\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346581; batch adversarial loss: 0.637907\n",
      "epoch 34; iter: 0; batch classifier loss: 0.329791; batch adversarial loss: 0.652310\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312433; batch adversarial loss: 0.591377\n",
      "epoch 36; iter: 0; batch classifier loss: 0.334965; batch adversarial loss: 0.639081\n",
      "epoch 37; iter: 0; batch classifier loss: 0.290930; batch adversarial loss: 0.654611\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340381; batch adversarial loss: 0.621325\n",
      "epoch 39; iter: 0; batch classifier loss: 0.330261; batch adversarial loss: 0.610171\n",
      "epoch 40; iter: 0; batch classifier loss: 0.316233; batch adversarial loss: 0.609862\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325471; batch adversarial loss: 0.712541\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389959; batch adversarial loss: 0.614643\n",
      "epoch 43; iter: 0; batch classifier loss: 0.327661; batch adversarial loss: 0.633619\n",
      "epoch 44; iter: 0; batch classifier loss: 0.316528; batch adversarial loss: 0.580110\n",
      "epoch 45; iter: 0; batch classifier loss: 0.343589; batch adversarial loss: 0.619523\n",
      "epoch 46; iter: 0; batch classifier loss: 0.268091; batch adversarial loss: 0.603453\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357878; batch adversarial loss: 0.637238\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332728; batch adversarial loss: 0.632899\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357130; batch adversarial loss: 0.600702\n",
      "epoch 50; iter: 0; batch classifier loss: 0.291820; batch adversarial loss: 0.573460\n",
      "epoch 51; iter: 0; batch classifier loss: 0.249537; batch adversarial loss: 0.632941\n",
      "epoch 52; iter: 0; batch classifier loss: 0.331257; batch adversarial loss: 0.646053\n",
      "epoch 53; iter: 0; batch classifier loss: 0.262030; batch adversarial loss: 0.608800\n",
      "epoch 54; iter: 0; batch classifier loss: 0.316964; batch adversarial loss: 0.600252\n",
      "epoch 55; iter: 0; batch classifier loss: 0.245886; batch adversarial loss: 0.566436\n",
      "epoch 56; iter: 0; batch classifier loss: 0.300521; batch adversarial loss: 0.598709\n",
      "epoch 57; iter: 0; batch classifier loss: 0.380542; batch adversarial loss: 0.611536\n",
      "epoch 58; iter: 0; batch classifier loss: 0.314199; batch adversarial loss: 0.634923\n",
      "epoch 59; iter: 0; batch classifier loss: 0.239530; batch adversarial loss: 0.657887\n",
      "epoch 0; iter: 0; batch classifier loss: 0.656073; batch adversarial loss: 0.604971\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634103; batch adversarial loss: 0.666613\n",
      "epoch 2; iter: 0; batch classifier loss: 0.570637; batch adversarial loss: 0.603412\n",
      "epoch 3; iter: 0; batch classifier loss: 0.524401; batch adversarial loss: 0.595218\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646769; batch adversarial loss: 0.715606\n",
      "epoch 5; iter: 0; batch classifier loss: 0.541711; batch adversarial loss: 0.550274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.502829; batch adversarial loss: 0.739244\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532513; batch adversarial loss: 0.666542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.464475; batch adversarial loss: 0.723095\n",
      "epoch 9; iter: 0; batch classifier loss: 0.478877; batch adversarial loss: 0.625947\n",
      "epoch 10; iter: 0; batch classifier loss: 0.454986; batch adversarial loss: 0.683468\n",
      "epoch 11; iter: 0; batch classifier loss: 0.425271; batch adversarial loss: 0.730902\n",
      "epoch 12; iter: 0; batch classifier loss: 0.436924; batch adversarial loss: 0.685675\n",
      "epoch 13; iter: 0; batch classifier loss: 0.381746; batch adversarial loss: 0.684089\n",
      "epoch 14; iter: 0; batch classifier loss: 0.470936; batch adversarial loss: 0.613094\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438340; batch adversarial loss: 0.663419\n",
      "epoch 16; iter: 0; batch classifier loss: 0.371351; batch adversarial loss: 0.638401\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377398; batch adversarial loss: 0.661938\n",
      "epoch 18; iter: 0; batch classifier loss: 0.382210; batch adversarial loss: 0.648397\n",
      "epoch 19; iter: 0; batch classifier loss: 0.380711; batch adversarial loss: 0.657481\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432880; batch adversarial loss: 0.735110\n",
      "epoch 21; iter: 0; batch classifier loss: 0.487400; batch adversarial loss: 0.634179\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446473; batch adversarial loss: 0.634559\n",
      "epoch 23; iter: 0; batch classifier loss: 0.351088; batch adversarial loss: 0.645347\n",
      "epoch 24; iter: 0; batch classifier loss: 0.382357; batch adversarial loss: 0.697857\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356221; batch adversarial loss: 0.695690\n",
      "epoch 26; iter: 0; batch classifier loss: 0.323587; batch adversarial loss: 0.624092\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291887; batch adversarial loss: 0.632225\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382162; batch adversarial loss: 0.704366\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363368; batch adversarial loss: 0.740110\n",
      "epoch 30; iter: 0; batch classifier loss: 0.358514; batch adversarial loss: 0.672679\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464553; batch adversarial loss: 0.678614\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374745; batch adversarial loss: 0.697958\n",
      "epoch 33; iter: 0; batch classifier loss: 0.337260; batch adversarial loss: 0.627860\n",
      "epoch 34; iter: 0; batch classifier loss: 0.335572; batch adversarial loss: 0.583320\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405167; batch adversarial loss: 0.665956\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290720; batch adversarial loss: 0.630015\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386765; batch adversarial loss: 0.751399\n",
      "epoch 38; iter: 0; batch classifier loss: 0.326441; batch adversarial loss: 0.638223\n",
      "epoch 39; iter: 0; batch classifier loss: 0.273416; batch adversarial loss: 0.650178\n",
      "epoch 40; iter: 0; batch classifier loss: 0.393650; batch adversarial loss: 0.678672\n",
      "epoch 41; iter: 0; batch classifier loss: 0.236631; batch adversarial loss: 0.549924\n",
      "epoch 42; iter: 0; batch classifier loss: 0.280207; batch adversarial loss: 0.594259\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302440; batch adversarial loss: 0.623558\n",
      "epoch 44; iter: 0; batch classifier loss: 0.326162; batch adversarial loss: 0.570282\n",
      "epoch 45; iter: 0; batch classifier loss: 0.329287; batch adversarial loss: 0.675751\n",
      "epoch 46; iter: 0; batch classifier loss: 0.296383; batch adversarial loss: 0.617706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366958; batch adversarial loss: 0.696402\n",
      "epoch 48; iter: 0; batch classifier loss: 0.238180; batch adversarial loss: 0.654284\n",
      "epoch 49; iter: 0; batch classifier loss: 0.290862; batch adversarial loss: 0.616768\n",
      "epoch 50; iter: 0; batch classifier loss: 0.286534; batch adversarial loss: 0.680513\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326075; batch adversarial loss: 0.622732\n",
      "epoch 52; iter: 0; batch classifier loss: 0.339401; batch adversarial loss: 0.665154\n",
      "epoch 53; iter: 0; batch classifier loss: 0.307537; batch adversarial loss: 0.641146\n",
      "epoch 54; iter: 0; batch classifier loss: 0.346736; batch adversarial loss: 0.631248\n",
      "epoch 55; iter: 0; batch classifier loss: 0.310620; batch adversarial loss: 0.704364\n",
      "epoch 56; iter: 0; batch classifier loss: 0.344956; batch adversarial loss: 0.674147\n",
      "epoch 57; iter: 0; batch classifier loss: 0.309074; batch adversarial loss: 0.611523\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386204; batch adversarial loss: 0.657991\n",
      "epoch 59; iter: 0; batch classifier loss: 0.264848; batch adversarial loss: 0.636516\n",
      "epoch 60; iter: 0; batch classifier loss: 0.200245; batch adversarial loss: 0.567363\n",
      "epoch 61; iter: 0; batch classifier loss: 0.355633; batch adversarial loss: 0.629606\n",
      "epoch 62; iter: 0; batch classifier loss: 0.343093; batch adversarial loss: 0.657510\n",
      "epoch 63; iter: 0; batch classifier loss: 0.238331; batch adversarial loss: 0.573488\n",
      "epoch 64; iter: 0; batch classifier loss: 0.237999; batch adversarial loss: 0.616221\n",
      "epoch 65; iter: 0; batch classifier loss: 0.239174; batch adversarial loss: 0.599770\n",
      "epoch 66; iter: 0; batch classifier loss: 0.348815; batch adversarial loss: 0.607312\n",
      "epoch 67; iter: 0; batch classifier loss: 0.411918; batch adversarial loss: 0.658637\n",
      "epoch 68; iter: 0; batch classifier loss: 0.307802; batch adversarial loss: 0.587814\n",
      "epoch 69; iter: 0; batch classifier loss: 0.302223; batch adversarial loss: 0.669095\n",
      "epoch 70; iter: 0; batch classifier loss: 0.248899; batch adversarial loss: 0.648896\n",
      "epoch 71; iter: 0; batch classifier loss: 0.349063; batch adversarial loss: 0.588424\n",
      "epoch 72; iter: 0; batch classifier loss: 0.376795; batch adversarial loss: 0.607786\n",
      "epoch 73; iter: 0; batch classifier loss: 0.272182; batch adversarial loss: 0.598961\n",
      "epoch 74; iter: 0; batch classifier loss: 0.318854; batch adversarial loss: 0.631337\n",
      "epoch 75; iter: 0; batch classifier loss: 0.406343; batch adversarial loss: 0.645682\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350325; batch adversarial loss: 0.637063\n",
      "epoch 77; iter: 0; batch classifier loss: 0.325079; batch adversarial loss: 0.699453\n",
      "epoch 78; iter: 0; batch classifier loss: 0.314790; batch adversarial loss: 0.636387\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367559; batch adversarial loss: 0.698500\n",
      "epoch 0; iter: 0; batch classifier loss: 0.784007; batch adversarial loss: 0.806503\n",
      "epoch 1; iter: 0; batch classifier loss: 0.707558; batch adversarial loss: 0.785338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.653531; batch adversarial loss: 0.781458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.576338; batch adversarial loss: 0.797813\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521837; batch adversarial loss: 0.794387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.507621; batch adversarial loss: 0.788635\n",
      "epoch 6; iter: 0; batch classifier loss: 0.507208; batch adversarial loss: 0.778881\n",
      "epoch 7; iter: 0; batch classifier loss: 0.374812; batch adversarial loss: 0.765966\n",
      "epoch 8; iter: 0; batch classifier loss: 0.451382; batch adversarial loss: 0.779569\n",
      "epoch 9; iter: 0; batch classifier loss: 0.374426; batch adversarial loss: 0.742505\n",
      "epoch 10; iter: 0; batch classifier loss: 0.415170; batch adversarial loss: 0.736649\n",
      "epoch 11; iter: 0; batch classifier loss: 0.368638; batch adversarial loss: 0.753595\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350918; batch adversarial loss: 0.721988\n",
      "epoch 13; iter: 0; batch classifier loss: 0.344078; batch adversarial loss: 0.738739\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348102; batch adversarial loss: 0.755322\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488344; batch adversarial loss: 0.715974\n",
      "epoch 16; iter: 0; batch classifier loss: 0.330022; batch adversarial loss: 0.738414\n",
      "epoch 17; iter: 0; batch classifier loss: 0.313491; batch adversarial loss: 0.720377\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370419; batch adversarial loss: 0.721861\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385468; batch adversarial loss: 0.750247\n",
      "epoch 20; iter: 0; batch classifier loss: 0.297418; batch adversarial loss: 0.716606\n",
      "epoch 21; iter: 0; batch classifier loss: 0.420101; batch adversarial loss: 0.702039\n",
      "epoch 22; iter: 0; batch classifier loss: 0.283271; batch adversarial loss: 0.713030\n",
      "epoch 23; iter: 0; batch classifier loss: 0.335640; batch adversarial loss: 0.678622\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421484; batch adversarial loss: 0.688128\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297655; batch adversarial loss: 0.708442\n",
      "epoch 26; iter: 0; batch classifier loss: 0.317627; batch adversarial loss: 0.681440\n",
      "epoch 27; iter: 0; batch classifier loss: 0.298835; batch adversarial loss: 0.666435\n",
      "epoch 28; iter: 0; batch classifier loss: 0.267743; batch adversarial loss: 0.673926\n",
      "epoch 29; iter: 0; batch classifier loss: 0.290742; batch adversarial loss: 0.677510\n",
      "epoch 30; iter: 0; batch classifier loss: 0.329904; batch adversarial loss: 0.653637\n",
      "epoch 31; iter: 0; batch classifier loss: 0.191386; batch adversarial loss: 0.695042\n",
      "epoch 32; iter: 0; batch classifier loss: 0.244409; batch adversarial loss: 0.670125\n",
      "epoch 33; iter: 0; batch classifier loss: 0.253587; batch adversarial loss: 0.676957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.239616; batch adversarial loss: 0.678330\n",
      "epoch 35; iter: 0; batch classifier loss: 0.265112; batch adversarial loss: 0.658346\n",
      "epoch 36; iter: 0; batch classifier loss: 0.242295; batch adversarial loss: 0.640574\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226764; batch adversarial loss: 0.640436\n",
      "epoch 38; iter: 0; batch classifier loss: 0.306672; batch adversarial loss: 0.671302\n",
      "epoch 39; iter: 0; batch classifier loss: 0.195856; batch adversarial loss: 0.643461\n",
      "epoch 40; iter: 0; batch classifier loss: 0.214197; batch adversarial loss: 0.645787\n",
      "epoch 41; iter: 0; batch classifier loss: 0.197554; batch adversarial loss: 0.637562\n",
      "epoch 42; iter: 0; batch classifier loss: 0.174035; batch adversarial loss: 0.637551\n",
      "epoch 43; iter: 0; batch classifier loss: 0.257888; batch adversarial loss: 0.634419\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263952; batch adversarial loss: 0.593957\n",
      "epoch 45; iter: 0; batch classifier loss: 0.235760; batch adversarial loss: 0.636857\n",
      "epoch 46; iter: 0; batch classifier loss: 0.248526; batch adversarial loss: 0.614922\n",
      "epoch 47; iter: 0; batch classifier loss: 0.201078; batch adversarial loss: 0.618592\n",
      "epoch 48; iter: 0; batch classifier loss: 0.277355; batch adversarial loss: 0.607220\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270536; batch adversarial loss: 0.610217\n",
      "epoch 50; iter: 0; batch classifier loss: 0.244952; batch adversarial loss: 0.601519\n",
      "epoch 51; iter: 0; batch classifier loss: 0.204367; batch adversarial loss: 0.616187\n",
      "epoch 52; iter: 0; batch classifier loss: 0.170735; batch adversarial loss: 0.610773\n",
      "epoch 53; iter: 0; batch classifier loss: 0.257285; batch adversarial loss: 0.634925\n",
      "epoch 54; iter: 0; batch classifier loss: 0.252488; batch adversarial loss: 0.588956\n",
      "epoch 55; iter: 0; batch classifier loss: 0.168145; batch adversarial loss: 0.613533\n",
      "epoch 56; iter: 0; batch classifier loss: 0.257647; batch adversarial loss: 0.635488\n",
      "epoch 57; iter: 0; batch classifier loss: 0.250701; batch adversarial loss: 0.612546\n",
      "epoch 58; iter: 0; batch classifier loss: 0.166425; batch adversarial loss: 0.553114\n",
      "epoch 59; iter: 0; batch classifier loss: 0.130358; batch adversarial loss: 0.602163\n",
      "epoch 60; iter: 0; batch classifier loss: 0.270963; batch adversarial loss: 0.609382\n",
      "epoch 61; iter: 0; batch classifier loss: 0.175247; batch adversarial loss: 0.605683\n",
      "epoch 62; iter: 0; batch classifier loss: 0.284509; batch adversarial loss: 0.576230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.261971; batch adversarial loss: 0.583928\n",
      "epoch 64; iter: 0; batch classifier loss: 0.233144; batch adversarial loss: 0.612960\n",
      "epoch 65; iter: 0; batch classifier loss: 0.138126; batch adversarial loss: 0.565036\n",
      "epoch 66; iter: 0; batch classifier loss: 0.228490; batch adversarial loss: 0.605010\n",
      "epoch 67; iter: 0; batch classifier loss: 0.276975; batch adversarial loss: 0.571940\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151081; batch adversarial loss: 0.566360\n",
      "epoch 69; iter: 0; batch classifier loss: 0.206328; batch adversarial loss: 0.644647\n",
      "epoch 70; iter: 0; batch classifier loss: 0.155348; batch adversarial loss: 0.596607\n",
      "epoch 71; iter: 0; batch classifier loss: 0.174827; batch adversarial loss: 0.553518\n",
      "epoch 72; iter: 0; batch classifier loss: 0.133254; batch adversarial loss: 0.606803\n",
      "epoch 73; iter: 0; batch classifier loss: 0.106564; batch adversarial loss: 0.565153\n",
      "epoch 74; iter: 0; batch classifier loss: 0.109518; batch adversarial loss: 0.591395\n",
      "epoch 75; iter: 0; batch classifier loss: 0.160189; batch adversarial loss: 0.590711\n",
      "epoch 76; iter: 0; batch classifier loss: 0.109807; batch adversarial loss: 0.612362\n",
      "epoch 77; iter: 0; batch classifier loss: 0.156196; batch adversarial loss: 0.623193\n",
      "epoch 78; iter: 0; batch classifier loss: 0.186125; batch adversarial loss: 0.628316\n",
      "epoch 79; iter: 0; batch classifier loss: 0.182992; batch adversarial loss: 0.593316\n",
      "epoch 0; iter: 0; batch classifier loss: 0.697127; batch adversarial loss: 1.061014\n",
      "epoch 1; iter: 0; batch classifier loss: 0.712863; batch adversarial loss: 1.039408\n",
      "epoch 2; iter: 0; batch classifier loss: 0.712667; batch adversarial loss: 1.037111\n",
      "epoch 3; iter: 0; batch classifier loss: 0.684382; batch adversarial loss: 1.059461\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676760; batch adversarial loss: 1.019202\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633244; batch adversarial loss: 1.050712\n",
      "epoch 6; iter: 0; batch classifier loss: 0.620451; batch adversarial loss: 1.141252\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623785; batch adversarial loss: 1.076041\n",
      "epoch 8; iter: 0; batch classifier loss: 0.645887; batch adversarial loss: 1.052184\n",
      "epoch 9; iter: 0; batch classifier loss: 0.592531; batch adversarial loss: 1.071098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.614037; batch adversarial loss: 0.988818\n",
      "epoch 11; iter: 0; batch classifier loss: 0.663574; batch adversarial loss: 1.075292\n",
      "epoch 12; iter: 0; batch classifier loss: 0.563028; batch adversarial loss: 1.039875\n",
      "epoch 13; iter: 0; batch classifier loss: 0.619616; batch adversarial loss: 1.015570\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556385; batch adversarial loss: 1.070801\n",
      "epoch 15; iter: 0; batch classifier loss: 0.626689; batch adversarial loss: 0.953921\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572641; batch adversarial loss: 1.077626\n",
      "epoch 17; iter: 0; batch classifier loss: 0.563936; batch adversarial loss: 1.112474\n",
      "epoch 18; iter: 0; batch classifier loss: 0.561893; batch adversarial loss: 0.978314\n",
      "epoch 19; iter: 0; batch classifier loss: 0.537847; batch adversarial loss: 1.117353\n",
      "epoch 20; iter: 0; batch classifier loss: 0.570082; batch adversarial loss: 0.991990\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535589; batch adversarial loss: 1.038856\n",
      "epoch 22; iter: 0; batch classifier loss: 0.535320; batch adversarial loss: 1.042231\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511497; batch adversarial loss: 1.037893\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427952; batch adversarial loss: 1.000598\n",
      "epoch 25; iter: 0; batch classifier loss: 0.555488; batch adversarial loss: 0.984525\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489176; batch adversarial loss: 1.015438\n",
      "epoch 27; iter: 0; batch classifier loss: 0.487918; batch adversarial loss: 1.029179\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418364; batch adversarial loss: 1.041944\n",
      "epoch 29; iter: 0; batch classifier loss: 0.445811; batch adversarial loss: 1.016560\n",
      "epoch 30; iter: 0; batch classifier loss: 0.516583; batch adversarial loss: 1.034018\n",
      "epoch 31; iter: 0; batch classifier loss: 0.470369; batch adversarial loss: 0.987320\n",
      "epoch 32; iter: 0; batch classifier loss: 0.484661; batch adversarial loss: 1.024296\n",
      "epoch 33; iter: 0; batch classifier loss: 0.503137; batch adversarial loss: 1.047178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.472902; batch adversarial loss: 0.985405\n",
      "epoch 35; iter: 0; batch classifier loss: 0.471243; batch adversarial loss: 1.001287\n",
      "epoch 36; iter: 0; batch classifier loss: 0.505009; batch adversarial loss: 0.951006\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385532; batch adversarial loss: 0.979300\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409028; batch adversarial loss: 0.982064\n",
      "epoch 39; iter: 0; batch classifier loss: 0.394789; batch adversarial loss: 1.015430\n",
      "epoch 40; iter: 0; batch classifier loss: 0.341270; batch adversarial loss: 0.959895\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446468; batch adversarial loss: 1.015324\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354809; batch adversarial loss: 1.017196\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422652; batch adversarial loss: 1.011393\n",
      "epoch 44; iter: 0; batch classifier loss: 0.372424; batch adversarial loss: 0.957029\n",
      "epoch 45; iter: 0; batch classifier loss: 0.404182; batch adversarial loss: 0.897139\n",
      "epoch 46; iter: 0; batch classifier loss: 0.393839; batch adversarial loss: 0.963170\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409184; batch adversarial loss: 0.948558\n",
      "epoch 48; iter: 0; batch classifier loss: 0.417891; batch adversarial loss: 0.972894\n",
      "epoch 49; iter: 0; batch classifier loss: 0.437584; batch adversarial loss: 0.871955\n",
      "epoch 50; iter: 0; batch classifier loss: 0.371570; batch adversarial loss: 0.927272\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414551; batch adversarial loss: 0.940517\n",
      "epoch 52; iter: 0; batch classifier loss: 0.334312; batch adversarial loss: 0.947773\n",
      "epoch 53; iter: 0; batch classifier loss: 0.357355; batch adversarial loss: 0.962326\n",
      "epoch 54; iter: 0; batch classifier loss: 0.372263; batch adversarial loss: 0.879624\n",
      "epoch 55; iter: 0; batch classifier loss: 0.396248; batch adversarial loss: 0.880492\n",
      "epoch 56; iter: 0; batch classifier loss: 0.342335; batch adversarial loss: 0.973865\n",
      "epoch 57; iter: 0; batch classifier loss: 0.410249; batch adversarial loss: 0.876069\n",
      "epoch 58; iter: 0; batch classifier loss: 0.359587; batch adversarial loss: 0.968529\n",
      "epoch 59; iter: 0; batch classifier loss: 0.322723; batch adversarial loss: 0.918124\n",
      "epoch 60; iter: 0; batch classifier loss: 0.328975; batch adversarial loss: 0.941864\n",
      "epoch 61; iter: 0; batch classifier loss: 0.346923; batch adversarial loss: 0.937033\n",
      "epoch 62; iter: 0; batch classifier loss: 0.356337; batch adversarial loss: 0.954230\n",
      "epoch 63; iter: 0; batch classifier loss: 0.336385; batch adversarial loss: 0.913896\n",
      "epoch 64; iter: 0; batch classifier loss: 0.316087; batch adversarial loss: 0.888926\n",
      "epoch 65; iter: 0; batch classifier loss: 0.363245; batch adversarial loss: 0.886645\n",
      "epoch 66; iter: 0; batch classifier loss: 0.369028; batch adversarial loss: 0.844127\n",
      "epoch 67; iter: 0; batch classifier loss: 0.308744; batch adversarial loss: 0.883363\n",
      "epoch 68; iter: 0; batch classifier loss: 0.363368; batch adversarial loss: 0.911275\n",
      "epoch 69; iter: 0; batch classifier loss: 0.354324; batch adversarial loss: 0.875392\n",
      "epoch 70; iter: 0; batch classifier loss: 0.372958; batch adversarial loss: 0.937360\n",
      "epoch 71; iter: 0; batch classifier loss: 0.291019; batch adversarial loss: 0.848165\n",
      "epoch 72; iter: 0; batch classifier loss: 0.347756; batch adversarial loss: 0.897494\n",
      "epoch 73; iter: 0; batch classifier loss: 0.294138; batch adversarial loss: 0.914543\n",
      "epoch 74; iter: 0; batch classifier loss: 0.329252; batch adversarial loss: 0.835080\n",
      "epoch 75; iter: 0; batch classifier loss: 0.328895; batch adversarial loss: 0.866548\n",
      "epoch 76; iter: 0; batch classifier loss: 0.353657; batch adversarial loss: 0.833848\n",
      "epoch 77; iter: 0; batch classifier loss: 0.287394; batch adversarial loss: 0.918045\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352747; batch adversarial loss: 0.836606\n",
      "epoch 79; iter: 0; batch classifier loss: 0.367263; batch adversarial loss: 0.834412\n",
      "epoch 0; iter: 0; batch classifier loss: 0.835358; batch adversarial loss: 0.656232\n",
      "epoch 1; iter: 0; batch classifier loss: 0.754496; batch adversarial loss: 0.627311\n",
      "epoch 2; iter: 0; batch classifier loss: 0.721598; batch adversarial loss: 0.652684\n",
      "epoch 3; iter: 0; batch classifier loss: 0.690938; batch adversarial loss: 0.642270\n",
      "epoch 4; iter: 0; batch classifier loss: 0.620612; batch adversarial loss: 0.648430\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586138; batch adversarial loss: 0.652385\n",
      "epoch 6; iter: 0; batch classifier loss: 0.566072; batch adversarial loss: 0.663348\n",
      "epoch 7; iter: 0; batch classifier loss: 0.587779; batch adversarial loss: 0.625218\n",
      "epoch 8; iter: 0; batch classifier loss: 0.533880; batch adversarial loss: 0.656197\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508607; batch adversarial loss: 0.657214\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503385; batch adversarial loss: 0.645627\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526162; batch adversarial loss: 0.642159\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504230; batch adversarial loss: 0.641684\n",
      "epoch 13; iter: 0; batch classifier loss: 0.460993; batch adversarial loss: 0.656010\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481899; batch adversarial loss: 0.616888\n",
      "epoch 15; iter: 0; batch classifier loss: 0.416401; batch adversarial loss: 0.645347\n",
      "epoch 16; iter: 0; batch classifier loss: 0.382874; batch adversarial loss: 0.619586\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463579; batch adversarial loss: 0.659425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448459; batch adversarial loss: 0.656522\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437946; batch adversarial loss: 0.627981\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420208; batch adversarial loss: 0.654208\n",
      "epoch 21; iter: 0; batch classifier loss: 0.425392; batch adversarial loss: 0.626437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.418073; batch adversarial loss: 0.663515\n",
      "epoch 23; iter: 0; batch classifier loss: 0.387280; batch adversarial loss: 0.635864\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361583; batch adversarial loss: 0.649250\n",
      "epoch 25; iter: 0; batch classifier loss: 0.426988; batch adversarial loss: 0.629982\n",
      "epoch 26; iter: 0; batch classifier loss: 0.317169; batch adversarial loss: 0.666601\n",
      "epoch 27; iter: 0; batch classifier loss: 0.431466; batch adversarial loss: 0.641509\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368875; batch adversarial loss: 0.625747\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338002; batch adversarial loss: 0.658121\n",
      "epoch 30; iter: 0; batch classifier loss: 0.359783; batch adversarial loss: 0.650558\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379499; batch adversarial loss: 0.652528\n",
      "epoch 32; iter: 0; batch classifier loss: 0.365954; batch adversarial loss: 0.620068\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385907; batch adversarial loss: 0.642110\n",
      "epoch 34; iter: 0; batch classifier loss: 0.312313; batch adversarial loss: 0.644375\n",
      "epoch 35; iter: 0; batch classifier loss: 0.304254; batch adversarial loss: 0.612745\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379009; batch adversarial loss: 0.634705\n",
      "epoch 37; iter: 0; batch classifier loss: 0.335236; batch adversarial loss: 0.631104\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380785; batch adversarial loss: 0.680585\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336549; batch adversarial loss: 0.645192\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382551; batch adversarial loss: 0.667368\n",
      "epoch 41; iter: 0; batch classifier loss: 0.346906; batch adversarial loss: 0.632471\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283062; batch adversarial loss: 0.606955\n",
      "epoch 43; iter: 0; batch classifier loss: 0.310184; batch adversarial loss: 0.620216\n",
      "epoch 44; iter: 0; batch classifier loss: 0.312750; batch adversarial loss: 0.627079\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339538; batch adversarial loss: 0.664143\n",
      "epoch 46; iter: 0; batch classifier loss: 0.270564; batch adversarial loss: 0.671195\n",
      "epoch 47; iter: 0; batch classifier loss: 0.327879; batch adversarial loss: 0.607055\n",
      "epoch 48; iter: 0; batch classifier loss: 0.352943; batch adversarial loss: 0.633461\n",
      "epoch 49; iter: 0; batch classifier loss: 0.306167; batch adversarial loss: 0.598935\n",
      "epoch 50; iter: 0; batch classifier loss: 0.306606; batch adversarial loss: 0.667399\n",
      "epoch 51; iter: 0; batch classifier loss: 0.291000; batch adversarial loss: 0.680974\n",
      "epoch 52; iter: 0; batch classifier loss: 0.281089; batch adversarial loss: 0.608775\n",
      "epoch 53; iter: 0; batch classifier loss: 0.300508; batch adversarial loss: 0.595859\n",
      "epoch 54; iter: 0; batch classifier loss: 0.289704; batch adversarial loss: 0.605280\n",
      "epoch 55; iter: 0; batch classifier loss: 0.255078; batch adversarial loss: 0.646197\n",
      "epoch 56; iter: 0; batch classifier loss: 0.341434; batch adversarial loss: 0.664144\n",
      "epoch 57; iter: 0; batch classifier loss: 0.337628; batch adversarial loss: 0.647311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.338206; batch adversarial loss: 0.612946\n",
      "epoch 59; iter: 0; batch classifier loss: 0.346108; batch adversarial loss: 0.649701\n",
      "epoch 60; iter: 0; batch classifier loss: 0.362769; batch adversarial loss: 0.619005\n",
      "epoch 61; iter: 0; batch classifier loss: 0.321564; batch adversarial loss: 0.656411\n",
      "epoch 62; iter: 0; batch classifier loss: 0.317430; batch adversarial loss: 0.651662\n",
      "epoch 63; iter: 0; batch classifier loss: 0.233924; batch adversarial loss: 0.698253\n",
      "epoch 64; iter: 0; batch classifier loss: 0.383666; batch adversarial loss: 0.686013\n",
      "epoch 65; iter: 0; batch classifier loss: 0.286598; batch adversarial loss: 0.619698\n",
      "epoch 66; iter: 0; batch classifier loss: 0.272663; batch adversarial loss: 0.640723\n",
      "epoch 67; iter: 0; batch classifier loss: 0.359472; batch adversarial loss: 0.670160\n",
      "epoch 68; iter: 0; batch classifier loss: 0.283295; batch adversarial loss: 0.629006\n",
      "epoch 69; iter: 0; batch classifier loss: 0.318582; batch adversarial loss: 0.632918\n",
      "epoch 70; iter: 0; batch classifier loss: 0.286867; batch adversarial loss: 0.638013\n",
      "epoch 71; iter: 0; batch classifier loss: 0.280853; batch adversarial loss: 0.629903\n",
      "epoch 72; iter: 0; batch classifier loss: 0.313243; batch adversarial loss: 0.606640\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318789; batch adversarial loss: 0.596874\n",
      "epoch 74; iter: 0; batch classifier loss: 0.396412; batch adversarial loss: 0.643426\n",
      "epoch 75; iter: 0; batch classifier loss: 0.291563; batch adversarial loss: 0.619337\n",
      "epoch 76; iter: 0; batch classifier loss: 0.325524; batch adversarial loss: 0.671741\n",
      "epoch 77; iter: 0; batch classifier loss: 0.286066; batch adversarial loss: 0.689362\n",
      "epoch 78; iter: 0; batch classifier loss: 0.245755; batch adversarial loss: 0.585741\n",
      "epoch 79; iter: 0; batch classifier loss: 0.304926; batch adversarial loss: 0.629349\n",
      "epoch 0; iter: 0; batch classifier loss: 0.797980; batch adversarial loss: 0.820290\n",
      "epoch 1; iter: 0; batch classifier loss: 0.749801; batch adversarial loss: 0.834918\n",
      "epoch 2; iter: 0; batch classifier loss: 0.643746; batch adversarial loss: 0.801066\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649243; batch adversarial loss: 0.786704\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584527; batch adversarial loss: 0.802385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637710; batch adversarial loss: 0.839505\n",
      "epoch 6; iter: 0; batch classifier loss: 0.486214; batch adversarial loss: 0.839317\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536919; batch adversarial loss: 0.805998\n",
      "epoch 8; iter: 0; batch classifier loss: 0.481554; batch adversarial loss: 0.798730\n",
      "epoch 9; iter: 0; batch classifier loss: 0.443260; batch adversarial loss: 0.827516\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461163; batch adversarial loss: 0.816630\n",
      "epoch 11; iter: 0; batch classifier loss: 0.432245; batch adversarial loss: 0.827073\n",
      "epoch 12; iter: 0; batch classifier loss: 0.439526; batch adversarial loss: 0.795902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469829; batch adversarial loss: 0.782567\n",
      "epoch 14; iter: 0; batch classifier loss: 0.383900; batch adversarial loss: 0.732854\n",
      "epoch 15; iter: 0; batch classifier loss: 0.411871; batch adversarial loss: 0.783024\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339511; batch adversarial loss: 0.755969\n",
      "epoch 17; iter: 0; batch classifier loss: 0.347870; batch adversarial loss: 0.744866\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492689; batch adversarial loss: 0.781449\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374433; batch adversarial loss: 0.774792\n",
      "epoch 20; iter: 0; batch classifier loss: 0.297236; batch adversarial loss: 0.763282\n",
      "epoch 21; iter: 0; batch classifier loss: 0.310817; batch adversarial loss: 0.749078\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324663; batch adversarial loss: 0.720902\n",
      "epoch 23; iter: 0; batch classifier loss: 0.341162; batch adversarial loss: 0.736105\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405805; batch adversarial loss: 0.716083\n",
      "epoch 25; iter: 0; batch classifier loss: 0.347941; batch adversarial loss: 0.728706\n",
      "epoch 26; iter: 0; batch classifier loss: 0.302928; batch adversarial loss: 0.704054\n",
      "epoch 27; iter: 0; batch classifier loss: 0.380824; batch adversarial loss: 0.709947\n",
      "epoch 28; iter: 0; batch classifier loss: 0.277922; batch adversarial loss: 0.717530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.310178; batch adversarial loss: 0.696827\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269625; batch adversarial loss: 0.687146\n",
      "epoch 31; iter: 0; batch classifier loss: 0.291427; batch adversarial loss: 0.699353\n",
      "epoch 32; iter: 0; batch classifier loss: 0.226842; batch adversarial loss: 0.671056\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323476; batch adversarial loss: 0.689002\n",
      "epoch 34; iter: 0; batch classifier loss: 0.372125; batch adversarial loss: 0.671913\n",
      "epoch 35; iter: 0; batch classifier loss: 0.320251; batch adversarial loss: 0.669120\n",
      "epoch 36; iter: 0; batch classifier loss: 0.321298; batch adversarial loss: 0.685529\n",
      "epoch 37; iter: 0; batch classifier loss: 0.310427; batch adversarial loss: 0.684351\n",
      "epoch 38; iter: 0; batch classifier loss: 0.358197; batch adversarial loss: 0.651600\n",
      "epoch 39; iter: 0; batch classifier loss: 0.296172; batch adversarial loss: 0.653793\n",
      "epoch 0; iter: 0; batch classifier loss: 0.817781; batch adversarial loss: 0.865780\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670777; batch adversarial loss: 0.816233\n",
      "epoch 2; iter: 0; batch classifier loss: 0.606264; batch adversarial loss: 0.797636\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607997; batch adversarial loss: 0.804600\n",
      "epoch 4; iter: 0; batch classifier loss: 0.559500; batch adversarial loss: 0.788511\n",
      "epoch 5; iter: 0; batch classifier loss: 0.626643; batch adversarial loss: 0.812483\n",
      "epoch 6; iter: 0; batch classifier loss: 0.548140; batch adversarial loss: 0.800041\n",
      "epoch 7; iter: 0; batch classifier loss: 0.640097; batch adversarial loss: 0.783541\n",
      "epoch 8; iter: 0; batch classifier loss: 0.667510; batch adversarial loss: 0.843987\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582641; batch adversarial loss: 0.802299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.667179; batch adversarial loss: 0.824331\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583774; batch adversarial loss: 0.786312\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463902; batch adversarial loss: 0.736396\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564128; batch adversarial loss: 0.771598\n",
      "epoch 14; iter: 0; batch classifier loss: 0.551487; batch adversarial loss: 0.754300\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554892; batch adversarial loss: 0.776719\n",
      "epoch 16; iter: 0; batch classifier loss: 0.544235; batch adversarial loss: 0.744015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.521035; batch adversarial loss: 0.748634\n",
      "epoch 18; iter: 0; batch classifier loss: 0.575010; batch adversarial loss: 0.752628\n",
      "epoch 19; iter: 0; batch classifier loss: 0.632029; batch adversarial loss: 0.757065\n",
      "epoch 20; iter: 0; batch classifier loss: 0.481728; batch adversarial loss: 0.721075\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537400; batch adversarial loss: 0.730701\n",
      "epoch 22; iter: 0; batch classifier loss: 0.620556; batch adversarial loss: 0.730099\n",
      "epoch 23; iter: 0; batch classifier loss: 0.616133; batch adversarial loss: 0.726986\n",
      "epoch 24; iter: 0; batch classifier loss: 0.547497; batch adversarial loss: 0.717928\n",
      "epoch 25; iter: 0; batch classifier loss: 0.597510; batch adversarial loss: 0.749997\n",
      "epoch 26; iter: 0; batch classifier loss: 0.705966; batch adversarial loss: 0.724344\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461310; batch adversarial loss: 0.682126\n",
      "epoch 28; iter: 0; batch classifier loss: 0.485483; batch adversarial loss: 0.721990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.582532; batch adversarial loss: 0.684543\n",
      "epoch 30; iter: 0; batch classifier loss: 0.528569; batch adversarial loss: 0.648256\n",
      "epoch 31; iter: 0; batch classifier loss: 0.577252; batch adversarial loss: 0.680539\n",
      "epoch 32; iter: 0; batch classifier loss: 0.398426; batch adversarial loss: 0.616924\n",
      "epoch 33; iter: 0; batch classifier loss: 0.491844; batch adversarial loss: 0.684677\n",
      "epoch 34; iter: 0; batch classifier loss: 0.697258; batch adversarial loss: 0.726916\n",
      "epoch 35; iter: 0; batch classifier loss: 0.592756; batch adversarial loss: 0.662108\n",
      "epoch 36; iter: 0; batch classifier loss: 0.476661; batch adversarial loss: 0.657392\n",
      "epoch 37; iter: 0; batch classifier loss: 0.444417; batch adversarial loss: 0.631525\n",
      "epoch 38; iter: 0; batch classifier loss: 0.492207; batch adversarial loss: 0.626883\n",
      "epoch 39; iter: 0; batch classifier loss: 0.334588; batch adversarial loss: 0.605830\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715158; batch adversarial loss: 0.686067\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682489; batch adversarial loss: 0.681169\n",
      "epoch 2; iter: 0; batch classifier loss: 0.694053; batch adversarial loss: 0.676388\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652492; batch adversarial loss: 0.680954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.637856; batch adversarial loss: 0.677240\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597076; batch adversarial loss: 0.673514\n",
      "epoch 6; iter: 0; batch classifier loss: 0.612905; batch adversarial loss: 0.672629\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584862; batch adversarial loss: 0.672642\n",
      "epoch 8; iter: 0; batch classifier loss: 0.534763; batch adversarial loss: 0.666506\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561256; batch adversarial loss: 0.665225\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523275; batch adversarial loss: 0.668358\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492423; batch adversarial loss: 0.667612\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502942; batch adversarial loss: 0.656956\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512337; batch adversarial loss: 0.658671\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487463; batch adversarial loss: 0.652315\n",
      "epoch 15; iter: 0; batch classifier loss: 0.455007; batch adversarial loss: 0.660071\n",
      "epoch 16; iter: 0; batch classifier loss: 0.429436; batch adversarial loss: 0.655624\n",
      "epoch 17; iter: 0; batch classifier loss: 0.446287; batch adversarial loss: 0.654388\n",
      "epoch 18; iter: 0; batch classifier loss: 0.432737; batch adversarial loss: 0.651517\n",
      "epoch 19; iter: 0; batch classifier loss: 0.421894; batch adversarial loss: 0.651023\n",
      "epoch 20; iter: 0; batch classifier loss: 0.408919; batch adversarial loss: 0.648436\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415976; batch adversarial loss: 0.652050\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350155; batch adversarial loss: 0.652060\n",
      "epoch 23; iter: 0; batch classifier loss: 0.447927; batch adversarial loss: 0.648094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.378115; batch adversarial loss: 0.655250\n",
      "epoch 25; iter: 0; batch classifier loss: 0.367729; batch adversarial loss: 0.641036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.403097; batch adversarial loss: 0.649646\n",
      "epoch 27; iter: 0; batch classifier loss: 0.438932; batch adversarial loss: 0.641735\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348779; batch adversarial loss: 0.632505\n",
      "epoch 29; iter: 0; batch classifier loss: 0.371097; batch adversarial loss: 0.645203\n",
      "epoch 30; iter: 0; batch classifier loss: 0.382481; batch adversarial loss: 0.621052\n",
      "epoch 31; iter: 0; batch classifier loss: 0.404206; batch adversarial loss: 0.624429\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421878; batch adversarial loss: 0.627967\n",
      "epoch 33; iter: 0; batch classifier loss: 0.350844; batch adversarial loss: 0.623066\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427019; batch adversarial loss: 0.641582\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330912; batch adversarial loss: 0.629239\n",
      "epoch 36; iter: 0; batch classifier loss: 0.397446; batch adversarial loss: 0.629578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383630; batch adversarial loss: 0.626372\n",
      "epoch 38; iter: 0; batch classifier loss: 0.394496; batch adversarial loss: 0.630176\n",
      "epoch 39; iter: 0; batch classifier loss: 0.347997; batch adversarial loss: 0.609360\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709659; batch adversarial loss: 0.692101\n",
      "epoch 1; iter: 0; batch classifier loss: 0.712045; batch adversarial loss: 0.691518\n",
      "epoch 2; iter: 0; batch classifier loss: 0.668684; batch adversarial loss: 0.689094\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618220; batch adversarial loss: 0.687173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649143; batch adversarial loss: 0.686792\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618078; batch adversarial loss: 0.681494\n",
      "epoch 6; iter: 0; batch classifier loss: 0.582958; batch adversarial loss: 0.681356\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524143; batch adversarial loss: 0.679692\n",
      "epoch 8; iter: 0; batch classifier loss: 0.538945; batch adversarial loss: 0.675991\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484122; batch adversarial loss: 0.677295\n",
      "epoch 10; iter: 0; batch classifier loss: 0.488705; batch adversarial loss: 0.675386\n",
      "epoch 11; iter: 0; batch classifier loss: 0.538316; batch adversarial loss: 0.673884\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468441; batch adversarial loss: 0.670523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.444059; batch adversarial loss: 0.662417\n",
      "epoch 14; iter: 0; batch classifier loss: 0.469591; batch adversarial loss: 0.661818\n",
      "epoch 15; iter: 0; batch classifier loss: 0.423628; batch adversarial loss: 0.658757\n",
      "epoch 16; iter: 0; batch classifier loss: 0.442883; batch adversarial loss: 0.664081\n",
      "epoch 17; iter: 0; batch classifier loss: 0.411880; batch adversarial loss: 0.664425\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355472; batch adversarial loss: 0.659003\n",
      "epoch 19; iter: 0; batch classifier loss: 0.419238; batch adversarial loss: 0.656538\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435117; batch adversarial loss: 0.657882\n",
      "epoch 21; iter: 0; batch classifier loss: 0.404144; batch adversarial loss: 0.644822\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411898; batch adversarial loss: 0.655077\n",
      "epoch 23; iter: 0; batch classifier loss: 0.363894; batch adversarial loss: 0.631731\n",
      "epoch 24; iter: 0; batch classifier loss: 0.334528; batch adversarial loss: 0.657642\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371247; batch adversarial loss: 0.641216\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363429; batch adversarial loss: 0.649132\n",
      "epoch 27; iter: 0; batch classifier loss: 0.326807; batch adversarial loss: 0.655549\n",
      "epoch 28; iter: 0; batch classifier loss: 0.354017; batch adversarial loss: 0.642148\n",
      "epoch 29; iter: 0; batch classifier loss: 0.369322; batch adversarial loss: 0.640241\n",
      "epoch 30; iter: 0; batch classifier loss: 0.349138; batch adversarial loss: 0.636957\n",
      "epoch 31; iter: 0; batch classifier loss: 0.356276; batch adversarial loss: 0.647766\n",
      "epoch 32; iter: 0; batch classifier loss: 0.394436; batch adversarial loss: 0.647092\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318950; batch adversarial loss: 0.633054\n",
      "epoch 34; iter: 0; batch classifier loss: 0.353698; batch adversarial loss: 0.630182\n",
      "epoch 35; iter: 0; batch classifier loss: 0.288927; batch adversarial loss: 0.653609\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290218; batch adversarial loss: 0.623751\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386076; batch adversarial loss: 0.637507\n",
      "epoch 38; iter: 0; batch classifier loss: 0.330450; batch adversarial loss: 0.646179\n",
      "epoch 39; iter: 0; batch classifier loss: 0.301206; batch adversarial loss: 0.641899\n",
      "epoch 0; iter: 0; batch classifier loss: 0.849946; batch adversarial loss: 0.544722\n",
      "epoch 1; iter: 0; batch classifier loss: 0.719106; batch adversarial loss: 0.502644\n",
      "epoch 2; iter: 0; batch classifier loss: 0.657859; batch adversarial loss: 0.559252\n",
      "epoch 3; iter: 0; batch classifier loss: 0.673412; batch adversarial loss: 0.603167\n",
      "epoch 4; iter: 0; batch classifier loss: 0.608775; batch adversarial loss: 0.510850\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565862; batch adversarial loss: 0.497501\n",
      "epoch 6; iter: 0; batch classifier loss: 0.534434; batch adversarial loss: 0.569098\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516345; batch adversarial loss: 0.722811\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535350; batch adversarial loss: 0.476145\n",
      "epoch 9; iter: 0; batch classifier loss: 0.508338; batch adversarial loss: 0.630540\n",
      "epoch 10; iter: 0; batch classifier loss: 0.456940; batch adversarial loss: 0.623363\n",
      "epoch 11; iter: 0; batch classifier loss: 0.366643; batch adversarial loss: 0.572654\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413962; batch adversarial loss: 0.563729\n",
      "epoch 13; iter: 0; batch classifier loss: 0.341909; batch adversarial loss: 0.577165\n",
      "epoch 14; iter: 0; batch classifier loss: 0.405545; batch adversarial loss: 0.535868\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481161; batch adversarial loss: 0.540616\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540129; batch adversarial loss: 0.586884\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365705; batch adversarial loss: 0.536228\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421989; batch adversarial loss: 0.593007\n",
      "epoch 19; iter: 0; batch classifier loss: 0.253619; batch adversarial loss: 0.609323\n",
      "epoch 20; iter: 0; batch classifier loss: 0.311565; batch adversarial loss: 0.659936\n",
      "epoch 21; iter: 0; batch classifier loss: 0.323702; batch adversarial loss: 0.667683\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324891; batch adversarial loss: 0.580103\n",
      "epoch 23; iter: 0; batch classifier loss: 0.314213; batch adversarial loss: 0.518015\n",
      "epoch 24; iter: 0; batch classifier loss: 0.271825; batch adversarial loss: 0.578424\n",
      "epoch 25; iter: 0; batch classifier loss: 0.270382; batch adversarial loss: 0.595524\n",
      "epoch 26; iter: 0; batch classifier loss: 0.299202; batch adversarial loss: 0.566139\n",
      "epoch 27; iter: 0; batch classifier loss: 0.329830; batch adversarial loss: 0.627187\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300531; batch adversarial loss: 0.631460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315443; batch adversarial loss: 0.666422\n",
      "epoch 30; iter: 0; batch classifier loss: 0.332552; batch adversarial loss: 0.577284\n",
      "epoch 31; iter: 0; batch classifier loss: 0.271734; batch adversarial loss: 0.734926\n",
      "epoch 32; iter: 0; batch classifier loss: 0.346622; batch adversarial loss: 0.639174\n",
      "epoch 33; iter: 0; batch classifier loss: 0.306640; batch adversarial loss: 0.547810\n",
      "epoch 34; iter: 0; batch classifier loss: 0.240010; batch adversarial loss: 0.609385\n",
      "epoch 35; iter: 0; batch classifier loss: 0.253329; batch adversarial loss: 0.578200\n",
      "epoch 36; iter: 0; batch classifier loss: 0.312024; batch adversarial loss: 0.557323\n",
      "epoch 37; iter: 0; batch classifier loss: 0.262573; batch adversarial loss: 0.589049\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279541; batch adversarial loss: 0.635439\n",
      "epoch 39; iter: 0; batch classifier loss: 0.330799; batch adversarial loss: 0.619865\n",
      "epoch 40; iter: 0; batch classifier loss: 0.223858; batch adversarial loss: 0.780093\n",
      "epoch 41; iter: 0; batch classifier loss: 0.409919; batch adversarial loss: 0.690523\n",
      "epoch 42; iter: 0; batch classifier loss: 0.287227; batch adversarial loss: 0.639022\n",
      "epoch 43; iter: 0; batch classifier loss: 0.386693; batch adversarial loss: 0.560616\n",
      "epoch 44; iter: 0; batch classifier loss: 0.320259; batch adversarial loss: 0.490830\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336761; batch adversarial loss: 0.599197\n",
      "epoch 46; iter: 0; batch classifier loss: 0.417101; batch adversarial loss: 0.583210\n",
      "epoch 47; iter: 0; batch classifier loss: 0.312986; batch adversarial loss: 0.532392\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391321; batch adversarial loss: 0.543964\n",
      "epoch 49; iter: 0; batch classifier loss: 0.284139; batch adversarial loss: 0.649133\n",
      "epoch 50; iter: 0; batch classifier loss: 0.315402; batch adversarial loss: 0.641434\n",
      "epoch 51; iter: 0; batch classifier loss: 0.288337; batch adversarial loss: 0.614308\n",
      "epoch 52; iter: 0; batch classifier loss: 0.233653; batch adversarial loss: 0.666551\n",
      "epoch 53; iter: 0; batch classifier loss: 0.284215; batch adversarial loss: 0.585322\n",
      "epoch 54; iter: 0; batch classifier loss: 0.274907; batch adversarial loss: 0.615316\n",
      "epoch 55; iter: 0; batch classifier loss: 0.475526; batch adversarial loss: 0.684265\n",
      "epoch 56; iter: 0; batch classifier loss: 0.252244; batch adversarial loss: 0.557992\n",
      "epoch 57; iter: 0; batch classifier loss: 0.334807; batch adversarial loss: 0.653525\n",
      "epoch 58; iter: 0; batch classifier loss: 0.332759; batch adversarial loss: 0.668336\n",
      "epoch 59; iter: 0; batch classifier loss: 0.303218; batch adversarial loss: 0.708498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.828411; batch adversarial loss: 0.667519\n",
      "epoch 1; iter: 0; batch classifier loss: 0.722477; batch adversarial loss: 0.658460\n",
      "epoch 2; iter: 0; batch classifier loss: 0.673422; batch adversarial loss: 0.649440\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567815; batch adversarial loss: 0.656434\n",
      "epoch 4; iter: 0; batch classifier loss: 0.567529; batch adversarial loss: 0.648508\n",
      "epoch 5; iter: 0; batch classifier loss: 0.488851; batch adversarial loss: 0.644309\n",
      "epoch 6; iter: 0; batch classifier loss: 0.474031; batch adversarial loss: 0.662076\n",
      "epoch 7; iter: 0; batch classifier loss: 0.432960; batch adversarial loss: 0.628558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.416512; batch adversarial loss: 0.644836\n",
      "epoch 9; iter: 0; batch classifier loss: 0.427498; batch adversarial loss: 0.644178\n",
      "epoch 10; iter: 0; batch classifier loss: 0.354389; batch adversarial loss: 0.625676\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420109; batch adversarial loss: 0.610044\n",
      "epoch 12; iter: 0; batch classifier loss: 0.456185; batch adversarial loss: 0.644856\n",
      "epoch 13; iter: 0; batch classifier loss: 0.349742; batch adversarial loss: 0.602100\n",
      "epoch 14; iter: 0; batch classifier loss: 0.394543; batch adversarial loss: 0.595687\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379188; batch adversarial loss: 0.623427\n",
      "epoch 16; iter: 0; batch classifier loss: 0.451691; batch adversarial loss: 0.622678\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365786; batch adversarial loss: 0.648647\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358784; batch adversarial loss: 0.643661\n",
      "epoch 19; iter: 0; batch classifier loss: 0.275728; batch adversarial loss: 0.564669\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325692; batch adversarial loss: 0.599809\n",
      "epoch 21; iter: 0; batch classifier loss: 0.287321; batch adversarial loss: 0.620817\n",
      "epoch 22; iter: 0; batch classifier loss: 0.288692; batch adversarial loss: 0.615874\n",
      "epoch 23; iter: 0; batch classifier loss: 0.233859; batch adversarial loss: 0.593920\n",
      "epoch 24; iter: 0; batch classifier loss: 0.279724; batch adversarial loss: 0.652529\n",
      "epoch 25; iter: 0; batch classifier loss: 0.351174; batch adversarial loss: 0.612153\n",
      "epoch 26; iter: 0; batch classifier loss: 0.305635; batch adversarial loss: 0.636452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.359456; batch adversarial loss: 0.629476\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302993; batch adversarial loss: 0.619975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.296982; batch adversarial loss: 0.595444\n",
      "epoch 30; iter: 0; batch classifier loss: 0.269978; batch adversarial loss: 0.649220\n",
      "epoch 31; iter: 0; batch classifier loss: 0.332953; batch adversarial loss: 0.618791\n",
      "epoch 32; iter: 0; batch classifier loss: 0.263925; batch adversarial loss: 0.608652\n",
      "epoch 33; iter: 0; batch classifier loss: 0.194834; batch adversarial loss: 0.557273\n",
      "epoch 34; iter: 0; batch classifier loss: 0.229313; batch adversarial loss: 0.657097\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314447; batch adversarial loss: 0.601988\n",
      "epoch 36; iter: 0; batch classifier loss: 0.290325; batch adversarial loss: 0.617411\n",
      "epoch 37; iter: 0; batch classifier loss: 0.296694; batch adversarial loss: 0.702259\n",
      "epoch 38; iter: 0; batch classifier loss: 0.219611; batch adversarial loss: 0.595683\n",
      "epoch 39; iter: 0; batch classifier loss: 0.204735; batch adversarial loss: 0.626409\n",
      "epoch 40; iter: 0; batch classifier loss: 0.298545; batch adversarial loss: 0.584372\n",
      "epoch 41; iter: 0; batch classifier loss: 0.237921; batch adversarial loss: 0.637609\n",
      "epoch 42; iter: 0; batch classifier loss: 0.278460; batch adversarial loss: 0.587584\n",
      "epoch 43; iter: 0; batch classifier loss: 0.341677; batch adversarial loss: 0.656248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.305909; batch adversarial loss: 0.629389\n",
      "epoch 45; iter: 0; batch classifier loss: 0.224983; batch adversarial loss: 0.601749\n",
      "epoch 46; iter: 0; batch classifier loss: 0.293628; batch adversarial loss: 0.591115\n",
      "epoch 47; iter: 0; batch classifier loss: 0.276266; batch adversarial loss: 0.647878\n",
      "epoch 48; iter: 0; batch classifier loss: 0.269192; batch adversarial loss: 0.652057\n",
      "epoch 49; iter: 0; batch classifier loss: 0.246088; batch adversarial loss: 0.615043\n",
      "epoch 50; iter: 0; batch classifier loss: 0.212944; batch adversarial loss: 0.655856\n",
      "epoch 51; iter: 0; batch classifier loss: 0.231589; batch adversarial loss: 0.572079\n",
      "epoch 52; iter: 0; batch classifier loss: 0.246012; batch adversarial loss: 0.672592\n",
      "epoch 53; iter: 0; batch classifier loss: 0.187184; batch adversarial loss: 0.629142\n",
      "epoch 54; iter: 0; batch classifier loss: 0.247830; batch adversarial loss: 0.632262\n",
      "epoch 55; iter: 0; batch classifier loss: 0.271727; batch adversarial loss: 0.606940\n",
      "epoch 56; iter: 0; batch classifier loss: 0.203251; batch adversarial loss: 0.546248\n",
      "epoch 57; iter: 0; batch classifier loss: 0.218605; batch adversarial loss: 0.656002\n",
      "epoch 58; iter: 0; batch classifier loss: 0.232711; batch adversarial loss: 0.588194\n",
      "epoch 59; iter: 0; batch classifier loss: 0.234730; batch adversarial loss: 0.590334\n",
      "epoch 0; iter: 0; batch classifier loss: 0.878790; batch adversarial loss: 0.768644\n",
      "epoch 1; iter: 0; batch classifier loss: 0.798058; batch adversarial loss: 0.775772\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708960; batch adversarial loss: 0.783747\n",
      "epoch 3; iter: 0; batch classifier loss: 0.736779; batch adversarial loss: 0.791015\n",
      "epoch 4; iter: 0; batch classifier loss: 0.700540; batch adversarial loss: 0.767576\n",
      "epoch 5; iter: 0; batch classifier loss: 0.701411; batch adversarial loss: 0.875180\n",
      "epoch 6; iter: 0; batch classifier loss: 0.684818; batch adversarial loss: 0.835761\n",
      "epoch 7; iter: 0; batch classifier loss: 0.615065; batch adversarial loss: 0.808095\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610536; batch adversarial loss: 0.900223\n",
      "epoch 9; iter: 0; batch classifier loss: 0.677685; batch adversarial loss: 0.893299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547592; batch adversarial loss: 0.909265\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519388; batch adversarial loss: 0.891589\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507097; batch adversarial loss: 0.982900\n",
      "epoch 13; iter: 0; batch classifier loss: 0.495448; batch adversarial loss: 0.872469\n",
      "epoch 14; iter: 0; batch classifier loss: 0.573402; batch adversarial loss: 0.954127\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498107; batch adversarial loss: 0.963035\n",
      "epoch 16; iter: 0; batch classifier loss: 0.482289; batch adversarial loss: 0.971114\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439709; batch adversarial loss: 0.937044\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440075; batch adversarial loss: 0.993198\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456563; batch adversarial loss: 1.018376\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475849; batch adversarial loss: 1.008218\n",
      "epoch 21; iter: 0; batch classifier loss: 0.486971; batch adversarial loss: 1.029303\n",
      "epoch 22; iter: 0; batch classifier loss: 0.422140; batch adversarial loss: 1.005268\n",
      "epoch 23; iter: 0; batch classifier loss: 0.403077; batch adversarial loss: 1.003171\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388296; batch adversarial loss: 0.939106\n",
      "epoch 25; iter: 0; batch classifier loss: 0.404983; batch adversarial loss: 1.023958\n",
      "epoch 26; iter: 0; batch classifier loss: 0.435606; batch adversarial loss: 1.120525\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402143; batch adversarial loss: 1.037492\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426918; batch adversarial loss: 1.112068\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443700; batch adversarial loss: 1.093172\n",
      "epoch 30; iter: 0; batch classifier loss: 0.434910; batch adversarial loss: 1.027418\n",
      "epoch 31; iter: 0; batch classifier loss: 0.412628; batch adversarial loss: 1.086230\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426369; batch adversarial loss: 0.993537\n",
      "epoch 33; iter: 0; batch classifier loss: 0.402590; batch adversarial loss: 1.060080\n",
      "epoch 34; iter: 0; batch classifier loss: 0.337304; batch adversarial loss: 1.147062\n",
      "epoch 35; iter: 0; batch classifier loss: 0.355077; batch adversarial loss: 1.043488\n",
      "epoch 36; iter: 0; batch classifier loss: 0.453799; batch adversarial loss: 1.085431\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392407; batch adversarial loss: 1.066943\n",
      "epoch 38; iter: 0; batch classifier loss: 0.427274; batch adversarial loss: 1.109159\n",
      "epoch 39; iter: 0; batch classifier loss: 0.331205; batch adversarial loss: 1.030879\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390027; batch adversarial loss: 1.136915\n",
      "epoch 41; iter: 0; batch classifier loss: 0.369258; batch adversarial loss: 1.055059\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350570; batch adversarial loss: 1.031399\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415763; batch adversarial loss: 1.094173\n",
      "epoch 44; iter: 0; batch classifier loss: 0.509599; batch adversarial loss: 1.026196\n",
      "epoch 45; iter: 0; batch classifier loss: 0.345796; batch adversarial loss: 1.088497\n",
      "epoch 46; iter: 0; batch classifier loss: 0.462246; batch adversarial loss: 1.033029\n",
      "epoch 47; iter: 0; batch classifier loss: 0.414502; batch adversarial loss: 1.014329\n",
      "epoch 48; iter: 0; batch classifier loss: 0.347856; batch adversarial loss: 1.072784\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332375; batch adversarial loss: 1.055176\n",
      "epoch 50; iter: 0; batch classifier loss: 0.429754; batch adversarial loss: 0.993387\n",
      "epoch 51; iter: 0; batch classifier loss: 0.334913; batch adversarial loss: 1.004296\n",
      "epoch 52; iter: 0; batch classifier loss: 0.349522; batch adversarial loss: 1.034093\n",
      "epoch 53; iter: 0; batch classifier loss: 0.368498; batch adversarial loss: 1.047174\n",
      "epoch 54; iter: 0; batch classifier loss: 0.423112; batch adversarial loss: 0.992264\n",
      "epoch 55; iter: 0; batch classifier loss: 0.486646; batch adversarial loss: 1.049162\n",
      "epoch 56; iter: 0; batch classifier loss: 0.378638; batch adversarial loss: 1.094866\n",
      "epoch 57; iter: 0; batch classifier loss: 0.315694; batch adversarial loss: 1.030945\n",
      "epoch 58; iter: 0; batch classifier loss: 0.450290; batch adversarial loss: 1.073220\n",
      "epoch 59; iter: 0; batch classifier loss: 0.374212; batch adversarial loss: 0.987280\n",
      "epoch 0; iter: 0; batch classifier loss: 0.686032; batch adversarial loss: 0.724631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.721848; batch adversarial loss: 0.721475\n",
      "epoch 2; iter: 0; batch classifier loss: 0.651588; batch adversarial loss: 0.707727\n",
      "epoch 3; iter: 0; batch classifier loss: 0.675969; batch adversarial loss: 0.712854\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586583; batch adversarial loss: 0.714339\n",
      "epoch 5; iter: 0; batch classifier loss: 0.616619; batch adversarial loss: 0.717353\n",
      "epoch 6; iter: 0; batch classifier loss: 0.549582; batch adversarial loss: 0.712274\n",
      "epoch 7; iter: 0; batch classifier loss: 0.560100; batch adversarial loss: 0.713715\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541092; batch adversarial loss: 0.711455\n",
      "epoch 9; iter: 0; batch classifier loss: 0.595852; batch adversarial loss: 0.713967\n",
      "epoch 10; iter: 0; batch classifier loss: 0.511867; batch adversarial loss: 0.708865\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518469; batch adversarial loss: 0.715784\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426091; batch adversarial loss: 0.699072\n",
      "epoch 13; iter: 0; batch classifier loss: 0.511749; batch adversarial loss: 0.696161\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489992; batch adversarial loss: 0.709005\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473702; batch adversarial loss: 0.709700\n",
      "epoch 16; iter: 0; batch classifier loss: 0.457689; batch adversarial loss: 0.698021\n",
      "epoch 17; iter: 0; batch classifier loss: 0.466761; batch adversarial loss: 0.701380\n",
      "epoch 18; iter: 0; batch classifier loss: 0.400749; batch adversarial loss: 0.695114\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469471; batch adversarial loss: 0.696993\n",
      "epoch 20; iter: 0; batch classifier loss: 0.415405; batch adversarial loss: 0.703180\n",
      "epoch 21; iter: 0; batch classifier loss: 0.428604; batch adversarial loss: 0.691029\n",
      "epoch 22; iter: 0; batch classifier loss: 0.415637; batch adversarial loss: 0.690882\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417553; batch adversarial loss: 0.687859\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424843; batch adversarial loss: 0.687212\n",
      "epoch 25; iter: 0; batch classifier loss: 0.389674; batch adversarial loss: 0.684308\n",
      "epoch 26; iter: 0; batch classifier loss: 0.396841; batch adversarial loss: 0.684347\n",
      "epoch 27; iter: 0; batch classifier loss: 0.362338; batch adversarial loss: 0.685587\n",
      "epoch 28; iter: 0; batch classifier loss: 0.394508; batch adversarial loss: 0.681792\n",
      "epoch 29; iter: 0; batch classifier loss: 0.359452; batch adversarial loss: 0.681902\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394838; batch adversarial loss: 0.677341\n",
      "epoch 31; iter: 0; batch classifier loss: 0.347830; batch adversarial loss: 0.678233\n",
      "epoch 32; iter: 0; batch classifier loss: 0.368907; batch adversarial loss: 0.675342\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403062; batch adversarial loss: 0.673284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.411165; batch adversarial loss: 0.672959\n",
      "epoch 35; iter: 0; batch classifier loss: 0.300006; batch adversarial loss: 0.668692\n",
      "epoch 36; iter: 0; batch classifier loss: 0.327409; batch adversarial loss: 0.668499\n",
      "epoch 37; iter: 0; batch classifier loss: 0.392026; batch adversarial loss: 0.670478\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308114; batch adversarial loss: 0.664959\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353871; batch adversarial loss: 0.661003\n",
      "epoch 40; iter: 0; batch classifier loss: 0.337362; batch adversarial loss: 0.659931\n",
      "epoch 41; iter: 0; batch classifier loss: 0.370224; batch adversarial loss: 0.666421\n",
      "epoch 42; iter: 0; batch classifier loss: 0.331297; batch adversarial loss: 0.661777\n",
      "epoch 43; iter: 0; batch classifier loss: 0.346453; batch adversarial loss: 0.663188\n",
      "epoch 44; iter: 0; batch classifier loss: 0.320294; batch adversarial loss: 0.653884\n",
      "epoch 45; iter: 0; batch classifier loss: 0.298045; batch adversarial loss: 0.656135\n",
      "epoch 46; iter: 0; batch classifier loss: 0.330862; batch adversarial loss: 0.646778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.289171; batch adversarial loss: 0.653162\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287231; batch adversarial loss: 0.650492\n",
      "epoch 49; iter: 0; batch classifier loss: 0.254381; batch adversarial loss: 0.636622\n",
      "epoch 50; iter: 0; batch classifier loss: 0.270311; batch adversarial loss: 0.643210\n",
      "epoch 51; iter: 0; batch classifier loss: 0.284888; batch adversarial loss: 0.649023\n",
      "epoch 52; iter: 0; batch classifier loss: 0.282341; batch adversarial loss: 0.656348\n",
      "epoch 53; iter: 0; batch classifier loss: 0.301569; batch adversarial loss: 0.632739\n",
      "epoch 54; iter: 0; batch classifier loss: 0.272126; batch adversarial loss: 0.639614\n",
      "epoch 55; iter: 0; batch classifier loss: 0.275481; batch adversarial loss: 0.637028\n",
      "epoch 56; iter: 0; batch classifier loss: 0.254655; batch adversarial loss: 0.643196\n",
      "epoch 57; iter: 0; batch classifier loss: 0.318440; batch adversarial loss: 0.643591\n",
      "epoch 58; iter: 0; batch classifier loss: 0.216537; batch adversarial loss: 0.627907\n",
      "epoch 59; iter: 0; batch classifier loss: 0.246067; batch adversarial loss: 0.629284\n",
      "epoch 0; iter: 0; batch classifier loss: 0.813461; batch adversarial loss: 0.738865\n",
      "epoch 1; iter: 0; batch classifier loss: 0.767934; batch adversarial loss: 0.751145\n",
      "epoch 2; iter: 0; batch classifier loss: 0.782449; batch adversarial loss: 0.736086\n",
      "epoch 3; iter: 0; batch classifier loss: 0.688179; batch adversarial loss: 0.739674\n",
      "epoch 4; iter: 0; batch classifier loss: 0.672834; batch adversarial loss: 0.732901\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643734; batch adversarial loss: 0.729496\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572267; batch adversarial loss: 0.713317\n",
      "epoch 7; iter: 0; batch classifier loss: 0.567745; batch adversarial loss: 0.714567\n",
      "epoch 8; iter: 0; batch classifier loss: 0.512576; batch adversarial loss: 0.704205\n",
      "epoch 9; iter: 0; batch classifier loss: 0.545862; batch adversarial loss: 0.702270\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485610; batch adversarial loss: 0.695439\n",
      "epoch 11; iter: 0; batch classifier loss: 0.484784; batch adversarial loss: 0.693190\n",
      "epoch 12; iter: 0; batch classifier loss: 0.552814; batch adversarial loss: 0.692902\n",
      "epoch 13; iter: 0; batch classifier loss: 0.469844; batch adversarial loss: 0.681144\n",
      "epoch 14; iter: 0; batch classifier loss: 0.489998; batch adversarial loss: 0.669510\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480301; batch adversarial loss: 0.671965\n",
      "epoch 16; iter: 0; batch classifier loss: 0.399386; batch adversarial loss: 0.670257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.432909; batch adversarial loss: 0.668070\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378554; batch adversarial loss: 0.643425\n",
      "epoch 19; iter: 0; batch classifier loss: 0.471000; batch adversarial loss: 0.668145\n",
      "epoch 20; iter: 0; batch classifier loss: 0.532524; batch adversarial loss: 0.655700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.388394; batch adversarial loss: 0.662445\n",
      "epoch 22; iter: 0; batch classifier loss: 0.383016; batch adversarial loss: 0.642494\n",
      "epoch 23; iter: 0; batch classifier loss: 0.445398; batch adversarial loss: 0.640681\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347123; batch adversarial loss: 0.646590\n",
      "epoch 25; iter: 0; batch classifier loss: 0.297579; batch adversarial loss: 0.627395\n",
      "epoch 26; iter: 0; batch classifier loss: 0.411103; batch adversarial loss: 0.614494\n",
      "epoch 27; iter: 0; batch classifier loss: 0.402336; batch adversarial loss: 0.656462\n",
      "epoch 28; iter: 0; batch classifier loss: 0.320414; batch adversarial loss: 0.639404\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386000; batch adversarial loss: 0.622209\n",
      "epoch 30; iter: 0; batch classifier loss: 0.360922; batch adversarial loss: 0.607841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426782; batch adversarial loss: 0.637424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311400; batch adversarial loss: 0.623669\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392693; batch adversarial loss: 0.627230\n",
      "epoch 34; iter: 0; batch classifier loss: 0.284802; batch adversarial loss: 0.630382\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419405; batch adversarial loss: 0.616883\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275900; batch adversarial loss: 0.627767\n",
      "epoch 37; iter: 0; batch classifier loss: 0.365441; batch adversarial loss: 0.628337\n",
      "epoch 38; iter: 0; batch classifier loss: 0.346918; batch adversarial loss: 0.609115\n",
      "epoch 39; iter: 0; batch classifier loss: 0.369874; batch adversarial loss: 0.575637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.338639; batch adversarial loss: 0.603424\n",
      "epoch 41; iter: 0; batch classifier loss: 0.309341; batch adversarial loss: 0.557550\n",
      "epoch 42; iter: 0; batch classifier loss: 0.286598; batch adversarial loss: 0.588428\n",
      "epoch 43; iter: 0; batch classifier loss: 0.211016; batch adversarial loss: 0.594745\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336097; batch adversarial loss: 0.582464\n",
      "epoch 45; iter: 0; batch classifier loss: 0.332819; batch adversarial loss: 0.612714\n",
      "epoch 46; iter: 0; batch classifier loss: 0.330767; batch adversarial loss: 0.599223\n",
      "epoch 47; iter: 0; batch classifier loss: 0.337778; batch adversarial loss: 0.599743\n",
      "epoch 48; iter: 0; batch classifier loss: 0.371498; batch adversarial loss: 0.574272\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399689; batch adversarial loss: 0.600802\n",
      "epoch 50; iter: 0; batch classifier loss: 0.297951; batch adversarial loss: 0.594347\n",
      "epoch 51; iter: 0; batch classifier loss: 0.214704; batch adversarial loss: 0.649630\n",
      "epoch 52; iter: 0; batch classifier loss: 0.306041; batch adversarial loss: 0.631460\n",
      "epoch 53; iter: 0; batch classifier loss: 0.212244; batch adversarial loss: 0.596582\n",
      "epoch 54; iter: 0; batch classifier loss: 0.202369; batch adversarial loss: 0.563400\n",
      "epoch 55; iter: 0; batch classifier loss: 0.376107; batch adversarial loss: 0.597324\n",
      "epoch 56; iter: 0; batch classifier loss: 0.247870; batch adversarial loss: 0.579898\n",
      "epoch 57; iter: 0; batch classifier loss: 0.245079; batch adversarial loss: 0.581818\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198865; batch adversarial loss: 0.562585\n",
      "epoch 59; iter: 0; batch classifier loss: 0.188260; batch adversarial loss: 0.556997\n",
      "epoch 60; iter: 0; batch classifier loss: 0.291994; batch adversarial loss: 0.629291\n",
      "epoch 61; iter: 0; batch classifier loss: 0.299637; batch adversarial loss: 0.604154\n",
      "epoch 62; iter: 0; batch classifier loss: 0.277259; batch adversarial loss: 0.598385\n",
      "epoch 63; iter: 0; batch classifier loss: 0.281267; batch adversarial loss: 0.586813\n",
      "epoch 64; iter: 0; batch classifier loss: 0.241869; batch adversarial loss: 0.593140\n",
      "epoch 65; iter: 0; batch classifier loss: 0.299865; batch adversarial loss: 0.543215\n",
      "epoch 66; iter: 0; batch classifier loss: 0.304174; batch adversarial loss: 0.628955\n",
      "epoch 67; iter: 0; batch classifier loss: 0.314172; batch adversarial loss: 0.686080\n",
      "epoch 68; iter: 0; batch classifier loss: 0.329067; batch adversarial loss: 0.567099\n",
      "epoch 69; iter: 0; batch classifier loss: 0.287538; batch adversarial loss: 0.545266\n",
      "epoch 70; iter: 0; batch classifier loss: 0.216280; batch adversarial loss: 0.537498\n",
      "epoch 71; iter: 0; batch classifier loss: 0.205001; batch adversarial loss: 0.506490\n",
      "epoch 72; iter: 0; batch classifier loss: 0.204448; batch adversarial loss: 0.524695\n",
      "epoch 73; iter: 0; batch classifier loss: 0.253485; batch adversarial loss: 0.605702\n",
      "epoch 74; iter: 0; batch classifier loss: 0.276075; batch adversarial loss: 0.515801\n",
      "epoch 75; iter: 0; batch classifier loss: 0.191504; batch adversarial loss: 0.593280\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202560; batch adversarial loss: 0.595745\n",
      "epoch 77; iter: 0; batch classifier loss: 0.182565; batch adversarial loss: 0.527138\n",
      "epoch 78; iter: 0; batch classifier loss: 0.295384; batch adversarial loss: 0.530414\n",
      "epoch 79; iter: 0; batch classifier loss: 0.325799; batch adversarial loss: 0.566690\n",
      "epoch 0; iter: 0; batch classifier loss: 0.832755; batch adversarial loss: 0.718026\n",
      "epoch 1; iter: 0; batch classifier loss: 0.697731; batch adversarial loss: 0.703910\n",
      "epoch 2; iter: 0; batch classifier loss: 0.696649; batch adversarial loss: 0.733705\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582895; batch adversarial loss: 0.719262\n",
      "epoch 4; iter: 0; batch classifier loss: 0.545052; batch adversarial loss: 0.721195\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571695; batch adversarial loss: 0.730397\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545459; batch adversarial loss: 0.706078\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486277; batch adversarial loss: 0.713036\n",
      "epoch 8; iter: 0; batch classifier loss: 0.501583; batch adversarial loss: 0.753739\n",
      "epoch 9; iter: 0; batch classifier loss: 0.421083; batch adversarial loss: 0.704666\n",
      "epoch 10; iter: 0; batch classifier loss: 0.411051; batch adversarial loss: 0.731885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.442311; batch adversarial loss: 0.721873\n",
      "epoch 12; iter: 0; batch classifier loss: 0.379322; batch adversarial loss: 0.724532\n",
      "epoch 13; iter: 0; batch classifier loss: 0.434031; batch adversarial loss: 0.673220\n",
      "epoch 14; iter: 0; batch classifier loss: 0.517593; batch adversarial loss: 0.703116\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373901; batch adversarial loss: 0.710585\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452774; batch adversarial loss: 0.687112\n",
      "epoch 17; iter: 0; batch classifier loss: 0.323204; batch adversarial loss: 0.700395\n",
      "epoch 18; iter: 0; batch classifier loss: 0.376824; batch adversarial loss: 0.688928\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406497; batch adversarial loss: 0.676103\n",
      "epoch 20; iter: 0; batch classifier loss: 0.341884; batch adversarial loss: 0.680796\n",
      "epoch 21; iter: 0; batch classifier loss: 0.419387; batch adversarial loss: 0.682703\n",
      "epoch 22; iter: 0; batch classifier loss: 0.394760; batch adversarial loss: 0.649901\n",
      "epoch 23; iter: 0; batch classifier loss: 0.318999; batch adversarial loss: 0.655675\n",
      "epoch 24; iter: 0; batch classifier loss: 0.195467; batch adversarial loss: 0.681417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.327460; batch adversarial loss: 0.658145\n",
      "epoch 26; iter: 0; batch classifier loss: 0.312487; batch adversarial loss: 0.662812\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383532; batch adversarial loss: 0.643371\n",
      "epoch 28; iter: 0; batch classifier loss: 0.328373; batch adversarial loss: 0.638107\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397786; batch adversarial loss: 0.664591\n",
      "epoch 30; iter: 0; batch classifier loss: 0.276861; batch adversarial loss: 0.641340\n",
      "epoch 31; iter: 0; batch classifier loss: 0.314034; batch adversarial loss: 0.618062\n",
      "epoch 32; iter: 0; batch classifier loss: 0.219268; batch adversarial loss: 0.637561\n",
      "epoch 33; iter: 0; batch classifier loss: 0.313610; batch adversarial loss: 0.635077\n",
      "epoch 34; iter: 0; batch classifier loss: 0.266555; batch adversarial loss: 0.639999\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297725; batch adversarial loss: 0.657844\n",
      "epoch 36; iter: 0; batch classifier loss: 0.255433; batch adversarial loss: 0.634745\n",
      "epoch 37; iter: 0; batch classifier loss: 0.283648; batch adversarial loss: 0.628335\n",
      "epoch 38; iter: 0; batch classifier loss: 0.278666; batch adversarial loss: 0.661210\n",
      "epoch 39; iter: 0; batch classifier loss: 0.293547; batch adversarial loss: 0.663059\n",
      "epoch 40; iter: 0; batch classifier loss: 0.279005; batch adversarial loss: 0.610125\n",
      "epoch 41; iter: 0; batch classifier loss: 0.332110; batch adversarial loss: 0.700358\n",
      "epoch 42; iter: 0; batch classifier loss: 0.201140; batch adversarial loss: 0.617134\n",
      "epoch 43; iter: 0; batch classifier loss: 0.266122; batch adversarial loss: 0.626732\n",
      "epoch 44; iter: 0; batch classifier loss: 0.268122; batch adversarial loss: 0.608932\n",
      "epoch 45; iter: 0; batch classifier loss: 0.297697; batch adversarial loss: 0.606502\n",
      "epoch 46; iter: 0; batch classifier loss: 0.282224; batch adversarial loss: 0.631995\n",
      "epoch 47; iter: 0; batch classifier loss: 0.276985; batch adversarial loss: 0.585843\n",
      "epoch 48; iter: 0; batch classifier loss: 0.258876; batch adversarial loss: 0.604489\n",
      "epoch 49; iter: 0; batch classifier loss: 0.192969; batch adversarial loss: 0.569663\n",
      "epoch 50; iter: 0; batch classifier loss: 0.292814; batch adversarial loss: 0.617890\n",
      "epoch 51; iter: 0; batch classifier loss: 0.212840; batch adversarial loss: 0.591600\n",
      "epoch 52; iter: 0; batch classifier loss: 0.203108; batch adversarial loss: 0.593658\n",
      "epoch 53; iter: 0; batch classifier loss: 0.124986; batch adversarial loss: 0.574866\n",
      "epoch 54; iter: 0; batch classifier loss: 0.143911; batch adversarial loss: 0.551076\n",
      "epoch 55; iter: 0; batch classifier loss: 0.166732; batch adversarial loss: 0.605607\n",
      "epoch 56; iter: 0; batch classifier loss: 0.186924; batch adversarial loss: 0.586246\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325446; batch adversarial loss: 0.609099\n",
      "epoch 58; iter: 0; batch classifier loss: 0.203348; batch adversarial loss: 0.611902\n",
      "epoch 59; iter: 0; batch classifier loss: 0.260073; batch adversarial loss: 0.602884\n",
      "epoch 60; iter: 0; batch classifier loss: 0.212572; batch adversarial loss: 0.601773\n",
      "epoch 61; iter: 0; batch classifier loss: 0.147596; batch adversarial loss: 0.557509\n",
      "epoch 62; iter: 0; batch classifier loss: 0.179509; batch adversarial loss: 0.608686\n",
      "epoch 63; iter: 0; batch classifier loss: 0.189702; batch adversarial loss: 0.618150\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222555; batch adversarial loss: 0.639362\n",
      "epoch 65; iter: 0; batch classifier loss: 0.228443; batch adversarial loss: 0.615494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.140177; batch adversarial loss: 0.578396\n",
      "epoch 67; iter: 0; batch classifier loss: 0.274725; batch adversarial loss: 0.609389\n",
      "epoch 68; iter: 0; batch classifier loss: 0.171274; batch adversarial loss: 0.636000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.253325; batch adversarial loss: 0.537183\n",
      "epoch 70; iter: 0; batch classifier loss: 0.233869; batch adversarial loss: 0.573330\n",
      "epoch 71; iter: 0; batch classifier loss: 0.190868; batch adversarial loss: 0.627862\n",
      "epoch 72; iter: 0; batch classifier loss: 0.209877; batch adversarial loss: 0.637475\n",
      "epoch 73; iter: 0; batch classifier loss: 0.155720; batch adversarial loss: 0.594907\n",
      "epoch 74; iter: 0; batch classifier loss: 0.153596; batch adversarial loss: 0.640525\n",
      "epoch 75; iter: 0; batch classifier loss: 0.230208; batch adversarial loss: 0.608679\n",
      "epoch 76; iter: 0; batch classifier loss: 0.114369; batch adversarial loss: 0.513850\n",
      "epoch 77; iter: 0; batch classifier loss: 0.126146; batch adversarial loss: 0.633506\n",
      "epoch 78; iter: 0; batch classifier loss: 0.152333; batch adversarial loss: 0.582042\n",
      "epoch 79; iter: 0; batch classifier loss: 0.191849; batch adversarial loss: 0.641348\n",
      "epoch 0; iter: 0; batch classifier loss: 0.754231; batch adversarial loss: 0.767445\n",
      "epoch 1; iter: 0; batch classifier loss: 0.716791; batch adversarial loss: 0.767082\n",
      "epoch 2; iter: 0; batch classifier loss: 0.689117; batch adversarial loss: 0.767330\n",
      "epoch 3; iter: 0; batch classifier loss: 0.692794; batch adversarial loss: 0.754183\n",
      "epoch 4; iter: 0; batch classifier loss: 0.669568; batch adversarial loss: 0.776255\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613734; batch adversarial loss: 0.772283\n",
      "epoch 6; iter: 0; batch classifier loss: 0.675543; batch adversarial loss: 0.757492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579419; batch adversarial loss: 0.762755\n",
      "epoch 8; iter: 0; batch classifier loss: 0.590595; batch adversarial loss: 0.784272\n",
      "epoch 9; iter: 0; batch classifier loss: 0.620773; batch adversarial loss: 0.780084\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585216; batch adversarial loss: 0.801244\n",
      "epoch 11; iter: 0; batch classifier loss: 0.600631; batch adversarial loss: 0.786132\n",
      "epoch 12; iter: 0; batch classifier loss: 0.557908; batch adversarial loss: 0.779047\n",
      "epoch 13; iter: 0; batch classifier loss: 0.465227; batch adversarial loss: 0.769518\n",
      "epoch 14; iter: 0; batch classifier loss: 0.544218; batch adversarial loss: 0.770405\n",
      "epoch 15; iter: 0; batch classifier loss: 0.563092; batch adversarial loss: 0.791399\n",
      "epoch 16; iter: 0; batch classifier loss: 0.473357; batch adversarial loss: 0.782131\n",
      "epoch 17; iter: 0; batch classifier loss: 0.474801; batch adversarial loss: 0.760409\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469423; batch adversarial loss: 0.768676\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456128; batch adversarial loss: 0.781538\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463383; batch adversarial loss: 0.793962\n",
      "epoch 21; iter: 0; batch classifier loss: 0.417470; batch adversarial loss: 0.769844\n",
      "epoch 22; iter: 0; batch classifier loss: 0.397425; batch adversarial loss: 0.800907\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434001; batch adversarial loss: 0.763572\n",
      "epoch 24; iter: 0; batch classifier loss: 0.444849; batch adversarial loss: 0.770050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.430419; batch adversarial loss: 0.803210\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440576; batch adversarial loss: 0.760890\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433180; batch adversarial loss: 0.742126\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413821; batch adversarial loss: 0.731357\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456578; batch adversarial loss: 0.781477\n",
      "epoch 30; iter: 0; batch classifier loss: 0.438407; batch adversarial loss: 0.778634\n",
      "epoch 31; iter: 0; batch classifier loss: 0.414745; batch adversarial loss: 0.772988\n",
      "epoch 32; iter: 0; batch classifier loss: 0.381063; batch adversarial loss: 0.744517\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386757; batch adversarial loss: 0.735422\n",
      "epoch 34; iter: 0; batch classifier loss: 0.394687; batch adversarial loss: 0.755869\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333848; batch adversarial loss: 0.752944\n",
      "epoch 36; iter: 0; batch classifier loss: 0.363537; batch adversarial loss: 0.741881\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354792; batch adversarial loss: 0.793477\n",
      "epoch 38; iter: 0; batch classifier loss: 0.358950; batch adversarial loss: 0.743702\n",
      "epoch 39; iter: 0; batch classifier loss: 0.415148; batch adversarial loss: 0.760075\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403525; batch adversarial loss: 0.741233\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385995; batch adversarial loss: 0.741491\n",
      "epoch 42; iter: 0; batch classifier loss: 0.378809; batch adversarial loss: 0.755731\n",
      "epoch 43; iter: 0; batch classifier loss: 0.366200; batch adversarial loss: 0.745206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.306479; batch adversarial loss: 0.745993\n",
      "epoch 45; iter: 0; batch classifier loss: 0.284228; batch adversarial loss: 0.754287\n",
      "epoch 46; iter: 0; batch classifier loss: 0.337695; batch adversarial loss: 0.720749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.298921; batch adversarial loss: 0.752524\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332802; batch adversarial loss: 0.724095\n",
      "epoch 49; iter: 0; batch classifier loss: 0.304236; batch adversarial loss: 0.731225\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392832; batch adversarial loss: 0.727584\n",
      "epoch 51; iter: 0; batch classifier loss: 0.363145; batch adversarial loss: 0.715463\n",
      "epoch 52; iter: 0; batch classifier loss: 0.337292; batch adversarial loss: 0.712643\n",
      "epoch 53; iter: 0; batch classifier loss: 0.322387; batch adversarial loss: 0.727975\n",
      "epoch 54; iter: 0; batch classifier loss: 0.346489; batch adversarial loss: 0.725041\n",
      "epoch 55; iter: 0; batch classifier loss: 0.298418; batch adversarial loss: 0.725432\n",
      "epoch 56; iter: 0; batch classifier loss: 0.266943; batch adversarial loss: 0.719803\n",
      "epoch 57; iter: 0; batch classifier loss: 0.390106; batch adversarial loss: 0.735702\n",
      "epoch 58; iter: 0; batch classifier loss: 0.386048; batch adversarial loss: 0.697091\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357043; batch adversarial loss: 0.694271\n",
      "epoch 60; iter: 0; batch classifier loss: 0.259241; batch adversarial loss: 0.697404\n",
      "epoch 61; iter: 0; batch classifier loss: 0.258986; batch adversarial loss: 0.715887\n",
      "epoch 62; iter: 0; batch classifier loss: 0.324834; batch adversarial loss: 0.713403\n",
      "epoch 63; iter: 0; batch classifier loss: 0.321357; batch adversarial loss: 0.699868\n",
      "epoch 64; iter: 0; batch classifier loss: 0.356427; batch adversarial loss: 0.688072\n",
      "epoch 65; iter: 0; batch classifier loss: 0.327817; batch adversarial loss: 0.692004\n",
      "epoch 66; iter: 0; batch classifier loss: 0.316749; batch adversarial loss: 0.700870\n",
      "epoch 67; iter: 0; batch classifier loss: 0.331609; batch adversarial loss: 0.690330\n",
      "epoch 68; iter: 0; batch classifier loss: 0.297179; batch adversarial loss: 0.698697\n",
      "epoch 69; iter: 0; batch classifier loss: 0.255345; batch adversarial loss: 0.679691\n",
      "epoch 70; iter: 0; batch classifier loss: 0.287575; batch adversarial loss: 0.687484\n",
      "epoch 71; iter: 0; batch classifier loss: 0.263118; batch adversarial loss: 0.676497\n",
      "epoch 72; iter: 0; batch classifier loss: 0.293207; batch adversarial loss: 0.691627\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329890; batch adversarial loss: 0.686535\n",
      "epoch 74; iter: 0; batch classifier loss: 0.288341; batch adversarial loss: 0.677549\n",
      "epoch 75; iter: 0; batch classifier loss: 0.245447; batch adversarial loss: 0.681618\n",
      "epoch 76; iter: 0; batch classifier loss: 0.265133; batch adversarial loss: 0.673588\n",
      "epoch 77; iter: 0; batch classifier loss: 0.329302; batch adversarial loss: 0.664342\n",
      "epoch 78; iter: 0; batch classifier loss: 0.278090; batch adversarial loss: 0.681150\n",
      "epoch 79; iter: 0; batch classifier loss: 0.248375; batch adversarial loss: 0.679686\n",
      "epoch 0; iter: 0; batch classifier loss: 0.726341; batch adversarial loss: 0.729155\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681906; batch adversarial loss: 0.724996\n",
      "epoch 2; iter: 0; batch classifier loss: 0.701391; batch adversarial loss: 0.719342\n",
      "epoch 3; iter: 0; batch classifier loss: 0.645571; batch adversarial loss: 0.714023\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607027; batch adversarial loss: 0.714910\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579132; batch adversarial loss: 0.710495\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632905; batch adversarial loss: 0.720481\n",
      "epoch 7; iter: 0; batch classifier loss: 0.579607; batch adversarial loss: 0.712436\n",
      "epoch 8; iter: 0; batch classifier loss: 0.551555; batch adversarial loss: 0.703074\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520138; batch adversarial loss: 0.704702\n",
      "epoch 10; iter: 0; batch classifier loss: 0.587360; batch adversarial loss: 0.707181\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567565; batch adversarial loss: 0.697889\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505379; batch adversarial loss: 0.695530\n",
      "epoch 13; iter: 0; batch classifier loss: 0.497607; batch adversarial loss: 0.693363\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520629; batch adversarial loss: 0.698926\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515506; batch adversarial loss: 0.686016\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469813; batch adversarial loss: 0.691015\n",
      "epoch 17; iter: 0; batch classifier loss: 0.453729; batch adversarial loss: 0.683524\n",
      "epoch 18; iter: 0; batch classifier loss: 0.460143; batch adversarial loss: 0.683523\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437024; batch adversarial loss: 0.661799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.435604; batch adversarial loss: 0.672087\n",
      "epoch 21; iter: 0; batch classifier loss: 0.442454; batch adversarial loss: 0.669577\n",
      "epoch 22; iter: 0; batch classifier loss: 0.442503; batch adversarial loss: 0.675030\n",
      "epoch 23; iter: 0; batch classifier loss: 0.414754; batch adversarial loss: 0.664364\n",
      "epoch 24; iter: 0; batch classifier loss: 0.482654; batch adversarial loss: 0.671781\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422690; batch adversarial loss: 0.667413\n",
      "epoch 26; iter: 0; batch classifier loss: 0.426959; batch adversarial loss: 0.665459\n",
      "epoch 27; iter: 0; batch classifier loss: 0.383456; batch adversarial loss: 0.650043\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452147; batch adversarial loss: 0.651304\n",
      "epoch 29; iter: 0; batch classifier loss: 0.428246; batch adversarial loss: 0.643380\n",
      "epoch 30; iter: 0; batch classifier loss: 0.443481; batch adversarial loss: 0.650262\n",
      "epoch 31; iter: 0; batch classifier loss: 0.378770; batch adversarial loss: 0.656987\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419672; batch adversarial loss: 0.659726\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363460; batch adversarial loss: 0.643072\n",
      "epoch 34; iter: 0; batch classifier loss: 0.355567; batch adversarial loss: 0.642299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372619; batch adversarial loss: 0.626572\n",
      "epoch 36; iter: 0; batch classifier loss: 0.366251; batch adversarial loss: 0.657440\n",
      "epoch 37; iter: 0; batch classifier loss: 0.348235; batch adversarial loss: 0.642262\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342556; batch adversarial loss: 0.628026\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321571; batch adversarial loss: 0.645788\n",
      "epoch 40; iter: 0; batch classifier loss: 0.363628; batch adversarial loss: 0.638890\n",
      "epoch 41; iter: 0; batch classifier loss: 0.327280; batch adversarial loss: 0.614701\n",
      "epoch 42; iter: 0; batch classifier loss: 0.325842; batch adversarial loss: 0.632587\n",
      "epoch 43; iter: 0; batch classifier loss: 0.314462; batch adversarial loss: 0.627738\n",
      "epoch 44; iter: 0; batch classifier loss: 0.272681; batch adversarial loss: 0.649755\n",
      "epoch 45; iter: 0; batch classifier loss: 0.315913; batch adversarial loss: 0.630165\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266913; batch adversarial loss: 0.616379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.297953; batch adversarial loss: 0.642078\n",
      "epoch 48; iter: 0; batch classifier loss: 0.385326; batch adversarial loss: 0.632271\n",
      "epoch 49; iter: 0; batch classifier loss: 0.326980; batch adversarial loss: 0.601421\n",
      "epoch 50; iter: 0; batch classifier loss: 0.312009; batch adversarial loss: 0.627958\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326658; batch adversarial loss: 0.651082\n",
      "epoch 52; iter: 0; batch classifier loss: 0.260165; batch adversarial loss: 0.637814\n",
      "epoch 53; iter: 0; batch classifier loss: 0.259824; batch adversarial loss: 0.632956\n",
      "epoch 54; iter: 0; batch classifier loss: 0.270498; batch adversarial loss: 0.609550\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346893; batch adversarial loss: 0.621557\n",
      "epoch 56; iter: 0; batch classifier loss: 0.301403; batch adversarial loss: 0.638716\n",
      "epoch 57; iter: 0; batch classifier loss: 0.304375; batch adversarial loss: 0.618879\n",
      "epoch 58; iter: 0; batch classifier loss: 0.254099; batch adversarial loss: 0.625353\n",
      "epoch 59; iter: 0; batch classifier loss: 0.279332; batch adversarial loss: 0.618979\n",
      "epoch 60; iter: 0; batch classifier loss: 0.258161; batch adversarial loss: 0.619533\n",
      "epoch 61; iter: 0; batch classifier loss: 0.250177; batch adversarial loss: 0.608666\n",
      "epoch 62; iter: 0; batch classifier loss: 0.245397; batch adversarial loss: 0.629856\n",
      "epoch 63; iter: 0; batch classifier loss: 0.257398; batch adversarial loss: 0.609681\n",
      "epoch 64; iter: 0; batch classifier loss: 0.318725; batch adversarial loss: 0.604828\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218918; batch adversarial loss: 0.605270\n",
      "epoch 66; iter: 0; batch classifier loss: 0.262847; batch adversarial loss: 0.574075\n",
      "epoch 67; iter: 0; batch classifier loss: 0.300468; batch adversarial loss: 0.621908\n",
      "epoch 68; iter: 0; batch classifier loss: 0.286785; batch adversarial loss: 0.623377\n",
      "epoch 69; iter: 0; batch classifier loss: 0.249671; batch adversarial loss: 0.593699\n",
      "epoch 70; iter: 0; batch classifier loss: 0.288566; batch adversarial loss: 0.621206\n",
      "epoch 71; iter: 0; batch classifier loss: 0.251304; batch adversarial loss: 0.610816\n",
      "epoch 72; iter: 0; batch classifier loss: 0.230875; batch adversarial loss: 0.608197\n",
      "epoch 73; iter: 0; batch classifier loss: 0.254782; batch adversarial loss: 0.613741\n",
      "epoch 74; iter: 0; batch classifier loss: 0.239250; batch adversarial loss: 0.599506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.206704; batch adversarial loss: 0.622624\n",
      "epoch 76; iter: 0; batch classifier loss: 0.217239; batch adversarial loss: 0.613881\n",
      "epoch 77; iter: 0; batch classifier loss: 0.254107; batch adversarial loss: 0.619345\n",
      "epoch 78; iter: 0; batch classifier loss: 0.206279; batch adversarial loss: 0.607705\n",
      "epoch 79; iter: 0; batch classifier loss: 0.260963; batch adversarial loss: 0.630791\n",
      "\n",
      "=== ADV in-proc (best) w=0.05, e=80, b=128, h=32 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.636986</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR     FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                     \n",
       "0    0.666667  0.0625  0.666667       0.157895  0.894737\n",
       "1    0.875000  0.1800  0.875000       0.636986  0.856164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8641 | DP diff: 0.4791 | EO diff: 0.2083 | combined gap (DP+EO)=0.6874; acc=0.8641\n"
     ]
    }
   ],
   "source": [
    "# Grid-tune AIF360 AdversarialDebiasing for better DP/EO balance and print with report_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "# small search over key knobs; widen if needed\n",
    "ADV_GRID = dict(\n",
    "    adversary_loss_weight=[0.02, 0.05, 0.1, 0.2, 0.3],\n",
    "    num_epochs=[40, 60, 80],\n",
    "    batch_size=[64, 128],\n",
    "    classifier_num_hidden_units=[32, 64]  # size of main net\n",
    ")\n",
    "\n",
    "def run_adv(loss_w=0.1, epochs=50, bs=128, hidden=64, seed=42):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            debias=True,\n",
    "            scope_name=f\"adv_w{loss_w}_e{epochs}_b{bs}_h{hidden}\",\n",
    "            adversary_loss_weight=loss_w,\n",
    "            num_epochs=epochs,\n",
    "            batch_size=bs,\n",
    "            classifier_num_hidden_units=hidden,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "        yhat = pred_te.labels.ravel().astype(int)\n",
    "        scores = getattr(pred_te, \"scores\", None)\n",
    "        if scores is None:\n",
    "            scores = yhat.astype(float)\n",
    "    sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    return yhat, scores\n",
    "\n",
    "# Build once (as you did)\n",
    "bld_tr = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "bld_te = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_test, name=label_name),\n",
    "                  pd.Series(A_test, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "\n",
    "# Search & pick the best by minimizing (DP + EO) with an accuracy floor\n",
    "best = None\n",
    "acc_floor = 0.86  # keep close to your current accuracy; adjust as you like\n",
    "results = []\n",
    "for w in ADV_GRID[\"adversary_loss_weight\"]:\n",
    "    for e in ADV_GRID[\"num_epochs\"]:\n",
    "        for bs in ADV_GRID[\"batch_size\"]:\n",
    "            for h in ADV_GRID[\"classifier_num_hidden_units\"]:\n",
    "                yhat, scores = run_adv(w, e, bs, h)\n",
    "                acc = accuracy_score(y_test, yhat)\n",
    "                dp, eo = fair_metrics(y_test, yhat, A_test, scores, absolute=True)\n",
    "                obj = dp + eo\n",
    "                results.append((obj, acc, dp, eo, w, e, bs, h, yhat, scores))\n",
    "                if (best is None or obj < best[0]) and acc >= acc_floor:\n",
    "                    best = (obj, acc, dp, eo, w, e, bs, h, yhat, scores)\n",
    "\n",
    "# Report best and (optionally) a few runners-up\n",
    "if best is None:\n",
    "    # fallback: take global best even if below floor\n",
    "    best = sorted(results, key=lambda t: t[0])[0]\n",
    "\n",
    "obj, acc, dp, eo, w, e, bs, h, yhat_best, scores_best = best\n",
    "_ = report_model(\n",
    "    f\"ADV in-proc (best) w={w}, e={e}, b={bs}, h={h}\",\n",
    "    y_test, yhat_best, A_test, scores=scores_best,\n",
    "    note=f\"combined gap (DP+EO)={obj:.4f}; acc={acc:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecba251",
   "metadata": {},
   "source": [
    "## ADV In-processing (tuned)\n",
    "\n",
    "### Results overview\n",
    "| Variant            | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|--------------------|---------:|--------:|------------------:|------:|\n",
    "| ADV in-proc (best) | 0.8641   | 0.4791  | 0.2083            | 0.6874 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### ADV in-proc (best, w=0.05, e=80, b=128, h=32)\n",
    "- **Selection rate:** 0 **0.158**, 1 **0.637** → DP gap **0.479** (very large).  \n",
    "- **TPR (Recall):** 0 **0.667**, 1 **0.875** → EO gap **0.208** (large, males recalled much better).  \n",
    "- **FPR:** 0 **0.063**, 1 **0.180** (males show much higher false positives).  \n",
    "- **Accuracy:** Female **0.895**, Male **0.856** → both groups perform reasonably, females slightly better.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **DP disparity is high (0.479)** — males are still much more likely to be selected.  \n",
    "- **EO disparity is also large (0.208)** — recall parity is not achieved, males benefit.  \n",
    "- **Accuracy (0.864)** is strong, but fairness metrics worsen compared to earlier tuned ADV runs.  \n",
    "- **Overall:** This ADV tuning favors accuracy but comes at the cost of both **DP** and **EO fairness**, leading to the **highest combined gap (≈0.687)** among ADV settings tested.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d7e49",
   "metadata": {},
   "source": [
    "# Overall Comparison of Bias Mitigation Results\n",
    "\n",
    "## Summary Table\n",
    "| Model | Best Variant | Accuracy | DP diff | EO diff | DP+EO | Key Trade-off |\n",
    "|-------|--------------|---------:|--------:|--------:|------:|---------------|\n",
    "| **KNN** | Pre: Reweigh | 0.8261 | **0.3590** | **0.0208** | **0.3798** | Modest accuracy drop, best fairness |\n",
    "| **DT**  | Post: EqOdds | 0.8152 | **0.2913** | 0.0938 | **0.3851** | Best DP+EO balance, small acc loss |\n",
    "| **RF**  | Baseline | 0.8424 | 0.4243 | **0.0312** | **0.4555** | Strong EO parity, but large DP gap |\n",
    "| **MLP** | Post: EqOdds | 0.7989 | **0.3133** | **0.0312** | **0.3445** | Largest fairness improvement, acc cost |\n",
    "| **ADV (untuned)** | Baseline ADV | 0.8424 | 0.4928 | 0.1979 | 0.6907 | Accuracy good, fairness worst |\n",
    "| **ADV (tuned)** | ADV best | 0.8641 | 0.4791 | 0.2083 | 0.6874 | Highest acc, but high disparities |\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Model Insights\n",
    "\n",
    "### 1. **Best Fairness Outcomes**\n",
    "- **MLP + Post: EqOdds** achieves the **lowest combined gap (DP+EO ≈ 0.345)**, drastically improving both DP and EO, though at the cost of accuracy (~0.799).  \n",
    "- **KNN + Pre: Reweigh** is the next most fair, nearly eliminating EO disparity and reducing DP while retaining accuracy above 0.82.  \n",
    "- **DT + Post: EqOdds** balances both DP and EO well, with the second-lowest combined disparity (~0.385).\n",
    "\n",
    "### 2. **Accuracy–Fairness Trade-offs**\n",
    "- **KNN** and **DT** show clear fairness gains with mitigation, but accuracy drops slightly compared to baseline.  \n",
    "- **RF** remains unchanged regardless of technique: baseline already has excellent EO (0.031) but suffers from a persistent DP gap (0.424).  \n",
    "- **MLP** sacrifices the most accuracy when fairness improves — post-processing reduces DP and EO dramatically but drops acc to ~0.80.  \n",
    "\n",
    "### 3. **ADV In-processing**\n",
    "- Both **untuned and tuned ADV** runs yield **high accuracy (0.842–0.864)** but perform poorly on fairness, with **DP ≈ 0.48–0.49** and **EO ≈ 0.20**.  \n",
    "- Earlier ADV configurations were stronger on EO, but these updated settings show worsened disparities.  \n",
    "- **Conclusion:** ADV in this configuration favors performance over fairness and is less effective than KNN/MLP mitigations.\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Takeaways\n",
    "- **Most fair approach overall:** **MLP with Post: Equalized Odds** (lowest DP+EO).  \n",
    "- **Best compromise (fairness + accuracy):** **KNN with Pre: Reweigh**, which improves both fairness metrics without heavily sacrificing accuracy.  \n",
    "- **Most stable model:** **RF baseline**, already strong in EO parity but resistant to fairness interventions.  \n",
    "- **Weakest fairness outcomes:** **ADV in-processing**, which increases disparities despite solid accuracy.  \n",
    "\n",
    "### Overall Observation\n",
    "- **Pre-processing (Reweighing)** generally helps **KNN** and slightly improves fairness in **MLP**, but worsens DT.  \n",
    "- **Post-processing (EqOdds)** is highly effective for **MLP** and **DT**, but ineffective for **KNN** and **RF**.  \n",
    "- **ADV** in this setup is not competitive with the other strategies in terms of fairness.  \n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
