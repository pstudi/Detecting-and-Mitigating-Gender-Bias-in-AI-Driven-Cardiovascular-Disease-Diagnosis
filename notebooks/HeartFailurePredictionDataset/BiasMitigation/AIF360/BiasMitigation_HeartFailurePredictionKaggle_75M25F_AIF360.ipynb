{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## Bias Mitigation using AIF360 - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   61    1              3      146.0        241.0          0           0   \n",
       "1   52    1              1      120.0        284.0          0           0   \n",
       "2   48    0              3      150.0        227.0          0           0   \n",
       "3   49    1              3      128.0        212.0          0           0   \n",
       "4   56    1              3      120.0        236.0          0           1   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  148.0               1      3.0         0             1  \n",
       "1  118.0               0      0.0         2             0  \n",
       "2  130.0               1      1.0         1             0  \n",
       "3   96.0               1      0.0         1             1  \n",
       "4  148.0               0      0.0         1             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2fe70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e79e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01e449c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sensitive attribute arrays - after creating X_train_ready and X_test_ready\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()  # 1=Male, 0=Female\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### PCA-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 12 | Explained variance retained: 0.967\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8858695652173914\n",
      "Precision: 0.9090909090909091\n",
      "Recall   : 0.8823529411764706\n",
      "F1 Score : 0.8955223880597015\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        82\n",
      "           1       0.91      0.88      0.90       102\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.88      0.89      0.88       184\n",
      "weighted avg       0.89      0.89      0.89       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [12 90]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best CV F1: 0.8593494246061409\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.8097826086956522\n",
      "Precision: 0.819047619047619\n",
      "Recall   : 0.8431372549019608\n",
      "F1 Score : 0.8309178743961353\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78        82\n",
      "           1       0.82      0.84      0.83       102\n",
      "\n",
      "    accuracy                           0.81       184\n",
      "   macro avg       0.81      0.81      0.81       184\n",
      "weighted avg       0.81      0.81      0.81       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[63 19]\n",
      " [16 86]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.8804347826086957\n",
      "Precision: 0.8703703703703703\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8952380952380953\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        82\n",
      "           1       0.87      0.92      0.90       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Adam MLP + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8586956521739131\n",
      "Precision: 0.8877551020408163\n",
      "Recall   : 0.8529411764705882\n",
      "F1 Score : 0.87\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        82\n",
      "           1       0.89      0.85      0.87       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [15 87]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762eb02",
   "metadata": {},
   "source": [
    "### Bias Mitigation AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e771c25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aif360 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\patri\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aif360) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aif360) (1.16.0)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aif360) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aif360) (1.7.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aif360) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24.0->aif360) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=0.24.0->aif360) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0->aif360) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn>=1.0->aif360) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (4.55.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\patri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib->aif360) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Setup: install AIF360\n",
    "# Uncomment the next line if running locally for the first time\n",
    "!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de3c1689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIF360 version: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "import aif360\n",
    "print(\"AIF360 version:\", aif360.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f648d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "from IPython.display import display \n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Config \n",
    "protected_attr = \"Sex\"  # 1=Male, 0=Female\n",
    "PRIV_VALUE = 1          # privileged = Male\n",
    "label_name = \"label\"\n",
    "favorable_label, unfavorable_label = 1, 0\n",
    "privileged_groups   = [{protected_attr: PRIV_VALUE}]\n",
    "unprivileged_groups = [{protected_attr: 1 - PRIV_VALUE}]\n",
    "\n",
    "# Ensure 1-D ints for targets\n",
    "y_train = np.asarray(y_train).astype(int).ravel()\n",
    "y_test  = np.asarray(y_test).astype(int).ravel()\n",
    "\n",
    "# Sensitive attribute arrays\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "\n",
    "def _to_bld(y, A):\n",
    "    y = (y.values if hasattr(y,'values') else np.asarray(y)).ravel()\n",
    "    A = (A.values if hasattr(A,'values') else np.asarray(A)).ravel()\n",
    "    df = pd.DataFrame({\"dummy\": np.zeros(len(y)), label_name: y, protected_attr: A})\n",
    "    return BinaryLabelDataset(df=df,\n",
    "                              label_names=[label_name],\n",
    "                              protected_attribute_names=[protected_attr],\n",
    "                              favorable_label=favorable_label,\n",
    "                              unfavorable_label=unfavorable_label)\n",
    "\n",
    "def fair_metrics(y_true, y_pred, A, y_scores=None, absolute=True):\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    if y_scores is not None:\n",
    "        p.scores = np.asarray(y_scores).reshape(-1,1)\n",
    "    cm = ClassificationMetric(t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups)\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.equal_opportunity_difference()\n",
    "    return (abs(dp), abs(eo)) if absolute else (dp, eo)\n",
    "\n",
    "def get_scores(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[:,1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        z = model.decision_function(X)\n",
    "        return (z - z.min())/(z.max()-z.min()+1e-12)\n",
    "    return model.predict(X).astype(float)\n",
    "\n",
    "def selection_rate(y_pred, positive=1):\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    return np.mean(y_pred == positive)\n",
    "\n",
    "def per_group_table(y_true, y_pred, A, positive=1, group_name=\"Sex\"):\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    A = np.asarray(A).ravel()\n",
    "    rows = []\n",
    "    for g in np.unique(A):\n",
    "        idx = (A == g)\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        # tn, fp, fn, tp with fixed label order [0,1]\n",
    "        tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0,1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "        rec = recall_score(yt, yp, pos_label=positive)   # equals TPR for binary\n",
    "        sr  = selection_rate(yp, positive=positive)\n",
    "        acc = accuracy_score(yt, yp)\n",
    "        rows.append({group_name: g, \"TPR\": tpr, \"FPR\": fpr,\n",
    "                     \"Recall\": rec, \"SelectionRate\": sr, \"Accuracy\": acc})\n",
    "    return pd.DataFrame(rows).set_index(group_name)\n",
    "\n",
    "def aif_diffs(y_true, y_pred, A, *, abs_vals=True):\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    cm = ClassificationMetric(t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups)\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.average_odds_difference()   # Equalized odds gap (avg of TPR/FPR diffs)\n",
    "    if abs_vals:\n",
    "        dp, eo = abs(dp), abs(eo)\n",
    "    return dp, eo\n",
    "\n",
    "def print_row(title, acc, dp, eo, note=\"\"):\n",
    "    print(f\"{title:>24s} | Acc {acc:.4f} | DP {dp:.4f} | EO {eo:.4f} {('|' if note else '')} {note}\")\n",
    "\n",
    "#to print a model cleanly\n",
    "def report_model(name, y_true, y_pred, A, scores=None, note=\"\"):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    dp, eo = fair_metrics(y_true, y_pred, A, y_scores=scores, absolute=True)\n",
    "    tbl = per_group_table(y_true, y_pred, A, positive=favorable_label, group_name=\"Sex\").round(6)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    display(tbl)\n",
    "    print(f\"Overall -> Accuracy: {acc:.4f} | DP diff: {dp:.4f} | EO diff: {eo:.4f}\"\n",
    "          + (f\" | {note}\" if note else \"\"))\n",
    "    \n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"DP diff\": dp, \"EO diff\": eo}\n",
    "\n",
    "\n",
    "# Pre: compute reweighing weights ONCE on TRAIN\n",
    "_bld_train = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name],\n",
    "    protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label,\n",
    "    unfavorable_label=unfavorable_label\n",
    ")\n",
    "_rw = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                 privileged_groups=privileged_groups).fit(_bld_train)\n",
    "_rw_weights = _rw.transform(_bld_train).instance_weights.ravel()\n",
    "\n",
    "# Turn weights into a resampled training set\n",
    "def resample_by_weights(X, y, A, weights, n_samples=None, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    Xn = np.asarray(X); yn = np.asarray(y).ravel(); An = np.asarray(A).ravel()\n",
    "    w = np.clip(np.asarray(weights, dtype=float), 1e-12, None)\n",
    "    p = w / w.sum()\n",
    "    n = n_samples or len(yn)\n",
    "    idx = rng.choice(len(yn), size=n, replace=True, p=p)\n",
    "    return Xn[idx], yn[idx], An[idx]\n",
    "\n",
    "Xrw, yrw, Arw = resample_by_weights(X_train_ready, y_train, A_train, _rw_weights,\n",
    "                                    n_samples=len(y_train), random_state=42)\n",
    "\n",
    "# Post: make a small TRAIN-based calibration split (no test leakage)\n",
    "trn_X, cal_X, trn_y, cal_y, trn_A, cal_A = train_test_split(\n",
    "    X_train_ready, y_train, A_train, test_size=0.12, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "#Make types consistent to avoid the PCA warning \n",
    "X_test_np = np.asarray(X_test_ready)\n",
    "trn_X_np  = np.asarray(trn_X)\n",
    "cal_X_np  = np.asarray(cal_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a80769d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9616d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KNN baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.000000  0.125  1.000000       0.263158  0.894737\n",
       "1    0.885417  0.100  0.885417       0.616438  0.890411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8913 | DP diff: 0.3533 | EO diff: 0.1146\n",
      "\n",
      "=== KNN pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TPR      FPR   Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.00000  0.09375  1.00000       0.236842  0.921053\n",
       "1    0.84375  0.14000  0.84375       0.602740  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8641 | DP diff: 0.3659 | EO diff: 0.1562 | resampled by AIF360 weights\n",
      "\n",
      "=== KNN post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.000000  0.125  1.000000       0.263158  0.894737\n",
       "1    0.916667  0.340  0.916667       0.719178  0.828767"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4560 | EO diff: 0.0833 | calibrated on held-out TRAIN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>DP diff</th>\n",
       "      <th>EO diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN baseline</th>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.3533</td>\n",
       "      <td>0.1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN pre: Reweigh</th>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN post: EqOdds</th>\n",
       "      <td>0.8424</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.0833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accuracy  DP diff  EO diff\n",
       "Model                                       \n",
       "KNN baseline        0.8913   0.3533   0.1146\n",
       "KNN pre: Reweigh    0.8641   0.3659   0.1562\n",
       "KNN post: EqOdds    0.8424   0.4560   0.0833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline\n",
    "knn_base = clone(pca_knn).fit(trn_X, trn_y)\n",
    "yhat_base   = knn_base.predict(X_test_np)\n",
    "scores_base = get_scores(knn_base, X_test_np)\n",
    "summ_base = report_model(\"KNN baseline\", y_test, yhat_base, A_test, scores=scores_base)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "knn_pre     = clone(pca_knn).fit(Xrw, yrw)\n",
    "yhat_pre    = knn_pre.predict(X_test_np)\n",
    "scores_pre  = get_scores(knn_pre, X_test_np)\n",
    "summ_pre = report_model(\"KNN pre: Reweigh\", y_test, yhat_pre, A_test, scores=scores_pre,\n",
    "                        note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores  = get_scores(knn_base, cal_X_np)\n",
    "post = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                            unprivileged_groups=unprivileged_groups)\n",
    "post.fit(_to_bld(cal_y, cal_A),\n",
    "         _to_bld((cal_scores >= 0.5).astype(int), cal_A))\n",
    "\n",
    "pred_post_bld = post.predict(_to_bld((scores_base >= 0.5).astype(int), A_test))\n",
    "yhat_post     = pred_post_bld.labels.ravel().astype(int)\n",
    "\n",
    "summ_post = report_model(\"KNN post: EqOdds\", y_test, yhat_post, A_test, scores=scores_base,\n",
    "                         note=\"calibrated on held-out TRAIN\")\n",
    "\n",
    "# Compact summary across models \n",
    "summary_df = pd.DataFrame([summ_base, summ_pre, summ_post]).set_index(\"Model\")\n",
    "display(summary_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a07aaa0",
   "metadata": {},
   "source": [
    "# KNN + AIF360 \n",
    "Sex: 0 = Female (unprivileged), 1 = Male (privileged)\n",
    "\n",
    "## Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) |\n",
    "|---------------------|---------:|--------:|-------------------:|\n",
    "| Baseline            | 0.8913   | 0.3533  | 0.1146 |\n",
    "| Pre: Reweigh        | 0.8641   | 0.3659  | 0.1562 |\n",
    "| Post: EqualizedOdds | 0.8207   | 0.4560  | 0.1042 |\n",
    "\n",
    "---\n",
    "\n",
    "## Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "### Baseline\n",
    "- **Selection rate:** Female **0.263** vs Male **0.616** → large DP gap (males flagged ≈ 2.3× more often).\n",
    "- **TPR (Recall):** Female **1.000** vs Male **0.885** → model misses more **male** CVD cases.\n",
    "- **FPR:** Female 0.125 vs Male 0.100.\n",
    "- **Takeaway:** Highest accuracy, **large DP disparity**; moderate EO gap, with **higher miss rate for men**.\n",
    "\n",
    "### Pre-processing: Reweigh\n",
    "- Accuracy ↓ to **0.864**; **DP** slightly worse (**0.366**), **EO** worse (**0.156**).\n",
    "- **TPR:** Female 1.000 (unchanged) vs Male **0.844** (down).  \n",
    "- **FPR:** Female 0.094 vs Male 0.140 (up).\n",
    "- **Takeaway:** For KNN, this resampling did **not improve fairness** and hurt performance—more missed **male** cases.\n",
    "\n",
    "### Post-processing: Equalized Odds\n",
    "- Accuracy ↓ to **0.821**; **EO** best (**0.104**, smaller TPR gap), but **DP** worst (**0.456**).\n",
    "- **TPR:** Female 1.000 vs Male **0.896** (gap narrowed).  \n",
    "- **FPR:** Female 0.125 vs Male **0.380** (big jump), **Selection rate** Male **0.719** (↑).\n",
    "- **Takeaway:** Achieves better **TPR parity** (fewer relative male misses) but at the cost of **many more false positives in men** and larger DP gap.\n",
    "\n",
    "---\n",
    "\n",
    "## Implications\n",
    "- None of the KNN variants simultaneously achieves small recall and selection disparities.\n",
    "- **Post: EqOdds** narrows the recall gap (**EO ≈ 0.10**) but at the cost of a much larger selection gap (**DP ≈ 0.46**) and the lowest accuracy.\n",
    "- **Baseline** delivers the highest accuracy and a smaller DP than EqOdds (**≈ 0.35**), but retains a noticeable recall gap (**EO ≈ 0.11**); male recall is lower than female.\n",
    "- **Pre: Reweigh** provides no fairness benefit for KNN (DP **≈ 0.37**, EO **≈ 0.16**) and reduces accuracy—indicative that resampling is a poor match for this model.\n",
    "\n",
    "\n",
    "For the KNN runs, **Baseline is the most balanced choice overall** —it has the lowest combined disparity (DP+EO ≈ 0.468, vs. Reweigh ≈ 0.522 and EqOdds ≈ 0.560) while keeping the highest accuracy, whereas EqOdds trims EO slightly but inflates DP and false positives in men.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c64ab072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DT baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.554795</td>\n",
       "      <td>0.773973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.21875  0.833333       0.315789  0.789474\n",
       "1    0.750000  0.18000  0.750000       0.554795  0.773973"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.7772 | DP diff: 0.2390 | EO diff: 0.0833\n",
      "\n",
      "=== DT pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR   FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                   \n",
       "0    1.000000  0.25  1.000000       0.368421  0.789474\n",
       "1    0.802083  0.16  0.802083       0.582192  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8098 | DP diff: 0.2138 | EO diff: 0.1979 | resampled by AIF360 weights\n",
      "\n",
      "=== DT post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.18000</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.589041</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.500000  0.21875  0.500000       0.263158  0.736842\n",
       "1    0.802083  0.18000  0.802083       0.589041  0.808219"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.7935 | DP diff: 0.3259 | EO diff: 0.3021 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree (DT)\n",
    "# Baseline\n",
    "dt_base = clone(tuned_dt).fit(trn_X_np, trn_y)\n",
    "yhat_dt = dt_base.predict(X_test_np)\n",
    "scores_dt = get_scores(dt_base, X_test_np)\n",
    "_ = report_model(\"DT baseline\", y_test, yhat_dt, A_test, scores=scores_dt)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "dt_pre = clone(tuned_dt).fit(Xrw, yrw)\n",
    "yhat_dt_pre = dt_pre.predict(X_test_np)\n",
    "scores_dt_pre = get_scores(dt_pre, X_test_np)\n",
    "_ = report_model(\"DT pre: Reweigh\", y_test, yhat_dt_pre, A_test, scores=scores_dt_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_dt = get_scores(dt_base, cal_X_np)\n",
    "post_dt = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_dt.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_dt >= 0.5).astype(int), cal_A))\n",
    "yhat_dt_post = post_dt.predict(_to_bld((scores_dt >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"DT post: EqOdds\", y_test, yhat_dt_post, A_test, scores=scores_dt,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e46588",
   "metadata": {},
   "source": [
    "## DT + AIF360 \n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) |\n",
    "|---------------------|---------:|--------:|-------------------:|\n",
    "| Baseline            | 0.7772   | 0.2390  | 0.0833 |\n",
    "| Pre: Reweigh        | 0.8098   | 0.2138  | 0.1979 |\n",
    "| Post: EqualizedOdds | 0.7935   | 0.3259  | 0.3021 |\n",
    "\n",
    "## Per-group reading\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** Female **0.316** vs Male **0.555** → noticeable DP gap.\n",
    "- **TPR (Recall):** Female **0.833** vs Male **0.750** → males are missed more often.\n",
    "- **FPR:** Female **0.219** vs Male **0.180**.\n",
    "- **Interpretation:** Moderate accuracy; moderate selection disparity; small recall gap favoring females.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Accuracy** improves to **0.810**.\n",
    "- **DP diff** improves slightly (**0.214**, smaller selection gap than baseline).\n",
    "- **EO diff** worsens (**0.198**): Female TPR **1.000** vs Male **0.802** → larger recall gap.\n",
    "- **FPR** rises for females (**0.25**) and falls for males (**0.16**).\n",
    "- **Interpretation:** Reweigh shifts the model to favor positives for females (higher TPR and SR), marginally reducing DP but **widening the recall gap**.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Accuracy** **0.794**.\n",
    "- **EO diff** becomes **worst** (**0.302**): Female TPR drops to **0.500** vs Male **0.802**.\n",
    "- **DP diff** also **worsens** (**0.326**): SR Female **0.263** vs Male **0.589**.\n",
    "- **FPR** stays close to baseline (Female **0.219**, Male **0.180**).\n",
    "- **Interpretation:** This run of EqOdds pushes recall down for females without reducing selection disparity—both fairness gaps increase relative to baseline.\n",
    "\n",
    "#### Implications\n",
    "- **Pre: Reweigh** is the only setting with **higher accuracy** and **slightly smaller DP** than baseline, but it **increases the recall gap**.\n",
    "- **Baseline** keeps the **smallest recall gap** of the three (EO ≈ **0.08**) with moderate DP (≈ **0.24**).\n",
    "- **Post: EqOdds** performs **worst** on both EO and DP here; not advisable with this DT configuration.\n",
    "\n",
    "For the DT runs, **Baseline is the fairest overall** —it has the smallest EO gap (0.0833) and only a slightly higher DP than Reweigh, yielding the lowest combined (DP+EO) disparity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a886023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RF baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    0.833333  0.125  0.833333       0.236842  0.868421\n",
       "1    0.895833  0.200  0.895833       0.657534  0.863014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8641 | DP diff: 0.4207 | EO diff: 0.0625\n",
      "\n",
      "=== RF pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.90625</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.869863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TPR      FPR   Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.00000  0.15625  1.00000       0.289474  0.868421\n",
       "1    0.90625  0.20000  0.90625       0.664384  0.869863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8696 | DP diff: 0.3749 | EO diff: 0.0938 | resampled by AIF360 weights\n",
      "\n",
      "=== RF post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR     FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                     \n",
       "0    0.666667  0.1875  0.666667       0.263158  0.789474\n",
       "1    0.916667  0.2600  0.916667       0.691781  0.856164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8424 | DP diff: 0.4286 | EO diff: 0.2500 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RF) \n",
    "# Baseline\n",
    "rf_base = clone(rf).fit(trn_X_np, trn_y)\n",
    "yhat_rf = rf_base.predict(X_test_np)\n",
    "scores_rf = get_scores(rf_base, X_test_np)\n",
    "_ = report_model(\"RF baseline\", y_test, yhat_rf, A_test, scores=scores_rf)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "rf_pre = clone(rf).fit(Xrw, yrw)\n",
    "yhat_rf_pre = rf_pre.predict(X_test_np)\n",
    "scores_rf_pre = get_scores(rf_pre, X_test_np)\n",
    "_ = report_model(\"RF pre: Reweigh\", y_test, yhat_rf_pre, A_test, scores=scores_rf_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_rf = get_scores(rf_base, cal_X_np)\n",
    "post_rf = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_rf.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_rf >= 0.5).astype(int), cal_A))\n",
    "yhat_rf_post = post_rf.predict(_to_bld((scores_rf >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"RF post: EqOdds\", y_test, yhat_rf_post, A_test, scores=scores_rf,\n",
    "                 note=\"calibrated on held-out TRAIN\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601db22",
   "metadata": {},
   "source": [
    "# RF + AIF360  \n",
    "\n",
    "\n",
    "## Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) |\n",
    "|---------------------|---------:|--------:|-------------------:|\n",
    "| Baseline            | 0.8641   | 0.4207  | 0.0625 |\n",
    "| Pre: Reweigh        | 0.8696   | 0.3749  | 0.0938 |\n",
    "| Post: EqualizedOdds | 0.8207   | 0.4286  | 0.2292 |\n",
    "\n",
    "---\n",
    "\n",
    "## Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "### Baseline\n",
    "- **Selection rate:** Female **0.237** vs Male **0.658** → large DP gap.\n",
    "- **TPR (Recall):** Female **0.833** vs Male **0.896** → small recall gap.\n",
    "- **FPR:** Female **0.125** vs Male **0.200**.\n",
    "- **Takeaway:** Good accuracy, **big selection disparity**, **small recall gap**.\n",
    "\n",
    "### Pre-processing: Reweigh\n",
    "- **Accuracy** highest (**0.8696**).\n",
    "- **DP diff** improves to **0.3749** (narrower selection gap: Female SR **0.289**, Male **0.664**).\n",
    "- **EO diff** worsens slightly to **0.0938** (Female TPR **1.000**, Male **0.906**).\n",
    "- **FPR:** Female **0.156**, Male **0.200**.\n",
    "- **Takeaway:** Mild DP improvement with small EO degradation; overall the **best combined fairness–accuracy** trade-off among the three.\n",
    "\n",
    "### Post-processing: Equalized Odds\n",
    "- **Accuracy** drops to **0.8207**.\n",
    "- **EO diff** becomes **worst** (**0.2292**) due to lower Female TPR (**0.667**) vs Male (**0.896**).\n",
    "- **DP diff** slightly **worse** than baseline (**0.4286**); Male SR stays high (**0.692**).\n",
    "- **FPR** increases for both groups (Female **0.188**, Male **0.300**).\n",
    "- **Takeaway:** Fails to reduce selection disparity and **widens the recall gap**; not helpful here.\n",
    "\n",
    "---\n",
    "\n",
    "## Implications\n",
    "- **Most fair RF setting overall: _Pre: Reweigh_.** It delivers the **highest accuracy** and the **lowest combined disparity** (DP+EO ≈ **0.4687**) compared with Baseline (≈ **0.4832**) and EqOdds (≈ **0.6578**); DP improves while EO remains reasonably small.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f76d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MLP baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.09375  1.000000       0.236842  0.921053\n",
       "1    0.895833  0.20000  0.895833       0.657534  0.863014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8750 | DP diff: 0.4207 | EO diff: 0.1042\n",
      "\n",
      "=== MLP pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.15625  1.000000       0.289474  0.868421\n",
       "1    0.885417  0.20000  0.885417       0.650685  0.856164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8587 | DP diff: 0.3612 | EO diff: 0.1146 | resampled by AIF360 weights\n",
      "\n",
      "=== MLP post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.22000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.09375  1.000000       0.236842  0.921053\n",
       "1    0.895833  0.22000  0.895833       0.664384  0.856164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8696 | DP diff: 0.4275 | EO diff: 0.1042 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "# === MLP ===\n",
    "# Baseline\n",
    "mlp_base = clone(adammlp).fit(trn_X_np, trn_y)\n",
    "yhat_mlp = mlp_base.predict(X_test_np)\n",
    "scores_mlp = get_scores(mlp_base, X_test_np)  # works with predict_proba or decision_function\n",
    "_ = report_model(\"MLP baseline\", y_test, yhat_mlp, A_test, scores=scores_mlp)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "mlp_pre = clone(adammlp).fit(Xrw, yrw)\n",
    "yhat_mlp_pre = mlp_pre.predict(X_test_np)\n",
    "scores_mlp_pre = get_scores(mlp_pre, X_test_np)\n",
    "_ = report_model(\"MLP pre: Reweigh\", y_test, yhat_mlp_pre, A_test, scores=scores_mlp_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_mlp = get_scores(mlp_base, cal_X_np)\n",
    "post_mlp = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups)\n",
    "post_mlp.fit(_to_bld(cal_y, cal_A),\n",
    "             _to_bld((cal_scores_mlp >= 0.5).astype(int), cal_A))\n",
    "yhat_mlp_post = post_mlp.predict(_to_bld((scores_mlp >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"MLP post: EqOdds\", y_test, yhat_mlp_post, A_test, scores=scores_mlp,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a68efc",
   "metadata": {},
   "source": [
    "# MLP + AIF360  \n",
    "\n",
    "## Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) |\n",
    "|---------------------|---------:|--------:|-------------------:|\n",
    "| Baseline            | 0.8750   | 0.4207  | 0.1042 |\n",
    "| Pre: Reweigh        | 0.8587   | 0.3612  | 0.1146 |\n",
    "| Post: EqualizedOdds | 0.8696   | 0.4275  | 0.1042 |\n",
    "\n",
    "---\n",
    "\n",
    "## Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "### Baseline\n",
    "- **Selection rate:** Female **0.237** vs Male **0.658** → large DP gap.\n",
    "- **TPR (Recall):** Female **1.000** vs Male **0.896** → small recall gap.\n",
    "- **FPR:** Female **0.094** vs Male **0.200**.\n",
    "- **Takeaway:** Highest accuracy; **big selection disparity**, **small recall gap**.\n",
    "\n",
    "### Pre-processing: Reweigh\n",
    "- **Accuracy** ↓ to **0.8587**.\n",
    "- **DP diff** improves to **0.3612** (Female SR **0.289**, Male **0.651**).\n",
    "- **EO diff** slightly worse (**0.1146**): Female TPR **1.000**, Male **0.885**.\n",
    "- **FPR:** Female **0.156** (↑), Male **0.200** (≈).\n",
    "- **Takeaway:** Best **DP** among the three with a small EO trade-off.\n",
    "\n",
    "### Post-processing: Equalized Odds\n",
    "- **Accuracy** **0.8696**.\n",
    "- **EO diff** ties baseline (**0.1042**) but **DP diff** worsens (**0.4275**).\n",
    "- **Per-group shifts:** Male **FPR** rises to **0.220** and **SR** to **0.664**; female metrics unchanged vs baseline.\n",
    "- **Takeaway:** Does not reduce selection disparity; minor EO benefit vs Pre only.\n",
    "\n",
    "---\n",
    "\n",
    "## Implications\n",
    "- **Most fair MLP setting overall: _Pre: Reweigh_.** It yields the **lowest combined disparity** (DP+EO ≈ **0.476**) vs Baseline (**≈ 0.525**) and EqOdds (**≈ 0.532**), with only a modest accuracy drop; Baseline is best for accuracy but has the largest DP, and EqOdds doesn’t improve DP while slightly increasing male false positives.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce511e42",
   "metadata": {},
   "source": [
    "First fairness mitigation: pre- and post-processing was performed on the designated best performing models (KNN, DT, RF, MLP) for CVD prediction.  In addition, these results are compared to a fairness-aware in-processing model - Adversarial Debiasing offered by AIF360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66355777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.709457; batch adversarial loss: 0.728360\n",
      "epoch 1; iter: 0; batch classifier loss: 0.654361; batch adversarial loss: 0.728184\n",
      "epoch 2; iter: 0; batch classifier loss: 0.600049; batch adversarial loss: 0.723977\n",
      "epoch 3; iter: 0; batch classifier loss: 0.553579; batch adversarial loss: 0.711474\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570828; batch adversarial loss: 0.724947\n",
      "epoch 5; iter: 0; batch classifier loss: 0.513129; batch adversarial loss: 0.717555\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535557; batch adversarial loss: 0.732722\n",
      "epoch 7; iter: 0; batch classifier loss: 0.434486; batch adversarial loss: 0.699306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.571101; batch adversarial loss: 0.733840\n",
      "epoch 9; iter: 0; batch classifier loss: 0.436359; batch adversarial loss: 0.702101\n",
      "epoch 10; iter: 0; batch classifier loss: 0.441133; batch adversarial loss: 0.694747\n",
      "epoch 11; iter: 0; batch classifier loss: 0.550509; batch adversarial loss: 0.734508\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515709; batch adversarial loss: 0.704008\n",
      "epoch 13; iter: 0; batch classifier loss: 0.521162; batch adversarial loss: 0.694060\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510998; batch adversarial loss: 0.714025\n",
      "epoch 15; iter: 0; batch classifier loss: 0.437557; batch adversarial loss: 0.679512\n",
      "epoch 16; iter: 0; batch classifier loss: 0.437881; batch adversarial loss: 0.687566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.523437; batch adversarial loss: 0.723605\n",
      "epoch 18; iter: 0; batch classifier loss: 0.448415; batch adversarial loss: 0.658031\n",
      "epoch 19; iter: 0; batch classifier loss: 0.418243; batch adversarial loss: 0.675264\n",
      "epoch 20; iter: 0; batch classifier loss: 0.352517; batch adversarial loss: 0.661632\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392078; batch adversarial loss: 0.669901\n",
      "epoch 22; iter: 0; batch classifier loss: 0.504909; batch adversarial loss: 0.693783\n",
      "epoch 23; iter: 0; batch classifier loss: 0.434843; batch adversarial loss: 0.666693\n",
      "epoch 24; iter: 0; batch classifier loss: 0.427447; batch adversarial loss: 0.663933\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424031; batch adversarial loss: 0.689201\n",
      "epoch 26; iter: 0; batch classifier loss: 0.434818; batch adversarial loss: 0.690080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.482410; batch adversarial loss: 0.705046\n",
      "epoch 28; iter: 0; batch classifier loss: 0.472215; batch adversarial loss: 0.665194\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407795; batch adversarial loss: 0.668281\n",
      "epoch 30; iter: 0; batch classifier loss: 0.463262; batch adversarial loss: 0.686768\n",
      "epoch 31; iter: 0; batch classifier loss: 0.464523; batch adversarial loss: 0.657361\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421708; batch adversarial loss: 0.663152\n",
      "epoch 33; iter: 0; batch classifier loss: 0.426202; batch adversarial loss: 0.654718\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391167; batch adversarial loss: 0.647838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.423639; batch adversarial loss: 0.660298\n",
      "epoch 36; iter: 0; batch classifier loss: 0.388863; batch adversarial loss: 0.653218\n",
      "epoch 37; iter: 0; batch classifier loss: 0.445456; batch adversarial loss: 0.684768\n",
      "epoch 38; iter: 0; batch classifier loss: 0.475129; batch adversarial loss: 0.668365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467006; batch adversarial loss: 0.667765\n",
      "epoch 40; iter: 0; batch classifier loss: 0.417973; batch adversarial loss: 0.648537\n",
      "epoch 41; iter: 0; batch classifier loss: 0.410966; batch adversarial loss: 0.663138\n",
      "epoch 42; iter: 0; batch classifier loss: 0.412073; batch adversarial loss: 0.644170\n",
      "epoch 43; iter: 0; batch classifier loss: 0.325814; batch adversarial loss: 0.615672\n",
      "epoch 44; iter: 0; batch classifier loss: 0.400184; batch adversarial loss: 0.667481\n",
      "epoch 45; iter: 0; batch classifier loss: 0.424683; batch adversarial loss: 0.636669\n",
      "epoch 46; iter: 0; batch classifier loss: 0.383933; batch adversarial loss: 0.651294\n",
      "epoch 47; iter: 0; batch classifier loss: 0.356919; batch adversarial loss: 0.627070\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429313; batch adversarial loss: 0.623950\n",
      "epoch 49; iter: 0; batch classifier loss: 0.378708; batch adversarial loss: 0.651388\n",
      "\n",
      "=== ADV in-proc (AIF360) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.03125</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.28000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TPR      FPR  Recall  SelectionRate  Accuracy\n",
       "Sex                                                  \n",
       "0    1.0000  0.03125  1.0000       0.184211  0.973684\n",
       "1    0.9375  0.28000  0.9375       0.712329  0.863014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8859 | DP diff: 0.5281 | EO diff: 0.0625 | trained on X_train_ready\n"
     ]
    }
   ],
   "source": [
    "#Adversarial Debiasing - In-processing by AIF360\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "    # TF1 graph mode - required by AIF360's implementation \n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "    # Build AIF360 datasets with FEATURES + label + sensitive attribute\n",
    "    bld_tr = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "            pd.Series(y_train, name=label_name),\n",
    "            pd.Series(A_train, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    bld_te = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "            pd.Series(y_test, name=label_name),\n",
    "            pd.Series(A_test, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    # Train + predict inside a TF1 session\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            scope_name=\"adv_debias\",\n",
    "            debias=True,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "\n",
    "        # Extract labels and (if available) scores\n",
    "        yhat_adv = pred_te.labels.ravel().astype(int)\n",
    "        scores_adv = getattr(pred_te, \"scores\", None)\n",
    "        if scores_adv is None:\n",
    "            scores_adv = yhat_adv.astype(float)\n",
    "\n",
    "    # Clean up TF graph\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sess.close()\n",
    "\n",
    "    # Same structured output as other models\n",
    "    _ = report_model(\n",
    "        \"ADV in-proc (AIF360)\",\n",
    "        y_test, yhat_adv, A_test,\n",
    "        scores=scores_adv,\n",
    "        note=\"trained on X_train_ready\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"AdversarialDebiasing skipped:\", type(e).__name__, e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2475ce",
   "metadata": {},
   "source": [
    "# Adversarial Debiasing (AIF360, in-processing)  \n",
    "\n",
    "## Results overview\n",
    "| Variant                       | Accuracy | DP diff | EO diff (TPR gap) |\n",
    "|-------------------------------|---------:|--------:|-------------------:|\n",
    "| ADV in-proc (current run)     | 0.8859   | 0.5281  | 0.0625 |\n",
    "\n",
    "## Per-group reading (Female → 0, Male → 1)\n",
    "- **Selection rate:** Female **0.184** vs Male **0.712** → **very large DP gap** (≈ 0.53).\n",
    "- **TPR (Recall):** Female **1.000** vs Male **0.938** → **small recall gap** (EO ≈ 0.063).\n",
    "- **FPR:** Female **0.031** vs Male **0.280** → many more **male false positives**, explaining the high male selection rate.\n",
    "- **Takeaway:** The adversary largely equalizes **recall** but at the cost of **inflated selection for men** (high DP) and higher male FPR.\n",
    "\n",
    "## Recommendation in one line\n",
    "This run is **good for recall parity** but **not acceptable on DP**; tune the adversary strength and/or apply a light **DP-oriented thresholding** after training to bring selection rates closer without losing the EO gain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a673e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.718607; batch adversarial loss: 0.667484\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641073; batch adversarial loss: 0.700037\n",
      "epoch 2; iter: 0; batch classifier loss: 0.629968; batch adversarial loss: 0.701720\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652680; batch adversarial loss: 0.666489\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528588; batch adversarial loss: 0.688654\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515349; batch adversarial loss: 0.618595\n",
      "epoch 6; iter: 0; batch classifier loss: 0.554970; batch adversarial loss: 0.670759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539512; batch adversarial loss: 0.652075\n",
      "epoch 8; iter: 0; batch classifier loss: 0.517960; batch adversarial loss: 0.624316\n",
      "epoch 9; iter: 0; batch classifier loss: 0.460147; batch adversarial loss: 0.664290\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475542; batch adversarial loss: 0.638117\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512593; batch adversarial loss: 0.578195\n",
      "epoch 12; iter: 0; batch classifier loss: 0.478435; batch adversarial loss: 0.655963\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467671; batch adversarial loss: 0.643519\n",
      "epoch 14; iter: 0; batch classifier loss: 0.482466; batch adversarial loss: 0.700331\n",
      "epoch 15; iter: 0; batch classifier loss: 0.376340; batch adversarial loss: 0.645496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.430725; batch adversarial loss: 0.626082\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476864; batch adversarial loss: 0.644521\n",
      "epoch 18; iter: 0; batch classifier loss: 0.342896; batch adversarial loss: 0.625626\n",
      "epoch 19; iter: 0; batch classifier loss: 0.345015; batch adversarial loss: 0.661811\n",
      "epoch 20; iter: 0; batch classifier loss: 0.416488; batch adversarial loss: 0.643193\n",
      "epoch 21; iter: 0; batch classifier loss: 0.410144; batch adversarial loss: 0.657905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333342; batch adversarial loss: 0.685022\n",
      "epoch 23; iter: 0; batch classifier loss: 0.343139; batch adversarial loss: 0.628499\n",
      "epoch 24; iter: 0; batch classifier loss: 0.424242; batch adversarial loss: 0.646302\n",
      "epoch 25; iter: 0; batch classifier loss: 0.302362; batch adversarial loss: 0.667026\n",
      "epoch 26; iter: 0; batch classifier loss: 0.306911; batch adversarial loss: 0.614426\n",
      "epoch 27; iter: 0; batch classifier loss: 0.473774; batch adversarial loss: 0.659169\n",
      "epoch 28; iter: 0; batch classifier loss: 0.278957; batch adversarial loss: 0.574229\n",
      "epoch 29; iter: 0; batch classifier loss: 0.376601; batch adversarial loss: 0.614208\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321724; batch adversarial loss: 0.657947\n",
      "epoch 31; iter: 0; batch classifier loss: 0.426024; batch adversarial loss: 0.587859\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374620; batch adversarial loss: 0.604778\n",
      "epoch 33; iter: 0; batch classifier loss: 0.221791; batch adversarial loss: 0.605747\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310310; batch adversarial loss: 0.625411\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420387; batch adversarial loss: 0.596459\n",
      "epoch 36; iter: 0; batch classifier loss: 0.408073; batch adversarial loss: 0.626162\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209805; batch adversarial loss: 0.638715\n",
      "epoch 38; iter: 0; batch classifier loss: 0.349187; batch adversarial loss: 0.599170\n",
      "epoch 39; iter: 0; batch classifier loss: 0.420477; batch adversarial loss: 0.555233\n",
      "epoch 0; iter: 0; batch classifier loss: 0.810263; batch adversarial loss: 1.094913\n",
      "epoch 1; iter: 0; batch classifier loss: 0.696558; batch adversarial loss: 0.954446\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614875; batch adversarial loss: 1.006470\n",
      "epoch 3; iter: 0; batch classifier loss: 0.545326; batch adversarial loss: 0.971668\n",
      "epoch 4; iter: 0; batch classifier loss: 0.508892; batch adversarial loss: 0.932762\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555535; batch adversarial loss: 0.907121\n",
      "epoch 6; iter: 0; batch classifier loss: 0.480197; batch adversarial loss: 0.917241\n",
      "epoch 7; iter: 0; batch classifier loss: 0.616584; batch adversarial loss: 0.977186\n",
      "epoch 8; iter: 0; batch classifier loss: 0.403734; batch adversarial loss: 0.899547\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512527; batch adversarial loss: 0.976351\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513160; batch adversarial loss: 0.926726\n",
      "epoch 11; iter: 0; batch classifier loss: 0.380516; batch adversarial loss: 0.916852\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515586; batch adversarial loss: 0.906270\n",
      "epoch 13; iter: 0; batch classifier loss: 0.607615; batch adversarial loss: 0.948028\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423768; batch adversarial loss: 0.864528\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508107; batch adversarial loss: 0.838392\n",
      "epoch 16; iter: 0; batch classifier loss: 0.439950; batch adversarial loss: 0.884403\n",
      "epoch 17; iter: 0; batch classifier loss: 0.553002; batch adversarial loss: 0.894738\n",
      "epoch 18; iter: 0; batch classifier loss: 0.605464; batch adversarial loss: 0.901163\n",
      "epoch 19; iter: 0; batch classifier loss: 0.363401; batch adversarial loss: 0.873867\n",
      "epoch 20; iter: 0; batch classifier loss: 0.382316; batch adversarial loss: 0.858475\n",
      "epoch 21; iter: 0; batch classifier loss: 0.406123; batch adversarial loss: 0.835007\n",
      "epoch 22; iter: 0; batch classifier loss: 0.580701; batch adversarial loss: 0.881505\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410170; batch adversarial loss: 0.791536\n",
      "epoch 24; iter: 0; batch classifier loss: 0.435877; batch adversarial loss: 0.790907\n",
      "epoch 25; iter: 0; batch classifier loss: 0.545964; batch adversarial loss: 0.804523\n",
      "epoch 26; iter: 0; batch classifier loss: 0.520696; batch adversarial loss: 0.828287\n",
      "epoch 27; iter: 0; batch classifier loss: 0.441850; batch adversarial loss: 0.822193\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393327; batch adversarial loss: 0.796063\n",
      "epoch 29; iter: 0; batch classifier loss: 0.544403; batch adversarial loss: 0.822580\n",
      "epoch 30; iter: 0; batch classifier loss: 0.549488; batch adversarial loss: 0.799541\n",
      "epoch 31; iter: 0; batch classifier loss: 0.507473; batch adversarial loss: 0.801843\n",
      "epoch 32; iter: 0; batch classifier loss: 0.467229; batch adversarial loss: 0.800924\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429276; batch adversarial loss: 0.776777\n",
      "epoch 34; iter: 0; batch classifier loss: 0.466427; batch adversarial loss: 0.761081\n",
      "epoch 35; iter: 0; batch classifier loss: 0.436984; batch adversarial loss: 0.768725\n",
      "epoch 36; iter: 0; batch classifier loss: 0.459910; batch adversarial loss: 0.757736\n",
      "epoch 37; iter: 0; batch classifier loss: 0.434626; batch adversarial loss: 0.758607\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447744; batch adversarial loss: 0.764457\n",
      "epoch 39; iter: 0; batch classifier loss: 0.456137; batch adversarial loss: 0.734670\n",
      "epoch 0; iter: 0; batch classifier loss: 0.655184; batch adversarial loss: 0.975248\n",
      "epoch 1; iter: 0; batch classifier loss: 0.611467; batch adversarial loss: 1.038118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607408; batch adversarial loss: 0.948856\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623604; batch adversarial loss: 0.959919\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555904; batch adversarial loss: 0.964645\n",
      "epoch 5; iter: 0; batch classifier loss: 0.586257; batch adversarial loss: 0.934771\n",
      "epoch 6; iter: 0; batch classifier loss: 0.531868; batch adversarial loss: 0.938270\n",
      "epoch 7; iter: 0; batch classifier loss: 0.553970; batch adversarial loss: 0.974681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572903; batch adversarial loss: 0.906023\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499507; batch adversarial loss: 1.002085\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522349; batch adversarial loss: 0.901060\n",
      "epoch 11; iter: 0; batch classifier loss: 0.583319; batch adversarial loss: 0.967404\n",
      "epoch 12; iter: 0; batch classifier loss: 0.487630; batch adversarial loss: 0.993764\n",
      "epoch 13; iter: 0; batch classifier loss: 0.426001; batch adversarial loss: 0.943288\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477245; batch adversarial loss: 0.971902\n",
      "epoch 15; iter: 0; batch classifier loss: 0.491154; batch adversarial loss: 0.833920\n",
      "epoch 16; iter: 0; batch classifier loss: 0.483928; batch adversarial loss: 0.897300\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435813; batch adversarial loss: 0.943655\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458408; batch adversarial loss: 0.951779\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437550; batch adversarial loss: 0.836816\n",
      "epoch 20; iter: 0; batch classifier loss: 0.505234; batch adversarial loss: 0.930396\n",
      "epoch 21; iter: 0; batch classifier loss: 0.412284; batch adversarial loss: 0.950987\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389083; batch adversarial loss: 0.890197\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378691; batch adversarial loss: 0.907399\n",
      "epoch 24; iter: 0; batch classifier loss: 0.371853; batch adversarial loss: 0.917466\n",
      "epoch 25; iter: 0; batch classifier loss: 0.524921; batch adversarial loss: 0.919292\n",
      "epoch 26; iter: 0; batch classifier loss: 0.515444; batch adversarial loss: 0.846410\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397407; batch adversarial loss: 0.852951\n",
      "epoch 28; iter: 0; batch classifier loss: 0.452963; batch adversarial loss: 0.926591\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386532; batch adversarial loss: 0.857336\n",
      "epoch 30; iter: 0; batch classifier loss: 0.419153; batch adversarial loss: 0.851663\n",
      "epoch 31; iter: 0; batch classifier loss: 0.454007; batch adversarial loss: 0.863610\n",
      "epoch 32; iter: 0; batch classifier loss: 0.452895; batch adversarial loss: 0.892735\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365693; batch adversarial loss: 0.897669\n",
      "epoch 34; iter: 0; batch classifier loss: 0.419920; batch adversarial loss: 0.818960\n",
      "epoch 35; iter: 0; batch classifier loss: 0.383395; batch adversarial loss: 0.853965\n",
      "epoch 36; iter: 0; batch classifier loss: 0.425299; batch adversarial loss: 0.942687\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413693; batch adversarial loss: 0.882035\n",
      "epoch 38; iter: 0; batch classifier loss: 0.434239; batch adversarial loss: 0.868044\n",
      "epoch 39; iter: 0; batch classifier loss: 0.357206; batch adversarial loss: 0.916072\n",
      "epoch 0; iter: 0; batch classifier loss: 0.681503; batch adversarial loss: 0.610214\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647776; batch adversarial loss: 0.664321\n",
      "epoch 2; iter: 0; batch classifier loss: 0.637770; batch adversarial loss: 0.634549\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572587; batch adversarial loss: 0.618588\n",
      "epoch 4; iter: 0; batch classifier loss: 0.570122; batch adversarial loss: 0.616900\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531862; batch adversarial loss: 0.627825\n",
      "epoch 6; iter: 0; batch classifier loss: 0.524549; batch adversarial loss: 0.623088\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513286; batch adversarial loss: 0.630859\n",
      "epoch 8; iter: 0; batch classifier loss: 0.499036; batch adversarial loss: 0.654327\n",
      "epoch 9; iter: 0; batch classifier loss: 0.500591; batch adversarial loss: 0.628872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.471097; batch adversarial loss: 0.598880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.444633; batch adversarial loss: 0.607988\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417756; batch adversarial loss: 0.595157\n",
      "epoch 13; iter: 0; batch classifier loss: 0.460314; batch adversarial loss: 0.622423\n",
      "epoch 14; iter: 0; batch classifier loss: 0.479252; batch adversarial loss: 0.605859\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398690; batch adversarial loss: 0.647030\n",
      "epoch 16; iter: 0; batch classifier loss: 0.394178; batch adversarial loss: 0.638979\n",
      "epoch 17; iter: 0; batch classifier loss: 0.404341; batch adversarial loss: 0.651267\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397145; batch adversarial loss: 0.614062\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459075; batch adversarial loss: 0.646936\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429532; batch adversarial loss: 0.637420\n",
      "epoch 21; iter: 0; batch classifier loss: 0.337813; batch adversarial loss: 0.650201\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447247; batch adversarial loss: 0.585548\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417370; batch adversarial loss: 0.671833\n",
      "epoch 24; iter: 0; batch classifier loss: 0.320920; batch adversarial loss: 0.591152\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339271; batch adversarial loss: 0.613945\n",
      "epoch 26; iter: 0; batch classifier loss: 0.331991; batch adversarial loss: 0.664613\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397636; batch adversarial loss: 0.613559\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351748; batch adversarial loss: 0.644701\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397621; batch adversarial loss: 0.584079\n",
      "epoch 30; iter: 0; batch classifier loss: 0.321977; batch adversarial loss: 0.655001\n",
      "epoch 31; iter: 0; batch classifier loss: 0.407413; batch adversarial loss: 0.613544\n",
      "epoch 32; iter: 0; batch classifier loss: 0.314434; batch adversarial loss: 0.605695\n",
      "epoch 33; iter: 0; batch classifier loss: 0.335579; batch adversarial loss: 0.612050\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385242; batch adversarial loss: 0.588970\n",
      "epoch 35; iter: 0; batch classifier loss: 0.268632; batch adversarial loss: 0.629338\n",
      "epoch 36; iter: 0; batch classifier loss: 0.389015; batch adversarial loss: 0.586548\n",
      "epoch 37; iter: 0; batch classifier loss: 0.289540; batch adversarial loss: 0.658643\n",
      "epoch 38; iter: 0; batch classifier loss: 0.383495; batch adversarial loss: 0.610154\n",
      "epoch 39; iter: 0; batch classifier loss: 0.363828; batch adversarial loss: 0.599360\n",
      "epoch 0; iter: 0; batch classifier loss: 0.789354; batch adversarial loss: 0.632434\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704183; batch adversarial loss: 0.652746\n",
      "epoch 2; iter: 0; batch classifier loss: 0.749694; batch adversarial loss: 0.625648\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652361; batch adversarial loss: 0.623399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.588011; batch adversarial loss: 0.612145\n",
      "epoch 5; iter: 0; batch classifier loss: 0.646760; batch adversarial loss: 0.683145\n",
      "epoch 6; iter: 0; batch classifier loss: 0.616979; batch adversarial loss: 0.710268\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532358; batch adversarial loss: 0.641045\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529233; batch adversarial loss: 0.696653\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444329; batch adversarial loss: 0.602574\n",
      "epoch 10; iter: 0; batch classifier loss: 0.472117; batch adversarial loss: 0.613442\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448607; batch adversarial loss: 0.625654\n",
      "epoch 12; iter: 0; batch classifier loss: 0.454094; batch adversarial loss: 0.689911\n",
      "epoch 13; iter: 0; batch classifier loss: 0.410213; batch adversarial loss: 0.625255\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510881; batch adversarial loss: 0.696115\n",
      "epoch 15; iter: 0; batch classifier loss: 0.371698; batch adversarial loss: 0.507183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475508; batch adversarial loss: 0.632035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.363535; batch adversarial loss: 0.668163\n",
      "epoch 18; iter: 0; batch classifier loss: 0.446855; batch adversarial loss: 0.567042\n",
      "epoch 19; iter: 0; batch classifier loss: 0.338360; batch adversarial loss: 0.593967\n",
      "epoch 20; iter: 0; batch classifier loss: 0.418361; batch adversarial loss: 0.588479\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382907; batch adversarial loss: 0.719981\n",
      "epoch 22; iter: 0; batch classifier loss: 0.368975; batch adversarial loss: 0.587080\n",
      "epoch 23; iter: 0; batch classifier loss: 0.571924; batch adversarial loss: 0.665366\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392868; batch adversarial loss: 0.622055\n",
      "epoch 25; iter: 0; batch classifier loss: 0.320541; batch adversarial loss: 0.554775\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271890; batch adversarial loss: 0.617313\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325268; batch adversarial loss: 0.737211\n",
      "epoch 28; iter: 0; batch classifier loss: 0.290968; batch adversarial loss: 0.638911\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443910; batch adversarial loss: 0.639070\n",
      "epoch 30; iter: 0; batch classifier loss: 0.266123; batch adversarial loss: 0.663446\n",
      "epoch 31; iter: 0; batch classifier loss: 0.330085; batch adversarial loss: 0.645420\n",
      "epoch 32; iter: 0; batch classifier loss: 0.349095; batch adversarial loss: 0.635718\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382806; batch adversarial loss: 0.687812\n",
      "epoch 34; iter: 0; batch classifier loss: 0.329122; batch adversarial loss: 0.701715\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408722; batch adversarial loss: 0.709338\n",
      "epoch 36; iter: 0; batch classifier loss: 0.268054; batch adversarial loss: 0.635061\n",
      "epoch 37; iter: 0; batch classifier loss: 0.222960; batch adversarial loss: 0.518115\n",
      "epoch 38; iter: 0; batch classifier loss: 0.308683; batch adversarial loss: 0.527256\n",
      "epoch 39; iter: 0; batch classifier loss: 0.400652; batch adversarial loss: 0.609415\n",
      "epoch 40; iter: 0; batch classifier loss: 0.463996; batch adversarial loss: 0.593365\n",
      "epoch 41; iter: 0; batch classifier loss: 0.442523; batch adversarial loss: 0.635560\n",
      "epoch 42; iter: 0; batch classifier loss: 0.313610; batch adversarial loss: 0.594520\n",
      "epoch 43; iter: 0; batch classifier loss: 0.282094; batch adversarial loss: 0.537719\n",
      "epoch 44; iter: 0; batch classifier loss: 0.397429; batch adversarial loss: 0.655131\n",
      "epoch 45; iter: 0; batch classifier loss: 0.332865; batch adversarial loss: 0.506830\n",
      "epoch 46; iter: 0; batch classifier loss: 0.425067; batch adversarial loss: 0.675794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.368666; batch adversarial loss: 0.587698\n",
      "epoch 48; iter: 0; batch classifier loss: 0.310990; batch adversarial loss: 0.587343\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269402; batch adversarial loss: 0.657792\n",
      "epoch 50; iter: 0; batch classifier loss: 0.309486; batch adversarial loss: 0.617730\n",
      "epoch 51; iter: 0; batch classifier loss: 0.245920; batch adversarial loss: 0.533865\n",
      "epoch 52; iter: 0; batch classifier loss: 0.301627; batch adversarial loss: 0.615937\n",
      "epoch 53; iter: 0; batch classifier loss: 0.285771; batch adversarial loss: 0.599892\n",
      "epoch 54; iter: 0; batch classifier loss: 0.288924; batch adversarial loss: 0.558439\n",
      "epoch 55; iter: 0; batch classifier loss: 0.470245; batch adversarial loss: 0.500890\n",
      "epoch 56; iter: 0; batch classifier loss: 0.276267; batch adversarial loss: 0.618468\n",
      "epoch 57; iter: 0; batch classifier loss: 0.314397; batch adversarial loss: 0.549211\n",
      "epoch 58; iter: 0; batch classifier loss: 0.378817; batch adversarial loss: 0.578994\n",
      "epoch 59; iter: 0; batch classifier loss: 0.366996; batch adversarial loss: 0.677205\n",
      "epoch 0; iter: 0; batch classifier loss: 0.819000; batch adversarial loss: 0.744502\n",
      "epoch 1; iter: 0; batch classifier loss: 0.648322; batch adversarial loss: 0.725226\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641645; batch adversarial loss: 0.737706\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593603; batch adversarial loss: 0.729818\n",
      "epoch 4; iter: 0; batch classifier loss: 0.507217; batch adversarial loss: 0.713402\n",
      "epoch 5; iter: 0; batch classifier loss: 0.432969; batch adversarial loss: 0.720033\n",
      "epoch 6; iter: 0; batch classifier loss: 0.508697; batch adversarial loss: 0.709882\n",
      "epoch 7; iter: 0; batch classifier loss: 0.389223; batch adversarial loss: 0.702913\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458678; batch adversarial loss: 0.705625\n",
      "epoch 9; iter: 0; batch classifier loss: 0.415891; batch adversarial loss: 0.697500\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397649; batch adversarial loss: 0.693951\n",
      "epoch 11; iter: 0; batch classifier loss: 0.423378; batch adversarial loss: 0.689582\n",
      "epoch 12; iter: 0; batch classifier loss: 0.292906; batch adversarial loss: 0.685647\n",
      "epoch 13; iter: 0; batch classifier loss: 0.265186; batch adversarial loss: 0.681356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339988; batch adversarial loss: 0.675112\n",
      "epoch 15; iter: 0; batch classifier loss: 0.457127; batch adversarial loss: 0.673310\n",
      "epoch 16; iter: 0; batch classifier loss: 0.353980; batch adversarial loss: 0.663133\n",
      "epoch 17; iter: 0; batch classifier loss: 0.357767; batch adversarial loss: 0.661915\n",
      "epoch 18; iter: 0; batch classifier loss: 0.388690; batch adversarial loss: 0.661442\n",
      "epoch 19; iter: 0; batch classifier loss: 0.206918; batch adversarial loss: 0.655100\n",
      "epoch 20; iter: 0; batch classifier loss: 0.282365; batch adversarial loss: 0.648570\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300007; batch adversarial loss: 0.625530\n",
      "epoch 22; iter: 0; batch classifier loss: 0.347101; batch adversarial loss: 0.655393\n",
      "epoch 23; iter: 0; batch classifier loss: 0.305877; batch adversarial loss: 0.639299\n",
      "epoch 24; iter: 0; batch classifier loss: 0.358308; batch adversarial loss: 0.631088\n",
      "epoch 25; iter: 0; batch classifier loss: 0.387578; batch adversarial loss: 0.636105\n",
      "epoch 26; iter: 0; batch classifier loss: 0.318050; batch adversarial loss: 0.628051\n",
      "epoch 27; iter: 0; batch classifier loss: 0.271087; batch adversarial loss: 0.651582\n",
      "epoch 28; iter: 0; batch classifier loss: 0.335869; batch adversarial loss: 0.634897\n",
      "epoch 29; iter: 0; batch classifier loss: 0.264955; batch adversarial loss: 0.633314\n",
      "epoch 30; iter: 0; batch classifier loss: 0.309876; batch adversarial loss: 0.636082\n",
      "epoch 31; iter: 0; batch classifier loss: 0.276409; batch adversarial loss: 0.613652\n",
      "epoch 32; iter: 0; batch classifier loss: 0.254275; batch adversarial loss: 0.602576\n",
      "epoch 33; iter: 0; batch classifier loss: 0.298854; batch adversarial loss: 0.619671\n",
      "epoch 34; iter: 0; batch classifier loss: 0.249886; batch adversarial loss: 0.609684\n",
      "epoch 35; iter: 0; batch classifier loss: 0.347398; batch adversarial loss: 0.632344\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305562; batch adversarial loss: 0.613402\n",
      "epoch 37; iter: 0; batch classifier loss: 0.325942; batch adversarial loss: 0.624500\n",
      "epoch 38; iter: 0; batch classifier loss: 0.336187; batch adversarial loss: 0.619788\n",
      "epoch 39; iter: 0; batch classifier loss: 0.283736; batch adversarial loss: 0.597330\n",
      "epoch 40; iter: 0; batch classifier loss: 0.289771; batch adversarial loss: 0.602428\n",
      "epoch 41; iter: 0; batch classifier loss: 0.408189; batch adversarial loss: 0.605348\n",
      "epoch 42; iter: 0; batch classifier loss: 0.234498; batch adversarial loss: 0.637541\n",
      "epoch 43; iter: 0; batch classifier loss: 0.264739; batch adversarial loss: 0.572502\n",
      "epoch 44; iter: 0; batch classifier loss: 0.259564; batch adversarial loss: 0.624663\n",
      "epoch 45; iter: 0; batch classifier loss: 0.244657; batch adversarial loss: 0.620417\n",
      "epoch 46; iter: 0; batch classifier loss: 0.219073; batch adversarial loss: 0.589722\n",
      "epoch 47; iter: 0; batch classifier loss: 0.219005; batch adversarial loss: 0.615744\n",
      "epoch 48; iter: 0; batch classifier loss: 0.308510; batch adversarial loss: 0.635488\n",
      "epoch 49; iter: 0; batch classifier loss: 0.425932; batch adversarial loss: 0.580789\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202345; batch adversarial loss: 0.643494\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448436; batch adversarial loss: 0.578694\n",
      "epoch 52; iter: 0; batch classifier loss: 0.281588; batch adversarial loss: 0.565092\n",
      "epoch 53; iter: 0; batch classifier loss: 0.332218; batch adversarial loss: 0.619852\n",
      "epoch 54; iter: 0; batch classifier loss: 0.301801; batch adversarial loss: 0.608329\n",
      "epoch 55; iter: 0; batch classifier loss: 0.284578; batch adversarial loss: 0.580220\n",
      "epoch 56; iter: 0; batch classifier loss: 0.191000; batch adversarial loss: 0.641853\n",
      "epoch 57; iter: 0; batch classifier loss: 0.211705; batch adversarial loss: 0.616464\n",
      "epoch 58; iter: 0; batch classifier loss: 0.339789; batch adversarial loss: 0.627283\n",
      "epoch 59; iter: 0; batch classifier loss: 0.326316; batch adversarial loss: 0.597455\n",
      "epoch 0; iter: 0; batch classifier loss: 0.809397; batch adversarial loss: 0.695872\n",
      "epoch 1; iter: 0; batch classifier loss: 0.779196; batch adversarial loss: 0.656331\n",
      "epoch 2; iter: 0; batch classifier loss: 0.759722; batch adversarial loss: 0.645287\n",
      "epoch 3; iter: 0; batch classifier loss: 0.725640; batch adversarial loss: 0.676054\n",
      "epoch 4; iter: 0; batch classifier loss: 0.728086; batch adversarial loss: 0.676784\n",
      "epoch 5; iter: 0; batch classifier loss: 0.737715; batch adversarial loss: 0.614095\n",
      "epoch 6; iter: 0; batch classifier loss: 0.661328; batch adversarial loss: 0.640730\n",
      "epoch 7; iter: 0; batch classifier loss: 0.633818; batch adversarial loss: 0.629073\n",
      "epoch 8; iter: 0; batch classifier loss: 0.632900; batch adversarial loss: 0.694147\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610378; batch adversarial loss: 0.681299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.579671; batch adversarial loss: 0.661559\n",
      "epoch 11; iter: 0; batch classifier loss: 0.600417; batch adversarial loss: 0.652804\n",
      "epoch 12; iter: 0; batch classifier loss: 0.576099; batch adversarial loss: 0.648253\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571727; batch adversarial loss: 0.683911\n",
      "epoch 14; iter: 0; batch classifier loss: 0.579290; batch adversarial loss: 0.631124\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554305; batch adversarial loss: 0.661496\n",
      "epoch 16; iter: 0; batch classifier loss: 0.518821; batch adversarial loss: 0.675061\n",
      "epoch 17; iter: 0; batch classifier loss: 0.525466; batch adversarial loss: 0.654905\n",
      "epoch 18; iter: 0; batch classifier loss: 0.490636; batch adversarial loss: 0.638625\n",
      "epoch 19; iter: 0; batch classifier loss: 0.513234; batch adversarial loss: 0.659614\n",
      "epoch 20; iter: 0; batch classifier loss: 0.518144; batch adversarial loss: 0.657540\n",
      "epoch 21; iter: 0; batch classifier loss: 0.504565; batch adversarial loss: 0.646603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.511009; batch adversarial loss: 0.622660\n",
      "epoch 23; iter: 0; batch classifier loss: 0.515365; batch adversarial loss: 0.590511\n",
      "epoch 24; iter: 0; batch classifier loss: 0.479423; batch adversarial loss: 0.666394\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497358; batch adversarial loss: 0.620491\n",
      "epoch 26; iter: 0; batch classifier loss: 0.489098; batch adversarial loss: 0.618816\n",
      "epoch 27; iter: 0; batch classifier loss: 0.437610; batch adversarial loss: 0.659869\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425059; batch adversarial loss: 0.664163\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484689; batch adversarial loss: 0.635427\n",
      "epoch 30; iter: 0; batch classifier loss: 0.439559; batch adversarial loss: 0.635224\n",
      "epoch 31; iter: 0; batch classifier loss: 0.444773; batch adversarial loss: 0.602746\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412433; batch adversarial loss: 0.616488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.489370; batch adversarial loss: 0.596221\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452050; batch adversarial loss: 0.644464\n",
      "epoch 35; iter: 0; batch classifier loss: 0.461369; batch adversarial loss: 0.621410\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424389; batch adversarial loss: 0.638480\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378443; batch adversarial loss: 0.606979\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419771; batch adversarial loss: 0.627059\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424608; batch adversarial loss: 0.605029\n",
      "epoch 40; iter: 0; batch classifier loss: 0.406983; batch adversarial loss: 0.653099\n",
      "epoch 41; iter: 0; batch classifier loss: 0.458709; batch adversarial loss: 0.628392\n",
      "epoch 42; iter: 0; batch classifier loss: 0.415698; batch adversarial loss: 0.599617\n",
      "epoch 43; iter: 0; batch classifier loss: 0.427200; batch adversarial loss: 0.611383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.333868; batch adversarial loss: 0.622366\n",
      "epoch 45; iter: 0; batch classifier loss: 0.397795; batch adversarial loss: 0.625893\n",
      "epoch 46; iter: 0; batch classifier loss: 0.355801; batch adversarial loss: 0.641234\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380304; batch adversarial loss: 0.678036\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377722; batch adversarial loss: 0.643569\n",
      "epoch 49; iter: 0; batch classifier loss: 0.400699; batch adversarial loss: 0.622136\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428834; batch adversarial loss: 0.599618\n",
      "epoch 51; iter: 0; batch classifier loss: 0.328674; batch adversarial loss: 0.608913\n",
      "epoch 52; iter: 0; batch classifier loss: 0.383758; batch adversarial loss: 0.650089\n",
      "epoch 53; iter: 0; batch classifier loss: 0.425468; batch adversarial loss: 0.587299\n",
      "epoch 54; iter: 0; batch classifier loss: 0.369243; batch adversarial loss: 0.607056\n",
      "epoch 55; iter: 0; batch classifier loss: 0.361502; batch adversarial loss: 0.628972\n",
      "epoch 56; iter: 0; batch classifier loss: 0.347325; batch adversarial loss: 0.598679\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347424; batch adversarial loss: 0.630144\n",
      "epoch 58; iter: 0; batch classifier loss: 0.367595; batch adversarial loss: 0.604822\n",
      "epoch 59; iter: 0; batch classifier loss: 0.299709; batch adversarial loss: 0.637931\n",
      "epoch 0; iter: 0; batch classifier loss: 0.733931; batch adversarial loss: 0.519334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.634547; batch adversarial loss: 0.520593\n",
      "epoch 2; iter: 0; batch classifier loss: 0.688564; batch adversarial loss: 0.552613\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627139; batch adversarial loss: 0.529954\n",
      "epoch 4; iter: 0; batch classifier loss: 0.584931; batch adversarial loss: 0.552435\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594531; batch adversarial loss: 0.504945\n",
      "epoch 6; iter: 0; batch classifier loss: 0.568925; batch adversarial loss: 0.562492\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558537; batch adversarial loss: 0.550785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529069; batch adversarial loss: 0.566322\n",
      "epoch 9; iter: 0; batch classifier loss: 0.528122; batch adversarial loss: 0.584412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.499248; batch adversarial loss: 0.514503\n",
      "epoch 11; iter: 0; batch classifier loss: 0.440000; batch adversarial loss: 0.537815\n",
      "epoch 12; iter: 0; batch classifier loss: 0.512576; batch adversarial loss: 0.527897\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526908; batch adversarial loss: 0.518163\n",
      "epoch 14; iter: 0; batch classifier loss: 0.462309; batch adversarial loss: 0.490680\n",
      "epoch 15; iter: 0; batch classifier loss: 0.451444; batch adversarial loss: 0.532335\n",
      "epoch 16; iter: 0; batch classifier loss: 0.448822; batch adversarial loss: 0.546431\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447563; batch adversarial loss: 0.504514\n",
      "epoch 18; iter: 0; batch classifier loss: 0.468919; batch adversarial loss: 0.567815\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455698; batch adversarial loss: 0.563747\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387976; batch adversarial loss: 0.526569\n",
      "epoch 21; iter: 0; batch classifier loss: 0.421855; batch adversarial loss: 0.518340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437539; batch adversarial loss: 0.566685\n",
      "epoch 23; iter: 0; batch classifier loss: 0.389506; batch adversarial loss: 0.511331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.419569; batch adversarial loss: 0.464120\n",
      "epoch 25; iter: 0; batch classifier loss: 0.393543; batch adversarial loss: 0.492878\n",
      "epoch 26; iter: 0; batch classifier loss: 0.396801; batch adversarial loss: 0.513803\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411236; batch adversarial loss: 0.574455\n",
      "epoch 28; iter: 0; batch classifier loss: 0.378644; batch adversarial loss: 0.581839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.391624; batch adversarial loss: 0.598851\n",
      "epoch 30; iter: 0; batch classifier loss: 0.330415; batch adversarial loss: 0.574420\n",
      "epoch 31; iter: 0; batch classifier loss: 0.385702; batch adversarial loss: 0.494045\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415380; batch adversarial loss: 0.472177\n",
      "epoch 33; iter: 0; batch classifier loss: 0.342483; batch adversarial loss: 0.504690\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389483; batch adversarial loss: 0.570754\n",
      "epoch 35; iter: 0; batch classifier loss: 0.455800; batch adversarial loss: 0.542096\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436187; batch adversarial loss: 0.520824\n",
      "epoch 37; iter: 0; batch classifier loss: 0.405664; batch adversarial loss: 0.582367\n",
      "epoch 38; iter: 0; batch classifier loss: 0.319373; batch adversarial loss: 0.533105\n",
      "epoch 39; iter: 0; batch classifier loss: 0.326555; batch adversarial loss: 0.537637\n",
      "epoch 40; iter: 0; batch classifier loss: 0.321089; batch adversarial loss: 0.546329\n",
      "epoch 41; iter: 0; batch classifier loss: 0.359139; batch adversarial loss: 0.511301\n",
      "epoch 42; iter: 0; batch classifier loss: 0.356647; batch adversarial loss: 0.458201\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383121; batch adversarial loss: 0.496411\n",
      "epoch 44; iter: 0; batch classifier loss: 0.338391; batch adversarial loss: 0.584097\n",
      "epoch 45; iter: 0; batch classifier loss: 0.347928; batch adversarial loss: 0.555446\n",
      "epoch 46; iter: 0; batch classifier loss: 0.353113; batch adversarial loss: 0.551717\n",
      "epoch 47; iter: 0; batch classifier loss: 0.313950; batch adversarial loss: 0.541463\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393237; batch adversarial loss: 0.554159\n",
      "epoch 49; iter: 0; batch classifier loss: 0.386259; batch adversarial loss: 0.526680\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362311; batch adversarial loss: 0.589656\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383371; batch adversarial loss: 0.540697\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373716; batch adversarial loss: 0.585258\n",
      "epoch 53; iter: 0; batch classifier loss: 0.352281; batch adversarial loss: 0.578107\n",
      "epoch 54; iter: 0; batch classifier loss: 0.313523; batch adversarial loss: 0.554544\n",
      "epoch 55; iter: 0; batch classifier loss: 0.329465; batch adversarial loss: 0.618525\n",
      "epoch 56; iter: 0; batch classifier loss: 0.390865; batch adversarial loss: 0.612913\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347205; batch adversarial loss: 0.439930\n",
      "epoch 58; iter: 0; batch classifier loss: 0.351237; batch adversarial loss: 0.500473\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343227; batch adversarial loss: 0.531040\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730389; batch adversarial loss: 0.709854\n",
      "epoch 1; iter: 0; batch classifier loss: 0.714430; batch adversarial loss: 0.656608\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697871; batch adversarial loss: 0.685782\n",
      "epoch 3; iter: 0; batch classifier loss: 0.623629; batch adversarial loss: 0.709102\n",
      "epoch 4; iter: 0; batch classifier loss: 0.638983; batch adversarial loss: 0.677007\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613859; batch adversarial loss: 0.688216\n",
      "epoch 6; iter: 0; batch classifier loss: 0.622617; batch adversarial loss: 0.651144\n",
      "epoch 7; iter: 0; batch classifier loss: 0.537856; batch adversarial loss: 0.727086\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535850; batch adversarial loss: 0.709563\n",
      "epoch 9; iter: 0; batch classifier loss: 0.475869; batch adversarial loss: 0.678630\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540460; batch adversarial loss: 0.667461\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457864; batch adversarial loss: 0.676172\n",
      "epoch 12; iter: 0; batch classifier loss: 0.468550; batch adversarial loss: 0.678710\n",
      "epoch 13; iter: 0; batch classifier loss: 0.513074; batch adversarial loss: 0.677853\n",
      "epoch 14; iter: 0; batch classifier loss: 0.440576; batch adversarial loss: 0.679870\n",
      "epoch 15; iter: 0; batch classifier loss: 0.488398; batch adversarial loss: 0.684416\n",
      "epoch 16; iter: 0; batch classifier loss: 0.444492; batch adversarial loss: 0.666294\n",
      "epoch 17; iter: 0; batch classifier loss: 0.415000; batch adversarial loss: 0.689637\n",
      "epoch 18; iter: 0; batch classifier loss: 0.348979; batch adversarial loss: 0.662112\n",
      "epoch 19; iter: 0; batch classifier loss: 0.417626; batch adversarial loss: 0.648739\n",
      "epoch 20; iter: 0; batch classifier loss: 0.414994; batch adversarial loss: 0.658210\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415040; batch adversarial loss: 0.658217\n",
      "epoch 22; iter: 0; batch classifier loss: 0.356228; batch adversarial loss: 0.636348\n",
      "epoch 23; iter: 0; batch classifier loss: 0.405487; batch adversarial loss: 0.614691\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409080; batch adversarial loss: 0.613700\n",
      "epoch 25; iter: 0; batch classifier loss: 0.334079; batch adversarial loss: 0.648350\n",
      "epoch 26; iter: 0; batch classifier loss: 0.373885; batch adversarial loss: 0.669046\n",
      "epoch 27; iter: 0; batch classifier loss: 0.317460; batch adversarial loss: 0.619631\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425831; batch adversarial loss: 0.643847\n",
      "epoch 29; iter: 0; batch classifier loss: 0.312760; batch adversarial loss: 0.679667\n",
      "epoch 30; iter: 0; batch classifier loss: 0.328902; batch adversarial loss: 0.624381\n",
      "epoch 31; iter: 0; batch classifier loss: 0.338416; batch adversarial loss: 0.610122\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386433; batch adversarial loss: 0.629672\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385593; batch adversarial loss: 0.617042\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445682; batch adversarial loss: 0.688542\n",
      "epoch 35; iter: 0; batch classifier loss: 0.351728; batch adversarial loss: 0.618025\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353995; batch adversarial loss: 0.595147\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385755; batch adversarial loss: 0.605179\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269030; batch adversarial loss: 0.616997\n",
      "epoch 39; iter: 0; batch classifier loss: 0.396642; batch adversarial loss: 0.609786\n",
      "epoch 40; iter: 0; batch classifier loss: 0.369825; batch adversarial loss: 0.618092\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378997; batch adversarial loss: 0.637149\n",
      "epoch 42; iter: 0; batch classifier loss: 0.268350; batch adversarial loss: 0.599301\n",
      "epoch 43; iter: 0; batch classifier loss: 0.347063; batch adversarial loss: 0.571014\n",
      "epoch 44; iter: 0; batch classifier loss: 0.223780; batch adversarial loss: 0.701555\n",
      "epoch 45; iter: 0; batch classifier loss: 0.309875; batch adversarial loss: 0.599280\n",
      "epoch 46; iter: 0; batch classifier loss: 0.274707; batch adversarial loss: 0.590066\n",
      "epoch 47; iter: 0; batch classifier loss: 0.401261; batch adversarial loss: 0.631676\n",
      "epoch 48; iter: 0; batch classifier loss: 0.239029; batch adversarial loss: 0.633217\n",
      "epoch 49; iter: 0; batch classifier loss: 0.249784; batch adversarial loss: 0.539871\n",
      "epoch 50; iter: 0; batch classifier loss: 0.205181; batch adversarial loss: 0.632713\n",
      "epoch 51; iter: 0; batch classifier loss: 0.331984; batch adversarial loss: 0.617934\n",
      "epoch 52; iter: 0; batch classifier loss: 0.291065; batch adversarial loss: 0.565466\n",
      "epoch 53; iter: 0; batch classifier loss: 0.359002; batch adversarial loss: 0.574213\n",
      "epoch 54; iter: 0; batch classifier loss: 0.266524; batch adversarial loss: 0.675299\n",
      "epoch 55; iter: 0; batch classifier loss: 0.326309; batch adversarial loss: 0.622566\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398165; batch adversarial loss: 0.560364\n",
      "epoch 57; iter: 0; batch classifier loss: 0.326936; batch adversarial loss: 0.591630\n",
      "epoch 58; iter: 0; batch classifier loss: 0.238324; batch adversarial loss: 0.573860\n",
      "epoch 59; iter: 0; batch classifier loss: 0.274048; batch adversarial loss: 0.603539\n",
      "epoch 60; iter: 0; batch classifier loss: 0.158226; batch adversarial loss: 0.604670\n",
      "epoch 61; iter: 0; batch classifier loss: 0.348854; batch adversarial loss: 0.567873\n",
      "epoch 62; iter: 0; batch classifier loss: 0.426334; batch adversarial loss: 0.596310\n",
      "epoch 63; iter: 0; batch classifier loss: 0.374191; batch adversarial loss: 0.617412\n",
      "epoch 64; iter: 0; batch classifier loss: 0.475369; batch adversarial loss: 0.659277\n",
      "epoch 65; iter: 0; batch classifier loss: 0.323870; batch adversarial loss: 0.623353\n",
      "epoch 66; iter: 0; batch classifier loss: 0.265358; batch adversarial loss: 0.555447\n",
      "epoch 67; iter: 0; batch classifier loss: 0.268707; batch adversarial loss: 0.533812\n",
      "epoch 68; iter: 0; batch classifier loss: 0.208049; batch adversarial loss: 0.605060\n",
      "epoch 69; iter: 0; batch classifier loss: 0.330418; batch adversarial loss: 0.666945\n",
      "epoch 70; iter: 0; batch classifier loss: 0.311080; batch adversarial loss: 0.571888\n",
      "epoch 71; iter: 0; batch classifier loss: 0.321888; batch adversarial loss: 0.565351\n",
      "epoch 72; iter: 0; batch classifier loss: 0.258245; batch adversarial loss: 0.572467\n",
      "epoch 73; iter: 0; batch classifier loss: 0.322246; batch adversarial loss: 0.587766\n",
      "epoch 74; iter: 0; batch classifier loss: 0.389562; batch adversarial loss: 0.515440\n",
      "epoch 75; iter: 0; batch classifier loss: 0.251231; batch adversarial loss: 0.580619\n",
      "epoch 76; iter: 0; batch classifier loss: 0.355388; batch adversarial loss: 0.601302\n",
      "epoch 77; iter: 0; batch classifier loss: 0.304595; batch adversarial loss: 0.528637\n",
      "epoch 78; iter: 0; batch classifier loss: 0.336732; batch adversarial loss: 0.516981\n",
      "epoch 79; iter: 0; batch classifier loss: 0.237882; batch adversarial loss: 0.559202\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715102; batch adversarial loss: 0.643187\n",
      "epoch 1; iter: 0; batch classifier loss: 0.604616; batch adversarial loss: 0.640527\n",
      "epoch 2; iter: 0; batch classifier loss: 0.604030; batch adversarial loss: 0.608037\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547245; batch adversarial loss: 0.611173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.442789; batch adversarial loss: 0.597717\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461958; batch adversarial loss: 0.567889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.466336; batch adversarial loss: 0.615275\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438255; batch adversarial loss: 0.584162\n",
      "epoch 8; iter: 0; batch classifier loss: 0.357427; batch adversarial loss: 0.603056\n",
      "epoch 9; iter: 0; batch classifier loss: 0.433450; batch adversarial loss: 0.604905\n",
      "epoch 10; iter: 0; batch classifier loss: 0.397849; batch adversarial loss: 0.579869\n",
      "epoch 11; iter: 0; batch classifier loss: 0.296599; batch adversarial loss: 0.576911\n",
      "epoch 12; iter: 0; batch classifier loss: 0.283299; batch adversarial loss: 0.597961\n",
      "epoch 13; iter: 0; batch classifier loss: 0.412379; batch adversarial loss: 0.568949\n",
      "epoch 14; iter: 0; batch classifier loss: 0.366486; batch adversarial loss: 0.640118\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382361; batch adversarial loss: 0.600906\n",
      "epoch 16; iter: 0; batch classifier loss: 0.327021; batch adversarial loss: 0.637207\n",
      "epoch 17; iter: 0; batch classifier loss: 0.411918; batch adversarial loss: 0.537923\n",
      "epoch 18; iter: 0; batch classifier loss: 0.371803; batch adversarial loss: 0.585392\n",
      "epoch 19; iter: 0; batch classifier loss: 0.331079; batch adversarial loss: 0.534916\n",
      "epoch 20; iter: 0; batch classifier loss: 0.420157; batch adversarial loss: 0.621743\n",
      "epoch 21; iter: 0; batch classifier loss: 0.331676; batch adversarial loss: 0.545420\n",
      "epoch 22; iter: 0; batch classifier loss: 0.244320; batch adversarial loss: 0.603062\n",
      "epoch 23; iter: 0; batch classifier loss: 0.256192; batch adversarial loss: 0.607094\n",
      "epoch 24; iter: 0; batch classifier loss: 0.322030; batch adversarial loss: 0.690190\n",
      "epoch 25; iter: 0; batch classifier loss: 0.216959; batch adversarial loss: 0.667465\n",
      "epoch 26; iter: 0; batch classifier loss: 0.368531; batch adversarial loss: 0.667012\n",
      "epoch 27; iter: 0; batch classifier loss: 0.404577; batch adversarial loss: 0.544092\n",
      "epoch 28; iter: 0; batch classifier loss: 0.298339; batch adversarial loss: 0.636952\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303471; batch adversarial loss: 0.601033\n",
      "epoch 30; iter: 0; batch classifier loss: 0.332176; batch adversarial loss: 0.605027\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334697; batch adversarial loss: 0.600169\n",
      "epoch 32; iter: 0; batch classifier loss: 0.323027; batch adversarial loss: 0.661137\n",
      "epoch 33; iter: 0; batch classifier loss: 0.413571; batch adversarial loss: 0.555459\n",
      "epoch 34; iter: 0; batch classifier loss: 0.198554; batch adversarial loss: 0.643606\n",
      "epoch 35; iter: 0; batch classifier loss: 0.285064; batch adversarial loss: 0.624828\n",
      "epoch 36; iter: 0; batch classifier loss: 0.262790; batch adversarial loss: 0.583953\n",
      "epoch 37; iter: 0; batch classifier loss: 0.428876; batch adversarial loss: 0.596036\n",
      "epoch 38; iter: 0; batch classifier loss: 0.271902; batch adversarial loss: 0.591056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.316892; batch adversarial loss: 0.595222\n",
      "epoch 40; iter: 0; batch classifier loss: 0.412230; batch adversarial loss: 0.487689\n",
      "epoch 41; iter: 0; batch classifier loss: 0.411320; batch adversarial loss: 0.711778\n",
      "epoch 42; iter: 0; batch classifier loss: 0.464207; batch adversarial loss: 0.619085\n",
      "epoch 43; iter: 0; batch classifier loss: 0.261902; batch adversarial loss: 0.526310\n",
      "epoch 44; iter: 0; batch classifier loss: 0.211756; batch adversarial loss: 0.613693\n",
      "epoch 45; iter: 0; batch classifier loss: 0.269695; batch adversarial loss: 0.591423\n",
      "epoch 46; iter: 0; batch classifier loss: 0.296313; batch adversarial loss: 0.603554\n",
      "epoch 47; iter: 0; batch classifier loss: 0.272338; batch adversarial loss: 0.537721\n",
      "epoch 48; iter: 0; batch classifier loss: 0.207041; batch adversarial loss: 0.574772\n",
      "epoch 49; iter: 0; batch classifier loss: 0.399276; batch adversarial loss: 0.678218\n",
      "epoch 50; iter: 0; batch classifier loss: 0.293229; batch adversarial loss: 0.635813\n",
      "epoch 51; iter: 0; batch classifier loss: 0.282547; batch adversarial loss: 0.546979\n",
      "epoch 52; iter: 0; batch classifier loss: 0.350867; batch adversarial loss: 0.663581\n",
      "epoch 53; iter: 0; batch classifier loss: 0.326347; batch adversarial loss: 0.617151\n",
      "epoch 54; iter: 0; batch classifier loss: 0.239669; batch adversarial loss: 0.590270\n",
      "epoch 55; iter: 0; batch classifier loss: 0.218655; batch adversarial loss: 0.523938\n",
      "epoch 56; iter: 0; batch classifier loss: 0.161378; batch adversarial loss: 0.691273\n",
      "epoch 57; iter: 0; batch classifier loss: 0.241304; batch adversarial loss: 0.640726\n",
      "epoch 58; iter: 0; batch classifier loss: 0.270335; batch adversarial loss: 0.615471\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348436; batch adversarial loss: 0.526504\n",
      "epoch 60; iter: 0; batch classifier loss: 0.216179; batch adversarial loss: 0.601013\n",
      "epoch 61; iter: 0; batch classifier loss: 0.251891; batch adversarial loss: 0.613833\n",
      "epoch 62; iter: 0; batch classifier loss: 0.353503; batch adversarial loss: 0.626653\n",
      "epoch 63; iter: 0; batch classifier loss: 0.262354; batch adversarial loss: 0.597925\n",
      "epoch 64; iter: 0; batch classifier loss: 0.306568; batch adversarial loss: 0.708976\n",
      "epoch 65; iter: 0; batch classifier loss: 0.206402; batch adversarial loss: 0.608836\n",
      "epoch 66; iter: 0; batch classifier loss: 0.273562; batch adversarial loss: 0.547280\n",
      "epoch 67; iter: 0; batch classifier loss: 0.208263; batch adversarial loss: 0.510583\n",
      "epoch 68; iter: 0; batch classifier loss: 0.380050; batch adversarial loss: 0.653474\n",
      "epoch 69; iter: 0; batch classifier loss: 0.246684; batch adversarial loss: 0.642986\n",
      "epoch 70; iter: 0; batch classifier loss: 0.200690; batch adversarial loss: 0.533661\n",
      "epoch 71; iter: 0; batch classifier loss: 0.173339; batch adversarial loss: 0.659175\n",
      "epoch 72; iter: 0; batch classifier loss: 0.176286; batch adversarial loss: 0.501468\n",
      "epoch 73; iter: 0; batch classifier loss: 0.238525; batch adversarial loss: 0.604213\n",
      "epoch 74; iter: 0; batch classifier loss: 0.340645; batch adversarial loss: 0.585901\n",
      "epoch 75; iter: 0; batch classifier loss: 0.335018; batch adversarial loss: 0.593095\n",
      "epoch 76; iter: 0; batch classifier loss: 0.231999; batch adversarial loss: 0.560793\n",
      "epoch 77; iter: 0; batch classifier loss: 0.331604; batch adversarial loss: 0.576836\n",
      "epoch 78; iter: 0; batch classifier loss: 0.205196; batch adversarial loss: 0.626004\n",
      "epoch 79; iter: 0; batch classifier loss: 0.284874; batch adversarial loss: 0.594377\n",
      "epoch 0; iter: 0; batch classifier loss: 0.657274; batch adversarial loss: 0.660814\n",
      "epoch 1; iter: 0; batch classifier loss: 0.678028; batch adversarial loss: 0.676433\n",
      "epoch 2; iter: 0; batch classifier loss: 0.613427; batch adversarial loss: 0.654787\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614596; batch adversarial loss: 0.655283\n",
      "epoch 4; iter: 0; batch classifier loss: 0.576876; batch adversarial loss: 0.650385\n",
      "epoch 5; iter: 0; batch classifier loss: 0.534249; batch adversarial loss: 0.650789\n",
      "epoch 6; iter: 0; batch classifier loss: 0.559895; batch adversarial loss: 0.646219\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547893; batch adversarial loss: 0.642421\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541901; batch adversarial loss: 0.642087\n",
      "epoch 9; iter: 0; batch classifier loss: 0.566111; batch adversarial loss: 0.637855\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526178; batch adversarial loss: 0.652754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.533186; batch adversarial loss: 0.637506\n",
      "epoch 12; iter: 0; batch classifier loss: 0.461401; batch adversarial loss: 0.655136\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539411; batch adversarial loss: 0.631764\n",
      "epoch 14; iter: 0; batch classifier loss: 0.542478; batch adversarial loss: 0.623495\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487026; batch adversarial loss: 0.629842\n",
      "epoch 16; iter: 0; batch classifier loss: 0.543501; batch adversarial loss: 0.624084\n",
      "epoch 17; iter: 0; batch classifier loss: 0.486207; batch adversarial loss: 0.637418\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434902; batch adversarial loss: 0.627758\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457967; batch adversarial loss: 0.629259\n",
      "epoch 20; iter: 0; batch classifier loss: 0.458679; batch adversarial loss: 0.621060\n",
      "epoch 21; iter: 0; batch classifier loss: 0.535976; batch adversarial loss: 0.603392\n",
      "epoch 22; iter: 0; batch classifier loss: 0.474181; batch adversarial loss: 0.610719\n",
      "epoch 23; iter: 0; batch classifier loss: 0.397455; batch adversarial loss: 0.647883\n",
      "epoch 24; iter: 0; batch classifier loss: 0.389678; batch adversarial loss: 0.646460\n",
      "epoch 25; iter: 0; batch classifier loss: 0.423518; batch adversarial loss: 0.625484\n",
      "epoch 26; iter: 0; batch classifier loss: 0.467376; batch adversarial loss: 0.605339\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461643; batch adversarial loss: 0.610095\n",
      "epoch 28; iter: 0; batch classifier loss: 0.408642; batch adversarial loss: 0.616399\n",
      "epoch 29; iter: 0; batch classifier loss: 0.419092; batch adversarial loss: 0.618486\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378354; batch adversarial loss: 0.612149\n",
      "epoch 31; iter: 0; batch classifier loss: 0.466410; batch adversarial loss: 0.604508\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402178; batch adversarial loss: 0.616816\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344196; batch adversarial loss: 0.627303\n",
      "epoch 34; iter: 0; batch classifier loss: 0.445764; batch adversarial loss: 0.615801\n",
      "epoch 35; iter: 0; batch classifier loss: 0.391198; batch adversarial loss: 0.605166\n",
      "epoch 36; iter: 0; batch classifier loss: 0.421956; batch adversarial loss: 0.599791\n",
      "epoch 37; iter: 0; batch classifier loss: 0.387153; batch adversarial loss: 0.603182\n",
      "epoch 38; iter: 0; batch classifier loss: 0.480531; batch adversarial loss: 0.593262\n",
      "epoch 39; iter: 0; batch classifier loss: 0.363188; batch adversarial loss: 0.610739\n",
      "epoch 40; iter: 0; batch classifier loss: 0.341900; batch adversarial loss: 0.619040\n",
      "epoch 41; iter: 0; batch classifier loss: 0.356160; batch adversarial loss: 0.601698\n",
      "epoch 42; iter: 0; batch classifier loss: 0.404994; batch adversarial loss: 0.599138\n",
      "epoch 43; iter: 0; batch classifier loss: 0.388368; batch adversarial loss: 0.596039\n",
      "epoch 44; iter: 0; batch classifier loss: 0.408325; batch adversarial loss: 0.608467\n",
      "epoch 45; iter: 0; batch classifier loss: 0.389969; batch adversarial loss: 0.576927\n",
      "epoch 46; iter: 0; batch classifier loss: 0.356505; batch adversarial loss: 0.603200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.471581; batch adversarial loss: 0.605421\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376064; batch adversarial loss: 0.612490\n",
      "epoch 49; iter: 0; batch classifier loss: 0.328036; batch adversarial loss: 0.610755\n",
      "epoch 50; iter: 0; batch classifier loss: 0.372547; batch adversarial loss: 0.589342\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390700; batch adversarial loss: 0.634421\n",
      "epoch 52; iter: 0; batch classifier loss: 0.389515; batch adversarial loss: 0.590195\n",
      "epoch 53; iter: 0; batch classifier loss: 0.338394; batch adversarial loss: 0.610209\n",
      "epoch 54; iter: 0; batch classifier loss: 0.402914; batch adversarial loss: 0.611559\n",
      "epoch 55; iter: 0; batch classifier loss: 0.362527; batch adversarial loss: 0.600262\n",
      "epoch 56; iter: 0; batch classifier loss: 0.308886; batch adversarial loss: 0.567262\n",
      "epoch 57; iter: 0; batch classifier loss: 0.406019; batch adversarial loss: 0.582454\n",
      "epoch 58; iter: 0; batch classifier loss: 0.399494; batch adversarial loss: 0.575698\n",
      "epoch 59; iter: 0; batch classifier loss: 0.343917; batch adversarial loss: 0.610611\n",
      "epoch 60; iter: 0; batch classifier loss: 0.434599; batch adversarial loss: 0.583091\n",
      "epoch 61; iter: 0; batch classifier loss: 0.381527; batch adversarial loss: 0.589826\n",
      "epoch 62; iter: 0; batch classifier loss: 0.325339; batch adversarial loss: 0.577131\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362289; batch adversarial loss: 0.594985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348555; batch adversarial loss: 0.608734\n",
      "epoch 65; iter: 0; batch classifier loss: 0.314280; batch adversarial loss: 0.599700\n",
      "epoch 66; iter: 0; batch classifier loss: 0.341127; batch adversarial loss: 0.577942\n",
      "epoch 67; iter: 0; batch classifier loss: 0.461616; batch adversarial loss: 0.618795\n",
      "epoch 68; iter: 0; batch classifier loss: 0.395926; batch adversarial loss: 0.580524\n",
      "epoch 69; iter: 0; batch classifier loss: 0.368698; batch adversarial loss: 0.604148\n",
      "epoch 70; iter: 0; batch classifier loss: 0.311752; batch adversarial loss: 0.598714\n",
      "epoch 71; iter: 0; batch classifier loss: 0.283051; batch adversarial loss: 0.613413\n",
      "epoch 72; iter: 0; batch classifier loss: 0.351201; batch adversarial loss: 0.576090\n",
      "epoch 73; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.580799\n",
      "epoch 74; iter: 0; batch classifier loss: 0.341471; batch adversarial loss: 0.577254\n",
      "epoch 75; iter: 0; batch classifier loss: 0.344592; batch adversarial loss: 0.580651\n",
      "epoch 76; iter: 0; batch classifier loss: 0.359014; batch adversarial loss: 0.607612\n",
      "epoch 77; iter: 0; batch classifier loss: 0.313391; batch adversarial loss: 0.558728\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369628; batch adversarial loss: 0.591807\n",
      "epoch 79; iter: 0; batch classifier loss: 0.417644; batch adversarial loss: 0.591196\n",
      "epoch 0; iter: 0; batch classifier loss: 0.678998; batch adversarial loss: 0.709172\n",
      "epoch 1; iter: 0; batch classifier loss: 0.650480; batch adversarial loss: 0.707980\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590700; batch adversarial loss: 0.704718\n",
      "epoch 3; iter: 0; batch classifier loss: 0.574652; batch adversarial loss: 0.699939\n",
      "epoch 4; iter: 0; batch classifier loss: 0.563490; batch adversarial loss: 0.698559\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549744; batch adversarial loss: 0.695028\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519103; batch adversarial loss: 0.696797\n",
      "epoch 7; iter: 0; batch classifier loss: 0.522538; batch adversarial loss: 0.693313\n",
      "epoch 8; iter: 0; batch classifier loss: 0.529187; batch adversarial loss: 0.694168\n",
      "epoch 9; iter: 0; batch classifier loss: 0.456820; batch adversarial loss: 0.685396\n",
      "epoch 10; iter: 0; batch classifier loss: 0.503207; batch adversarial loss: 0.689883\n",
      "epoch 11; iter: 0; batch classifier loss: 0.457869; batch adversarial loss: 0.685678\n",
      "epoch 12; iter: 0; batch classifier loss: 0.477438; batch adversarial loss: 0.678063\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438266; batch adversarial loss: 0.677162\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502982; batch adversarial loss: 0.677062\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449163; batch adversarial loss: 0.674553\n",
      "epoch 16; iter: 0; batch classifier loss: 0.423233; batch adversarial loss: 0.670649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532383; batch adversarial loss: 0.674798\n",
      "epoch 18; iter: 0; batch classifier loss: 0.433046; batch adversarial loss: 0.663430\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415391; batch adversarial loss: 0.668563\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433665; batch adversarial loss: 0.660707\n",
      "epoch 21; iter: 0; batch classifier loss: 0.442824; batch adversarial loss: 0.667220\n",
      "epoch 22; iter: 0; batch classifier loss: 0.402195; batch adversarial loss: 0.659953\n",
      "epoch 23; iter: 0; batch classifier loss: 0.332624; batch adversarial loss: 0.660086\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465015; batch adversarial loss: 0.659625\n",
      "epoch 25; iter: 0; batch classifier loss: 0.356631; batch adversarial loss: 0.659660\n",
      "epoch 26; iter: 0; batch classifier loss: 0.375964; batch adversarial loss: 0.660204\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373925; batch adversarial loss: 0.645137\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368797; batch adversarial loss: 0.655536\n",
      "epoch 29; iter: 0; batch classifier loss: 0.310202; batch adversarial loss: 0.653570\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391662; batch adversarial loss: 0.655596\n",
      "epoch 31; iter: 0; batch classifier loss: 0.280173; batch adversarial loss: 0.649739\n",
      "epoch 32; iter: 0; batch classifier loss: 0.424353; batch adversarial loss: 0.643128\n",
      "epoch 33; iter: 0; batch classifier loss: 0.313375; batch adversarial loss: 0.640085\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293461; batch adversarial loss: 0.639888\n",
      "epoch 35; iter: 0; batch classifier loss: 0.400613; batch adversarial loss: 0.652246\n",
      "epoch 36; iter: 0; batch classifier loss: 0.306315; batch adversarial loss: 0.650334\n",
      "epoch 37; iter: 0; batch classifier loss: 0.342675; batch adversarial loss: 0.647230\n",
      "epoch 38; iter: 0; batch classifier loss: 0.264887; batch adversarial loss: 0.662122\n",
      "epoch 39; iter: 0; batch classifier loss: 0.289754; batch adversarial loss: 0.627752\n",
      "epoch 40; iter: 0; batch classifier loss: 0.338337; batch adversarial loss: 0.630267\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340720; batch adversarial loss: 0.631662\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283808; batch adversarial loss: 0.636713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329843; batch adversarial loss: 0.638524\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323281; batch adversarial loss: 0.626420\n",
      "epoch 45; iter: 0; batch classifier loss: 0.324280; batch adversarial loss: 0.631474\n",
      "epoch 46; iter: 0; batch classifier loss: 0.369517; batch adversarial loss: 0.646364\n",
      "epoch 47; iter: 0; batch classifier loss: 0.335729; batch adversarial loss: 0.619965\n",
      "epoch 48; iter: 0; batch classifier loss: 0.321534; batch adversarial loss: 0.625091\n",
      "epoch 49; iter: 0; batch classifier loss: 0.307441; batch adversarial loss: 0.633608\n",
      "epoch 50; iter: 0; batch classifier loss: 0.229416; batch adversarial loss: 0.614560\n",
      "epoch 51; iter: 0; batch classifier loss: 0.322668; batch adversarial loss: 0.634850\n",
      "epoch 52; iter: 0; batch classifier loss: 0.291546; batch adversarial loss: 0.617492\n",
      "epoch 53; iter: 0; batch classifier loss: 0.338849; batch adversarial loss: 0.608025\n",
      "epoch 54; iter: 0; batch classifier loss: 0.251085; batch adversarial loss: 0.615881\n",
      "epoch 55; iter: 0; batch classifier loss: 0.242427; batch adversarial loss: 0.619405\n",
      "epoch 56; iter: 0; batch classifier loss: 0.268244; batch adversarial loss: 0.624960\n",
      "epoch 57; iter: 0; batch classifier loss: 0.329719; batch adversarial loss: 0.628036\n",
      "epoch 58; iter: 0; batch classifier loss: 0.277878; batch adversarial loss: 0.638361\n",
      "epoch 59; iter: 0; batch classifier loss: 0.319595; batch adversarial loss: 0.607423\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367625; batch adversarial loss: 0.598102\n",
      "epoch 61; iter: 0; batch classifier loss: 0.253516; batch adversarial loss: 0.606024\n",
      "epoch 62; iter: 0; batch classifier loss: 0.398031; batch adversarial loss: 0.612527\n",
      "epoch 63; iter: 0; batch classifier loss: 0.317626; batch adversarial loss: 0.632075\n",
      "epoch 64; iter: 0; batch classifier loss: 0.265923; batch adversarial loss: 0.621438\n",
      "epoch 65; iter: 0; batch classifier loss: 0.328906; batch adversarial loss: 0.633322\n",
      "epoch 66; iter: 0; batch classifier loss: 0.286515; batch adversarial loss: 0.603936\n",
      "epoch 67; iter: 0; batch classifier loss: 0.318900; batch adversarial loss: 0.603144\n",
      "epoch 68; iter: 0; batch classifier loss: 0.294396; batch adversarial loss: 0.625431\n",
      "epoch 69; iter: 0; batch classifier loss: 0.319868; batch adversarial loss: 0.616048\n",
      "epoch 70; iter: 0; batch classifier loss: 0.310594; batch adversarial loss: 0.631716\n",
      "epoch 71; iter: 0; batch classifier loss: 0.358812; batch adversarial loss: 0.596746\n",
      "epoch 72; iter: 0; batch classifier loss: 0.268090; batch adversarial loss: 0.625186\n",
      "epoch 73; iter: 0; batch classifier loss: 0.268279; batch adversarial loss: 0.623787\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316045; batch adversarial loss: 0.592670\n",
      "epoch 75; iter: 0; batch classifier loss: 0.331083; batch adversarial loss: 0.611189\n",
      "epoch 76; iter: 0; batch classifier loss: 0.306270; batch adversarial loss: 0.604032\n",
      "epoch 77; iter: 0; batch classifier loss: 0.282978; batch adversarial loss: 0.614058\n",
      "epoch 78; iter: 0; batch classifier loss: 0.308723; batch adversarial loss: 0.617531\n",
      "epoch 79; iter: 0; batch classifier loss: 0.259609; batch adversarial loss: 0.613294\n",
      "epoch 0; iter: 0; batch classifier loss: 0.812855; batch adversarial loss: 0.946763\n",
      "epoch 1; iter: 0; batch classifier loss: 0.835020; batch adversarial loss: 0.984866\n",
      "epoch 2; iter: 0; batch classifier loss: 0.670594; batch adversarial loss: 0.916031\n",
      "epoch 3; iter: 0; batch classifier loss: 0.683450; batch adversarial loss: 0.919611\n",
      "epoch 4; iter: 0; batch classifier loss: 0.676050; batch adversarial loss: 0.896458\n",
      "epoch 5; iter: 0; batch classifier loss: 0.635812; batch adversarial loss: 0.928498\n",
      "epoch 6; iter: 0; batch classifier loss: 0.699253; batch adversarial loss: 0.903281\n",
      "epoch 7; iter: 0; batch classifier loss: 0.635862; batch adversarial loss: 0.853022\n",
      "epoch 8; iter: 0; batch classifier loss: 0.610418; batch adversarial loss: 0.867631\n",
      "epoch 9; iter: 0; batch classifier loss: 0.574695; batch adversarial loss: 0.872044\n",
      "epoch 10; iter: 0; batch classifier loss: 0.599506; batch adversarial loss: 0.826894\n",
      "epoch 11; iter: 0; batch classifier loss: 0.604389; batch adversarial loss: 0.820710\n",
      "epoch 12; iter: 0; batch classifier loss: 0.575678; batch adversarial loss: 0.831602\n",
      "epoch 13; iter: 0; batch classifier loss: 0.617648; batch adversarial loss: 0.834057\n",
      "epoch 14; iter: 0; batch classifier loss: 0.555496; batch adversarial loss: 0.823120\n",
      "epoch 15; iter: 0; batch classifier loss: 0.513798; batch adversarial loss: 0.823517\n",
      "epoch 16; iter: 0; batch classifier loss: 0.519540; batch adversarial loss: 0.790085\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470271; batch adversarial loss: 0.781623\n",
      "epoch 18; iter: 0; batch classifier loss: 0.566674; batch adversarial loss: 0.768351\n",
      "epoch 19; iter: 0; batch classifier loss: 0.650577; batch adversarial loss: 0.770731\n",
      "epoch 20; iter: 0; batch classifier loss: 0.548884; batch adversarial loss: 0.762798\n",
      "epoch 21; iter: 0; batch classifier loss: 0.493229; batch adversarial loss: 0.765149\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437152; batch adversarial loss: 0.752123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.486662; batch adversarial loss: 0.746773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.423568; batch adversarial loss: 0.728349\n",
      "epoch 25; iter: 0; batch classifier loss: 0.473590; batch adversarial loss: 0.734123\n",
      "epoch 26; iter: 0; batch classifier loss: 0.583306; batch adversarial loss: 0.739696\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407539; batch adversarial loss: 0.719953\n",
      "epoch 28; iter: 0; batch classifier loss: 0.505814; batch adversarial loss: 0.712609\n",
      "epoch 29; iter: 0; batch classifier loss: 0.549650; batch adversarial loss: 0.724481\n",
      "epoch 30; iter: 0; batch classifier loss: 0.565198; batch adversarial loss: 0.718030\n",
      "epoch 31; iter: 0; batch classifier loss: 0.572671; batch adversarial loss: 0.715522\n",
      "epoch 32; iter: 0; batch classifier loss: 0.473486; batch adversarial loss: 0.710740\n",
      "epoch 33; iter: 0; batch classifier loss: 0.419091; batch adversarial loss: 0.701919\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437927; batch adversarial loss: 0.696579\n",
      "epoch 35; iter: 0; batch classifier loss: 0.475463; batch adversarial loss: 0.689911\n",
      "epoch 36; iter: 0; batch classifier loss: 0.448478; batch adversarial loss: 0.685194\n",
      "epoch 37; iter: 0; batch classifier loss: 0.555853; batch adversarial loss: 0.685558\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478924; batch adversarial loss: 0.677080\n",
      "epoch 39; iter: 0; batch classifier loss: 0.496883; batch adversarial loss: 0.673886\n",
      "epoch 0; iter: 0; batch classifier loss: 0.767120; batch adversarial loss: 0.720739\n",
      "epoch 1; iter: 0; batch classifier loss: 0.622347; batch adversarial loss: 0.716857\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607082; batch adversarial loss: 0.720339\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594804; batch adversarial loss: 0.707920\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548807; batch adversarial loss: 0.701185\n",
      "epoch 5; iter: 0; batch classifier loss: 0.490687; batch adversarial loss: 0.695814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519058; batch adversarial loss: 0.703235\n",
      "epoch 7; iter: 0; batch classifier loss: 0.474818; batch adversarial loss: 0.681196\n",
      "epoch 8; iter: 0; batch classifier loss: 0.460102; batch adversarial loss: 0.681600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.452003; batch adversarial loss: 0.681834\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480507; batch adversarial loss: 0.681133\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498003; batch adversarial loss: 0.660950\n",
      "epoch 12; iter: 0; batch classifier loss: 0.349214; batch adversarial loss: 0.665091\n",
      "epoch 13; iter: 0; batch classifier loss: 0.371741; batch adversarial loss: 0.654732\n",
      "epoch 14; iter: 0; batch classifier loss: 0.296165; batch adversarial loss: 0.643125\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432939; batch adversarial loss: 0.657931\n",
      "epoch 16; iter: 0; batch classifier loss: 0.339097; batch adversarial loss: 0.669801\n",
      "epoch 17; iter: 0; batch classifier loss: 0.380601; batch adversarial loss: 0.634293\n",
      "epoch 18; iter: 0; batch classifier loss: 0.293005; batch adversarial loss: 0.630001\n",
      "epoch 19; iter: 0; batch classifier loss: 0.370481; batch adversarial loss: 0.643817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.506604; batch adversarial loss: 0.655285\n",
      "epoch 21; iter: 0; batch classifier loss: 0.319314; batch adversarial loss: 0.642326\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329397; batch adversarial loss: 0.620862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.424183; batch adversarial loss: 0.623808\n",
      "epoch 24; iter: 0; batch classifier loss: 0.275013; batch adversarial loss: 0.609003\n",
      "epoch 25; iter: 0; batch classifier loss: 0.316399; batch adversarial loss: 0.621117\n",
      "epoch 26; iter: 0; batch classifier loss: 0.319535; batch adversarial loss: 0.597484\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277882; batch adversarial loss: 0.629666\n",
      "epoch 28; iter: 0; batch classifier loss: 0.445254; batch adversarial loss: 0.608447\n",
      "epoch 29; iter: 0; batch classifier loss: 0.360938; batch adversarial loss: 0.614312\n",
      "epoch 30; iter: 0; batch classifier loss: 0.300419; batch adversarial loss: 0.590502\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306364; batch adversarial loss: 0.603397\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356286; batch adversarial loss: 0.641577\n",
      "epoch 33; iter: 0; batch classifier loss: 0.314994; batch adversarial loss: 0.614529\n",
      "epoch 34; iter: 0; batch classifier loss: 0.343556; batch adversarial loss: 0.586202\n",
      "epoch 35; iter: 0; batch classifier loss: 0.372202; batch adversarial loss: 0.601441\n",
      "epoch 36; iter: 0; batch classifier loss: 0.257700; batch adversarial loss: 0.599968\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363020; batch adversarial loss: 0.615081\n",
      "epoch 38; iter: 0; batch classifier loss: 0.325838; batch adversarial loss: 0.604181\n",
      "epoch 39; iter: 0; batch classifier loss: 0.176845; batch adversarial loss: 0.576382\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730549; batch adversarial loss: 0.678396\n",
      "epoch 1; iter: 0; batch classifier loss: 0.675264; batch adversarial loss: 0.681582\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589761; batch adversarial loss: 0.687764\n",
      "epoch 3; iter: 0; batch classifier loss: 0.642414; batch adversarial loss: 0.683072\n",
      "epoch 4; iter: 0; batch classifier loss: 0.617077; batch adversarial loss: 0.669755\n",
      "epoch 5; iter: 0; batch classifier loss: 0.585580; batch adversarial loss: 0.671408\n",
      "epoch 6; iter: 0; batch classifier loss: 0.577085; batch adversarial loss: 0.687979\n",
      "epoch 7; iter: 0; batch classifier loss: 0.544519; batch adversarial loss: 0.673841\n",
      "epoch 8; iter: 0; batch classifier loss: 0.615839; batch adversarial loss: 0.669061\n",
      "epoch 9; iter: 0; batch classifier loss: 0.548436; batch adversarial loss: 0.666374\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557173; batch adversarial loss: 0.679956\n",
      "epoch 11; iter: 0; batch classifier loss: 0.529595; batch adversarial loss: 0.649835\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475686; batch adversarial loss: 0.675605\n",
      "epoch 13; iter: 0; batch classifier loss: 0.488990; batch adversarial loss: 0.660488\n",
      "epoch 14; iter: 0; batch classifier loss: 0.521248; batch adversarial loss: 0.679324\n",
      "epoch 15; iter: 0; batch classifier loss: 0.502653; batch adversarial loss: 0.644898\n",
      "epoch 16; iter: 0; batch classifier loss: 0.493216; batch adversarial loss: 0.649040\n",
      "epoch 17; iter: 0; batch classifier loss: 0.488037; batch adversarial loss: 0.652476\n",
      "epoch 18; iter: 0; batch classifier loss: 0.462017; batch adversarial loss: 0.658454\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505974; batch adversarial loss: 0.648925\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502873; batch adversarial loss: 0.631895\n",
      "epoch 21; iter: 0; batch classifier loss: 0.462160; batch adversarial loss: 0.653431\n",
      "epoch 22; iter: 0; batch classifier loss: 0.466512; batch adversarial loss: 0.645514\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477853; batch adversarial loss: 0.641541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.421035; batch adversarial loss: 0.655172\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402280; batch adversarial loss: 0.640203\n",
      "epoch 26; iter: 0; batch classifier loss: 0.391776; batch adversarial loss: 0.657920\n",
      "epoch 27; iter: 0; batch classifier loss: 0.404750; batch adversarial loss: 0.651133\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397384; batch adversarial loss: 0.649444\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443291; batch adversarial loss: 0.645094\n",
      "epoch 30; iter: 0; batch classifier loss: 0.436074; batch adversarial loss: 0.641287\n",
      "epoch 31; iter: 0; batch classifier loss: 0.358603; batch adversarial loss: 0.635239\n",
      "epoch 32; iter: 0; batch classifier loss: 0.382529; batch adversarial loss: 0.641908\n",
      "epoch 33; iter: 0; batch classifier loss: 0.359342; batch adversarial loss: 0.646019\n",
      "epoch 34; iter: 0; batch classifier loss: 0.391002; batch adversarial loss: 0.632848\n",
      "epoch 35; iter: 0; batch classifier loss: 0.392342; batch adversarial loss: 0.643180\n",
      "epoch 36; iter: 0; batch classifier loss: 0.474285; batch adversarial loss: 0.653175\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346406; batch adversarial loss: 0.621724\n",
      "epoch 38; iter: 0; batch classifier loss: 0.447313; batch adversarial loss: 0.619704\n",
      "epoch 39; iter: 0; batch classifier loss: 0.309444; batch adversarial loss: 0.642136\n",
      "epoch 0; iter: 0; batch classifier loss: 0.763589; batch adversarial loss: 0.991687\n",
      "epoch 1; iter: 0; batch classifier loss: 0.730677; batch adversarial loss: 0.940341\n",
      "epoch 2; iter: 0; batch classifier loss: 0.704910; batch adversarial loss: 0.964476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.697135; batch adversarial loss: 0.925634\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634671; batch adversarial loss: 0.990625\n",
      "epoch 5; iter: 0; batch classifier loss: 0.577765; batch adversarial loss: 1.004941\n",
      "epoch 6; iter: 0; batch classifier loss: 0.590772; batch adversarial loss: 0.989195\n",
      "epoch 7; iter: 0; batch classifier loss: 0.531496; batch adversarial loss: 1.001147\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530245; batch adversarial loss: 0.973551\n",
      "epoch 9; iter: 0; batch classifier loss: 0.527030; batch adversarial loss: 1.018301\n",
      "epoch 10; iter: 0; batch classifier loss: 0.509793; batch adversarial loss: 1.029925\n",
      "epoch 11; iter: 0; batch classifier loss: 0.539861; batch adversarial loss: 0.972078\n",
      "epoch 12; iter: 0; batch classifier loss: 0.489218; batch adversarial loss: 1.001331\n",
      "epoch 13; iter: 0; batch classifier loss: 0.467635; batch adversarial loss: 0.937448\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487583; batch adversarial loss: 0.924427\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422943; batch adversarial loss: 0.952537\n",
      "epoch 16; iter: 0; batch classifier loss: 0.420845; batch adversarial loss: 1.012115\n",
      "epoch 17; iter: 0; batch classifier loss: 0.454139; batch adversarial loss: 0.966324\n",
      "epoch 18; iter: 0; batch classifier loss: 0.341520; batch adversarial loss: 1.024557\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435464; batch adversarial loss: 1.002125\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433099; batch adversarial loss: 1.007851\n",
      "epoch 21; iter: 0; batch classifier loss: 0.406199; batch adversarial loss: 0.950789\n",
      "epoch 22; iter: 0; batch classifier loss: 0.324262; batch adversarial loss: 0.922762\n",
      "epoch 23; iter: 0; batch classifier loss: 0.409346; batch adversarial loss: 0.891331\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324949; batch adversarial loss: 0.927089\n",
      "epoch 25; iter: 0; batch classifier loss: 0.407067; batch adversarial loss: 0.980455\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356008; batch adversarial loss: 0.936452\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373614; batch adversarial loss: 0.996623\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416597; batch adversarial loss: 0.916439\n",
      "epoch 29; iter: 0; batch classifier loss: 0.397675; batch adversarial loss: 1.041589\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404096; batch adversarial loss: 0.983829\n",
      "epoch 31; iter: 0; batch classifier loss: 0.387269; batch adversarial loss: 0.937601\n",
      "epoch 32; iter: 0; batch classifier loss: 0.375764; batch adversarial loss: 0.994689\n",
      "epoch 33; iter: 0; batch classifier loss: 0.387295; batch adversarial loss: 0.951598\n",
      "epoch 34; iter: 0; batch classifier loss: 0.331724; batch adversarial loss: 0.957448\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337008; batch adversarial loss: 0.981670\n",
      "epoch 36; iter: 0; batch classifier loss: 0.312747; batch adversarial loss: 0.900051\n",
      "epoch 37; iter: 0; batch classifier loss: 0.390995; batch adversarial loss: 0.936137\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377583; batch adversarial loss: 0.884534\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353619; batch adversarial loss: 0.946771\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710482; batch adversarial loss: 0.607087\n",
      "epoch 1; iter: 0; batch classifier loss: 0.675608; batch adversarial loss: 0.669890\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624597; batch adversarial loss: 0.646614\n",
      "epoch 3; iter: 0; batch classifier loss: 0.582890; batch adversarial loss: 0.598667\n",
      "epoch 4; iter: 0; batch classifier loss: 0.582815; batch adversarial loss: 0.590700\n",
      "epoch 5; iter: 0; batch classifier loss: 0.486948; batch adversarial loss: 0.574508\n",
      "epoch 6; iter: 0; batch classifier loss: 0.519058; batch adversarial loss: 0.610732\n",
      "epoch 7; iter: 0; batch classifier loss: 0.468361; batch adversarial loss: 0.625527\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455984; batch adversarial loss: 0.571228\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471927; batch adversarial loss: 0.643819\n",
      "epoch 10; iter: 0; batch classifier loss: 0.490585; batch adversarial loss: 0.656097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.527099; batch adversarial loss: 0.619805\n",
      "epoch 12; iter: 0; batch classifier loss: 0.311919; batch adversarial loss: 0.574932\n",
      "epoch 13; iter: 0; batch classifier loss: 0.404002; batch adversarial loss: 0.599304\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459477; batch adversarial loss: 0.622408\n",
      "epoch 15; iter: 0; batch classifier loss: 0.419175; batch adversarial loss: 0.644833\n",
      "epoch 16; iter: 0; batch classifier loss: 0.503254; batch adversarial loss: 0.564348\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462629; batch adversarial loss: 0.639007\n",
      "epoch 18; iter: 0; batch classifier loss: 0.327832; batch adversarial loss: 0.573484\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444745; batch adversarial loss: 0.644286\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440619; batch adversarial loss: 0.602777\n",
      "epoch 21; iter: 0; batch classifier loss: 0.359956; batch adversarial loss: 0.582953\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378114; batch adversarial loss: 0.643535\n",
      "epoch 23; iter: 0; batch classifier loss: 0.306107; batch adversarial loss: 0.643865\n",
      "epoch 24; iter: 0; batch classifier loss: 0.388014; batch adversarial loss: 0.598959\n",
      "epoch 25; iter: 0; batch classifier loss: 0.301535; batch adversarial loss: 0.665036\n",
      "epoch 26; iter: 0; batch classifier loss: 0.285282; batch adversarial loss: 0.600899\n",
      "epoch 27; iter: 0; batch classifier loss: 0.286212; batch adversarial loss: 0.573106\n",
      "epoch 28; iter: 0; batch classifier loss: 0.237442; batch adversarial loss: 0.623467\n",
      "epoch 29; iter: 0; batch classifier loss: 0.301984; batch adversarial loss: 0.557562\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318880; batch adversarial loss: 0.679669\n",
      "epoch 31; iter: 0; batch classifier loss: 0.349045; batch adversarial loss: 0.608401\n",
      "epoch 32; iter: 0; batch classifier loss: 0.363684; batch adversarial loss: 0.646869\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310140; batch adversarial loss: 0.612647\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357076; batch adversarial loss: 0.650945\n",
      "epoch 35; iter: 0; batch classifier loss: 0.381867; batch adversarial loss: 0.568817\n",
      "epoch 36; iter: 0; batch classifier loss: 0.243312; batch adversarial loss: 0.590608\n",
      "epoch 37; iter: 0; batch classifier loss: 0.250646; batch adversarial loss: 0.675018\n",
      "epoch 38; iter: 0; batch classifier loss: 0.344405; batch adversarial loss: 0.606365\n",
      "epoch 39; iter: 0; batch classifier loss: 0.242131; batch adversarial loss: 0.496787\n",
      "epoch 40; iter: 0; batch classifier loss: 0.398400; batch adversarial loss: 0.691604\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378961; batch adversarial loss: 0.699410\n",
      "epoch 42; iter: 0; batch classifier loss: 0.346608; batch adversarial loss: 0.578559\n",
      "epoch 43; iter: 0; batch classifier loss: 0.487853; batch adversarial loss: 0.527910\n",
      "epoch 44; iter: 0; batch classifier loss: 0.339304; batch adversarial loss: 0.566490\n",
      "epoch 45; iter: 0; batch classifier loss: 0.381175; batch adversarial loss: 0.625971\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357136; batch adversarial loss: 0.632585\n",
      "epoch 47; iter: 0; batch classifier loss: 0.242241; batch adversarial loss: 0.533665\n",
      "epoch 48; iter: 0; batch classifier loss: 0.335707; batch adversarial loss: 0.618708\n",
      "epoch 49; iter: 0; batch classifier loss: 0.338840; batch adversarial loss: 0.582877\n",
      "epoch 50; iter: 0; batch classifier loss: 0.240626; batch adversarial loss: 0.610932\n",
      "epoch 51; iter: 0; batch classifier loss: 0.275864; batch adversarial loss: 0.507160\n",
      "epoch 52; iter: 0; batch classifier loss: 0.272738; batch adversarial loss: 0.540070\n",
      "epoch 53; iter: 0; batch classifier loss: 0.367169; batch adversarial loss: 0.611618\n",
      "epoch 54; iter: 0; batch classifier loss: 0.391191; batch adversarial loss: 0.696475\n",
      "epoch 55; iter: 0; batch classifier loss: 0.329379; batch adversarial loss: 0.585991\n",
      "epoch 56; iter: 0; batch classifier loss: 0.368870; batch adversarial loss: 0.535419\n",
      "epoch 57; iter: 0; batch classifier loss: 0.362426; batch adversarial loss: 0.607937\n",
      "epoch 58; iter: 0; batch classifier loss: 0.491821; batch adversarial loss: 0.564023\n",
      "epoch 59; iter: 0; batch classifier loss: 0.428828; batch adversarial loss: 0.552564\n",
      "epoch 0; iter: 0; batch classifier loss: 0.710107; batch adversarial loss: 0.689156\n",
      "epoch 1; iter: 0; batch classifier loss: 0.617022; batch adversarial loss: 0.675484\n",
      "epoch 2; iter: 0; batch classifier loss: 0.580836; batch adversarial loss: 0.679957\n",
      "epoch 3; iter: 0; batch classifier loss: 0.501651; batch adversarial loss: 0.665500\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501013; batch adversarial loss: 0.676710\n",
      "epoch 5; iter: 0; batch classifier loss: 0.465801; batch adversarial loss: 0.656141\n",
      "epoch 6; iter: 0; batch classifier loss: 0.451036; batch adversarial loss: 0.649777\n",
      "epoch 7; iter: 0; batch classifier loss: 0.414687; batch adversarial loss: 0.653390\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455584; batch adversarial loss: 0.647608\n",
      "epoch 9; iter: 0; batch classifier loss: 0.401309; batch adversarial loss: 0.665401\n",
      "epoch 10; iter: 0; batch classifier loss: 0.440065; batch adversarial loss: 0.634589\n",
      "epoch 11; iter: 0; batch classifier loss: 0.363099; batch adversarial loss: 0.645898\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376250; batch adversarial loss: 0.655125\n",
      "epoch 13; iter: 0; batch classifier loss: 0.339509; batch adversarial loss: 0.643065\n",
      "epoch 14; iter: 0; batch classifier loss: 0.269204; batch adversarial loss: 0.632470\n",
      "epoch 15; iter: 0; batch classifier loss: 0.323555; batch adversarial loss: 0.635089\n",
      "epoch 16; iter: 0; batch classifier loss: 0.324596; batch adversarial loss: 0.663475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.410991; batch adversarial loss: 0.624143\n",
      "epoch 18; iter: 0; batch classifier loss: 0.282814; batch adversarial loss: 0.614023\n",
      "epoch 19; iter: 0; batch classifier loss: 0.430288; batch adversarial loss: 0.604420\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337622; batch adversarial loss: 0.640978\n",
      "epoch 21; iter: 0; batch classifier loss: 0.256656; batch adversarial loss: 0.637276\n",
      "epoch 22; iter: 0; batch classifier loss: 0.363786; batch adversarial loss: 0.610156\n",
      "epoch 23; iter: 0; batch classifier loss: 0.355729; batch adversarial loss: 0.578073\n",
      "epoch 24; iter: 0; batch classifier loss: 0.265352; batch adversarial loss: 0.639214\n",
      "epoch 25; iter: 0; batch classifier loss: 0.432137; batch adversarial loss: 0.640946\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356070; batch adversarial loss: 0.615488\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253264; batch adversarial loss: 0.601379\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273207; batch adversarial loss: 0.639532\n",
      "epoch 29; iter: 0; batch classifier loss: 0.383500; batch adversarial loss: 0.556284\n",
      "epoch 30; iter: 0; batch classifier loss: 0.315017; batch adversarial loss: 0.576663\n",
      "epoch 31; iter: 0; batch classifier loss: 0.278970; batch adversarial loss: 0.589435\n",
      "epoch 32; iter: 0; batch classifier loss: 0.260113; batch adversarial loss: 0.627304\n",
      "epoch 33; iter: 0; batch classifier loss: 0.249938; batch adversarial loss: 0.610318\n",
      "epoch 34; iter: 0; batch classifier loss: 0.361545; batch adversarial loss: 0.611824\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333641; batch adversarial loss: 0.596431\n",
      "epoch 36; iter: 0; batch classifier loss: 0.277465; batch adversarial loss: 0.575276\n",
      "epoch 37; iter: 0; batch classifier loss: 0.177993; batch adversarial loss: 0.600195\n",
      "epoch 38; iter: 0; batch classifier loss: 0.262254; batch adversarial loss: 0.643530\n",
      "epoch 39; iter: 0; batch classifier loss: 0.294013; batch adversarial loss: 0.590107\n",
      "epoch 40; iter: 0; batch classifier loss: 0.425168; batch adversarial loss: 0.590696\n",
      "epoch 41; iter: 0; batch classifier loss: 0.277920; batch adversarial loss: 0.646614\n",
      "epoch 42; iter: 0; batch classifier loss: 0.324554; batch adversarial loss: 0.548142\n",
      "epoch 43; iter: 0; batch classifier loss: 0.190299; batch adversarial loss: 0.583251\n",
      "epoch 44; iter: 0; batch classifier loss: 0.261903; batch adversarial loss: 0.634319\n",
      "epoch 45; iter: 0; batch classifier loss: 0.311312; batch adversarial loss: 0.560078\n",
      "epoch 46; iter: 0; batch classifier loss: 0.264105; batch adversarial loss: 0.620834\n",
      "epoch 47; iter: 0; batch classifier loss: 0.326328; batch adversarial loss: 0.570620\n",
      "epoch 48; iter: 0; batch classifier loss: 0.232314; batch adversarial loss: 0.573937\n",
      "epoch 49; iter: 0; batch classifier loss: 0.239885; batch adversarial loss: 0.683522\n",
      "epoch 50; iter: 0; batch classifier loss: 0.258702; batch adversarial loss: 0.565664\n",
      "epoch 51; iter: 0; batch classifier loss: 0.296975; batch adversarial loss: 0.664610\n",
      "epoch 52; iter: 0; batch classifier loss: 0.252652; batch adversarial loss: 0.583674\n",
      "epoch 53; iter: 0; batch classifier loss: 0.333191; batch adversarial loss: 0.592385\n",
      "epoch 54; iter: 0; batch classifier loss: 0.237854; batch adversarial loss: 0.545335\n",
      "epoch 55; iter: 0; batch classifier loss: 0.314246; batch adversarial loss: 0.625538\n",
      "epoch 56; iter: 0; batch classifier loss: 0.346554; batch adversarial loss: 0.547718\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270399; batch adversarial loss: 0.597010\n",
      "epoch 58; iter: 0; batch classifier loss: 0.370378; batch adversarial loss: 0.560258\n",
      "epoch 59; iter: 0; batch classifier loss: 0.355431; batch adversarial loss: 0.622804\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747970; batch adversarial loss: 0.660295\n",
      "epoch 1; iter: 0; batch classifier loss: 0.696157; batch adversarial loss: 0.648516\n",
      "epoch 2; iter: 0; batch classifier loss: 0.666140; batch adversarial loss: 0.651439\n",
      "epoch 3; iter: 0; batch classifier loss: 0.643884; batch adversarial loss: 0.644163\n",
      "epoch 4; iter: 0; batch classifier loss: 0.628364; batch adversarial loss: 0.626422\n",
      "epoch 5; iter: 0; batch classifier loss: 0.568086; batch adversarial loss: 0.636810\n",
      "epoch 6; iter: 0; batch classifier loss: 0.597552; batch adversarial loss: 0.643994\n",
      "epoch 7; iter: 0; batch classifier loss: 0.599459; batch adversarial loss: 0.624756\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566184; batch adversarial loss: 0.613883\n",
      "epoch 9; iter: 0; batch classifier loss: 0.564737; batch adversarial loss: 0.649588\n",
      "epoch 10; iter: 0; batch classifier loss: 0.543461; batch adversarial loss: 0.619580\n",
      "epoch 11; iter: 0; batch classifier loss: 0.555865; batch adversarial loss: 0.620264\n",
      "epoch 12; iter: 0; batch classifier loss: 0.504969; batch adversarial loss: 0.625360\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500013; batch adversarial loss: 0.632382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.499793; batch adversarial loss: 0.625554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.487065; batch adversarial loss: 0.627549\n",
      "epoch 16; iter: 0; batch classifier loss: 0.499942; batch adversarial loss: 0.606058\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443108; batch adversarial loss: 0.623485\n",
      "epoch 18; iter: 0; batch classifier loss: 0.523608; batch adversarial loss: 0.638165\n",
      "epoch 19; iter: 0; batch classifier loss: 0.529361; batch adversarial loss: 0.615346\n",
      "epoch 20; iter: 0; batch classifier loss: 0.462552; batch adversarial loss: 0.653188\n",
      "epoch 21; iter: 0; batch classifier loss: 0.404024; batch adversarial loss: 0.555044\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423242; batch adversarial loss: 0.618685\n",
      "epoch 23; iter: 0; batch classifier loss: 0.429970; batch adversarial loss: 0.646712\n",
      "epoch 24; iter: 0; batch classifier loss: 0.397393; batch adversarial loss: 0.602121\n",
      "epoch 25; iter: 0; batch classifier loss: 0.427402; batch adversarial loss: 0.594974\n",
      "epoch 26; iter: 0; batch classifier loss: 0.425964; batch adversarial loss: 0.641297\n",
      "epoch 27; iter: 0; batch classifier loss: 0.433298; batch adversarial loss: 0.579275\n",
      "epoch 28; iter: 0; batch classifier loss: 0.382207; batch adversarial loss: 0.623204\n",
      "epoch 29; iter: 0; batch classifier loss: 0.410314; batch adversarial loss: 0.597211\n",
      "epoch 30; iter: 0; batch classifier loss: 0.395801; batch adversarial loss: 0.603323\n",
      "epoch 31; iter: 0; batch classifier loss: 0.433510; batch adversarial loss: 0.612022\n",
      "epoch 32; iter: 0; batch classifier loss: 0.412222; batch adversarial loss: 0.642910\n",
      "epoch 33; iter: 0; batch classifier loss: 0.371555; batch adversarial loss: 0.615313\n",
      "epoch 34; iter: 0; batch classifier loss: 0.369001; batch adversarial loss: 0.580898\n",
      "epoch 35; iter: 0; batch classifier loss: 0.366415; batch adversarial loss: 0.592268\n",
      "epoch 36; iter: 0; batch classifier loss: 0.406881; batch adversarial loss: 0.625127\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334502; batch adversarial loss: 0.624141\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396976; batch adversarial loss: 0.605566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.360506; batch adversarial loss: 0.613413\n",
      "epoch 40; iter: 0; batch classifier loss: 0.334624; batch adversarial loss: 0.618692\n",
      "epoch 41; iter: 0; batch classifier loss: 0.355028; batch adversarial loss: 0.657864\n",
      "epoch 42; iter: 0; batch classifier loss: 0.439557; batch adversarial loss: 0.615370\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394011; batch adversarial loss: 0.623100\n",
      "epoch 44; iter: 0; batch classifier loss: 0.338665; batch adversarial loss: 0.634982\n",
      "epoch 45; iter: 0; batch classifier loss: 0.336163; batch adversarial loss: 0.566371\n",
      "epoch 46; iter: 0; batch classifier loss: 0.253669; batch adversarial loss: 0.611706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.344254; batch adversarial loss: 0.606472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.355677; batch adversarial loss: 0.576324\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357398; batch adversarial loss: 0.619343\n",
      "epoch 50; iter: 0; batch classifier loss: 0.355632; batch adversarial loss: 0.595532\n",
      "epoch 51; iter: 0; batch classifier loss: 0.315670; batch adversarial loss: 0.626860\n",
      "epoch 52; iter: 0; batch classifier loss: 0.321876; batch adversarial loss: 0.599452\n",
      "epoch 53; iter: 0; batch classifier loss: 0.371095; batch adversarial loss: 0.594627\n",
      "epoch 54; iter: 0; batch classifier loss: 0.349549; batch adversarial loss: 0.622705\n",
      "epoch 55; iter: 0; batch classifier loss: 0.338869; batch adversarial loss: 0.621314\n",
      "epoch 56; iter: 0; batch classifier loss: 0.305192; batch adversarial loss: 0.639312\n",
      "epoch 57; iter: 0; batch classifier loss: 0.300151; batch adversarial loss: 0.565895\n",
      "epoch 58; iter: 0; batch classifier loss: 0.361661; batch adversarial loss: 0.632793\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396701; batch adversarial loss: 0.616800\n",
      "epoch 0; iter: 0; batch classifier loss: 0.820294; batch adversarial loss: 0.707423\n",
      "epoch 1; iter: 0; batch classifier loss: 0.743490; batch adversarial loss: 0.712570\n",
      "epoch 2; iter: 0; batch classifier loss: 0.739430; batch adversarial loss: 0.673756\n",
      "epoch 3; iter: 0; batch classifier loss: 0.687956; batch adversarial loss: 0.694173\n",
      "epoch 4; iter: 0; batch classifier loss: 0.689759; batch adversarial loss: 0.666002\n",
      "epoch 5; iter: 0; batch classifier loss: 0.684458; batch adversarial loss: 0.661244\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656370; batch adversarial loss: 0.695283\n",
      "epoch 7; iter: 0; batch classifier loss: 0.635236; batch adversarial loss: 0.683387\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613673; batch adversarial loss: 0.682549\n",
      "epoch 9; iter: 0; batch classifier loss: 0.629521; batch adversarial loss: 0.674126\n",
      "epoch 10; iter: 0; batch classifier loss: 0.570914; batch adversarial loss: 0.692246\n",
      "epoch 11; iter: 0; batch classifier loss: 0.560705; batch adversarial loss: 0.692929\n",
      "epoch 12; iter: 0; batch classifier loss: 0.574692; batch adversarial loss: 0.661795\n",
      "epoch 13; iter: 0; batch classifier loss: 0.539565; batch adversarial loss: 0.692930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.515722; batch adversarial loss: 0.699834\n",
      "epoch 15; iter: 0; batch classifier loss: 0.524827; batch adversarial loss: 0.668864\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536151; batch adversarial loss: 0.653285\n",
      "epoch 17; iter: 0; batch classifier loss: 0.529560; batch adversarial loss: 0.674392\n",
      "epoch 18; iter: 0; batch classifier loss: 0.485656; batch adversarial loss: 0.681436\n",
      "epoch 19; iter: 0; batch classifier loss: 0.464715; batch adversarial loss: 0.675355\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492009; batch adversarial loss: 0.678693\n",
      "epoch 21; iter: 0; batch classifier loss: 0.534609; batch adversarial loss: 0.666386\n",
      "epoch 22; iter: 0; batch classifier loss: 0.429286; batch adversarial loss: 0.692042\n",
      "epoch 23; iter: 0; batch classifier loss: 0.540188; batch adversarial loss: 0.645023\n",
      "epoch 24; iter: 0; batch classifier loss: 0.445114; batch adversarial loss: 0.672286\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446417; batch adversarial loss: 0.671911\n",
      "epoch 26; iter: 0; batch classifier loss: 0.413772; batch adversarial loss: 0.667781\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390710; batch adversarial loss: 0.671926\n",
      "epoch 28; iter: 0; batch classifier loss: 0.425407; batch adversarial loss: 0.674193\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456699; batch adversarial loss: 0.653093\n",
      "epoch 30; iter: 0; batch classifier loss: 0.385574; batch adversarial loss: 0.670163\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409963; batch adversarial loss: 0.690173\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409623; batch adversarial loss: 0.648075\n",
      "epoch 33; iter: 0; batch classifier loss: 0.416703; batch adversarial loss: 0.648376\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395023; batch adversarial loss: 0.681561\n",
      "epoch 35; iter: 0; batch classifier loss: 0.430190; batch adversarial loss: 0.668899\n",
      "epoch 36; iter: 0; batch classifier loss: 0.414051; batch adversarial loss: 0.668041\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343530; batch adversarial loss: 0.672256\n",
      "epoch 38; iter: 0; batch classifier loss: 0.342997; batch adversarial loss: 0.650099\n",
      "epoch 39; iter: 0; batch classifier loss: 0.318354; batch adversarial loss: 0.658954\n",
      "epoch 40; iter: 0; batch classifier loss: 0.391140; batch adversarial loss: 0.630148\n",
      "epoch 41; iter: 0; batch classifier loss: 0.306617; batch adversarial loss: 0.665110\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306266; batch adversarial loss: 0.655874\n",
      "epoch 43; iter: 0; batch classifier loss: 0.348864; batch adversarial loss: 0.650765\n",
      "epoch 44; iter: 0; batch classifier loss: 0.302217; batch adversarial loss: 0.654656\n",
      "epoch 45; iter: 0; batch classifier loss: 0.375174; batch adversarial loss: 0.635420\n",
      "epoch 46; iter: 0; batch classifier loss: 0.303562; batch adversarial loss: 0.654767\n",
      "epoch 47; iter: 0; batch classifier loss: 0.314138; batch adversarial loss: 0.640102\n",
      "epoch 48; iter: 0; batch classifier loss: 0.370270; batch adversarial loss: 0.631982\n",
      "epoch 49; iter: 0; batch classifier loss: 0.361335; batch adversarial loss: 0.649940\n",
      "epoch 50; iter: 0; batch classifier loss: 0.285324; batch adversarial loss: 0.639537\n",
      "epoch 51; iter: 0; batch classifier loss: 0.308622; batch adversarial loss: 0.645200\n",
      "epoch 52; iter: 0; batch classifier loss: 0.374834; batch adversarial loss: 0.641801\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389347; batch adversarial loss: 0.628936\n",
      "epoch 54; iter: 0; batch classifier loss: 0.384723; batch adversarial loss: 0.672006\n",
      "epoch 55; iter: 0; batch classifier loss: 0.332858; batch adversarial loss: 0.635092\n",
      "epoch 56; iter: 0; batch classifier loss: 0.360087; batch adversarial loss: 0.632702\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347891; batch adversarial loss: 0.627244\n",
      "epoch 58; iter: 0; batch classifier loss: 0.330535; batch adversarial loss: 0.630161\n",
      "epoch 59; iter: 0; batch classifier loss: 0.369659; batch adversarial loss: 0.614905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.703474; batch adversarial loss: 0.641848\n",
      "epoch 1; iter: 0; batch classifier loss: 0.590786; batch adversarial loss: 0.610481\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591103; batch adversarial loss: 0.609608\n",
      "epoch 3; iter: 0; batch classifier loss: 0.542917; batch adversarial loss: 0.605440\n",
      "epoch 4; iter: 0; batch classifier loss: 0.528764; batch adversarial loss: 0.549060\n",
      "epoch 5; iter: 0; batch classifier loss: 0.497356; batch adversarial loss: 0.643881\n",
      "epoch 6; iter: 0; batch classifier loss: 0.484952; batch adversarial loss: 0.601778\n",
      "epoch 7; iter: 0; batch classifier loss: 0.473436; batch adversarial loss: 0.616735\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526447; batch adversarial loss: 0.632869\n",
      "epoch 9; iter: 0; batch classifier loss: 0.432091; batch adversarial loss: 0.617010\n",
      "epoch 10; iter: 0; batch classifier loss: 0.496913; batch adversarial loss: 0.557286\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441833; batch adversarial loss: 0.694567\n",
      "epoch 12; iter: 0; batch classifier loss: 0.475265; batch adversarial loss: 0.581637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.439427; batch adversarial loss: 0.626755\n",
      "epoch 14; iter: 0; batch classifier loss: 0.350019; batch adversarial loss: 0.634106\n",
      "epoch 15; iter: 0; batch classifier loss: 0.382164; batch adversarial loss: 0.474707\n",
      "epoch 16; iter: 0; batch classifier loss: 0.381120; batch adversarial loss: 0.664563\n",
      "epoch 17; iter: 0; batch classifier loss: 0.339835; batch adversarial loss: 0.596475\n",
      "epoch 18; iter: 0; batch classifier loss: 0.367885; batch adversarial loss: 0.700888\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369234; batch adversarial loss: 0.643974\n",
      "epoch 20; iter: 0; batch classifier loss: 0.388282; batch adversarial loss: 0.601177\n",
      "epoch 21; iter: 0; batch classifier loss: 0.375692; batch adversarial loss: 0.565846\n",
      "epoch 22; iter: 0; batch classifier loss: 0.375989; batch adversarial loss: 0.562781\n",
      "epoch 23; iter: 0; batch classifier loss: 0.241635; batch adversarial loss: 0.536862\n",
      "epoch 24; iter: 0; batch classifier loss: 0.373334; batch adversarial loss: 0.569824\n",
      "epoch 25; iter: 0; batch classifier loss: 0.397629; batch adversarial loss: 0.657318\n",
      "epoch 26; iter: 0; batch classifier loss: 0.510329; batch adversarial loss: 0.602525\n",
      "epoch 27; iter: 0; batch classifier loss: 0.188728; batch adversarial loss: 0.596505\n",
      "epoch 28; iter: 0; batch classifier loss: 0.300806; batch adversarial loss: 0.557645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.293550; batch adversarial loss: 0.639163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378413; batch adversarial loss: 0.576473\n",
      "epoch 31; iter: 0; batch classifier loss: 0.227156; batch adversarial loss: 0.537794\n",
      "epoch 32; iter: 0; batch classifier loss: 0.247717; batch adversarial loss: 0.580804\n",
      "epoch 33; iter: 0; batch classifier loss: 0.340865; batch adversarial loss: 0.657162\n",
      "epoch 34; iter: 0; batch classifier loss: 0.280245; batch adversarial loss: 0.674165\n",
      "epoch 35; iter: 0; batch classifier loss: 0.287068; batch adversarial loss: 0.625936\n",
      "epoch 36; iter: 0; batch classifier loss: 0.296154; batch adversarial loss: 0.604207\n",
      "epoch 37; iter: 0; batch classifier loss: 0.266043; batch adversarial loss: 0.626728\n",
      "epoch 38; iter: 0; batch classifier loss: 0.331406; batch adversarial loss: 0.699024\n",
      "epoch 39; iter: 0; batch classifier loss: 0.442468; batch adversarial loss: 0.686872\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351163; batch adversarial loss: 0.683879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.290692; batch adversarial loss: 0.674045\n",
      "epoch 42; iter: 0; batch classifier loss: 0.259029; batch adversarial loss: 0.561636\n",
      "epoch 43; iter: 0; batch classifier loss: 0.318305; batch adversarial loss: 0.613573\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323322; batch adversarial loss: 0.579836\n",
      "epoch 45; iter: 0; batch classifier loss: 0.257471; batch adversarial loss: 0.566676\n",
      "epoch 46; iter: 0; batch classifier loss: 0.228603; batch adversarial loss: 0.599079\n",
      "epoch 47; iter: 0; batch classifier loss: 0.325412; batch adversarial loss: 0.616091\n",
      "epoch 48; iter: 0; batch classifier loss: 0.248429; batch adversarial loss: 0.469986\n",
      "epoch 49; iter: 0; batch classifier loss: 0.513728; batch adversarial loss: 0.635526\n",
      "epoch 50; iter: 0; batch classifier loss: 0.257702; batch adversarial loss: 0.571781\n",
      "epoch 51; iter: 0; batch classifier loss: 0.272908; batch adversarial loss: 0.663898\n",
      "epoch 52; iter: 0; batch classifier loss: 0.288758; batch adversarial loss: 0.637653\n",
      "epoch 53; iter: 0; batch classifier loss: 0.262999; batch adversarial loss: 0.621990\n",
      "epoch 54; iter: 0; batch classifier loss: 0.338198; batch adversarial loss: 0.625947\n",
      "epoch 55; iter: 0; batch classifier loss: 0.240041; batch adversarial loss: 0.662247\n",
      "epoch 56; iter: 0; batch classifier loss: 0.361737; batch adversarial loss: 0.633357\n",
      "epoch 57; iter: 0; batch classifier loss: 0.263338; batch adversarial loss: 0.553311\n",
      "epoch 58; iter: 0; batch classifier loss: 0.211749; batch adversarial loss: 0.576773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.329116; batch adversarial loss: 0.540126\n",
      "epoch 60; iter: 0; batch classifier loss: 0.241934; batch adversarial loss: 0.621536\n",
      "epoch 61; iter: 0; batch classifier loss: 0.233770; batch adversarial loss: 0.597626\n",
      "epoch 62; iter: 0; batch classifier loss: 0.244014; batch adversarial loss: 0.579109\n",
      "epoch 63; iter: 0; batch classifier loss: 0.277905; batch adversarial loss: 0.539395\n",
      "epoch 64; iter: 0; batch classifier loss: 0.257431; batch adversarial loss: 0.538279\n",
      "epoch 65; iter: 0; batch classifier loss: 0.345140; batch adversarial loss: 0.658807\n",
      "epoch 66; iter: 0; batch classifier loss: 0.260432; batch adversarial loss: 0.586217\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361527; batch adversarial loss: 0.631868\n",
      "epoch 68; iter: 0; batch classifier loss: 0.234395; batch adversarial loss: 0.631314\n",
      "epoch 69; iter: 0; batch classifier loss: 0.206627; batch adversarial loss: 0.433458\n",
      "epoch 70; iter: 0; batch classifier loss: 0.208572; batch adversarial loss: 0.556901\n",
      "epoch 71; iter: 0; batch classifier loss: 0.376778; batch adversarial loss: 0.522441\n",
      "epoch 72; iter: 0; batch classifier loss: 0.345389; batch adversarial loss: 0.640635\n",
      "epoch 73; iter: 0; batch classifier loss: 0.503125; batch adversarial loss: 0.652688\n",
      "epoch 74; iter: 0; batch classifier loss: 0.245927; batch adversarial loss: 0.571471\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288456; batch adversarial loss: 0.549610\n",
      "epoch 76; iter: 0; batch classifier loss: 0.206967; batch adversarial loss: 0.640056\n",
      "epoch 77; iter: 0; batch classifier loss: 0.362359; batch adversarial loss: 0.608472\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192255; batch adversarial loss: 0.645733\n",
      "epoch 79; iter: 0; batch classifier loss: 0.252313; batch adversarial loss: 0.637528\n",
      "epoch 0; iter: 0; batch classifier loss: 0.782588; batch adversarial loss: 0.591392\n",
      "epoch 1; iter: 0; batch classifier loss: 0.651964; batch adversarial loss: 0.580279\n",
      "epoch 2; iter: 0; batch classifier loss: 0.592455; batch adversarial loss: 0.629696\n",
      "epoch 3; iter: 0; batch classifier loss: 0.544400; batch adversarial loss: 0.566241\n",
      "epoch 4; iter: 0; batch classifier loss: 0.501033; batch adversarial loss: 0.600026\n",
      "epoch 5; iter: 0; batch classifier loss: 0.422067; batch adversarial loss: 0.595733\n",
      "epoch 6; iter: 0; batch classifier loss: 0.443102; batch adversarial loss: 0.637728\n",
      "epoch 7; iter: 0; batch classifier loss: 0.426475; batch adversarial loss: 0.678785\n",
      "epoch 8; iter: 0; batch classifier loss: 0.394711; batch adversarial loss: 0.583746\n",
      "epoch 9; iter: 0; batch classifier loss: 0.419079; batch adversarial loss: 0.619323\n",
      "epoch 10; iter: 0; batch classifier loss: 0.469899; batch adversarial loss: 0.603343\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393391; batch adversarial loss: 0.663625\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410003; batch adversarial loss: 0.585475\n",
      "epoch 13; iter: 0; batch classifier loss: 0.400002; batch adversarial loss: 0.651746\n",
      "epoch 14; iter: 0; batch classifier loss: 0.351338; batch adversarial loss: 0.627568\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368253; batch adversarial loss: 0.498985\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481508; batch adversarial loss: 0.576159\n",
      "epoch 17; iter: 0; batch classifier loss: 0.354675; batch adversarial loss: 0.598538\n",
      "epoch 18; iter: 0; batch classifier loss: 0.328656; batch adversarial loss: 0.605258\n",
      "epoch 19; iter: 0; batch classifier loss: 0.285598; batch adversarial loss: 0.614567\n",
      "epoch 20; iter: 0; batch classifier loss: 0.324852; batch adversarial loss: 0.604408\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372028; batch adversarial loss: 0.524166\n",
      "epoch 22; iter: 0; batch classifier loss: 0.194345; batch adversarial loss: 0.576212\n",
      "epoch 23; iter: 0; batch classifier loss: 0.316257; batch adversarial loss: 0.563400\n",
      "epoch 24; iter: 0; batch classifier loss: 0.301647; batch adversarial loss: 0.574111\n",
      "epoch 25; iter: 0; batch classifier loss: 0.339031; batch adversarial loss: 0.575961\n",
      "epoch 26; iter: 0; batch classifier loss: 0.351649; batch adversarial loss: 0.658513\n",
      "epoch 27; iter: 0; batch classifier loss: 0.339599; batch adversarial loss: 0.648734\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334748; batch adversarial loss: 0.693512\n",
      "epoch 29; iter: 0; batch classifier loss: 0.227499; batch adversarial loss: 0.620066\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318328; batch adversarial loss: 0.684058\n",
      "epoch 31; iter: 0; batch classifier loss: 0.569195; batch adversarial loss: 0.617514\n",
      "epoch 32; iter: 0; batch classifier loss: 0.252520; batch adversarial loss: 0.571327\n",
      "epoch 33; iter: 0; batch classifier loss: 0.284322; batch adversarial loss: 0.601079\n",
      "epoch 34; iter: 0; batch classifier loss: 0.306226; batch adversarial loss: 0.536026\n",
      "epoch 35; iter: 0; batch classifier loss: 0.355212; batch adversarial loss: 0.602127\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293732; batch adversarial loss: 0.577296\n",
      "epoch 37; iter: 0; batch classifier loss: 0.209353; batch adversarial loss: 0.618560\n",
      "epoch 38; iter: 0; batch classifier loss: 0.247137; batch adversarial loss: 0.590803\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362776; batch adversarial loss: 0.612966\n",
      "epoch 40; iter: 0; batch classifier loss: 0.277305; batch adversarial loss: 0.687973\n",
      "epoch 41; iter: 0; batch classifier loss: 0.256376; batch adversarial loss: 0.561775\n",
      "epoch 42; iter: 0; batch classifier loss: 0.205077; batch adversarial loss: 0.558947\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287950; batch adversarial loss: 0.610362\n",
      "epoch 44; iter: 0; batch classifier loss: 0.351243; batch adversarial loss: 0.646946\n",
      "epoch 45; iter: 0; batch classifier loss: 0.246632; batch adversarial loss: 0.600093\n",
      "epoch 46; iter: 0; batch classifier loss: 0.260017; batch adversarial loss: 0.551878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.249425; batch adversarial loss: 0.643867\n",
      "epoch 48; iter: 0; batch classifier loss: 0.196961; batch adversarial loss: 0.612697\n",
      "epoch 49; iter: 0; batch classifier loss: 0.293674; batch adversarial loss: 0.602154\n",
      "epoch 50; iter: 0; batch classifier loss: 0.219966; batch adversarial loss: 0.656119\n",
      "epoch 51; iter: 0; batch classifier loss: 0.379809; batch adversarial loss: 0.470683\n",
      "epoch 52; iter: 0; batch classifier loss: 0.286432; batch adversarial loss: 0.605124\n",
      "epoch 53; iter: 0; batch classifier loss: 0.350934; batch adversarial loss: 0.590160\n",
      "epoch 54; iter: 0; batch classifier loss: 0.258838; batch adversarial loss: 0.610306\n",
      "epoch 55; iter: 0; batch classifier loss: 0.287479; batch adversarial loss: 0.640788\n",
      "epoch 56; iter: 0; batch classifier loss: 0.201202; batch adversarial loss: 0.576606\n",
      "epoch 57; iter: 0; batch classifier loss: 0.215115; batch adversarial loss: 0.590988\n",
      "epoch 58; iter: 0; batch classifier loss: 0.289948; batch adversarial loss: 0.570066\n",
      "epoch 59; iter: 0; batch classifier loss: 0.322377; batch adversarial loss: 0.636604\n",
      "epoch 60; iter: 0; batch classifier loss: 0.287961; batch adversarial loss: 0.623742\n",
      "epoch 61; iter: 0; batch classifier loss: 0.248578; batch adversarial loss: 0.605504\n",
      "epoch 62; iter: 0; batch classifier loss: 0.217764; batch adversarial loss: 0.697471\n",
      "epoch 63; iter: 0; batch classifier loss: 0.268885; batch adversarial loss: 0.575975\n",
      "epoch 64; iter: 0; batch classifier loss: 0.274158; batch adversarial loss: 0.558687\n",
      "epoch 65; iter: 0; batch classifier loss: 0.270782; batch adversarial loss: 0.543586\n",
      "epoch 66; iter: 0; batch classifier loss: 0.390110; batch adversarial loss: 0.535451\n",
      "epoch 67; iter: 0; batch classifier loss: 0.281121; batch adversarial loss: 0.601595\n",
      "epoch 68; iter: 0; batch classifier loss: 0.144919; batch adversarial loss: 0.550792\n",
      "epoch 69; iter: 0; batch classifier loss: 0.357751; batch adversarial loss: 0.628921\n",
      "epoch 70; iter: 0; batch classifier loss: 0.237465; batch adversarial loss: 0.636868\n",
      "epoch 71; iter: 0; batch classifier loss: 0.193166; batch adversarial loss: 0.620827\n",
      "epoch 72; iter: 0; batch classifier loss: 0.262249; batch adversarial loss: 0.600409\n",
      "epoch 73; iter: 0; batch classifier loss: 0.250745; batch adversarial loss: 0.581477\n",
      "epoch 74; iter: 0; batch classifier loss: 0.336510; batch adversarial loss: 0.636799\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329140; batch adversarial loss: 0.588190\n",
      "epoch 76; iter: 0; batch classifier loss: 0.267497; batch adversarial loss: 0.476591\n",
      "epoch 77; iter: 0; batch classifier loss: 0.186619; batch adversarial loss: 0.585161\n",
      "epoch 78; iter: 0; batch classifier loss: 0.192520; batch adversarial loss: 0.545510\n",
      "epoch 79; iter: 0; batch classifier loss: 0.193974; batch adversarial loss: 0.568805\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717023; batch adversarial loss: 0.595278\n",
      "epoch 1; iter: 0; batch classifier loss: 0.682527; batch adversarial loss: 0.572191\n",
      "epoch 2; iter: 0; batch classifier loss: 0.680001; batch adversarial loss: 0.631885\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659414; batch adversarial loss: 0.586123\n",
      "epoch 4; iter: 0; batch classifier loss: 0.623297; batch adversarial loss: 0.566460\n",
      "epoch 5; iter: 0; batch classifier loss: 0.650460; batch adversarial loss: 0.616274\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573847; batch adversarial loss: 0.609837\n",
      "epoch 7; iter: 0; batch classifier loss: 0.591935; batch adversarial loss: 0.616012\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554972; batch adversarial loss: 0.599260\n",
      "epoch 9; iter: 0; batch classifier loss: 0.589648; batch adversarial loss: 0.551225\n",
      "epoch 10; iter: 0; batch classifier loss: 0.547289; batch adversarial loss: 0.595661\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519405; batch adversarial loss: 0.541775\n",
      "epoch 12; iter: 0; batch classifier loss: 0.537413; batch adversarial loss: 0.597214\n",
      "epoch 13; iter: 0; batch classifier loss: 0.564884; batch adversarial loss: 0.659289\n",
      "epoch 14; iter: 0; batch classifier loss: 0.508560; batch adversarial loss: 0.565364\n",
      "epoch 15; iter: 0; batch classifier loss: 0.473221; batch adversarial loss: 0.537118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472740; batch adversarial loss: 0.581027\n",
      "epoch 17; iter: 0; batch classifier loss: 0.477533; batch adversarial loss: 0.559411\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513498; batch adversarial loss: 0.612789\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439985; batch adversarial loss: 0.601958\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441749; batch adversarial loss: 0.500194\n",
      "epoch 21; iter: 0; batch classifier loss: 0.507791; batch adversarial loss: 0.609998\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372225; batch adversarial loss: 0.636410\n",
      "epoch 23; iter: 0; batch classifier loss: 0.418154; batch adversarial loss: 0.584570\n",
      "epoch 24; iter: 0; batch classifier loss: 0.510029; batch adversarial loss: 0.622560\n",
      "epoch 25; iter: 0; batch classifier loss: 0.376890; batch adversarial loss: 0.604129\n",
      "epoch 26; iter: 0; batch classifier loss: 0.402484; batch adversarial loss: 0.582345\n",
      "epoch 27; iter: 0; batch classifier loss: 0.417813; batch adversarial loss: 0.510993\n",
      "epoch 28; iter: 0; batch classifier loss: 0.383745; batch adversarial loss: 0.571124\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429862; batch adversarial loss: 0.670191\n",
      "epoch 30; iter: 0; batch classifier loss: 0.392869; batch adversarial loss: 0.598327\n",
      "epoch 31; iter: 0; batch classifier loss: 0.422122; batch adversarial loss: 0.571041\n",
      "epoch 32; iter: 0; batch classifier loss: 0.359867; batch adversarial loss: 0.640138\n",
      "epoch 33; iter: 0; batch classifier loss: 0.400299; batch adversarial loss: 0.611548\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380070; batch adversarial loss: 0.540868\n",
      "epoch 35; iter: 0; batch classifier loss: 0.467610; batch adversarial loss: 0.590773\n",
      "epoch 36; iter: 0; batch classifier loss: 0.395437; batch adversarial loss: 0.630549\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368143; batch adversarial loss: 0.628452\n",
      "epoch 38; iter: 0; batch classifier loss: 0.372305; batch adversarial loss: 0.598389\n",
      "epoch 39; iter: 0; batch classifier loss: 0.376302; batch adversarial loss: 0.698433\n",
      "epoch 40; iter: 0; batch classifier loss: 0.371730; batch adversarial loss: 0.621633\n",
      "epoch 41; iter: 0; batch classifier loss: 0.327011; batch adversarial loss: 0.631218\n",
      "epoch 42; iter: 0; batch classifier loss: 0.417736; batch adversarial loss: 0.560862\n",
      "epoch 43; iter: 0; batch classifier loss: 0.374356; batch adversarial loss: 0.594593\n",
      "epoch 44; iter: 0; batch classifier loss: 0.441399; batch adversarial loss: 0.562778\n",
      "epoch 45; iter: 0; batch classifier loss: 0.355628; batch adversarial loss: 0.617119\n",
      "epoch 46; iter: 0; batch classifier loss: 0.381690; batch adversarial loss: 0.694447\n",
      "epoch 47; iter: 0; batch classifier loss: 0.299155; batch adversarial loss: 0.674674\n",
      "epoch 48; iter: 0; batch classifier loss: 0.434264; batch adversarial loss: 0.583378\n",
      "epoch 49; iter: 0; batch classifier loss: 0.377321; batch adversarial loss: 0.613866\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393817; batch adversarial loss: 0.619206\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326809; batch adversarial loss: 0.640460\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384585; batch adversarial loss: 0.601557\n",
      "epoch 53; iter: 0; batch classifier loss: 0.311243; batch adversarial loss: 0.628523\n",
      "epoch 54; iter: 0; batch classifier loss: 0.363473; batch adversarial loss: 0.662764\n",
      "epoch 55; iter: 0; batch classifier loss: 0.316132; batch adversarial loss: 0.611954\n",
      "epoch 56; iter: 0; batch classifier loss: 0.383937; batch adversarial loss: 0.548650\n",
      "epoch 57; iter: 0; batch classifier loss: 0.355939; batch adversarial loss: 0.624924\n",
      "epoch 58; iter: 0; batch classifier loss: 0.302810; batch adversarial loss: 0.580476\n",
      "epoch 59; iter: 0; batch classifier loss: 0.282799; batch adversarial loss: 0.594192\n",
      "epoch 60; iter: 0; batch classifier loss: 0.348107; batch adversarial loss: 0.622521\n",
      "epoch 61; iter: 0; batch classifier loss: 0.361284; batch adversarial loss: 0.617491\n",
      "epoch 62; iter: 0; batch classifier loss: 0.340543; batch adversarial loss: 0.557492\n",
      "epoch 63; iter: 0; batch classifier loss: 0.300328; batch adversarial loss: 0.620003\n",
      "epoch 64; iter: 0; batch classifier loss: 0.322225; batch adversarial loss: 0.678960\n",
      "epoch 65; iter: 0; batch classifier loss: 0.395780; batch adversarial loss: 0.546051\n",
      "epoch 66; iter: 0; batch classifier loss: 0.353997; batch adversarial loss: 0.607889\n",
      "epoch 67; iter: 0; batch classifier loss: 0.284235; batch adversarial loss: 0.610279\n",
      "epoch 68; iter: 0; batch classifier loss: 0.341275; batch adversarial loss: 0.625462\n",
      "epoch 69; iter: 0; batch classifier loss: 0.386985; batch adversarial loss: 0.578126\n",
      "epoch 70; iter: 0; batch classifier loss: 0.331846; batch adversarial loss: 0.625587\n",
      "epoch 71; iter: 0; batch classifier loss: 0.264192; batch adversarial loss: 0.633871\n",
      "epoch 72; iter: 0; batch classifier loss: 0.313314; batch adversarial loss: 0.538779\n",
      "epoch 73; iter: 0; batch classifier loss: 0.321430; batch adversarial loss: 0.609871\n",
      "epoch 74; iter: 0; batch classifier loss: 0.318624; batch adversarial loss: 0.595979\n",
      "epoch 75; iter: 0; batch classifier loss: 0.329921; batch adversarial loss: 0.674053\n",
      "epoch 76; iter: 0; batch classifier loss: 0.313902; batch adversarial loss: 0.625249\n",
      "epoch 77; iter: 0; batch classifier loss: 0.315416; batch adversarial loss: 0.641283\n",
      "epoch 78; iter: 0; batch classifier loss: 0.293817; batch adversarial loss: 0.634165\n",
      "epoch 79; iter: 0; batch classifier loss: 0.276969; batch adversarial loss: 0.648053\n",
      "epoch 0; iter: 0; batch classifier loss: 0.719045; batch adversarial loss: 0.719139\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692852; batch adversarial loss: 0.752936\n",
      "epoch 2; iter: 0; batch classifier loss: 0.649411; batch adversarial loss: 0.753797\n",
      "epoch 3; iter: 0; batch classifier loss: 0.620227; batch adversarial loss: 0.747244\n",
      "epoch 4; iter: 0; batch classifier loss: 0.606964; batch adversarial loss: 0.765483\n",
      "epoch 5; iter: 0; batch classifier loss: 0.576772; batch adversarial loss: 0.734482\n",
      "epoch 6; iter: 0; batch classifier loss: 0.598436; batch adversarial loss: 0.724132\n",
      "epoch 7; iter: 0; batch classifier loss: 0.565187; batch adversarial loss: 0.728341\n",
      "epoch 8; iter: 0; batch classifier loss: 0.555850; batch adversarial loss: 0.720375\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544337; batch adversarial loss: 0.715113\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522097; batch adversarial loss: 0.724671\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540783; batch adversarial loss: 0.720549\n",
      "epoch 12; iter: 0; batch classifier loss: 0.531120; batch adversarial loss: 0.702897\n",
      "epoch 13; iter: 0; batch classifier loss: 0.593378; batch adversarial loss: 0.718382\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571592; batch adversarial loss: 0.712428\n",
      "epoch 15; iter: 0; batch classifier loss: 0.531352; batch adversarial loss: 0.717166\n",
      "epoch 16; iter: 0; batch classifier loss: 0.570498; batch adversarial loss: 0.700243\n",
      "epoch 17; iter: 0; batch classifier loss: 0.487048; batch adversarial loss: 0.716759\n",
      "epoch 18; iter: 0; batch classifier loss: 0.508993; batch adversarial loss: 0.708370\n",
      "epoch 19; iter: 0; batch classifier loss: 0.514420; batch adversarial loss: 0.689209\n",
      "epoch 20; iter: 0; batch classifier loss: 0.537044; batch adversarial loss: 0.699342\n",
      "epoch 21; iter: 0; batch classifier loss: 0.437061; batch adversarial loss: 0.681087\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457518; batch adversarial loss: 0.686883\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479818; batch adversarial loss: 0.687852\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500197; batch adversarial loss: 0.707109\n",
      "epoch 25; iter: 0; batch classifier loss: 0.464387; batch adversarial loss: 0.673236\n",
      "epoch 26; iter: 0; batch classifier loss: 0.508722; batch adversarial loss: 0.696721\n",
      "epoch 27; iter: 0; batch classifier loss: 0.447747; batch adversarial loss: 0.682575\n",
      "epoch 28; iter: 0; batch classifier loss: 0.497941; batch adversarial loss: 0.673336\n",
      "epoch 29; iter: 0; batch classifier loss: 0.484773; batch adversarial loss: 0.681426\n",
      "epoch 30; iter: 0; batch classifier loss: 0.488637; batch adversarial loss: 0.682934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.480896; batch adversarial loss: 0.677290\n",
      "epoch 32; iter: 0; batch classifier loss: 0.487017; batch adversarial loss: 0.702608\n",
      "epoch 33; iter: 0; batch classifier loss: 0.432641; batch adversarial loss: 0.674032\n",
      "epoch 34; iter: 0; batch classifier loss: 0.486963; batch adversarial loss: 0.680497\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420913; batch adversarial loss: 0.657965\n",
      "epoch 36; iter: 0; batch classifier loss: 0.447285; batch adversarial loss: 0.669313\n",
      "epoch 37; iter: 0; batch classifier loss: 0.421080; batch adversarial loss: 0.665506\n",
      "epoch 38; iter: 0; batch classifier loss: 0.351700; batch adversarial loss: 0.650180\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418511; batch adversarial loss: 0.656172\n",
      "epoch 40; iter: 0; batch classifier loss: 0.390211; batch adversarial loss: 0.626558\n",
      "epoch 41; iter: 0; batch classifier loss: 0.430927; batch adversarial loss: 0.656442\n",
      "epoch 42; iter: 0; batch classifier loss: 0.519593; batch adversarial loss: 0.655478\n",
      "epoch 43; iter: 0; batch classifier loss: 0.474884; batch adversarial loss: 0.670912\n",
      "epoch 44; iter: 0; batch classifier loss: 0.472129; batch adversarial loss: 0.640077\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367222; batch adversarial loss: 0.646782\n",
      "epoch 46; iter: 0; batch classifier loss: 0.402015; batch adversarial loss: 0.649636\n",
      "epoch 47; iter: 0; batch classifier loss: 0.428613; batch adversarial loss: 0.651062\n",
      "epoch 48; iter: 0; batch classifier loss: 0.429936; batch adversarial loss: 0.652484\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404281; batch adversarial loss: 0.654864\n",
      "epoch 50; iter: 0; batch classifier loss: 0.420978; batch adversarial loss: 0.657027\n",
      "epoch 51; iter: 0; batch classifier loss: 0.430209; batch adversarial loss: 0.634849\n",
      "epoch 52; iter: 0; batch classifier loss: 0.445788; batch adversarial loss: 0.643785\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375204; batch adversarial loss: 0.649850\n",
      "epoch 54; iter: 0; batch classifier loss: 0.283424; batch adversarial loss: 0.617453\n",
      "epoch 55; iter: 0; batch classifier loss: 0.353812; batch adversarial loss: 0.618729\n",
      "epoch 56; iter: 0; batch classifier loss: 0.305703; batch adversarial loss: 0.637054\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325296; batch adversarial loss: 0.633554\n",
      "epoch 58; iter: 0; batch classifier loss: 0.371989; batch adversarial loss: 0.653900\n",
      "epoch 59; iter: 0; batch classifier loss: 0.396036; batch adversarial loss: 0.630641\n",
      "epoch 60; iter: 0; batch classifier loss: 0.367564; batch adversarial loss: 0.623834\n",
      "epoch 61; iter: 0; batch classifier loss: 0.364099; batch adversarial loss: 0.581497\n",
      "epoch 62; iter: 0; batch classifier loss: 0.337655; batch adversarial loss: 0.631310\n",
      "epoch 63; iter: 0; batch classifier loss: 0.297647; batch adversarial loss: 0.637265\n",
      "epoch 64; iter: 0; batch classifier loss: 0.286657; batch adversarial loss: 0.628824\n",
      "epoch 65; iter: 0; batch classifier loss: 0.310595; batch adversarial loss: 0.631250\n",
      "epoch 66; iter: 0; batch classifier loss: 0.302312; batch adversarial loss: 0.631433\n",
      "epoch 67; iter: 0; batch classifier loss: 0.311211; batch adversarial loss: 0.608059\n",
      "epoch 68; iter: 0; batch classifier loss: 0.342720; batch adversarial loss: 0.605595\n",
      "epoch 69; iter: 0; batch classifier loss: 0.275467; batch adversarial loss: 0.604519\n",
      "epoch 70; iter: 0; batch classifier loss: 0.359997; batch adversarial loss: 0.610846\n",
      "epoch 71; iter: 0; batch classifier loss: 0.287334; batch adversarial loss: 0.607489\n",
      "epoch 72; iter: 0; batch classifier loss: 0.322968; batch adversarial loss: 0.601365\n",
      "epoch 73; iter: 0; batch classifier loss: 0.249755; batch adversarial loss: 0.612223\n",
      "epoch 74; iter: 0; batch classifier loss: 0.315773; batch adversarial loss: 0.622002\n",
      "epoch 75; iter: 0; batch classifier loss: 0.325808; batch adversarial loss: 0.620011\n",
      "epoch 76; iter: 0; batch classifier loss: 0.298165; batch adversarial loss: 0.610859\n",
      "epoch 77; iter: 0; batch classifier loss: 0.342367; batch adversarial loss: 0.613754\n",
      "epoch 78; iter: 0; batch classifier loss: 0.311732; batch adversarial loss: 0.611348\n",
      "epoch 79; iter: 0; batch classifier loss: 0.304462; batch adversarial loss: 0.633045\n",
      "epoch 0; iter: 0; batch classifier loss: 0.642115; batch adversarial loss: 0.719071\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591057; batch adversarial loss: 0.708305\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616927; batch adversarial loss: 0.707454\n",
      "epoch 3; iter: 0; batch classifier loss: 0.593357; batch adversarial loss: 0.714147\n",
      "epoch 4; iter: 0; batch classifier loss: 0.596087; batch adversarial loss: 0.699144\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540151; batch adversarial loss: 0.700149\n",
      "epoch 6; iter: 0; batch classifier loss: 0.496270; batch adversarial loss: 0.699533\n",
      "epoch 7; iter: 0; batch classifier loss: 0.510409; batch adversarial loss: 0.693177\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475812; batch adversarial loss: 0.692246\n",
      "epoch 9; iter: 0; batch classifier loss: 0.406381; batch adversarial loss: 0.684096\n",
      "epoch 10; iter: 0; batch classifier loss: 0.432248; batch adversarial loss: 0.671804\n",
      "epoch 11; iter: 0; batch classifier loss: 0.446930; batch adversarial loss: 0.672278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.400602; batch adversarial loss: 0.669925\n",
      "epoch 13; iter: 0; batch classifier loss: 0.452811; batch adversarial loss: 0.676108\n",
      "epoch 14; iter: 0; batch classifier loss: 0.397489; batch adversarial loss: 0.659575\n",
      "epoch 15; iter: 0; batch classifier loss: 0.446905; batch adversarial loss: 0.662189\n",
      "epoch 16; iter: 0; batch classifier loss: 0.419285; batch adversarial loss: 0.664661\n",
      "epoch 17; iter: 0; batch classifier loss: 0.463466; batch adversarial loss: 0.659079\n",
      "epoch 18; iter: 0; batch classifier loss: 0.436569; batch adversarial loss: 0.643664\n",
      "epoch 19; iter: 0; batch classifier loss: 0.373180; batch adversarial loss: 0.652791\n",
      "epoch 20; iter: 0; batch classifier loss: 0.422592; batch adversarial loss: 0.644330\n",
      "epoch 21; iter: 0; batch classifier loss: 0.425508; batch adversarial loss: 0.652790\n",
      "epoch 22; iter: 0; batch classifier loss: 0.435678; batch adversarial loss: 0.624087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.284999; batch adversarial loss: 0.646448\n",
      "epoch 24; iter: 0; batch classifier loss: 0.414923; batch adversarial loss: 0.642495\n",
      "epoch 25; iter: 0; batch classifier loss: 0.321175; batch adversarial loss: 0.628056\n",
      "epoch 26; iter: 0; batch classifier loss: 0.366343; batch adversarial loss: 0.629833\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253116; batch adversarial loss: 0.626612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.350516; batch adversarial loss: 0.616453\n",
      "epoch 29; iter: 0; batch classifier loss: 0.368856; batch adversarial loss: 0.613160\n",
      "epoch 30; iter: 0; batch classifier loss: 0.323823; batch adversarial loss: 0.624109\n",
      "epoch 31; iter: 0; batch classifier loss: 0.322761; batch adversarial loss: 0.588164\n",
      "epoch 32; iter: 0; batch classifier loss: 0.300021; batch adversarial loss: 0.613307\n",
      "epoch 33; iter: 0; batch classifier loss: 0.307833; batch adversarial loss: 0.628664\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260954; batch adversarial loss: 0.609597\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299515; batch adversarial loss: 0.609250\n",
      "epoch 36; iter: 0; batch classifier loss: 0.296891; batch adversarial loss: 0.600518\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354051; batch adversarial loss: 0.622823\n",
      "epoch 38; iter: 0; batch classifier loss: 0.327849; batch adversarial loss: 0.610779\n",
      "epoch 39; iter: 0; batch classifier loss: 0.288956; batch adversarial loss: 0.617278\n",
      "epoch 0; iter: 0; batch classifier loss: 0.644494; batch adversarial loss: 0.671199\n",
      "epoch 1; iter: 0; batch classifier loss: 0.555795; batch adversarial loss: 0.649438\n",
      "epoch 2; iter: 0; batch classifier loss: 0.520799; batch adversarial loss: 0.656243\n",
      "epoch 3; iter: 0; batch classifier loss: 0.529134; batch adversarial loss: 0.636065\n",
      "epoch 4; iter: 0; batch classifier loss: 0.546760; batch adversarial loss: 0.640045\n",
      "epoch 5; iter: 0; batch classifier loss: 0.460330; batch adversarial loss: 0.646505\n",
      "epoch 6; iter: 0; batch classifier loss: 0.459055; batch adversarial loss: 0.652215\n",
      "epoch 7; iter: 0; batch classifier loss: 0.431381; batch adversarial loss: 0.642545\n",
      "epoch 8; iter: 0; batch classifier loss: 0.400871; batch adversarial loss: 0.620084\n",
      "epoch 9; iter: 0; batch classifier loss: 0.325182; batch adversarial loss: 0.657622\n",
      "epoch 10; iter: 0; batch classifier loss: 0.374425; batch adversarial loss: 0.621201\n",
      "epoch 11; iter: 0; batch classifier loss: 0.449627; batch adversarial loss: 0.625926\n",
      "epoch 12; iter: 0; batch classifier loss: 0.350413; batch adversarial loss: 0.622338\n",
      "epoch 13; iter: 0; batch classifier loss: 0.409751; batch adversarial loss: 0.644145\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335108; batch adversarial loss: 0.624418\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403131; batch adversarial loss: 0.624142\n",
      "epoch 16; iter: 0; batch classifier loss: 0.426730; batch adversarial loss: 0.592960\n",
      "epoch 17; iter: 0; batch classifier loss: 0.345564; batch adversarial loss: 0.619838\n",
      "epoch 18; iter: 0; batch classifier loss: 0.257599; batch adversarial loss: 0.629718\n",
      "epoch 19; iter: 0; batch classifier loss: 0.343143; batch adversarial loss: 0.618219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295219; batch adversarial loss: 0.586059\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366401; batch adversarial loss: 0.670513\n",
      "epoch 22; iter: 0; batch classifier loss: 0.372814; batch adversarial loss: 0.595187\n",
      "epoch 23; iter: 0; batch classifier loss: 0.328130; batch adversarial loss: 0.604643\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314302; batch adversarial loss: 0.648306\n",
      "epoch 25; iter: 0; batch classifier loss: 0.312398; batch adversarial loss: 0.643398\n",
      "epoch 26; iter: 0; batch classifier loss: 0.361204; batch adversarial loss: 0.655581\n",
      "epoch 27; iter: 0; batch classifier loss: 0.386025; batch adversarial loss: 0.610916\n",
      "epoch 28; iter: 0; batch classifier loss: 0.290976; batch adversarial loss: 0.632438\n",
      "epoch 29; iter: 0; batch classifier loss: 0.407791; batch adversarial loss: 0.572228\n",
      "epoch 30; iter: 0; batch classifier loss: 0.231937; batch adversarial loss: 0.547841\n",
      "epoch 31; iter: 0; batch classifier loss: 0.383771; batch adversarial loss: 0.601828\n",
      "epoch 32; iter: 0; batch classifier loss: 0.267615; batch adversarial loss: 0.613942\n",
      "epoch 33; iter: 0; batch classifier loss: 0.278745; batch adversarial loss: 0.616178\n",
      "epoch 34; iter: 0; batch classifier loss: 0.282975; batch adversarial loss: 0.594471\n",
      "epoch 35; iter: 0; batch classifier loss: 0.240459; batch adversarial loss: 0.546733\n",
      "epoch 36; iter: 0; batch classifier loss: 0.323287; batch adversarial loss: 0.644585\n",
      "epoch 37; iter: 0; batch classifier loss: 0.243299; batch adversarial loss: 0.548043\n",
      "epoch 38; iter: 0; batch classifier loss: 0.331253; batch adversarial loss: 0.608914\n",
      "epoch 39; iter: 0; batch classifier loss: 0.183377; batch adversarial loss: 0.584886\n",
      "epoch 0; iter: 0; batch classifier loss: 0.646208; batch adversarial loss: 0.836988\n",
      "epoch 1; iter: 0; batch classifier loss: 0.595706; batch adversarial loss: 0.894386\n",
      "epoch 2; iter: 0; batch classifier loss: 0.601775; batch adversarial loss: 0.895083\n",
      "epoch 3; iter: 0; batch classifier loss: 0.567102; batch adversarial loss: 0.831631\n",
      "epoch 4; iter: 0; batch classifier loss: 0.555802; batch adversarial loss: 0.879722\n",
      "epoch 5; iter: 0; batch classifier loss: 0.536420; batch adversarial loss: 0.855712\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520225; batch adversarial loss: 0.939917\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551798; batch adversarial loss: 0.938494\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532209; batch adversarial loss: 0.941750\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513651; batch adversarial loss: 0.921019\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522216; batch adversarial loss: 0.860880\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496942; batch adversarial loss: 0.848961\n",
      "epoch 12; iter: 0; batch classifier loss: 0.452985; batch adversarial loss: 0.904545\n",
      "epoch 13; iter: 0; batch classifier loss: 0.476977; batch adversarial loss: 0.897865\n",
      "epoch 14; iter: 0; batch classifier loss: 0.510352; batch adversarial loss: 0.931310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498697; batch adversarial loss: 0.913494\n",
      "epoch 16; iter: 0; batch classifier loss: 0.436474; batch adversarial loss: 0.915157\n",
      "epoch 17; iter: 0; batch classifier loss: 0.490919; batch adversarial loss: 0.841097\n",
      "epoch 18; iter: 0; batch classifier loss: 0.458955; batch adversarial loss: 0.874971\n",
      "epoch 19; iter: 0; batch classifier loss: 0.434131; batch adversarial loss: 0.889746\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433322; batch adversarial loss: 0.884101\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403577; batch adversarial loss: 0.873178\n",
      "epoch 22; iter: 0; batch classifier loss: 0.398078; batch adversarial loss: 0.868432\n",
      "epoch 23; iter: 0; batch classifier loss: 0.366225; batch adversarial loss: 0.868226\n",
      "epoch 24; iter: 0; batch classifier loss: 0.379306; batch adversarial loss: 0.889827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.370894; batch adversarial loss: 0.891431\n",
      "epoch 26; iter: 0; batch classifier loss: 0.428449; batch adversarial loss: 0.915299\n",
      "epoch 27; iter: 0; batch classifier loss: 0.399745; batch adversarial loss: 0.878615\n",
      "epoch 28; iter: 0; batch classifier loss: 0.343222; batch adversarial loss: 0.869459\n",
      "epoch 29; iter: 0; batch classifier loss: 0.400938; batch adversarial loss: 0.837938\n",
      "epoch 30; iter: 0; batch classifier loss: 0.369009; batch adversarial loss: 0.845126\n",
      "epoch 31; iter: 0; batch classifier loss: 0.347785; batch adversarial loss: 0.818172\n",
      "epoch 32; iter: 0; batch classifier loss: 0.385011; batch adversarial loss: 0.843724\n",
      "epoch 33; iter: 0; batch classifier loss: 0.355578; batch adversarial loss: 0.863384\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430709; batch adversarial loss: 0.852301\n",
      "epoch 35; iter: 0; batch classifier loss: 0.345639; batch adversarial loss: 0.837639\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379768; batch adversarial loss: 0.797576\n",
      "epoch 37; iter: 0; batch classifier loss: 0.407597; batch adversarial loss: 0.914217\n",
      "epoch 38; iter: 0; batch classifier loss: 0.335727; batch adversarial loss: 0.879643\n",
      "epoch 39; iter: 0; batch classifier loss: 0.399365; batch adversarial loss: 0.783635\n",
      "epoch 0; iter: 0; batch classifier loss: 0.758036; batch adversarial loss: 0.978410\n",
      "epoch 1; iter: 0; batch classifier loss: 0.762312; batch adversarial loss: 1.095444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.741778; batch adversarial loss: 1.080604\n",
      "epoch 3; iter: 0; batch classifier loss: 0.635661; batch adversarial loss: 1.129085\n",
      "epoch 4; iter: 0; batch classifier loss: 0.635452; batch adversarial loss: 1.031463\n",
      "epoch 5; iter: 0; batch classifier loss: 0.597992; batch adversarial loss: 1.088617\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606142; batch adversarial loss: 1.075541\n",
      "epoch 7; iter: 0; batch classifier loss: 0.611992; batch adversarial loss: 1.089878\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575635; batch adversarial loss: 1.016847\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530931; batch adversarial loss: 1.082113\n",
      "epoch 10; iter: 0; batch classifier loss: 0.521225; batch adversarial loss: 1.146821\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580256; batch adversarial loss: 1.115786\n",
      "epoch 12; iter: 0; batch classifier loss: 0.560317; batch adversarial loss: 1.128270\n",
      "epoch 13; iter: 0; batch classifier loss: 0.530619; batch adversarial loss: 1.086592\n",
      "epoch 14; iter: 0; batch classifier loss: 0.484848; batch adversarial loss: 1.037433\n",
      "epoch 15; iter: 0; batch classifier loss: 0.624791; batch adversarial loss: 1.140486\n",
      "epoch 16; iter: 0; batch classifier loss: 0.572724; batch adversarial loss: 1.097758\n",
      "epoch 17; iter: 0; batch classifier loss: 0.545638; batch adversarial loss: 1.161261\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466140; batch adversarial loss: 1.141447\n",
      "epoch 19; iter: 0; batch classifier loss: 0.573420; batch adversarial loss: 1.083815\n",
      "epoch 20; iter: 0; batch classifier loss: 0.479979; batch adversarial loss: 1.096626\n",
      "epoch 21; iter: 0; batch classifier loss: 0.536083; batch adversarial loss: 1.090729\n",
      "epoch 22; iter: 0; batch classifier loss: 0.489625; batch adversarial loss: 1.076179\n",
      "epoch 23; iter: 0; batch classifier loss: 0.560161; batch adversarial loss: 1.061554\n",
      "epoch 24; iter: 0; batch classifier loss: 0.594514; batch adversarial loss: 1.076311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.594530; batch adversarial loss: 1.172590\n",
      "epoch 26; iter: 0; batch classifier loss: 0.599881; batch adversarial loss: 1.089145\n",
      "epoch 27; iter: 0; batch classifier loss: 0.575052; batch adversarial loss: 1.029528\n",
      "epoch 28; iter: 0; batch classifier loss: 0.648245; batch adversarial loss: 1.128567\n",
      "epoch 29; iter: 0; batch classifier loss: 0.551433; batch adversarial loss: 1.104178\n",
      "epoch 30; iter: 0; batch classifier loss: 0.711401; batch adversarial loss: 1.071805\n",
      "epoch 31; iter: 0; batch classifier loss: 0.610681; batch adversarial loss: 1.093845\n",
      "epoch 32; iter: 0; batch classifier loss: 0.658173; batch adversarial loss: 1.141574\n",
      "epoch 33; iter: 0; batch classifier loss: 0.582914; batch adversarial loss: 1.084276\n",
      "epoch 34; iter: 0; batch classifier loss: 0.564014; batch adversarial loss: 1.108838\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507858; batch adversarial loss: 1.057675\n",
      "epoch 36; iter: 0; batch classifier loss: 0.596223; batch adversarial loss: 1.053698\n",
      "epoch 37; iter: 0; batch classifier loss: 0.554581; batch adversarial loss: 1.101108\n",
      "epoch 38; iter: 0; batch classifier loss: 0.628376; batch adversarial loss: 1.084019\n",
      "epoch 39; iter: 0; batch classifier loss: 0.613784; batch adversarial loss: 1.072911\n",
      "epoch 0; iter: 0; batch classifier loss: 0.670673; batch adversarial loss: 0.721207\n",
      "epoch 1; iter: 0; batch classifier loss: 0.618138; batch adversarial loss: 0.716959\n",
      "epoch 2; iter: 0; batch classifier loss: 0.571966; batch adversarial loss: 0.707613\n",
      "epoch 3; iter: 0; batch classifier loss: 0.525290; batch adversarial loss: 0.705528\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517703; batch adversarial loss: 0.697490\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550068; batch adversarial loss: 0.691105\n",
      "epoch 6; iter: 0; batch classifier loss: 0.545658; batch adversarial loss: 0.687780\n",
      "epoch 7; iter: 0; batch classifier loss: 0.506700; batch adversarial loss: 0.682643\n",
      "epoch 8; iter: 0; batch classifier loss: 0.490913; batch adversarial loss: 0.679812\n",
      "epoch 9; iter: 0; batch classifier loss: 0.492176; batch adversarial loss: 0.672314\n",
      "epoch 10; iter: 0; batch classifier loss: 0.518790; batch adversarial loss: 0.669591\n",
      "epoch 11; iter: 0; batch classifier loss: 0.370605; batch adversarial loss: 0.655460\n",
      "epoch 12; iter: 0; batch classifier loss: 0.472192; batch adversarial loss: 0.648139\n",
      "epoch 13; iter: 0; batch classifier loss: 0.479375; batch adversarial loss: 0.671624\n",
      "epoch 14; iter: 0; batch classifier loss: 0.423661; batch adversarial loss: 0.659464\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466719; batch adversarial loss: 0.652758\n",
      "epoch 16; iter: 0; batch classifier loss: 0.341303; batch adversarial loss: 0.653463\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392627; batch adversarial loss: 0.638105\n",
      "epoch 18; iter: 0; batch classifier loss: 0.365976; batch adversarial loss: 0.638803\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465391; batch adversarial loss: 0.658535\n",
      "epoch 20; iter: 0; batch classifier loss: 0.469443; batch adversarial loss: 0.642042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.434017; batch adversarial loss: 0.660294\n",
      "epoch 22; iter: 0; batch classifier loss: 0.367383; batch adversarial loss: 0.612310\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344370; batch adversarial loss: 0.635637\n",
      "epoch 24; iter: 0; batch classifier loss: 0.422090; batch adversarial loss: 0.660411\n",
      "epoch 25; iter: 0; batch classifier loss: 0.368818; batch adversarial loss: 0.620510\n",
      "epoch 26; iter: 0; batch classifier loss: 0.359028; batch adversarial loss: 0.635475\n",
      "epoch 27; iter: 0; batch classifier loss: 0.376829; batch adversarial loss: 0.665208\n",
      "epoch 28; iter: 0; batch classifier loss: 0.287006; batch adversarial loss: 0.602889\n",
      "epoch 29; iter: 0; batch classifier loss: 0.222251; batch adversarial loss: 0.606725\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404539; batch adversarial loss: 0.617622\n",
      "epoch 31; iter: 0; batch classifier loss: 0.400608; batch adversarial loss: 0.648432\n",
      "epoch 32; iter: 0; batch classifier loss: 0.323938; batch adversarial loss: 0.644234\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356029; batch adversarial loss: 0.618479\n",
      "epoch 34; iter: 0; batch classifier loss: 0.359658; batch adversarial loss: 0.576010\n",
      "epoch 35; iter: 0; batch classifier loss: 0.203520; batch adversarial loss: 0.625420\n",
      "epoch 36; iter: 0; batch classifier loss: 0.240866; batch adversarial loss: 0.610340\n",
      "epoch 37; iter: 0; batch classifier loss: 0.310842; batch adversarial loss: 0.628870\n",
      "epoch 38; iter: 0; batch classifier loss: 0.337699; batch adversarial loss: 0.571229\n",
      "epoch 39; iter: 0; batch classifier loss: 0.236237; batch adversarial loss: 0.593917\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430013; batch adversarial loss: 0.588122\n",
      "epoch 41; iter: 0; batch classifier loss: 0.398902; batch adversarial loss: 0.586950\n",
      "epoch 42; iter: 0; batch classifier loss: 0.283985; batch adversarial loss: 0.618920\n",
      "epoch 43; iter: 0; batch classifier loss: 0.381642; batch adversarial loss: 0.590764\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414429; batch adversarial loss: 0.603231\n",
      "epoch 45; iter: 0; batch classifier loss: 0.391710; batch adversarial loss: 0.634740\n",
      "epoch 46; iter: 0; batch classifier loss: 0.360718; batch adversarial loss: 0.615742\n",
      "epoch 47; iter: 0; batch classifier loss: 0.222986; batch adversarial loss: 0.574845\n",
      "epoch 48; iter: 0; batch classifier loss: 0.233388; batch adversarial loss: 0.599181\n",
      "epoch 49; iter: 0; batch classifier loss: 0.357066; batch adversarial loss: 0.610068\n",
      "epoch 50; iter: 0; batch classifier loss: 0.306261; batch adversarial loss: 0.626568\n",
      "epoch 51; iter: 0; batch classifier loss: 0.376703; batch adversarial loss: 0.597224\n",
      "epoch 52; iter: 0; batch classifier loss: 0.382613; batch adversarial loss: 0.620699\n",
      "epoch 53; iter: 0; batch classifier loss: 0.297666; batch adversarial loss: 0.630755\n",
      "epoch 54; iter: 0; batch classifier loss: 0.354874; batch adversarial loss: 0.609382\n",
      "epoch 55; iter: 0; batch classifier loss: 0.294815; batch adversarial loss: 0.602977\n",
      "epoch 56; iter: 0; batch classifier loss: 0.377244; batch adversarial loss: 0.637177\n",
      "epoch 57; iter: 0; batch classifier loss: 0.339130; batch adversarial loss: 0.647319\n",
      "epoch 58; iter: 0; batch classifier loss: 0.198791; batch adversarial loss: 0.566848\n",
      "epoch 59; iter: 0; batch classifier loss: 0.324934; batch adversarial loss: 0.531725\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770477; batch adversarial loss: 0.566386\n",
      "epoch 1; iter: 0; batch classifier loss: 0.745171; batch adversarial loss: 0.582815\n",
      "epoch 2; iter: 0; batch classifier loss: 0.669570; batch adversarial loss: 0.592798\n",
      "epoch 3; iter: 0; batch classifier loss: 0.601724; batch adversarial loss: 0.592291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.568150; batch adversarial loss: 0.617389\n",
      "epoch 5; iter: 0; batch classifier loss: 0.466204; batch adversarial loss: 0.614399\n",
      "epoch 6; iter: 0; batch classifier loss: 0.454246; batch adversarial loss: 0.687233\n",
      "epoch 7; iter: 0; batch classifier loss: 0.438208; batch adversarial loss: 0.511308\n",
      "epoch 8; iter: 0; batch classifier loss: 0.486444; batch adversarial loss: 0.612270\n",
      "epoch 9; iter: 0; batch classifier loss: 0.437629; batch adversarial loss: 0.594341\n",
      "epoch 10; iter: 0; batch classifier loss: 0.407586; batch adversarial loss: 0.563584\n",
      "epoch 11; iter: 0; batch classifier loss: 0.405304; batch adversarial loss: 0.655958\n",
      "epoch 12; iter: 0; batch classifier loss: 0.412887; batch adversarial loss: 0.618635\n",
      "epoch 13; iter: 0; batch classifier loss: 0.438549; batch adversarial loss: 0.683752\n",
      "epoch 14; iter: 0; batch classifier loss: 0.310869; batch adversarial loss: 0.617651\n",
      "epoch 15; iter: 0; batch classifier loss: 0.349908; batch adversarial loss: 0.649939\n",
      "epoch 16; iter: 0; batch classifier loss: 0.452126; batch adversarial loss: 0.514291\n",
      "epoch 17; iter: 0; batch classifier loss: 0.317416; batch adversarial loss: 0.671948\n",
      "epoch 18; iter: 0; batch classifier loss: 0.378847; batch adversarial loss: 0.565963\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382960; batch adversarial loss: 0.603576\n",
      "epoch 20; iter: 0; batch classifier loss: 0.256263; batch adversarial loss: 0.526230\n",
      "epoch 21; iter: 0; batch classifier loss: 0.374176; batch adversarial loss: 0.645588\n",
      "epoch 22; iter: 0; batch classifier loss: 0.321695; batch adversarial loss: 0.728377\n",
      "epoch 23; iter: 0; batch classifier loss: 0.353442; batch adversarial loss: 0.546662\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314205; batch adversarial loss: 0.551516\n",
      "epoch 25; iter: 0; batch classifier loss: 0.452285; batch adversarial loss: 0.601135\n",
      "epoch 26; iter: 0; batch classifier loss: 0.254404; batch adversarial loss: 0.672684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414909; batch adversarial loss: 0.539915\n",
      "epoch 28; iter: 0; batch classifier loss: 0.215595; batch adversarial loss: 0.582483\n",
      "epoch 29; iter: 0; batch classifier loss: 0.343091; batch adversarial loss: 0.671144\n",
      "epoch 30; iter: 0; batch classifier loss: 0.426903; batch adversarial loss: 0.559865\n",
      "epoch 31; iter: 0; batch classifier loss: 0.355312; batch adversarial loss: 0.606465\n",
      "epoch 32; iter: 0; batch classifier loss: 0.236386; batch adversarial loss: 0.683681\n",
      "epoch 33; iter: 0; batch classifier loss: 0.284469; batch adversarial loss: 0.637408\n",
      "epoch 34; iter: 0; batch classifier loss: 0.362963; batch adversarial loss: 0.571675\n",
      "epoch 35; iter: 0; batch classifier loss: 0.292194; batch adversarial loss: 0.596955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.341670; batch adversarial loss: 0.636842\n",
      "epoch 37; iter: 0; batch classifier loss: 0.359672; batch adversarial loss: 0.588750\n",
      "epoch 38; iter: 0; batch classifier loss: 0.293830; batch adversarial loss: 0.551326\n",
      "epoch 39; iter: 0; batch classifier loss: 0.287102; batch adversarial loss: 0.581891\n",
      "epoch 40; iter: 0; batch classifier loss: 0.306545; batch adversarial loss: 0.572822\n",
      "epoch 41; iter: 0; batch classifier loss: 0.330590; batch adversarial loss: 0.685871\n",
      "epoch 42; iter: 0; batch classifier loss: 0.309819; batch adversarial loss: 0.611792\n",
      "epoch 43; iter: 0; batch classifier loss: 0.258569; batch adversarial loss: 0.520339\n",
      "epoch 44; iter: 0; batch classifier loss: 0.279246; batch adversarial loss: 0.622516\n",
      "epoch 45; iter: 0; batch classifier loss: 0.353192; batch adversarial loss: 0.600320\n",
      "epoch 46; iter: 0; batch classifier loss: 0.279363; batch adversarial loss: 0.562745\n",
      "epoch 47; iter: 0; batch classifier loss: 0.237430; batch adversarial loss: 0.494489\n",
      "epoch 48; iter: 0; batch classifier loss: 0.367867; batch adversarial loss: 0.635708\n",
      "epoch 49; iter: 0; batch classifier loss: 0.315969; batch adversarial loss: 0.632782\n",
      "epoch 50; iter: 0; batch classifier loss: 0.358811; batch adversarial loss: 0.601886\n",
      "epoch 51; iter: 0; batch classifier loss: 0.241245; batch adversarial loss: 0.524409\n",
      "epoch 52; iter: 0; batch classifier loss: 0.324860; batch adversarial loss: 0.626871\n",
      "epoch 53; iter: 0; batch classifier loss: 0.239346; batch adversarial loss: 0.597476\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195987; batch adversarial loss: 0.681099\n",
      "epoch 55; iter: 0; batch classifier loss: 0.268906; batch adversarial loss: 0.566970\n",
      "epoch 56; iter: 0; batch classifier loss: 0.277117; batch adversarial loss: 0.663892\n",
      "epoch 57; iter: 0; batch classifier loss: 0.261004; batch adversarial loss: 0.647509\n",
      "epoch 58; iter: 0; batch classifier loss: 0.296762; batch adversarial loss: 0.587416\n",
      "epoch 59; iter: 0; batch classifier loss: 0.192812; batch adversarial loss: 0.596713\n",
      "epoch 0; iter: 0; batch classifier loss: 0.626793; batch adversarial loss: 0.680772\n",
      "epoch 1; iter: 0; batch classifier loss: 0.580104; batch adversarial loss: 0.674670\n",
      "epoch 2; iter: 0; batch classifier loss: 0.616216; batch adversarial loss: 0.689233\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607876; batch adversarial loss: 0.659914\n",
      "epoch 4; iter: 0; batch classifier loss: 0.527271; batch adversarial loss: 0.688995\n",
      "epoch 5; iter: 0; batch classifier loss: 0.549231; batch adversarial loss: 0.668348\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552409; batch adversarial loss: 0.669137\n",
      "epoch 7; iter: 0; batch classifier loss: 0.502571; batch adversarial loss: 0.657996\n",
      "epoch 8; iter: 0; batch classifier loss: 0.532656; batch adversarial loss: 0.661012\n",
      "epoch 9; iter: 0; batch classifier loss: 0.507564; batch adversarial loss: 0.660840\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542171; batch adversarial loss: 0.680022\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512032; batch adversarial loss: 0.647699\n",
      "epoch 12; iter: 0; batch classifier loss: 0.498757; batch adversarial loss: 0.648162\n",
      "epoch 13; iter: 0; batch classifier loss: 0.440509; batch adversarial loss: 0.660499\n",
      "epoch 14; iter: 0; batch classifier loss: 0.392661; batch adversarial loss: 0.676046\n",
      "epoch 15; iter: 0; batch classifier loss: 0.468532; batch adversarial loss: 0.678379\n",
      "epoch 16; iter: 0; batch classifier loss: 0.429668; batch adversarial loss: 0.652798\n",
      "epoch 17; iter: 0; batch classifier loss: 0.444664; batch adversarial loss: 0.665348\n",
      "epoch 18; iter: 0; batch classifier loss: 0.461310; batch adversarial loss: 0.642554\n",
      "epoch 19; iter: 0; batch classifier loss: 0.439909; batch adversarial loss: 0.658481\n",
      "epoch 20; iter: 0; batch classifier loss: 0.475491; batch adversarial loss: 0.671521\n",
      "epoch 21; iter: 0; batch classifier loss: 0.415188; batch adversarial loss: 0.650470\n",
      "epoch 22; iter: 0; batch classifier loss: 0.430922; batch adversarial loss: 0.639166\n",
      "epoch 23; iter: 0; batch classifier loss: 0.404257; batch adversarial loss: 0.645618\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429709; batch adversarial loss: 0.634394\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409557; batch adversarial loss: 0.643019\n",
      "epoch 26; iter: 0; batch classifier loss: 0.429505; batch adversarial loss: 0.654806\n",
      "epoch 27; iter: 0; batch classifier loss: 0.413310; batch adversarial loss: 0.651907\n",
      "epoch 28; iter: 0; batch classifier loss: 0.405377; batch adversarial loss: 0.641850\n",
      "epoch 29; iter: 0; batch classifier loss: 0.362751; batch adversarial loss: 0.652578\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352996; batch adversarial loss: 0.651755\n",
      "epoch 31; iter: 0; batch classifier loss: 0.344907; batch adversarial loss: 0.643539\n",
      "epoch 32; iter: 0; batch classifier loss: 0.377777; batch adversarial loss: 0.669589\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385042; batch adversarial loss: 0.635725\n",
      "epoch 34; iter: 0; batch classifier loss: 0.453778; batch adversarial loss: 0.625587\n",
      "epoch 35; iter: 0; batch classifier loss: 0.407171; batch adversarial loss: 0.641731\n",
      "epoch 36; iter: 0; batch classifier loss: 0.344112; batch adversarial loss: 0.646587\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394668; batch adversarial loss: 0.630500\n",
      "epoch 38; iter: 0; batch classifier loss: 0.356212; batch adversarial loss: 0.649977\n",
      "epoch 39; iter: 0; batch classifier loss: 0.387307; batch adversarial loss: 0.647713\n",
      "epoch 40; iter: 0; batch classifier loss: 0.356084; batch adversarial loss: 0.647522\n",
      "epoch 41; iter: 0; batch classifier loss: 0.352439; batch adversarial loss: 0.633916\n",
      "epoch 42; iter: 0; batch classifier loss: 0.340797; batch adversarial loss: 0.610375\n",
      "epoch 43; iter: 0; batch classifier loss: 0.330299; batch adversarial loss: 0.629473\n",
      "epoch 44; iter: 0; batch classifier loss: 0.374962; batch adversarial loss: 0.613202\n",
      "epoch 45; iter: 0; batch classifier loss: 0.367664; batch adversarial loss: 0.621712\n",
      "epoch 46; iter: 0; batch classifier loss: 0.312895; batch adversarial loss: 0.627120\n",
      "epoch 47; iter: 0; batch classifier loss: 0.371553; batch adversarial loss: 0.652466\n",
      "epoch 48; iter: 0; batch classifier loss: 0.319484; batch adversarial loss: 0.635014\n",
      "epoch 49; iter: 0; batch classifier loss: 0.393738; batch adversarial loss: 0.623601\n",
      "epoch 50; iter: 0; batch classifier loss: 0.359192; batch adversarial loss: 0.661853\n",
      "epoch 51; iter: 0; batch classifier loss: 0.363972; batch adversarial loss: 0.604731\n",
      "epoch 52; iter: 0; batch classifier loss: 0.328007; batch adversarial loss: 0.634184\n",
      "epoch 53; iter: 0; batch classifier loss: 0.385945; batch adversarial loss: 0.610965\n",
      "epoch 54; iter: 0; batch classifier loss: 0.296638; batch adversarial loss: 0.631685\n",
      "epoch 55; iter: 0; batch classifier loss: 0.276730; batch adversarial loss: 0.622017\n",
      "epoch 56; iter: 0; batch classifier loss: 0.388320; batch adversarial loss: 0.632658\n",
      "epoch 57; iter: 0; batch classifier loss: 0.317640; batch adversarial loss: 0.631376\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328261; batch adversarial loss: 0.598161\n",
      "epoch 59; iter: 0; batch classifier loss: 0.386953; batch adversarial loss: 0.626915\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712717; batch adversarial loss: 0.690508\n",
      "epoch 1; iter: 0; batch classifier loss: 0.663047; batch adversarial loss: 0.687771\n",
      "epoch 2; iter: 0; batch classifier loss: 0.658532; batch adversarial loss: 0.688742\n",
      "epoch 3; iter: 0; batch classifier loss: 0.653684; batch adversarial loss: 0.686188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.586416; batch adversarial loss: 0.684839\n",
      "epoch 5; iter: 0; batch classifier loss: 0.620581; batch adversarial loss: 0.676747\n",
      "epoch 6; iter: 0; batch classifier loss: 0.544298; batch adversarial loss: 0.682505\n",
      "epoch 7; iter: 0; batch classifier loss: 0.584712; batch adversarial loss: 0.682091\n",
      "epoch 8; iter: 0; batch classifier loss: 0.513917; batch adversarial loss: 0.681181\n",
      "epoch 9; iter: 0; batch classifier loss: 0.537359; batch adversarial loss: 0.677740\n",
      "epoch 10; iter: 0; batch classifier loss: 0.526036; batch adversarial loss: 0.673523\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515837; batch adversarial loss: 0.675707\n",
      "epoch 12; iter: 0; batch classifier loss: 0.505768; batch adversarial loss: 0.673346\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484370; batch adversarial loss: 0.671705\n",
      "epoch 14; iter: 0; batch classifier loss: 0.417163; batch adversarial loss: 0.670935\n",
      "epoch 15; iter: 0; batch classifier loss: 0.447109; batch adversarial loss: 0.676991\n",
      "epoch 16; iter: 0; batch classifier loss: 0.502049; batch adversarial loss: 0.663171\n",
      "epoch 17; iter: 0; batch classifier loss: 0.459715; batch adversarial loss: 0.668697\n",
      "epoch 18; iter: 0; batch classifier loss: 0.467799; batch adversarial loss: 0.658667\n",
      "epoch 19; iter: 0; batch classifier loss: 0.462017; batch adversarial loss: 0.655817\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387139; batch adversarial loss: 0.677722\n",
      "epoch 21; iter: 0; batch classifier loss: 0.443409; batch adversarial loss: 0.656726\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452101; batch adversarial loss: 0.663716\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368569; batch adversarial loss: 0.668443\n",
      "epoch 24; iter: 0; batch classifier loss: 0.348000; batch adversarial loss: 0.654477\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396152; batch adversarial loss: 0.666096\n",
      "epoch 26; iter: 0; batch classifier loss: 0.453411; batch adversarial loss: 0.643336\n",
      "epoch 27; iter: 0; batch classifier loss: 0.405904; batch adversarial loss: 0.644076\n",
      "epoch 28; iter: 0; batch classifier loss: 0.372933; batch adversarial loss: 0.655102\n",
      "epoch 29; iter: 0; batch classifier loss: 0.460654; batch adversarial loss: 0.654954\n",
      "epoch 30; iter: 0; batch classifier loss: 0.456521; batch adversarial loss: 0.647353\n",
      "epoch 31; iter: 0; batch classifier loss: 0.469346; batch adversarial loss: 0.653224\n",
      "epoch 32; iter: 0; batch classifier loss: 0.360706; batch adversarial loss: 0.646023\n",
      "epoch 33; iter: 0; batch classifier loss: 0.433098; batch adversarial loss: 0.667601\n",
      "epoch 34; iter: 0; batch classifier loss: 0.430740; batch adversarial loss: 0.647912\n",
      "epoch 35; iter: 0; batch classifier loss: 0.422322; batch adversarial loss: 0.649107\n",
      "epoch 36; iter: 0; batch classifier loss: 0.348575; batch adversarial loss: 0.639095\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439006; batch adversarial loss: 0.656360\n",
      "epoch 38; iter: 0; batch classifier loss: 0.309598; batch adversarial loss: 0.665512\n",
      "epoch 39; iter: 0; batch classifier loss: 0.408164; batch adversarial loss: 0.637811\n",
      "epoch 40; iter: 0; batch classifier loss: 0.360125; batch adversarial loss: 0.630171\n",
      "epoch 41; iter: 0; batch classifier loss: 0.406757; batch adversarial loss: 0.656553\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374822; batch adversarial loss: 0.656153\n",
      "epoch 43; iter: 0; batch classifier loss: 0.406201; batch adversarial loss: 0.667541\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393850; batch adversarial loss: 0.641456\n",
      "epoch 45; iter: 0; batch classifier loss: 0.444014; batch adversarial loss: 0.646208\n",
      "epoch 46; iter: 0; batch classifier loss: 0.401418; batch adversarial loss: 0.648095\n",
      "epoch 47; iter: 0; batch classifier loss: 0.362207; batch adversarial loss: 0.646277\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391515; batch adversarial loss: 0.631504\n",
      "epoch 49; iter: 0; batch classifier loss: 0.380713; batch adversarial loss: 0.658938\n",
      "epoch 50; iter: 0; batch classifier loss: 0.393737; batch adversarial loss: 0.651527\n",
      "epoch 51; iter: 0; batch classifier loss: 0.438766; batch adversarial loss: 0.662158\n",
      "epoch 52; iter: 0; batch classifier loss: 0.329056; batch adversarial loss: 0.649921\n",
      "epoch 53; iter: 0; batch classifier loss: 0.335865; batch adversarial loss: 0.644287\n",
      "epoch 54; iter: 0; batch classifier loss: 0.383246; batch adversarial loss: 0.634230\n",
      "epoch 55; iter: 0; batch classifier loss: 0.348237; batch adversarial loss: 0.646504\n",
      "epoch 56; iter: 0; batch classifier loss: 0.344846; batch adversarial loss: 0.649793\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372348; batch adversarial loss: 0.620764\n",
      "epoch 58; iter: 0; batch classifier loss: 0.353644; batch adversarial loss: 0.630320\n",
      "epoch 59; iter: 0; batch classifier loss: 0.430517; batch adversarial loss: 0.633457\n",
      "epoch 0; iter: 0; batch classifier loss: 0.852094; batch adversarial loss: 0.604787\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780365; batch adversarial loss: 0.660642\n",
      "epoch 2; iter: 0; batch classifier loss: 0.752251; batch adversarial loss: 0.642318\n",
      "epoch 3; iter: 0; batch classifier loss: 0.653022; batch adversarial loss: 0.633130\n",
      "epoch 4; iter: 0; batch classifier loss: 0.603342; batch adversarial loss: 0.623903\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543537; batch adversarial loss: 0.664091\n",
      "epoch 6; iter: 0; batch classifier loss: 0.520176; batch adversarial loss: 0.676803\n",
      "epoch 7; iter: 0; batch classifier loss: 0.501568; batch adversarial loss: 0.636267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520788; batch adversarial loss: 0.618132\n",
      "epoch 9; iter: 0; batch classifier loss: 0.447528; batch adversarial loss: 0.634233\n",
      "epoch 10; iter: 0; batch classifier loss: 0.451558; batch adversarial loss: 0.666052\n",
      "epoch 11; iter: 0; batch classifier loss: 0.390113; batch adversarial loss: 0.615859\n",
      "epoch 12; iter: 0; batch classifier loss: 0.437564; batch adversarial loss: 0.652843\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435828; batch adversarial loss: 0.675785\n",
      "epoch 14; iter: 0; batch classifier loss: 0.481573; batch adversarial loss: 0.585264\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443219; batch adversarial loss: 0.728896\n",
      "epoch 16; iter: 0; batch classifier loss: 0.393583; batch adversarial loss: 0.619252\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349812; batch adversarial loss: 0.560394\n",
      "epoch 18; iter: 0; batch classifier loss: 0.274564; batch adversarial loss: 0.617260\n",
      "epoch 19; iter: 0; batch classifier loss: 0.392678; batch adversarial loss: 0.615708\n",
      "epoch 20; iter: 0; batch classifier loss: 0.401839; batch adversarial loss: 0.638092\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439424; batch adversarial loss: 0.590833\n",
      "epoch 22; iter: 0; batch classifier loss: 0.475392; batch adversarial loss: 0.634436\n",
      "epoch 23; iter: 0; batch classifier loss: 0.436905; batch adversarial loss: 0.618084\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362793; batch adversarial loss: 0.600497\n",
      "epoch 25; iter: 0; batch classifier loss: 0.269481; batch adversarial loss: 0.615173\n",
      "epoch 26; iter: 0; batch classifier loss: 0.502200; batch adversarial loss: 0.605404\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411889; batch adversarial loss: 0.633701\n",
      "epoch 28; iter: 0; batch classifier loss: 0.351222; batch adversarial loss: 0.526880\n",
      "epoch 29; iter: 0; batch classifier loss: 0.303666; batch adversarial loss: 0.654130\n",
      "epoch 30; iter: 0; batch classifier loss: 0.346794; batch adversarial loss: 0.655158\n",
      "epoch 31; iter: 0; batch classifier loss: 0.345054; batch adversarial loss: 0.581629\n",
      "epoch 32; iter: 0; batch classifier loss: 0.278999; batch adversarial loss: 0.662760\n",
      "epoch 33; iter: 0; batch classifier loss: 0.279108; batch adversarial loss: 0.632961\n",
      "epoch 34; iter: 0; batch classifier loss: 0.429809; batch adversarial loss: 0.641011\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403315; batch adversarial loss: 0.641617\n",
      "epoch 36; iter: 0; batch classifier loss: 0.305145; batch adversarial loss: 0.602190\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402986; batch adversarial loss: 0.656712\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359931; batch adversarial loss: 0.615132\n",
      "epoch 39; iter: 0; batch classifier loss: 0.421850; batch adversarial loss: 0.641826\n",
      "epoch 40; iter: 0; batch classifier loss: 0.501674; batch adversarial loss: 0.594292\n",
      "epoch 41; iter: 0; batch classifier loss: 0.317923; batch adversarial loss: 0.639544\n",
      "epoch 42; iter: 0; batch classifier loss: 0.313812; batch adversarial loss: 0.557228\n",
      "epoch 43; iter: 0; batch classifier loss: 0.449180; batch adversarial loss: 0.594518\n",
      "epoch 44; iter: 0; batch classifier loss: 0.283603; batch adversarial loss: 0.524348\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289924; batch adversarial loss: 0.581342\n",
      "epoch 46; iter: 0; batch classifier loss: 0.320376; batch adversarial loss: 0.640640\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431416; batch adversarial loss: 0.588755\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314467; batch adversarial loss: 0.578846\n",
      "epoch 49; iter: 0; batch classifier loss: 0.299518; batch adversarial loss: 0.643640\n",
      "epoch 50; iter: 0; batch classifier loss: 0.296037; batch adversarial loss: 0.625044\n",
      "epoch 51; iter: 0; batch classifier loss: 0.302631; batch adversarial loss: 0.586948\n",
      "epoch 52; iter: 0; batch classifier loss: 0.278671; batch adversarial loss: 0.568607\n",
      "epoch 53; iter: 0; batch classifier loss: 0.338975; batch adversarial loss: 0.575114\n",
      "epoch 54; iter: 0; batch classifier loss: 0.377532; batch adversarial loss: 0.637373\n",
      "epoch 55; iter: 0; batch classifier loss: 0.417293; batch adversarial loss: 0.614803\n",
      "epoch 56; iter: 0; batch classifier loss: 0.432665; batch adversarial loss: 0.586522\n",
      "epoch 57; iter: 0; batch classifier loss: 0.464345; batch adversarial loss: 0.550108\n",
      "epoch 58; iter: 0; batch classifier loss: 0.338328; batch adversarial loss: 0.623488\n",
      "epoch 59; iter: 0; batch classifier loss: 0.307747; batch adversarial loss: 0.568816\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396112; batch adversarial loss: 0.527543\n",
      "epoch 61; iter: 0; batch classifier loss: 0.294935; batch adversarial loss: 0.690550\n",
      "epoch 62; iter: 0; batch classifier loss: 0.267585; batch adversarial loss: 0.596444\n",
      "epoch 63; iter: 0; batch classifier loss: 0.335455; batch adversarial loss: 0.592622\n",
      "epoch 64; iter: 0; batch classifier loss: 0.409581; batch adversarial loss: 0.636507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.303218; batch adversarial loss: 0.641861\n",
      "epoch 66; iter: 0; batch classifier loss: 0.284157; batch adversarial loss: 0.657015\n",
      "epoch 67; iter: 0; batch classifier loss: 0.294033; batch adversarial loss: 0.590490\n",
      "epoch 68; iter: 0; batch classifier loss: 0.353121; batch adversarial loss: 0.616618\n",
      "epoch 69; iter: 0; batch classifier loss: 0.328948; batch adversarial loss: 0.591494\n",
      "epoch 70; iter: 0; batch classifier loss: 0.298671; batch adversarial loss: 0.596496\n",
      "epoch 71; iter: 0; batch classifier loss: 0.292180; batch adversarial loss: 0.713696\n",
      "epoch 72; iter: 0; batch classifier loss: 0.263759; batch adversarial loss: 0.544607\n",
      "epoch 73; iter: 0; batch classifier loss: 0.378545; batch adversarial loss: 0.588682\n",
      "epoch 74; iter: 0; batch classifier loss: 0.376831; batch adversarial loss: 0.617035\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339264; batch adversarial loss: 0.558956\n",
      "epoch 76; iter: 0; batch classifier loss: 0.327756; batch adversarial loss: 0.557279\n",
      "epoch 77; iter: 0; batch classifier loss: 0.328967; batch adversarial loss: 0.634245\n",
      "epoch 78; iter: 0; batch classifier loss: 0.398138; batch adversarial loss: 0.543019\n",
      "epoch 79; iter: 0; batch classifier loss: 0.277507; batch adversarial loss: 0.539541\n",
      "epoch 0; iter: 0; batch classifier loss: 0.727440; batch adversarial loss: 0.638599\n",
      "epoch 1; iter: 0; batch classifier loss: 0.692702; batch adversarial loss: 0.624181\n",
      "epoch 2; iter: 0; batch classifier loss: 0.612611; batch adversarial loss: 0.646124\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612770; batch adversarial loss: 0.672291\n",
      "epoch 4; iter: 0; batch classifier loss: 0.549965; batch adversarial loss: 0.638764\n",
      "epoch 5; iter: 0; batch classifier loss: 0.544833; batch adversarial loss: 0.645349\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573907; batch adversarial loss: 0.628374\n",
      "epoch 7; iter: 0; batch classifier loss: 0.461685; batch adversarial loss: 0.660728\n",
      "epoch 8; iter: 0; batch classifier loss: 0.348990; batch adversarial loss: 0.653293\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455761; batch adversarial loss: 0.611759\n",
      "epoch 10; iter: 0; batch classifier loss: 0.372193; batch adversarial loss: 0.647534\n",
      "epoch 11; iter: 0; batch classifier loss: 0.381817; batch adversarial loss: 0.650838\n",
      "epoch 12; iter: 0; batch classifier loss: 0.376078; batch adversarial loss: 0.630437\n",
      "epoch 13; iter: 0; batch classifier loss: 0.348359; batch adversarial loss: 0.637468\n",
      "epoch 14; iter: 0; batch classifier loss: 0.362387; batch adversarial loss: 0.577869\n",
      "epoch 15; iter: 0; batch classifier loss: 0.372623; batch adversarial loss: 0.624398\n",
      "epoch 16; iter: 0; batch classifier loss: 0.296816; batch adversarial loss: 0.622838\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377847; batch adversarial loss: 0.590622\n",
      "epoch 18; iter: 0; batch classifier loss: 0.273155; batch adversarial loss: 0.634266\n",
      "epoch 19; iter: 0; batch classifier loss: 0.415440; batch adversarial loss: 0.601067\n",
      "epoch 20; iter: 0; batch classifier loss: 0.374995; batch adversarial loss: 0.615650\n",
      "epoch 21; iter: 0; batch classifier loss: 0.292115; batch adversarial loss: 0.583061\n",
      "epoch 22; iter: 0; batch classifier loss: 0.308556; batch adversarial loss: 0.625473\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444798; batch adversarial loss: 0.574219\n",
      "epoch 24; iter: 0; batch classifier loss: 0.258838; batch adversarial loss: 0.592137\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275362; batch adversarial loss: 0.581336\n",
      "epoch 26; iter: 0; batch classifier loss: 0.264976; batch adversarial loss: 0.581497\n",
      "epoch 27; iter: 0; batch classifier loss: 0.171738; batch adversarial loss: 0.547445\n",
      "epoch 28; iter: 0; batch classifier loss: 0.302379; batch adversarial loss: 0.647167\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320672; batch adversarial loss: 0.643997\n",
      "epoch 30; iter: 0; batch classifier loss: 0.229988; batch adversarial loss: 0.634443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.475972; batch adversarial loss: 0.542349\n",
      "epoch 32; iter: 0; batch classifier loss: 0.521602; batch adversarial loss: 0.594393\n",
      "epoch 33; iter: 0; batch classifier loss: 0.520217; batch adversarial loss: 0.583627\n",
      "epoch 34; iter: 0; batch classifier loss: 0.268089; batch adversarial loss: 0.605889\n",
      "epoch 35; iter: 0; batch classifier loss: 0.249705; batch adversarial loss: 0.621384\n",
      "epoch 36; iter: 0; batch classifier loss: 0.235656; batch adversarial loss: 0.603760\n",
      "epoch 37; iter: 0; batch classifier loss: 0.305874; batch adversarial loss: 0.588629\n",
      "epoch 38; iter: 0; batch classifier loss: 0.269050; batch adversarial loss: 0.634056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.294528; batch adversarial loss: 0.655025\n",
      "epoch 40; iter: 0; batch classifier loss: 0.209421; batch adversarial loss: 0.625598\n",
      "epoch 41; iter: 0; batch classifier loss: 0.265482; batch adversarial loss: 0.585197\n",
      "epoch 42; iter: 0; batch classifier loss: 0.318703; batch adversarial loss: 0.587034\n",
      "epoch 43; iter: 0; batch classifier loss: 0.230101; batch adversarial loss: 0.603557\n",
      "epoch 44; iter: 0; batch classifier loss: 0.250335; batch adversarial loss: 0.589454\n",
      "epoch 45; iter: 0; batch classifier loss: 0.319781; batch adversarial loss: 0.598275\n",
      "epoch 46; iter: 0; batch classifier loss: 0.253484; batch adversarial loss: 0.597680\n",
      "epoch 47; iter: 0; batch classifier loss: 0.409412; batch adversarial loss: 0.645104\n",
      "epoch 48; iter: 0; batch classifier loss: 0.306766; batch adversarial loss: 0.555192\n",
      "epoch 49; iter: 0; batch classifier loss: 0.325153; batch adversarial loss: 0.669514\n",
      "epoch 50; iter: 0; batch classifier loss: 0.243711; batch adversarial loss: 0.642226\n",
      "epoch 51; iter: 0; batch classifier loss: 0.307826; batch adversarial loss: 0.676213\n",
      "epoch 52; iter: 0; batch classifier loss: 0.342886; batch adversarial loss: 0.652365\n",
      "epoch 53; iter: 0; batch classifier loss: 0.285238; batch adversarial loss: 0.574026\n",
      "epoch 54; iter: 0; batch classifier loss: 0.224914; batch adversarial loss: 0.605760\n",
      "epoch 55; iter: 0; batch classifier loss: 0.258801; batch adversarial loss: 0.651246\n",
      "epoch 56; iter: 0; batch classifier loss: 0.239088; batch adversarial loss: 0.610576\n",
      "epoch 57; iter: 0; batch classifier loss: 0.267790; batch adversarial loss: 0.531370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.270525; batch adversarial loss: 0.580305\n",
      "epoch 59; iter: 0; batch classifier loss: 0.199260; batch adversarial loss: 0.655527\n",
      "epoch 60; iter: 0; batch classifier loss: 0.285192; batch adversarial loss: 0.515857\n",
      "epoch 61; iter: 0; batch classifier loss: 0.308167; batch adversarial loss: 0.512713\n",
      "epoch 62; iter: 0; batch classifier loss: 0.291010; batch adversarial loss: 0.672234\n",
      "epoch 63; iter: 0; batch classifier loss: 0.229188; batch adversarial loss: 0.597082\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249233; batch adversarial loss: 0.612787\n",
      "epoch 65; iter: 0; batch classifier loss: 0.331851; batch adversarial loss: 0.603798\n",
      "epoch 66; iter: 0; batch classifier loss: 0.309281; batch adversarial loss: 0.665759\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391626; batch adversarial loss: 0.694132\n",
      "epoch 68; iter: 0; batch classifier loss: 0.268281; batch adversarial loss: 0.575480\n",
      "epoch 69; iter: 0; batch classifier loss: 0.487760; batch adversarial loss: 0.589810\n",
      "epoch 70; iter: 0; batch classifier loss: 0.272117; batch adversarial loss: 0.594965\n",
      "epoch 71; iter: 0; batch classifier loss: 0.252763; batch adversarial loss: 0.550427\n",
      "epoch 72; iter: 0; batch classifier loss: 0.348758; batch adversarial loss: 0.625924\n",
      "epoch 73; iter: 0; batch classifier loss: 0.168939; batch adversarial loss: 0.604058\n",
      "epoch 74; iter: 0; batch classifier loss: 0.228198; batch adversarial loss: 0.577081\n",
      "epoch 75; iter: 0; batch classifier loss: 0.219414; batch adversarial loss: 0.667891\n",
      "epoch 76; iter: 0; batch classifier loss: 0.222880; batch adversarial loss: 0.656630\n",
      "epoch 77; iter: 0; batch classifier loss: 0.266139; batch adversarial loss: 0.596452\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216326; batch adversarial loss: 0.608103\n",
      "epoch 79; iter: 0; batch classifier loss: 0.168882; batch adversarial loss: 0.576225\n",
      "epoch 0; iter: 0; batch classifier loss: 0.807490; batch adversarial loss: 0.747016\n",
      "epoch 1; iter: 0; batch classifier loss: 0.815487; batch adversarial loss: 0.736855\n",
      "epoch 2; iter: 0; batch classifier loss: 0.739979; batch adversarial loss: 0.743786\n",
      "epoch 3; iter: 0; batch classifier loss: 0.712619; batch adversarial loss: 0.736574\n",
      "epoch 4; iter: 0; batch classifier loss: 0.666678; batch adversarial loss: 0.728593\n",
      "epoch 5; iter: 0; batch classifier loss: 0.673195; batch adversarial loss: 0.738454\n",
      "epoch 6; iter: 0; batch classifier loss: 0.699144; batch adversarial loss: 0.722393\n",
      "epoch 7; iter: 0; batch classifier loss: 0.630772; batch adversarial loss: 0.729370\n",
      "epoch 8; iter: 0; batch classifier loss: 0.606195; batch adversarial loss: 0.721681\n",
      "epoch 9; iter: 0; batch classifier loss: 0.585810; batch adversarial loss: 0.730221\n",
      "epoch 10; iter: 0; batch classifier loss: 0.572528; batch adversarial loss: 0.713641\n",
      "epoch 11; iter: 0; batch classifier loss: 0.518564; batch adversarial loss: 0.716568\n",
      "epoch 12; iter: 0; batch classifier loss: 0.541655; batch adversarial loss: 0.728049\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536341; batch adversarial loss: 0.724873\n",
      "epoch 14; iter: 0; batch classifier loss: 0.545528; batch adversarial loss: 0.719963\n",
      "epoch 15; iter: 0; batch classifier loss: 0.496502; batch adversarial loss: 0.717740\n",
      "epoch 16; iter: 0; batch classifier loss: 0.536668; batch adversarial loss: 0.711002\n",
      "epoch 17; iter: 0; batch classifier loss: 0.541260; batch adversarial loss: 0.704072\n",
      "epoch 18; iter: 0; batch classifier loss: 0.494501; batch adversarial loss: 0.720326\n",
      "epoch 19; iter: 0; batch classifier loss: 0.422135; batch adversarial loss: 0.698598\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504831; batch adversarial loss: 0.695975\n",
      "epoch 21; iter: 0; batch classifier loss: 0.427859; batch adversarial loss: 0.701155\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423084; batch adversarial loss: 0.705037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423980; batch adversarial loss: 0.704773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.405668; batch adversarial loss: 0.697772\n",
      "epoch 25; iter: 0; batch classifier loss: 0.424747; batch adversarial loss: 0.695022\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472030; batch adversarial loss: 0.694447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.351236; batch adversarial loss: 0.690774\n",
      "epoch 28; iter: 0; batch classifier loss: 0.415066; batch adversarial loss: 0.692972\n",
      "epoch 29; iter: 0; batch classifier loss: 0.364910; batch adversarial loss: 0.689183\n",
      "epoch 30; iter: 0; batch classifier loss: 0.449995; batch adversarial loss: 0.686566\n",
      "epoch 31; iter: 0; batch classifier loss: 0.462063; batch adversarial loss: 0.682081\n",
      "epoch 32; iter: 0; batch classifier loss: 0.404551; batch adversarial loss: 0.678754\n",
      "epoch 33; iter: 0; batch classifier loss: 0.362389; batch adversarial loss: 0.681686\n",
      "epoch 34; iter: 0; batch classifier loss: 0.444124; batch adversarial loss: 0.680775\n",
      "epoch 35; iter: 0; batch classifier loss: 0.376613; batch adversarial loss: 0.672592\n",
      "epoch 36; iter: 0; batch classifier loss: 0.337359; batch adversarial loss: 0.670843\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385496; batch adversarial loss: 0.672165\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419449; batch adversarial loss: 0.665609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.411120; batch adversarial loss: 0.661623\n",
      "epoch 40; iter: 0; batch classifier loss: 0.516323; batch adversarial loss: 0.668446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.381301; batch adversarial loss: 0.665725\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385888; batch adversarial loss: 0.667973\n",
      "epoch 43; iter: 0; batch classifier loss: 0.422350; batch adversarial loss: 0.668275\n",
      "epoch 44; iter: 0; batch classifier loss: 0.312014; batch adversarial loss: 0.664434\n",
      "epoch 45; iter: 0; batch classifier loss: 0.331276; batch adversarial loss: 0.658437\n",
      "epoch 46; iter: 0; batch classifier loss: 0.341613; batch adversarial loss: 0.658258\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348252; batch adversarial loss: 0.651799\n",
      "epoch 48; iter: 0; batch classifier loss: 0.326451; batch adversarial loss: 0.661598\n",
      "epoch 49; iter: 0; batch classifier loss: 0.334603; batch adversarial loss: 0.657998\n",
      "epoch 50; iter: 0; batch classifier loss: 0.345828; batch adversarial loss: 0.649190\n",
      "epoch 51; iter: 0; batch classifier loss: 0.339402; batch adversarial loss: 0.645064\n",
      "epoch 52; iter: 0; batch classifier loss: 0.277284; batch adversarial loss: 0.650295\n",
      "epoch 53; iter: 0; batch classifier loss: 0.442134; batch adversarial loss: 0.643021\n",
      "epoch 54; iter: 0; batch classifier loss: 0.412421; batch adversarial loss: 0.639313\n",
      "epoch 55; iter: 0; batch classifier loss: 0.308230; batch adversarial loss: 0.655647\n",
      "epoch 56; iter: 0; batch classifier loss: 0.354667; batch adversarial loss: 0.659541\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393633; batch adversarial loss: 0.648634\n",
      "epoch 58; iter: 0; batch classifier loss: 0.389748; batch adversarial loss: 0.641147\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357746; batch adversarial loss: 0.629995\n",
      "epoch 60; iter: 0; batch classifier loss: 0.382360; batch adversarial loss: 0.642434\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392567; batch adversarial loss: 0.638963\n",
      "epoch 62; iter: 0; batch classifier loss: 0.361071; batch adversarial loss: 0.626701\n",
      "epoch 63; iter: 0; batch classifier loss: 0.297974; batch adversarial loss: 0.628153\n",
      "epoch 64; iter: 0; batch classifier loss: 0.411168; batch adversarial loss: 0.647381\n",
      "epoch 65; iter: 0; batch classifier loss: 0.389633; batch adversarial loss: 0.645494\n",
      "epoch 66; iter: 0; batch classifier loss: 0.379841; batch adversarial loss: 0.636981\n",
      "epoch 67; iter: 0; batch classifier loss: 0.283308; batch adversarial loss: 0.641646\n",
      "epoch 68; iter: 0; batch classifier loss: 0.400150; batch adversarial loss: 0.653292\n",
      "epoch 69; iter: 0; batch classifier loss: 0.377509; batch adversarial loss: 0.629255\n",
      "epoch 70; iter: 0; batch classifier loss: 0.364676; batch adversarial loss: 0.632963\n",
      "epoch 71; iter: 0; batch classifier loss: 0.448081; batch adversarial loss: 0.619446\n",
      "epoch 72; iter: 0; batch classifier loss: 0.372223; batch adversarial loss: 0.606931\n",
      "epoch 73; iter: 0; batch classifier loss: 0.293473; batch adversarial loss: 0.625103\n",
      "epoch 74; iter: 0; batch classifier loss: 0.346515; batch adversarial loss: 0.630644\n",
      "epoch 75; iter: 0; batch classifier loss: 0.399298; batch adversarial loss: 0.625643\n",
      "epoch 76; iter: 0; batch classifier loss: 0.285658; batch adversarial loss: 0.602217\n",
      "epoch 77; iter: 0; batch classifier loss: 0.330968; batch adversarial loss: 0.642683\n",
      "epoch 78; iter: 0; batch classifier loss: 0.302128; batch adversarial loss: 0.608048\n",
      "epoch 79; iter: 0; batch classifier loss: 0.358194; batch adversarial loss: 0.620708\n",
      "epoch 0; iter: 0; batch classifier loss: 0.843753; batch adversarial loss: 0.693450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.798621; batch adversarial loss: 0.693610\n",
      "epoch 2; iter: 0; batch classifier loss: 0.771766; batch adversarial loss: 0.691633\n",
      "epoch 3; iter: 0; batch classifier loss: 0.751227; batch adversarial loss: 0.687412\n",
      "epoch 4; iter: 0; batch classifier loss: 0.729038; batch adversarial loss: 0.692174\n",
      "epoch 5; iter: 0; batch classifier loss: 0.719794; batch adversarial loss: 0.685561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.690173; batch adversarial loss: 0.698520\n",
      "epoch 7; iter: 0; batch classifier loss: 0.669031; batch adversarial loss: 0.679569\n",
      "epoch 8; iter: 0; batch classifier loss: 0.659942; batch adversarial loss: 0.665056\n",
      "epoch 9; iter: 0; batch classifier loss: 0.582104; batch adversarial loss: 0.678291\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635288; batch adversarial loss: 0.687471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.593029; batch adversarial loss: 0.669739\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613227; batch adversarial loss: 0.677175\n",
      "epoch 13; iter: 0; batch classifier loss: 0.571391; batch adversarial loss: 0.654239\n",
      "epoch 14; iter: 0; batch classifier loss: 0.574345; batch adversarial loss: 0.672477\n",
      "epoch 15; iter: 0; batch classifier loss: 0.582937; batch adversarial loss: 0.685714\n",
      "epoch 16; iter: 0; batch classifier loss: 0.558287; batch adversarial loss: 0.671997\n",
      "epoch 17; iter: 0; batch classifier loss: 0.480040; batch adversarial loss: 0.692598\n",
      "epoch 18; iter: 0; batch classifier loss: 0.515471; batch adversarial loss: 0.662529\n",
      "epoch 19; iter: 0; batch classifier loss: 0.505989; batch adversarial loss: 0.672737\n",
      "epoch 20; iter: 0; batch classifier loss: 0.514835; batch adversarial loss: 0.663198\n",
      "epoch 21; iter: 0; batch classifier loss: 0.460125; batch adversarial loss: 0.683297\n",
      "epoch 22; iter: 0; batch classifier loss: 0.517464; batch adversarial loss: 0.643416\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477468; batch adversarial loss: 0.659405\n",
      "epoch 24; iter: 0; batch classifier loss: 0.529245; batch adversarial loss: 0.656740\n",
      "epoch 25; iter: 0; batch classifier loss: 0.537812; batch adversarial loss: 0.657218\n",
      "epoch 26; iter: 0; batch classifier loss: 0.558070; batch adversarial loss: 0.693113\n",
      "epoch 27; iter: 0; batch classifier loss: 0.544543; batch adversarial loss: 0.676942\n",
      "epoch 28; iter: 0; batch classifier loss: 0.418711; batch adversarial loss: 0.655510\n",
      "epoch 29; iter: 0; batch classifier loss: 0.487904; batch adversarial loss: 0.678645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.404096; batch adversarial loss: 0.679093\n",
      "epoch 31; iter: 0; batch classifier loss: 0.515088; batch adversarial loss: 0.653702\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459962; batch adversarial loss: 0.663571\n",
      "epoch 33; iter: 0; batch classifier loss: 0.462854; batch adversarial loss: 0.633382\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427192; batch adversarial loss: 0.668828\n",
      "epoch 35; iter: 0; batch classifier loss: 0.447911; batch adversarial loss: 0.652139\n",
      "epoch 36; iter: 0; batch classifier loss: 0.424004; batch adversarial loss: 0.641300\n",
      "epoch 37; iter: 0; batch classifier loss: 0.496824; batch adversarial loss: 0.635788\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451813; batch adversarial loss: 0.646844\n",
      "epoch 39; iter: 0; batch classifier loss: 0.467219; batch adversarial loss: 0.656283\n",
      "epoch 40; iter: 0; batch classifier loss: 0.419583; batch adversarial loss: 0.647460\n",
      "epoch 41; iter: 0; batch classifier loss: 0.465016; batch adversarial loss: 0.657723\n",
      "epoch 42; iter: 0; batch classifier loss: 0.394257; batch adversarial loss: 0.647351\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414413; batch adversarial loss: 0.643484\n",
      "epoch 44; iter: 0; batch classifier loss: 0.476840; batch adversarial loss: 0.653590\n",
      "epoch 45; iter: 0; batch classifier loss: 0.487992; batch adversarial loss: 0.654968\n",
      "epoch 46; iter: 0; batch classifier loss: 0.519862; batch adversarial loss: 0.638235\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487395; batch adversarial loss: 0.655083\n",
      "epoch 48; iter: 0; batch classifier loss: 0.459516; batch adversarial loss: 0.641563\n",
      "epoch 49; iter: 0; batch classifier loss: 0.467470; batch adversarial loss: 0.633807\n",
      "epoch 50; iter: 0; batch classifier loss: 0.498203; batch adversarial loss: 0.627281\n",
      "epoch 51; iter: 0; batch classifier loss: 0.455058; batch adversarial loss: 0.624118\n",
      "epoch 52; iter: 0; batch classifier loss: 0.415876; batch adversarial loss: 0.656738\n",
      "epoch 53; iter: 0; batch classifier loss: 0.466475; batch adversarial loss: 0.659873\n",
      "epoch 54; iter: 0; batch classifier loss: 0.432023; batch adversarial loss: 0.624410\n",
      "epoch 55; iter: 0; batch classifier loss: 0.439709; batch adversarial loss: 0.637868\n",
      "epoch 56; iter: 0; batch classifier loss: 0.481592; batch adversarial loss: 0.603671\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361093; batch adversarial loss: 0.670920\n",
      "epoch 58; iter: 0; batch classifier loss: 0.419347; batch adversarial loss: 0.627241\n",
      "epoch 59; iter: 0; batch classifier loss: 0.398992; batch adversarial loss: 0.620757\n",
      "epoch 60; iter: 0; batch classifier loss: 0.432437; batch adversarial loss: 0.640949\n",
      "epoch 61; iter: 0; batch classifier loss: 0.366830; batch adversarial loss: 0.644312\n",
      "epoch 62; iter: 0; batch classifier loss: 0.335560; batch adversarial loss: 0.677022\n",
      "epoch 63; iter: 0; batch classifier loss: 0.343376; batch adversarial loss: 0.649972\n",
      "epoch 64; iter: 0; batch classifier loss: 0.424841; batch adversarial loss: 0.637668\n",
      "epoch 65; iter: 0; batch classifier loss: 0.420399; batch adversarial loss: 0.626566\n",
      "epoch 66; iter: 0; batch classifier loss: 0.381225; batch adversarial loss: 0.635098\n",
      "epoch 67; iter: 0; batch classifier loss: 0.381224; batch adversarial loss: 0.650210\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383447; batch adversarial loss: 0.633428\n",
      "epoch 69; iter: 0; batch classifier loss: 0.397861; batch adversarial loss: 0.633963\n",
      "epoch 70; iter: 0; batch classifier loss: 0.318574; batch adversarial loss: 0.675092\n",
      "epoch 71; iter: 0; batch classifier loss: 0.437544; batch adversarial loss: 0.601218\n",
      "epoch 72; iter: 0; batch classifier loss: 0.332866; batch adversarial loss: 0.640671\n",
      "epoch 73; iter: 0; batch classifier loss: 0.408859; batch adversarial loss: 0.622300\n",
      "epoch 74; iter: 0; batch classifier loss: 0.390112; batch adversarial loss: 0.630941\n",
      "epoch 75; iter: 0; batch classifier loss: 0.327231; batch adversarial loss: 0.608853\n",
      "epoch 76; iter: 0; batch classifier loss: 0.400645; batch adversarial loss: 0.613427\n",
      "epoch 77; iter: 0; batch classifier loss: 0.352741; batch adversarial loss: 0.627408\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352885; batch adversarial loss: 0.626563\n",
      "epoch 79; iter: 0; batch classifier loss: 0.292536; batch adversarial loss: 0.624806\n",
      "epoch 0; iter: 0; batch classifier loss: 0.795331; batch adversarial loss: 0.959247\n",
      "epoch 1; iter: 0; batch classifier loss: 0.680146; batch adversarial loss: 0.935475\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652850; batch adversarial loss: 0.989790\n",
      "epoch 3; iter: 0; batch classifier loss: 0.639894; batch adversarial loss: 0.954133\n",
      "epoch 4; iter: 0; batch classifier loss: 0.604968; batch adversarial loss: 1.007043\n",
      "epoch 5; iter: 0; batch classifier loss: 0.543666; batch adversarial loss: 0.938277\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624446; batch adversarial loss: 0.993416\n",
      "epoch 7; iter: 0; batch classifier loss: 0.509504; batch adversarial loss: 0.958490\n",
      "epoch 8; iter: 0; batch classifier loss: 0.449282; batch adversarial loss: 0.952642\n",
      "epoch 9; iter: 0; batch classifier loss: 0.606046; batch adversarial loss: 0.997754\n",
      "epoch 10; iter: 0; batch classifier loss: 0.533674; batch adversarial loss: 0.925746\n",
      "epoch 11; iter: 0; batch classifier loss: 0.625368; batch adversarial loss: 1.006201\n",
      "epoch 12; iter: 0; batch classifier loss: 0.587328; batch adversarial loss: 0.935431\n",
      "epoch 13; iter: 0; batch classifier loss: 0.686251; batch adversarial loss: 0.986172\n",
      "epoch 14; iter: 0; batch classifier loss: 0.679299; batch adversarial loss: 0.945416\n",
      "epoch 15; iter: 0; batch classifier loss: 0.807793; batch adversarial loss: 1.042819\n",
      "epoch 16; iter: 0; batch classifier loss: 0.555166; batch adversarial loss: 0.951297\n",
      "epoch 17; iter: 0; batch classifier loss: 0.683255; batch adversarial loss: 0.959056\n",
      "epoch 18; iter: 0; batch classifier loss: 0.632682; batch adversarial loss: 0.970441\n",
      "epoch 19; iter: 0; batch classifier loss: 0.776225; batch adversarial loss: 0.978159\n",
      "epoch 20; iter: 0; batch classifier loss: 0.774040; batch adversarial loss: 0.971085\n",
      "epoch 21; iter: 0; batch classifier loss: 0.695291; batch adversarial loss: 0.928854\n",
      "epoch 22; iter: 0; batch classifier loss: 0.591069; batch adversarial loss: 0.906610\n",
      "epoch 23; iter: 0; batch classifier loss: 0.847869; batch adversarial loss: 0.948953\n",
      "epoch 24; iter: 0; batch classifier loss: 0.516147; batch adversarial loss: 0.881346\n",
      "epoch 25; iter: 0; batch classifier loss: 0.700883; batch adversarial loss: 0.892876\n",
      "epoch 26; iter: 0; batch classifier loss: 0.650526; batch adversarial loss: 0.872462\n",
      "epoch 27; iter: 0; batch classifier loss: 0.906914; batch adversarial loss: 0.910771\n",
      "epoch 28; iter: 0; batch classifier loss: 0.552670; batch adversarial loss: 0.881373\n",
      "epoch 29; iter: 0; batch classifier loss: 0.862480; batch adversarial loss: 0.898519\n",
      "epoch 30; iter: 0; batch classifier loss: 0.796428; batch adversarial loss: 0.894890\n",
      "epoch 31; iter: 0; batch classifier loss: 0.625676; batch adversarial loss: 0.834816\n",
      "epoch 32; iter: 0; batch classifier loss: 0.673150; batch adversarial loss: 0.851255\n",
      "epoch 33; iter: 0; batch classifier loss: 0.638287; batch adversarial loss: 0.834216\n",
      "epoch 34; iter: 0; batch classifier loss: 0.781590; batch adversarial loss: 0.838716\n",
      "epoch 35; iter: 0; batch classifier loss: 0.526148; batch adversarial loss: 0.812241\n",
      "epoch 36; iter: 0; batch classifier loss: 0.732348; batch adversarial loss: 0.837699\n",
      "epoch 37; iter: 0; batch classifier loss: 0.531062; batch adversarial loss: 0.805764\n",
      "epoch 38; iter: 0; batch classifier loss: 0.693119; batch adversarial loss: 0.803564\n",
      "epoch 39; iter: 0; batch classifier loss: 0.778847; batch adversarial loss: 0.814782\n",
      "epoch 0; iter: 0; batch classifier loss: 0.729728; batch adversarial loss: 0.728013\n",
      "epoch 1; iter: 0; batch classifier loss: 0.766315; batch adversarial loss: 0.720911\n",
      "epoch 2; iter: 0; batch classifier loss: 0.663904; batch adversarial loss: 0.706795\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610124; batch adversarial loss: 0.697615\n",
      "epoch 4; iter: 0; batch classifier loss: 0.512269; batch adversarial loss: 0.695458\n",
      "epoch 5; iter: 0; batch classifier loss: 0.575260; batch adversarial loss: 0.683427\n",
      "epoch 6; iter: 0; batch classifier loss: 0.633543; batch adversarial loss: 0.688067\n",
      "epoch 7; iter: 0; batch classifier loss: 0.491453; batch adversarial loss: 0.668156\n",
      "epoch 8; iter: 0; batch classifier loss: 0.452262; batch adversarial loss: 0.665743\n",
      "epoch 9; iter: 0; batch classifier loss: 0.474706; batch adversarial loss: 0.664671\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463678; batch adversarial loss: 0.646522\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389945; batch adversarial loss: 0.648820\n",
      "epoch 12; iter: 0; batch classifier loss: 0.430247; batch adversarial loss: 0.659721\n",
      "epoch 13; iter: 0; batch classifier loss: 0.430952; batch adversarial loss: 0.651811\n",
      "epoch 14; iter: 0; batch classifier loss: 0.335001; batch adversarial loss: 0.660631\n",
      "epoch 15; iter: 0; batch classifier loss: 0.268748; batch adversarial loss: 0.630069\n",
      "epoch 16; iter: 0; batch classifier loss: 0.379482; batch adversarial loss: 0.664192\n",
      "epoch 17; iter: 0; batch classifier loss: 0.344714; batch adversarial loss: 0.594413\n",
      "epoch 18; iter: 0; batch classifier loss: 0.289911; batch adversarial loss: 0.621870\n",
      "epoch 19; iter: 0; batch classifier loss: 0.321327; batch adversarial loss: 0.646267\n",
      "epoch 20; iter: 0; batch classifier loss: 0.226939; batch adversarial loss: 0.610029\n",
      "epoch 21; iter: 0; batch classifier loss: 0.369291; batch adversarial loss: 0.636708\n",
      "epoch 22; iter: 0; batch classifier loss: 0.316499; batch adversarial loss: 0.613288\n",
      "epoch 23; iter: 0; batch classifier loss: 0.383089; batch adversarial loss: 0.644802\n",
      "epoch 24; iter: 0; batch classifier loss: 0.327938; batch adversarial loss: 0.633200\n",
      "epoch 25; iter: 0; batch classifier loss: 0.322141; batch adversarial loss: 0.624434\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275682; batch adversarial loss: 0.622670\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377968; batch adversarial loss: 0.644757\n",
      "epoch 28; iter: 0; batch classifier loss: 0.249756; batch adversarial loss: 0.627460\n",
      "epoch 29; iter: 0; batch classifier loss: 0.315979; batch adversarial loss: 0.579875\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324230; batch adversarial loss: 0.574420\n",
      "epoch 31; iter: 0; batch classifier loss: 0.281178; batch adversarial loss: 0.598507\n",
      "epoch 32; iter: 0; batch classifier loss: 0.352834; batch adversarial loss: 0.611714\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318444; batch adversarial loss: 0.604259\n",
      "epoch 34; iter: 0; batch classifier loss: 0.253586; batch adversarial loss: 0.637392\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382661; batch adversarial loss: 0.625772\n",
      "epoch 36; iter: 0; batch classifier loss: 0.304653; batch adversarial loss: 0.609385\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385174; batch adversarial loss: 0.602503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.304839; batch adversarial loss: 0.668926\n",
      "epoch 39; iter: 0; batch classifier loss: 0.392541; batch adversarial loss: 0.570498\n",
      "epoch 0; iter: 0; batch classifier loss: 0.711982; batch adversarial loss: 0.689161\n",
      "epoch 1; iter: 0; batch classifier loss: 0.702263; batch adversarial loss: 0.685187\n",
      "epoch 2; iter: 0; batch classifier loss: 0.726028; batch adversarial loss: 0.678447\n",
      "epoch 3; iter: 0; batch classifier loss: 0.688952; batch adversarial loss: 0.674652\n",
      "epoch 4; iter: 0; batch classifier loss: 0.614036; batch adversarial loss: 0.696155\n",
      "epoch 5; iter: 0; batch classifier loss: 0.665728; batch adversarial loss: 0.668338\n",
      "epoch 6; iter: 0; batch classifier loss: 0.611351; batch adversarial loss: 0.671431\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561918; batch adversarial loss: 0.681574\n",
      "epoch 8; iter: 0; batch classifier loss: 0.618939; batch adversarial loss: 0.666327\n",
      "epoch 9; iter: 0; batch classifier loss: 0.605997; batch adversarial loss: 0.685912\n",
      "epoch 10; iter: 0; batch classifier loss: 0.584397; batch adversarial loss: 0.674494\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551825; batch adversarial loss: 0.682276\n",
      "epoch 12; iter: 0; batch classifier loss: 0.534601; batch adversarial loss: 0.652484\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518761; batch adversarial loss: 0.677418\n",
      "epoch 14; iter: 0; batch classifier loss: 0.504935; batch adversarial loss: 0.686249\n",
      "epoch 15; iter: 0; batch classifier loss: 0.527425; batch adversarial loss: 0.687312\n",
      "epoch 16; iter: 0; batch classifier loss: 0.508772; batch adversarial loss: 0.660957\n",
      "epoch 17; iter: 0; batch classifier loss: 0.505674; batch adversarial loss: 0.673602\n",
      "epoch 18; iter: 0; batch classifier loss: 0.483229; batch adversarial loss: 0.657791\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451965; batch adversarial loss: 0.661639\n",
      "epoch 20; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.677834\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473776; batch adversarial loss: 0.633543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.425128; batch adversarial loss: 0.672341\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439446; batch adversarial loss: 0.628887\n",
      "epoch 24; iter: 0; batch classifier loss: 0.452152; batch adversarial loss: 0.658660\n",
      "epoch 25; iter: 0; batch classifier loss: 0.437252; batch adversarial loss: 0.637188\n",
      "epoch 26; iter: 0; batch classifier loss: 0.446581; batch adversarial loss: 0.674270\n",
      "epoch 27; iter: 0; batch classifier loss: 0.421297; batch adversarial loss: 0.654684\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440510; batch adversarial loss: 0.643644\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422141; batch adversarial loss: 0.650887\n",
      "epoch 30; iter: 0; batch classifier loss: 0.489316; batch adversarial loss: 0.651531\n",
      "epoch 31; iter: 0; batch classifier loss: 0.420743; batch adversarial loss: 0.668694\n",
      "epoch 32; iter: 0; batch classifier loss: 0.393250; batch adversarial loss: 0.653378\n",
      "epoch 33; iter: 0; batch classifier loss: 0.377772; batch adversarial loss: 0.672776\n",
      "epoch 34; iter: 0; batch classifier loss: 0.344323; batch adversarial loss: 0.655741\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397568; batch adversarial loss: 0.632303\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383695; batch adversarial loss: 0.652102\n",
      "epoch 37; iter: 0; batch classifier loss: 0.339332; batch adversarial loss: 0.670664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.381435; batch adversarial loss: 0.652566\n",
      "epoch 39; iter: 0; batch classifier loss: 0.381675; batch adversarial loss: 0.669242\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736271; batch adversarial loss: 0.821631\n",
      "epoch 1; iter: 0; batch classifier loss: 0.669969; batch adversarial loss: 0.842206\n",
      "epoch 2; iter: 0; batch classifier loss: 0.674977; batch adversarial loss: 0.839572\n",
      "epoch 3; iter: 0; batch classifier loss: 0.640375; batch adversarial loss: 0.880003\n",
      "epoch 4; iter: 0; batch classifier loss: 0.635717; batch adversarial loss: 0.851390\n",
      "epoch 5; iter: 0; batch classifier loss: 0.580817; batch adversarial loss: 0.853446\n",
      "epoch 6; iter: 0; batch classifier loss: 0.565554; batch adversarial loss: 0.878008\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569646; batch adversarial loss: 0.898713\n",
      "epoch 8; iter: 0; batch classifier loss: 0.519570; batch adversarial loss: 0.911678\n",
      "epoch 9; iter: 0; batch classifier loss: 0.517813; batch adversarial loss: 0.899273\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569600; batch adversarial loss: 0.866595\n",
      "epoch 11; iter: 0; batch classifier loss: 0.489235; batch adversarial loss: 0.916171\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474144; batch adversarial loss: 0.999007\n",
      "epoch 13; iter: 0; batch classifier loss: 0.449226; batch adversarial loss: 0.941451\n",
      "epoch 14; iter: 0; batch classifier loss: 0.420554; batch adversarial loss: 0.938758\n",
      "epoch 15; iter: 0; batch classifier loss: 0.432060; batch adversarial loss: 0.930580\n",
      "epoch 16; iter: 0; batch classifier loss: 0.471474; batch adversarial loss: 0.879020\n",
      "epoch 17; iter: 0; batch classifier loss: 0.435289; batch adversarial loss: 0.944321\n",
      "epoch 18; iter: 0; batch classifier loss: 0.357294; batch adversarial loss: 1.026831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.405707; batch adversarial loss: 0.905989\n",
      "epoch 20; iter: 0; batch classifier loss: 0.384492; batch adversarial loss: 0.980310\n",
      "epoch 21; iter: 0; batch classifier loss: 0.381910; batch adversarial loss: 0.966059\n",
      "epoch 22; iter: 0; batch classifier loss: 0.382700; batch adversarial loss: 0.884459\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390392; batch adversarial loss: 0.944144\n",
      "epoch 24; iter: 0; batch classifier loss: 0.420170; batch adversarial loss: 0.903878\n",
      "epoch 25; iter: 0; batch classifier loss: 0.394540; batch adversarial loss: 0.889556\n",
      "epoch 26; iter: 0; batch classifier loss: 0.380440; batch adversarial loss: 0.917270\n",
      "epoch 27; iter: 0; batch classifier loss: 0.305237; batch adversarial loss: 0.996241\n",
      "epoch 28; iter: 0; batch classifier loss: 0.386604; batch adversarial loss: 0.913985\n",
      "epoch 29; iter: 0; batch classifier loss: 0.392245; batch adversarial loss: 0.922165\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399782; batch adversarial loss: 0.878319\n",
      "epoch 31; iter: 0; batch classifier loss: 0.334463; batch adversarial loss: 0.924772\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410207; batch adversarial loss: 0.938515\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323788; batch adversarial loss: 0.867215\n",
      "epoch 34; iter: 0; batch classifier loss: 0.290732; batch adversarial loss: 0.938261\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333226; batch adversarial loss: 0.894935\n",
      "epoch 36; iter: 0; batch classifier loss: 0.293678; batch adversarial loss: 0.892758\n",
      "epoch 37; iter: 0; batch classifier loss: 0.291706; batch adversarial loss: 0.952523\n",
      "epoch 38; iter: 0; batch classifier loss: 0.481626; batch adversarial loss: 0.916310\n",
      "epoch 39; iter: 0; batch classifier loss: 0.375792; batch adversarial loss: 0.902658\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698020; batch adversarial loss: 0.680804\n",
      "epoch 1; iter: 0; batch classifier loss: 0.759319; batch adversarial loss: 0.705604\n",
      "epoch 2; iter: 0; batch classifier loss: 0.622016; batch adversarial loss: 0.657767\n",
      "epoch 3; iter: 0; batch classifier loss: 0.624341; batch adversarial loss: 0.655119\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520970; batch adversarial loss: 0.636199\n",
      "epoch 5; iter: 0; batch classifier loss: 0.520197; batch adversarial loss: 0.660190\n",
      "epoch 6; iter: 0; batch classifier loss: 0.586423; batch adversarial loss: 0.651428\n",
      "epoch 7; iter: 0; batch classifier loss: 0.494175; batch adversarial loss: 0.653813\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455956; batch adversarial loss: 0.671781\n",
      "epoch 9; iter: 0; batch classifier loss: 0.525426; batch adversarial loss: 0.642220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.427141; batch adversarial loss: 0.612833\n",
      "epoch 11; iter: 0; batch classifier loss: 0.327039; batch adversarial loss: 0.618455\n",
      "epoch 12; iter: 0; batch classifier loss: 0.410149; batch adversarial loss: 0.639366\n",
      "epoch 13; iter: 0; batch classifier loss: 0.364147; batch adversarial loss: 0.659228\n",
      "epoch 14; iter: 0; batch classifier loss: 0.476611; batch adversarial loss: 0.691119\n",
      "epoch 15; iter: 0; batch classifier loss: 0.464028; batch adversarial loss: 0.629311\n",
      "epoch 16; iter: 0; batch classifier loss: 0.481353; batch adversarial loss: 0.635090\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413170; batch adversarial loss: 0.640690\n",
      "epoch 18; iter: 0; batch classifier loss: 0.382113; batch adversarial loss: 0.633571\n",
      "epoch 19; iter: 0; batch classifier loss: 0.345100; batch adversarial loss: 0.603723\n",
      "epoch 20; iter: 0; batch classifier loss: 0.415213; batch adversarial loss: 0.625049\n",
      "epoch 21; iter: 0; batch classifier loss: 0.333261; batch adversarial loss: 0.692085\n",
      "epoch 22; iter: 0; batch classifier loss: 0.302713; batch adversarial loss: 0.636778\n",
      "epoch 23; iter: 0; batch classifier loss: 0.421309; batch adversarial loss: 0.589748\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360328; batch adversarial loss: 0.643012\n",
      "epoch 25; iter: 0; batch classifier loss: 0.324465; batch adversarial loss: 0.646765\n",
      "epoch 26; iter: 0; batch classifier loss: 0.300265; batch adversarial loss: 0.626011\n",
      "epoch 27; iter: 0; batch classifier loss: 0.288602; batch adversarial loss: 0.649778\n",
      "epoch 28; iter: 0; batch classifier loss: 0.375879; batch adversarial loss: 0.613306\n",
      "epoch 29; iter: 0; batch classifier loss: 0.318795; batch adversarial loss: 0.542092\n",
      "epoch 30; iter: 0; batch classifier loss: 0.430026; batch adversarial loss: 0.648410\n",
      "epoch 31; iter: 0; batch classifier loss: 0.386714; batch adversarial loss: 0.573997\n",
      "epoch 32; iter: 0; batch classifier loss: 0.416486; batch adversarial loss: 0.609237\n",
      "epoch 33; iter: 0; batch classifier loss: 0.370110; batch adversarial loss: 0.579865\n",
      "epoch 34; iter: 0; batch classifier loss: 0.402994; batch adversarial loss: 0.619589\n",
      "epoch 35; iter: 0; batch classifier loss: 0.327643; batch adversarial loss: 0.637547\n",
      "epoch 36; iter: 0; batch classifier loss: 0.349297; batch adversarial loss: 0.610866\n",
      "epoch 37; iter: 0; batch classifier loss: 0.257136; batch adversarial loss: 0.607553\n",
      "epoch 38; iter: 0; batch classifier loss: 0.451363; batch adversarial loss: 0.627443\n",
      "epoch 39; iter: 0; batch classifier loss: 0.368027; batch adversarial loss: 0.638173\n",
      "epoch 40; iter: 0; batch classifier loss: 0.325727; batch adversarial loss: 0.549879\n",
      "epoch 41; iter: 0; batch classifier loss: 0.407982; batch adversarial loss: 0.575158\n",
      "epoch 42; iter: 0; batch classifier loss: 0.351533; batch adversarial loss: 0.646452\n",
      "epoch 43; iter: 0; batch classifier loss: 0.351030; batch adversarial loss: 0.631571\n",
      "epoch 44; iter: 0; batch classifier loss: 0.383379; batch adversarial loss: 0.574821\n",
      "epoch 45; iter: 0; batch classifier loss: 0.376777; batch adversarial loss: 0.618190\n",
      "epoch 46; iter: 0; batch classifier loss: 0.331366; batch adversarial loss: 0.645940\n",
      "epoch 47; iter: 0; batch classifier loss: 0.420555; batch adversarial loss: 0.638724\n",
      "epoch 48; iter: 0; batch classifier loss: 0.315703; batch adversarial loss: 0.631878\n",
      "epoch 49; iter: 0; batch classifier loss: 0.286904; batch adversarial loss: 0.570769\n",
      "epoch 50; iter: 0; batch classifier loss: 0.446151; batch adversarial loss: 0.622574\n",
      "epoch 51; iter: 0; batch classifier loss: 0.381304; batch adversarial loss: 0.542078\n",
      "epoch 52; iter: 0; batch classifier loss: 0.209255; batch adversarial loss: 0.634524\n",
      "epoch 53; iter: 0; batch classifier loss: 0.272274; batch adversarial loss: 0.612801\n",
      "epoch 54; iter: 0; batch classifier loss: 0.297816; batch adversarial loss: 0.634888\n",
      "epoch 55; iter: 0; batch classifier loss: 0.304653; batch adversarial loss: 0.679109\n",
      "epoch 56; iter: 0; batch classifier loss: 0.248234; batch adversarial loss: 0.700920\n",
      "epoch 57; iter: 0; batch classifier loss: 0.372506; batch adversarial loss: 0.741382\n",
      "epoch 58; iter: 0; batch classifier loss: 0.307929; batch adversarial loss: 0.572404\n",
      "epoch 59; iter: 0; batch classifier loss: 0.215465; batch adversarial loss: 0.676515\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717366; batch adversarial loss: 0.886526\n",
      "epoch 1; iter: 0; batch classifier loss: 0.612725; batch adversarial loss: 0.904648\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577403; batch adversarial loss: 0.930617\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541103; batch adversarial loss: 0.847760\n",
      "epoch 4; iter: 0; batch classifier loss: 0.513707; batch adversarial loss: 0.921003\n",
      "epoch 5; iter: 0; batch classifier loss: 0.462773; batch adversarial loss: 0.920758\n",
      "epoch 6; iter: 0; batch classifier loss: 0.478250; batch adversarial loss: 0.881879\n",
      "epoch 7; iter: 0; batch classifier loss: 0.512314; batch adversarial loss: 0.972190\n",
      "epoch 8; iter: 0; batch classifier loss: 0.390755; batch adversarial loss: 0.995472\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363522; batch adversarial loss: 1.033515\n",
      "epoch 10; iter: 0; batch classifier loss: 0.393364; batch adversarial loss: 0.933318\n",
      "epoch 11; iter: 0; batch classifier loss: 0.294352; batch adversarial loss: 0.846149\n",
      "epoch 12; iter: 0; batch classifier loss: 0.380962; batch adversarial loss: 0.821934\n",
      "epoch 13; iter: 0; batch classifier loss: 0.269186; batch adversarial loss: 0.903491\n",
      "epoch 14; iter: 0; batch classifier loss: 0.250754; batch adversarial loss: 0.953909\n",
      "epoch 15; iter: 0; batch classifier loss: 0.318257; batch adversarial loss: 0.938140\n",
      "epoch 16; iter: 0; batch classifier loss: 0.414085; batch adversarial loss: 0.913456\n",
      "epoch 17; iter: 0; batch classifier loss: 0.340946; batch adversarial loss: 0.844379\n",
      "epoch 18; iter: 0; batch classifier loss: 0.360984; batch adversarial loss: 0.870333\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369702; batch adversarial loss: 0.876179\n",
      "epoch 20; iter: 0; batch classifier loss: 0.342306; batch adversarial loss: 0.824088\n",
      "epoch 21; iter: 0; batch classifier loss: 0.436579; batch adversarial loss: 0.924032\n",
      "epoch 22; iter: 0; batch classifier loss: 0.355724; batch adversarial loss: 0.848167\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398749; batch adversarial loss: 0.794502\n",
      "epoch 24; iter: 0; batch classifier loss: 0.347654; batch adversarial loss: 0.819417\n",
      "epoch 25; iter: 0; batch classifier loss: 0.290401; batch adversarial loss: 0.823705\n",
      "epoch 26; iter: 0; batch classifier loss: 0.237715; batch adversarial loss: 0.769069\n",
      "epoch 27; iter: 0; batch classifier loss: 0.277867; batch adversarial loss: 0.861952\n",
      "epoch 28; iter: 0; batch classifier loss: 0.273704; batch adversarial loss: 0.831485\n",
      "epoch 29; iter: 0; batch classifier loss: 0.298795; batch adversarial loss: 0.792296\n",
      "epoch 30; iter: 0; batch classifier loss: 0.391902; batch adversarial loss: 0.802868\n",
      "epoch 31; iter: 0; batch classifier loss: 0.228295; batch adversarial loss: 0.749605\n",
      "epoch 32; iter: 0; batch classifier loss: 0.302342; batch adversarial loss: 0.783278\n",
      "epoch 33; iter: 0; batch classifier loss: 0.244049; batch adversarial loss: 0.773372\n",
      "epoch 34; iter: 0; batch classifier loss: 0.282613; batch adversarial loss: 0.786045\n",
      "epoch 35; iter: 0; batch classifier loss: 0.256770; batch adversarial loss: 0.749331\n",
      "epoch 36; iter: 0; batch classifier loss: 0.333204; batch adversarial loss: 0.690693\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412708; batch adversarial loss: 0.759563\n",
      "epoch 38; iter: 0; batch classifier loss: 0.295489; batch adversarial loss: 0.711966\n",
      "epoch 39; iter: 0; batch classifier loss: 0.324053; batch adversarial loss: 0.787417\n",
      "epoch 40; iter: 0; batch classifier loss: 0.260328; batch adversarial loss: 0.758032\n",
      "epoch 41; iter: 0; batch classifier loss: 0.288116; batch adversarial loss: 0.744485\n",
      "epoch 42; iter: 0; batch classifier loss: 0.302612; batch adversarial loss: 0.742759\n",
      "epoch 43; iter: 0; batch classifier loss: 0.270973; batch adversarial loss: 0.752505\n",
      "epoch 44; iter: 0; batch classifier loss: 0.257500; batch adversarial loss: 0.743760\n",
      "epoch 45; iter: 0; batch classifier loss: 0.364112; batch adversarial loss: 0.774181\n",
      "epoch 46; iter: 0; batch classifier loss: 0.370417; batch adversarial loss: 0.697407\n",
      "epoch 47; iter: 0; batch classifier loss: 0.285112; batch adversarial loss: 0.721352\n",
      "epoch 48; iter: 0; batch classifier loss: 0.507564; batch adversarial loss: 0.718913\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313776; batch adversarial loss: 0.722108\n",
      "epoch 50; iter: 0; batch classifier loss: 0.202026; batch adversarial loss: 0.686646\n",
      "epoch 51; iter: 0; batch classifier loss: 0.254319; batch adversarial loss: 0.719502\n",
      "epoch 52; iter: 0; batch classifier loss: 0.357360; batch adversarial loss: 0.724693\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358367; batch adversarial loss: 0.692930\n",
      "epoch 54; iter: 0; batch classifier loss: 0.255568; batch adversarial loss: 0.676295\n",
      "epoch 55; iter: 0; batch classifier loss: 0.298347; batch adversarial loss: 0.676252\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350589; batch adversarial loss: 0.668676\n",
      "epoch 57; iter: 0; batch classifier loss: 0.386662; batch adversarial loss: 0.672892\n",
      "epoch 58; iter: 0; batch classifier loss: 0.311802; batch adversarial loss: 0.664913\n",
      "epoch 59; iter: 0; batch classifier loss: 0.311260; batch adversarial loss: 0.684182\n",
      "epoch 0; iter: 0; batch classifier loss: 0.809145; batch adversarial loss: 0.666734\n",
      "epoch 1; iter: 0; batch classifier loss: 0.759556; batch adversarial loss: 0.630451\n",
      "epoch 2; iter: 0; batch classifier loss: 0.770683; batch adversarial loss: 0.638201\n",
      "epoch 3; iter: 0; batch classifier loss: 0.720215; batch adversarial loss: 0.620516\n",
      "epoch 4; iter: 0; batch classifier loss: 0.713304; batch adversarial loss: 0.662623\n",
      "epoch 5; iter: 0; batch classifier loss: 0.682154; batch adversarial loss: 0.646913\n",
      "epoch 6; iter: 0; batch classifier loss: 0.650328; batch adversarial loss: 0.693109\n",
      "epoch 7; iter: 0; batch classifier loss: 0.629062; batch adversarial loss: 0.645239\n",
      "epoch 8; iter: 0; batch classifier loss: 0.613156; batch adversarial loss: 0.597551\n",
      "epoch 9; iter: 0; batch classifier loss: 0.587084; batch adversarial loss: 0.627230\n",
      "epoch 10; iter: 0; batch classifier loss: 0.610525; batch adversarial loss: 0.714949\n",
      "epoch 11; iter: 0; batch classifier loss: 0.580142; batch adversarial loss: 0.660062\n",
      "epoch 12; iter: 0; batch classifier loss: 0.529271; batch adversarial loss: 0.642720\n",
      "epoch 13; iter: 0; batch classifier loss: 0.536896; batch adversarial loss: 0.630158\n",
      "epoch 14; iter: 0; batch classifier loss: 0.487082; batch adversarial loss: 0.651633\n",
      "epoch 15; iter: 0; batch classifier loss: 0.551704; batch adversarial loss: 0.620339\n",
      "epoch 16; iter: 0; batch classifier loss: 0.524837; batch adversarial loss: 0.612842\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449545; batch adversarial loss: 0.606474\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488916; batch adversarial loss: 0.713364\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475629; batch adversarial loss: 0.681518\n",
      "epoch 20; iter: 0; batch classifier loss: 0.502506; batch adversarial loss: 0.623496\n",
      "epoch 21; iter: 0; batch classifier loss: 0.501455; batch adversarial loss: 0.607162\n",
      "epoch 22; iter: 0; batch classifier loss: 0.472375; batch adversarial loss: 0.634050\n",
      "epoch 23; iter: 0; batch classifier loss: 0.466901; batch adversarial loss: 0.625482\n",
      "epoch 24; iter: 0; batch classifier loss: 0.464835; batch adversarial loss: 0.689352\n",
      "epoch 25; iter: 0; batch classifier loss: 0.493714; batch adversarial loss: 0.621379\n",
      "epoch 26; iter: 0; batch classifier loss: 0.420974; batch adversarial loss: 0.656406\n",
      "epoch 27; iter: 0; batch classifier loss: 0.461633; batch adversarial loss: 0.671627\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433023; batch adversarial loss: 0.622008\n",
      "epoch 29; iter: 0; batch classifier loss: 0.434482; batch adversarial loss: 0.596565\n",
      "epoch 30; iter: 0; batch classifier loss: 0.420938; batch adversarial loss: 0.649666\n",
      "epoch 31; iter: 0; batch classifier loss: 0.429162; batch adversarial loss: 0.660867\n",
      "epoch 32; iter: 0; batch classifier loss: 0.352887; batch adversarial loss: 0.625051\n",
      "epoch 33; iter: 0; batch classifier loss: 0.385262; batch adversarial loss: 0.601555\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390111; batch adversarial loss: 0.626824\n",
      "epoch 35; iter: 0; batch classifier loss: 0.388018; batch adversarial loss: 0.668198\n",
      "epoch 36; iter: 0; batch classifier loss: 0.383165; batch adversarial loss: 0.667831\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334759; batch adversarial loss: 0.609384\n",
      "epoch 38; iter: 0; batch classifier loss: 0.400819; batch adversarial loss: 0.619890\n",
      "epoch 39; iter: 0; batch classifier loss: 0.353277; batch adversarial loss: 0.683210\n",
      "epoch 40; iter: 0; batch classifier loss: 0.339963; batch adversarial loss: 0.641031\n",
      "epoch 41; iter: 0; batch classifier loss: 0.358298; batch adversarial loss: 0.609833\n",
      "epoch 42; iter: 0; batch classifier loss: 0.320500; batch adversarial loss: 0.653222\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399112; batch adversarial loss: 0.644383\n",
      "epoch 44; iter: 0; batch classifier loss: 0.386512; batch adversarial loss: 0.632518\n",
      "epoch 45; iter: 0; batch classifier loss: 0.401531; batch adversarial loss: 0.658415\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371729; batch adversarial loss: 0.605200\n",
      "epoch 47; iter: 0; batch classifier loss: 0.396104; batch adversarial loss: 0.631011\n",
      "epoch 48; iter: 0; batch classifier loss: 0.380119; batch adversarial loss: 0.646445\n",
      "epoch 49; iter: 0; batch classifier loss: 0.370054; batch adversarial loss: 0.661475\n",
      "epoch 50; iter: 0; batch classifier loss: 0.224804; batch adversarial loss: 0.605454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.350442; batch adversarial loss: 0.546111\n",
      "epoch 52; iter: 0; batch classifier loss: 0.357270; batch adversarial loss: 0.632326\n",
      "epoch 53; iter: 0; batch classifier loss: 0.318114; batch adversarial loss: 0.604471\n",
      "epoch 54; iter: 0; batch classifier loss: 0.390815; batch adversarial loss: 0.650945\n",
      "epoch 55; iter: 0; batch classifier loss: 0.419207; batch adversarial loss: 0.643085\n",
      "epoch 56; iter: 0; batch classifier loss: 0.394510; batch adversarial loss: 0.643574\n",
      "epoch 57; iter: 0; batch classifier loss: 0.322013; batch adversarial loss: 0.614970\n",
      "epoch 58; iter: 0; batch classifier loss: 0.355954; batch adversarial loss: 0.663661\n",
      "epoch 59; iter: 0; batch classifier loss: 0.310575; batch adversarial loss: 0.649887\n",
      "epoch 0; iter: 0; batch classifier loss: 0.849083; batch adversarial loss: 0.659539\n",
      "epoch 1; iter: 0; batch classifier loss: 0.806720; batch adversarial loss: 0.652098\n",
      "epoch 2; iter: 0; batch classifier loss: 0.719883; batch adversarial loss: 0.618054\n",
      "epoch 3; iter: 0; batch classifier loss: 0.732426; batch adversarial loss: 0.645507\n",
      "epoch 4; iter: 0; batch classifier loss: 0.689816; batch adversarial loss: 0.659050\n",
      "epoch 5; iter: 0; batch classifier loss: 0.675415; batch adversarial loss: 0.664259\n",
      "epoch 6; iter: 0; batch classifier loss: 0.656079; batch adversarial loss: 0.660060\n",
      "epoch 7; iter: 0; batch classifier loss: 0.647374; batch adversarial loss: 0.659066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.599369; batch adversarial loss: 0.652033\n",
      "epoch 9; iter: 0; batch classifier loss: 0.540084; batch adversarial loss: 0.677425\n",
      "epoch 10; iter: 0; batch classifier loss: 0.594233; batch adversarial loss: 0.621361\n",
      "epoch 11; iter: 0; batch classifier loss: 0.540573; batch adversarial loss: 0.669552\n",
      "epoch 12; iter: 0; batch classifier loss: 0.539545; batch adversarial loss: 0.622893\n",
      "epoch 13; iter: 0; batch classifier loss: 0.499079; batch adversarial loss: 0.628282\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501485; batch adversarial loss: 0.640200\n",
      "epoch 15; iter: 0; batch classifier loss: 0.443173; batch adversarial loss: 0.623958\n",
      "epoch 16; iter: 0; batch classifier loss: 0.412039; batch adversarial loss: 0.651881\n",
      "epoch 17; iter: 0; batch classifier loss: 0.455843; batch adversarial loss: 0.643710\n",
      "epoch 18; iter: 0; batch classifier loss: 0.403321; batch adversarial loss: 0.620554\n",
      "epoch 19; iter: 0; batch classifier loss: 0.435594; batch adversarial loss: 0.708229\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457722; batch adversarial loss: 0.636033\n",
      "epoch 21; iter: 0; batch classifier loss: 0.387697; batch adversarial loss: 0.604515\n",
      "epoch 22; iter: 0; batch classifier loss: 0.426903; batch adversarial loss: 0.684098\n",
      "epoch 23; iter: 0; batch classifier loss: 0.426179; batch adversarial loss: 0.709275\n",
      "epoch 24; iter: 0; batch classifier loss: 0.420572; batch adversarial loss: 0.647341\n",
      "epoch 25; iter: 0; batch classifier loss: 0.372195; batch adversarial loss: 0.683605\n",
      "epoch 26; iter: 0; batch classifier loss: 0.397228; batch adversarial loss: 0.598913\n",
      "epoch 27; iter: 0; batch classifier loss: 0.407792; batch adversarial loss: 0.583830\n",
      "epoch 28; iter: 0; batch classifier loss: 0.393860; batch adversarial loss: 0.639519\n",
      "epoch 29; iter: 0; batch classifier loss: 0.447844; batch adversarial loss: 0.633234\n",
      "epoch 30; iter: 0; batch classifier loss: 0.331648; batch adversarial loss: 0.669763\n",
      "epoch 31; iter: 0; batch classifier loss: 0.366816; batch adversarial loss: 0.633299\n",
      "epoch 32; iter: 0; batch classifier loss: 0.348468; batch adversarial loss: 0.658563\n",
      "epoch 33; iter: 0; batch classifier loss: 0.321799; batch adversarial loss: 0.638546\n",
      "epoch 34; iter: 0; batch classifier loss: 0.303983; batch adversarial loss: 0.616173\n",
      "epoch 35; iter: 0; batch classifier loss: 0.339686; batch adversarial loss: 0.629341\n",
      "epoch 36; iter: 0; batch classifier loss: 0.347774; batch adversarial loss: 0.634125\n",
      "epoch 37; iter: 0; batch classifier loss: 0.333114; batch adversarial loss: 0.625322\n",
      "epoch 38; iter: 0; batch classifier loss: 0.361093; batch adversarial loss: 0.592821\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370695; batch adversarial loss: 0.618564\n",
      "epoch 40; iter: 0; batch classifier loss: 0.311715; batch adversarial loss: 0.615446\n",
      "epoch 41; iter: 0; batch classifier loss: 0.384170; batch adversarial loss: 0.665004\n",
      "epoch 42; iter: 0; batch classifier loss: 0.290981; batch adversarial loss: 0.666462\n",
      "epoch 43; iter: 0; batch classifier loss: 0.338371; batch adversarial loss: 0.652496\n",
      "epoch 44; iter: 0; batch classifier loss: 0.401747; batch adversarial loss: 0.643482\n",
      "epoch 45; iter: 0; batch classifier loss: 0.302319; batch adversarial loss: 0.589953\n",
      "epoch 46; iter: 0; batch classifier loss: 0.385884; batch adversarial loss: 0.639845\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348235; batch adversarial loss: 0.658018\n",
      "epoch 48; iter: 0; batch classifier loss: 0.377620; batch adversarial loss: 0.656370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.309988; batch adversarial loss: 0.586288\n",
      "epoch 50; iter: 0; batch classifier loss: 0.304966; batch adversarial loss: 0.640454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.316223; batch adversarial loss: 0.596067\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386036; batch adversarial loss: 0.629517\n",
      "epoch 53; iter: 0; batch classifier loss: 0.360579; batch adversarial loss: 0.653078\n",
      "epoch 54; iter: 0; batch classifier loss: 0.212898; batch adversarial loss: 0.633746\n",
      "epoch 55; iter: 0; batch classifier loss: 0.345295; batch adversarial loss: 0.594283\n",
      "epoch 56; iter: 0; batch classifier loss: 0.341238; batch adversarial loss: 0.595408\n",
      "epoch 57; iter: 0; batch classifier loss: 0.289457; batch adversarial loss: 0.630698\n",
      "epoch 58; iter: 0; batch classifier loss: 0.325544; batch adversarial loss: 0.565827\n",
      "epoch 59; iter: 0; batch classifier loss: 0.279276; batch adversarial loss: 0.644271\n",
      "epoch 0; iter: 0; batch classifier loss: 0.687050; batch adversarial loss: 0.548348\n",
      "epoch 1; iter: 0; batch classifier loss: 0.675730; batch adversarial loss: 0.611789\n",
      "epoch 2; iter: 0; batch classifier loss: 0.633737; batch adversarial loss: 0.511305\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569065; batch adversarial loss: 0.574521\n",
      "epoch 4; iter: 0; batch classifier loss: 0.522877; batch adversarial loss: 0.631383\n",
      "epoch 5; iter: 0; batch classifier loss: 0.512478; batch adversarial loss: 0.683049\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535776; batch adversarial loss: 0.652291\n",
      "epoch 7; iter: 0; batch classifier loss: 0.524042; batch adversarial loss: 0.586942\n",
      "epoch 8; iter: 0; batch classifier loss: 0.459877; batch adversarial loss: 0.587941\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488067; batch adversarial loss: 0.564480\n",
      "epoch 10; iter: 0; batch classifier loss: 0.453663; batch adversarial loss: 0.540251\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508847; batch adversarial loss: 0.481682\n",
      "epoch 12; iter: 0; batch classifier loss: 0.300440; batch adversarial loss: 0.635444\n",
      "epoch 13; iter: 0; batch classifier loss: 0.390925; batch adversarial loss: 0.581089\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474176; batch adversarial loss: 0.650584\n",
      "epoch 15; iter: 0; batch classifier loss: 0.429727; batch adversarial loss: 0.656795\n",
      "epoch 16; iter: 0; batch classifier loss: 0.477645; batch adversarial loss: 0.515001\n",
      "epoch 17; iter: 0; batch classifier loss: 0.405279; batch adversarial loss: 0.581785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.531592; batch adversarial loss: 0.605048\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344462; batch adversarial loss: 0.614120\n",
      "epoch 20; iter: 0; batch classifier loss: 0.350984; batch adversarial loss: 0.595925\n",
      "epoch 21; iter: 0; batch classifier loss: 0.517146; batch adversarial loss: 0.563562\n",
      "epoch 22; iter: 0; batch classifier loss: 0.378956; batch adversarial loss: 0.590957\n",
      "epoch 23; iter: 0; batch classifier loss: 0.378642; batch adversarial loss: 0.557608\n",
      "epoch 24; iter: 0; batch classifier loss: 0.346329; batch adversarial loss: 0.608399\n",
      "epoch 25; iter: 0; batch classifier loss: 0.330872; batch adversarial loss: 0.595692\n",
      "epoch 26; iter: 0; batch classifier loss: 0.371342; batch adversarial loss: 0.530722\n",
      "epoch 27; iter: 0; batch classifier loss: 0.363639; batch adversarial loss: 0.540633\n",
      "epoch 28; iter: 0; batch classifier loss: 0.422224; batch adversarial loss: 0.527839\n",
      "epoch 29; iter: 0; batch classifier loss: 0.448444; batch adversarial loss: 0.616049\n",
      "epoch 30; iter: 0; batch classifier loss: 0.319386; batch adversarial loss: 0.597432\n",
      "epoch 31; iter: 0; batch classifier loss: 0.278534; batch adversarial loss: 0.619977\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256945; batch adversarial loss: 0.578962\n",
      "epoch 33; iter: 0; batch classifier loss: 0.377688; batch adversarial loss: 0.606370\n",
      "epoch 34; iter: 0; batch classifier loss: 0.390886; batch adversarial loss: 0.614110\n",
      "epoch 35; iter: 0; batch classifier loss: 0.312529; batch adversarial loss: 0.582497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.428779; batch adversarial loss: 0.695020\n",
      "epoch 37; iter: 0; batch classifier loss: 0.292788; batch adversarial loss: 0.593759\n",
      "epoch 38; iter: 0; batch classifier loss: 0.261477; batch adversarial loss: 0.515294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.327897; batch adversarial loss: 0.518333\n",
      "epoch 40; iter: 0; batch classifier loss: 0.382415; batch adversarial loss: 0.617995\n",
      "epoch 41; iter: 0; batch classifier loss: 0.307622; batch adversarial loss: 0.595235\n",
      "epoch 42; iter: 0; batch classifier loss: 0.306730; batch adversarial loss: 0.606119\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394375; batch adversarial loss: 0.581273\n",
      "epoch 44; iter: 0; batch classifier loss: 0.194730; batch adversarial loss: 0.642875\n",
      "epoch 45; iter: 0; batch classifier loss: 0.380984; batch adversarial loss: 0.665380\n",
      "epoch 46; iter: 0; batch classifier loss: 0.291957; batch adversarial loss: 0.592977\n",
      "epoch 47; iter: 0; batch classifier loss: 0.307140; batch adversarial loss: 0.559882\n",
      "epoch 48; iter: 0; batch classifier loss: 0.281783; batch adversarial loss: 0.648239\n",
      "epoch 49; iter: 0; batch classifier loss: 0.283368; batch adversarial loss: 0.671433\n",
      "epoch 50; iter: 0; batch classifier loss: 0.346459; batch adversarial loss: 0.589844\n",
      "epoch 51; iter: 0; batch classifier loss: 0.283469; batch adversarial loss: 0.600676\n",
      "epoch 52; iter: 0; batch classifier loss: 0.401927; batch adversarial loss: 0.629950\n",
      "epoch 53; iter: 0; batch classifier loss: 0.298133; batch adversarial loss: 0.661020\n",
      "epoch 54; iter: 0; batch classifier loss: 0.216517; batch adversarial loss: 0.585554\n",
      "epoch 55; iter: 0; batch classifier loss: 0.338026; batch adversarial loss: 0.519510\n",
      "epoch 56; iter: 0; batch classifier loss: 0.233447; batch adversarial loss: 0.640787\n",
      "epoch 57; iter: 0; batch classifier loss: 0.200740; batch adversarial loss: 0.613133\n",
      "epoch 58; iter: 0; batch classifier loss: 0.360875; batch adversarial loss: 0.553627\n",
      "epoch 59; iter: 0; batch classifier loss: 0.312066; batch adversarial loss: 0.534866\n",
      "epoch 60; iter: 0; batch classifier loss: 0.277357; batch adversarial loss: 0.608467\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379847; batch adversarial loss: 0.650929\n",
      "epoch 62; iter: 0; batch classifier loss: 0.367674; batch adversarial loss: 0.541049\n",
      "epoch 63; iter: 0; batch classifier loss: 0.247202; batch adversarial loss: 0.611468\n",
      "epoch 64; iter: 0; batch classifier loss: 0.271414; batch adversarial loss: 0.625245\n",
      "epoch 65; iter: 0; batch classifier loss: 0.298274; batch adversarial loss: 0.532092\n",
      "epoch 66; iter: 0; batch classifier loss: 0.282920; batch adversarial loss: 0.605457\n",
      "epoch 67; iter: 0; batch classifier loss: 0.270009; batch adversarial loss: 0.560144\n",
      "epoch 68; iter: 0; batch classifier loss: 0.160710; batch adversarial loss: 0.589219\n",
      "epoch 69; iter: 0; batch classifier loss: 0.409008; batch adversarial loss: 0.451391\n",
      "epoch 70; iter: 0; batch classifier loss: 0.212374; batch adversarial loss: 0.467399\n",
      "epoch 71; iter: 0; batch classifier loss: 0.338674; batch adversarial loss: 0.505825\n",
      "epoch 72; iter: 0; batch classifier loss: 0.235019; batch adversarial loss: 0.544644\n",
      "epoch 73; iter: 0; batch classifier loss: 0.397560; batch adversarial loss: 0.574893\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222961; batch adversarial loss: 0.668041\n",
      "epoch 75; iter: 0; batch classifier loss: 0.361560; batch adversarial loss: 0.589555\n",
      "epoch 76; iter: 0; batch classifier loss: 0.372467; batch adversarial loss: 0.529489\n",
      "epoch 77; iter: 0; batch classifier loss: 0.317116; batch adversarial loss: 0.547100\n",
      "epoch 78; iter: 0; batch classifier loss: 0.304985; batch adversarial loss: 0.586538\n",
      "epoch 79; iter: 0; batch classifier loss: 0.295133; batch adversarial loss: 0.621846\n",
      "epoch 0; iter: 0; batch classifier loss: 0.934696; batch adversarial loss: 0.774366\n",
      "epoch 1; iter: 0; batch classifier loss: 0.810321; batch adversarial loss: 0.800045\n",
      "epoch 2; iter: 0; batch classifier loss: 0.687230; batch adversarial loss: 0.755978\n",
      "epoch 3; iter: 0; batch classifier loss: 0.570951; batch adversarial loss: 0.810834\n",
      "epoch 4; iter: 0; batch classifier loss: 0.510859; batch adversarial loss: 0.812957\n",
      "epoch 5; iter: 0; batch classifier loss: 0.501755; batch adversarial loss: 0.823901\n",
      "epoch 6; iter: 0; batch classifier loss: 0.526366; batch adversarial loss: 0.843133\n",
      "epoch 7; iter: 0; batch classifier loss: 0.460559; batch adversarial loss: 0.813805\n",
      "epoch 8; iter: 0; batch classifier loss: 0.410253; batch adversarial loss: 0.751117\n",
      "epoch 9; iter: 0; batch classifier loss: 0.408915; batch adversarial loss: 0.788948\n",
      "epoch 10; iter: 0; batch classifier loss: 0.401476; batch adversarial loss: 0.793763\n",
      "epoch 11; iter: 0; batch classifier loss: 0.316635; batch adversarial loss: 0.770846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.377707; batch adversarial loss: 0.776557\n",
      "epoch 13; iter: 0; batch classifier loss: 0.383852; batch adversarial loss: 0.778276\n",
      "epoch 14; iter: 0; batch classifier loss: 0.342140; batch adversarial loss: 0.768056\n",
      "epoch 15; iter: 0; batch classifier loss: 0.251680; batch adversarial loss: 0.775524\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368475; batch adversarial loss: 0.781372\n",
      "epoch 17; iter: 0; batch classifier loss: 0.362013; batch adversarial loss: 0.703977\n",
      "epoch 18; iter: 0; batch classifier loss: 0.370767; batch adversarial loss: 0.723052\n",
      "epoch 19; iter: 0; batch classifier loss: 0.334169; batch adversarial loss: 0.730359\n",
      "epoch 20; iter: 0; batch classifier loss: 0.303480; batch adversarial loss: 0.750462\n",
      "epoch 21; iter: 0; batch classifier loss: 0.335488; batch adversarial loss: 0.753345\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354099; batch adversarial loss: 0.712688\n",
      "epoch 23; iter: 0; batch classifier loss: 0.473075; batch adversarial loss: 0.701207\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315397; batch adversarial loss: 0.726185\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333878; batch adversarial loss: 0.688862\n",
      "epoch 26; iter: 0; batch classifier loss: 0.354218; batch adversarial loss: 0.716498\n",
      "epoch 27; iter: 0; batch classifier loss: 0.296715; batch adversarial loss: 0.706833\n",
      "epoch 28; iter: 0; batch classifier loss: 0.330030; batch adversarial loss: 0.668968\n",
      "epoch 29; iter: 0; batch classifier loss: 0.254888; batch adversarial loss: 0.662090\n",
      "epoch 30; iter: 0; batch classifier loss: 0.362519; batch adversarial loss: 0.673355\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326222; batch adversarial loss: 0.668850\n",
      "epoch 32; iter: 0; batch classifier loss: 0.227040; batch adversarial loss: 0.690376\n",
      "epoch 33; iter: 0; batch classifier loss: 0.340621; batch adversarial loss: 0.681828\n",
      "epoch 34; iter: 0; batch classifier loss: 0.194496; batch adversarial loss: 0.672677\n",
      "epoch 35; iter: 0; batch classifier loss: 0.269116; batch adversarial loss: 0.675393\n",
      "epoch 36; iter: 0; batch classifier loss: 0.252208; batch adversarial loss: 0.668866\n",
      "epoch 37; iter: 0; batch classifier loss: 0.244799; batch adversarial loss: 0.673262\n",
      "epoch 38; iter: 0; batch classifier loss: 0.223935; batch adversarial loss: 0.655056\n",
      "epoch 39; iter: 0; batch classifier loss: 0.162762; batch adversarial loss: 0.659211\n",
      "epoch 40; iter: 0; batch classifier loss: 0.210334; batch adversarial loss: 0.676750\n",
      "epoch 41; iter: 0; batch classifier loss: 0.318426; batch adversarial loss: 0.648101\n",
      "epoch 42; iter: 0; batch classifier loss: 0.305473; batch adversarial loss: 0.624010\n",
      "epoch 43; iter: 0; batch classifier loss: 0.291426; batch adversarial loss: 0.641694\n",
      "epoch 44; iter: 0; batch classifier loss: 0.357172; batch adversarial loss: 0.635848\n",
      "epoch 45; iter: 0; batch classifier loss: 0.320438; batch adversarial loss: 0.624855\n",
      "epoch 46; iter: 0; batch classifier loss: 0.276162; batch adversarial loss: 0.628637\n",
      "epoch 47; iter: 0; batch classifier loss: 0.263698; batch adversarial loss: 0.634912\n",
      "epoch 48; iter: 0; batch classifier loss: 0.285442; batch adversarial loss: 0.665138\n",
      "epoch 49; iter: 0; batch classifier loss: 0.236301; batch adversarial loss: 0.635975\n",
      "epoch 50; iter: 0; batch classifier loss: 0.288380; batch adversarial loss: 0.653546\n",
      "epoch 51; iter: 0; batch classifier loss: 0.346151; batch adversarial loss: 0.626123\n",
      "epoch 52; iter: 0; batch classifier loss: 0.323592; batch adversarial loss: 0.643865\n",
      "epoch 53; iter: 0; batch classifier loss: 0.252844; batch adversarial loss: 0.592833\n",
      "epoch 54; iter: 0; batch classifier loss: 0.195722; batch adversarial loss: 0.638931\n",
      "epoch 55; iter: 0; batch classifier loss: 0.315588; batch adversarial loss: 0.625681\n",
      "epoch 56; iter: 0; batch classifier loss: 0.296710; batch adversarial loss: 0.616032\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270504; batch adversarial loss: 0.574068\n",
      "epoch 58; iter: 0; batch classifier loss: 0.147513; batch adversarial loss: 0.589217\n",
      "epoch 59; iter: 0; batch classifier loss: 0.258494; batch adversarial loss: 0.580551\n",
      "epoch 60; iter: 0; batch classifier loss: 0.311473; batch adversarial loss: 0.636075\n",
      "epoch 61; iter: 0; batch classifier loss: 0.163428; batch adversarial loss: 0.588957\n",
      "epoch 62; iter: 0; batch classifier loss: 0.289992; batch adversarial loss: 0.649559\n",
      "epoch 63; iter: 0; batch classifier loss: 0.236075; batch adversarial loss: 0.613812\n",
      "epoch 64; iter: 0; batch classifier loss: 0.224387; batch adversarial loss: 0.589518\n",
      "epoch 65; iter: 0; batch classifier loss: 0.379782; batch adversarial loss: 0.611690\n",
      "epoch 66; iter: 0; batch classifier loss: 0.387997; batch adversarial loss: 0.610369\n",
      "epoch 67; iter: 0; batch classifier loss: 0.273542; batch adversarial loss: 0.577275\n",
      "epoch 68; iter: 0; batch classifier loss: 0.148191; batch adversarial loss: 0.583238\n",
      "epoch 69; iter: 0; batch classifier loss: 0.276584; batch adversarial loss: 0.616228\n",
      "epoch 70; iter: 0; batch classifier loss: 0.221111; batch adversarial loss: 0.623087\n",
      "epoch 71; iter: 0; batch classifier loss: 0.251376; batch adversarial loss: 0.604677\n",
      "epoch 72; iter: 0; batch classifier loss: 0.317036; batch adversarial loss: 0.607576\n",
      "epoch 73; iter: 0; batch classifier loss: 0.233847; batch adversarial loss: 0.592085\n",
      "epoch 74; iter: 0; batch classifier loss: 0.231076; batch adversarial loss: 0.618020\n",
      "epoch 75; iter: 0; batch classifier loss: 0.177370; batch adversarial loss: 0.585378\n",
      "epoch 76; iter: 0; batch classifier loss: 0.153577; batch adversarial loss: 0.541065\n",
      "epoch 77; iter: 0; batch classifier loss: 0.303631; batch adversarial loss: 0.566959\n",
      "epoch 78; iter: 0; batch classifier loss: 0.247191; batch adversarial loss: 0.602465\n",
      "epoch 79; iter: 0; batch classifier loss: 0.262531; batch adversarial loss: 0.598560\n",
      "epoch 0; iter: 0; batch classifier loss: 0.585991; batch adversarial loss: 0.643028\n",
      "epoch 1; iter: 0; batch classifier loss: 0.627523; batch adversarial loss: 0.666627\n",
      "epoch 2; iter: 0; batch classifier loss: 0.557124; batch adversarial loss: 0.661284\n",
      "epoch 3; iter: 0; batch classifier loss: 0.566883; batch adversarial loss: 0.648293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.578988; batch adversarial loss: 0.665472\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493930; batch adversarial loss: 0.671725\n",
      "epoch 6; iter: 0; batch classifier loss: 0.497935; batch adversarial loss: 0.656144\n",
      "epoch 7; iter: 0; batch classifier loss: 0.507853; batch adversarial loss: 0.646284\n",
      "epoch 8; iter: 0; batch classifier loss: 0.530696; batch adversarial loss: 0.648154\n",
      "epoch 9; iter: 0; batch classifier loss: 0.499492; batch adversarial loss: 0.634536\n",
      "epoch 10; iter: 0; batch classifier loss: 0.489045; batch adversarial loss: 0.664604\n",
      "epoch 11; iter: 0; batch classifier loss: 0.520736; batch adversarial loss: 0.651625\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457591; batch adversarial loss: 0.636034\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456678; batch adversarial loss: 0.633356\n",
      "epoch 14; iter: 0; batch classifier loss: 0.448120; batch adversarial loss: 0.649615\n",
      "epoch 15; iter: 0; batch classifier loss: 0.442081; batch adversarial loss: 0.640469\n",
      "epoch 16; iter: 0; batch classifier loss: 0.461389; batch adversarial loss: 0.646002\n",
      "epoch 17; iter: 0; batch classifier loss: 0.478438; batch adversarial loss: 0.641278\n",
      "epoch 18; iter: 0; batch classifier loss: 0.440849; batch adversarial loss: 0.627116\n",
      "epoch 19; iter: 0; batch classifier loss: 0.444717; batch adversarial loss: 0.656648\n",
      "epoch 20; iter: 0; batch classifier loss: 0.441082; batch adversarial loss: 0.627138\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372235; batch adversarial loss: 0.630193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392986; batch adversarial loss: 0.618485\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423491; batch adversarial loss: 0.638658\n",
      "epoch 24; iter: 0; batch classifier loss: 0.363664; batch adversarial loss: 0.613440\n",
      "epoch 25; iter: 0; batch classifier loss: 0.457087; batch adversarial loss: 0.590277\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393556; batch adversarial loss: 0.657470\n",
      "epoch 27; iter: 0; batch classifier loss: 0.403587; batch adversarial loss: 0.637192\n",
      "epoch 28; iter: 0; batch classifier loss: 0.348671; batch adversarial loss: 0.647634\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422180; batch adversarial loss: 0.628059\n",
      "epoch 30; iter: 0; batch classifier loss: 0.384712; batch adversarial loss: 0.631840\n",
      "epoch 31; iter: 0; batch classifier loss: 0.374189; batch adversarial loss: 0.627760\n",
      "epoch 32; iter: 0; batch classifier loss: 0.378086; batch adversarial loss: 0.659690\n",
      "epoch 33; iter: 0; batch classifier loss: 0.344563; batch adversarial loss: 0.636502\n",
      "epoch 34; iter: 0; batch classifier loss: 0.395790; batch adversarial loss: 0.622416\n",
      "epoch 35; iter: 0; batch classifier loss: 0.337433; batch adversarial loss: 0.631969\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379507; batch adversarial loss: 0.648510\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416436; batch adversarial loss: 0.645964\n",
      "epoch 38; iter: 0; batch classifier loss: 0.392601; batch adversarial loss: 0.614835\n",
      "epoch 39; iter: 0; batch classifier loss: 0.490680; batch adversarial loss: 0.607838\n",
      "epoch 40; iter: 0; batch classifier loss: 0.358611; batch adversarial loss: 0.631581\n",
      "epoch 41; iter: 0; batch classifier loss: 0.473281; batch adversarial loss: 0.581998\n",
      "epoch 42; iter: 0; batch classifier loss: 0.354644; batch adversarial loss: 0.609065\n",
      "epoch 43; iter: 0; batch classifier loss: 0.319296; batch adversarial loss: 0.620796\n",
      "epoch 44; iter: 0; batch classifier loss: 0.376482; batch adversarial loss: 0.655000\n",
      "epoch 45; iter: 0; batch classifier loss: 0.321324; batch adversarial loss: 0.646351\n",
      "epoch 46; iter: 0; batch classifier loss: 0.358566; batch adversarial loss: 0.591428\n",
      "epoch 47; iter: 0; batch classifier loss: 0.303520; batch adversarial loss: 0.620219\n",
      "epoch 48; iter: 0; batch classifier loss: 0.401641; batch adversarial loss: 0.629679\n",
      "epoch 49; iter: 0; batch classifier loss: 0.366950; batch adversarial loss: 0.667645\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362304; batch adversarial loss: 0.617188\n",
      "epoch 51; iter: 0; batch classifier loss: 0.362494; batch adversarial loss: 0.622825\n",
      "epoch 52; iter: 0; batch classifier loss: 0.369945; batch adversarial loss: 0.570766\n",
      "epoch 53; iter: 0; batch classifier loss: 0.328966; batch adversarial loss: 0.625129\n",
      "epoch 54; iter: 0; batch classifier loss: 0.241624; batch adversarial loss: 0.637958\n",
      "epoch 55; iter: 0; batch classifier loss: 0.335042; batch adversarial loss: 0.612110\n",
      "epoch 56; iter: 0; batch classifier loss: 0.318137; batch adversarial loss: 0.628935\n",
      "epoch 57; iter: 0; batch classifier loss: 0.502374; batch adversarial loss: 0.634448\n",
      "epoch 58; iter: 0; batch classifier loss: 0.318388; batch adversarial loss: 0.593279\n",
      "epoch 59; iter: 0; batch classifier loss: 0.384927; batch adversarial loss: 0.620583\n",
      "epoch 60; iter: 0; batch classifier loss: 0.381802; batch adversarial loss: 0.609325\n",
      "epoch 61; iter: 0; batch classifier loss: 0.347690; batch adversarial loss: 0.606880\n",
      "epoch 62; iter: 0; batch classifier loss: 0.354134; batch adversarial loss: 0.590538\n",
      "epoch 63; iter: 0; batch classifier loss: 0.282638; batch adversarial loss: 0.636941\n",
      "epoch 64; iter: 0; batch classifier loss: 0.335314; batch adversarial loss: 0.616208\n",
      "epoch 65; iter: 0; batch classifier loss: 0.384488; batch adversarial loss: 0.583965\n",
      "epoch 66; iter: 0; batch classifier loss: 0.423943; batch adversarial loss: 0.644911\n",
      "epoch 67; iter: 0; batch classifier loss: 0.337651; batch adversarial loss: 0.619463\n",
      "epoch 68; iter: 0; batch classifier loss: 0.383270; batch adversarial loss: 0.627557\n",
      "epoch 69; iter: 0; batch classifier loss: 0.311097; batch adversarial loss: 0.626186\n",
      "epoch 70; iter: 0; batch classifier loss: 0.328305; batch adversarial loss: 0.629980\n",
      "epoch 71; iter: 0; batch classifier loss: 0.286778; batch adversarial loss: 0.632586\n",
      "epoch 72; iter: 0; batch classifier loss: 0.283616; batch adversarial loss: 0.627761\n",
      "epoch 73; iter: 0; batch classifier loss: 0.329031; batch adversarial loss: 0.614961\n",
      "epoch 74; iter: 0; batch classifier loss: 0.308309; batch adversarial loss: 0.546462\n",
      "epoch 75; iter: 0; batch classifier loss: 0.371455; batch adversarial loss: 0.587916\n",
      "epoch 76; iter: 0; batch classifier loss: 0.307650; batch adversarial loss: 0.613832\n",
      "epoch 77; iter: 0; batch classifier loss: 0.326238; batch adversarial loss: 0.632359\n",
      "epoch 78; iter: 0; batch classifier loss: 0.277387; batch adversarial loss: 0.642585\n",
      "epoch 79; iter: 0; batch classifier loss: 0.272821; batch adversarial loss: 0.617064\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708211; batch adversarial loss: 0.693985\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699020; batch adversarial loss: 0.688338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.680890; batch adversarial loss: 0.690826\n",
      "epoch 3; iter: 0; batch classifier loss: 0.669260; batch adversarial loss: 0.689932\n",
      "epoch 4; iter: 0; batch classifier loss: 0.653053; batch adversarial loss: 0.678783\n",
      "epoch 5; iter: 0; batch classifier loss: 0.624678; batch adversarial loss: 0.677941\n",
      "epoch 6; iter: 0; batch classifier loss: 0.607484; batch adversarial loss: 0.675583\n",
      "epoch 7; iter: 0; batch classifier loss: 0.607195; batch adversarial loss: 0.681168\n",
      "epoch 8; iter: 0; batch classifier loss: 0.579815; batch adversarial loss: 0.675169\n",
      "epoch 9; iter: 0; batch classifier loss: 0.599799; batch adversarial loss: 0.677171\n",
      "epoch 10; iter: 0; batch classifier loss: 0.578766; batch adversarial loss: 0.664561\n",
      "epoch 11; iter: 0; batch classifier loss: 0.554471; batch adversarial loss: 0.670859\n",
      "epoch 12; iter: 0; batch classifier loss: 0.569996; batch adversarial loss: 0.667885\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550593; batch adversarial loss: 0.665743\n",
      "epoch 14; iter: 0; batch classifier loss: 0.547824; batch adversarial loss: 0.663621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.525829; batch adversarial loss: 0.659863\n",
      "epoch 16; iter: 0; batch classifier loss: 0.487841; batch adversarial loss: 0.660099\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495900; batch adversarial loss: 0.662694\n",
      "epoch 18; iter: 0; batch classifier loss: 0.488636; batch adversarial loss: 0.662176\n",
      "epoch 19; iter: 0; batch classifier loss: 0.536848; batch adversarial loss: 0.667719\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490859; batch adversarial loss: 0.655517\n",
      "epoch 21; iter: 0; batch classifier loss: 0.465322; batch adversarial loss: 0.662688\n",
      "epoch 22; iter: 0; batch classifier loss: 0.432676; batch adversarial loss: 0.662284\n",
      "epoch 23; iter: 0; batch classifier loss: 0.461514; batch adversarial loss: 0.671275\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416912; batch adversarial loss: 0.655862\n",
      "epoch 25; iter: 0; batch classifier loss: 0.443257; batch adversarial loss: 0.650076\n",
      "epoch 26; iter: 0; batch classifier loss: 0.438718; batch adversarial loss: 0.648463\n",
      "epoch 27; iter: 0; batch classifier loss: 0.480150; batch adversarial loss: 0.646011\n",
      "epoch 28; iter: 0; batch classifier loss: 0.454637; batch adversarial loss: 0.664634\n",
      "epoch 29; iter: 0; batch classifier loss: 0.476115; batch adversarial loss: 0.655638\n",
      "epoch 30; iter: 0; batch classifier loss: 0.480076; batch adversarial loss: 0.651793\n",
      "epoch 31; iter: 0; batch classifier loss: 0.409819; batch adversarial loss: 0.654912\n",
      "epoch 32; iter: 0; batch classifier loss: 0.423821; batch adversarial loss: 0.653775\n",
      "epoch 33; iter: 0; batch classifier loss: 0.405994; batch adversarial loss: 0.650705\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414188; batch adversarial loss: 0.668941\n",
      "epoch 35; iter: 0; batch classifier loss: 0.452265; batch adversarial loss: 0.670102\n",
      "epoch 36; iter: 0; batch classifier loss: 0.441496; batch adversarial loss: 0.659944\n",
      "epoch 37; iter: 0; batch classifier loss: 0.504180; batch adversarial loss: 0.644824\n",
      "epoch 38; iter: 0; batch classifier loss: 0.362162; batch adversarial loss: 0.666234\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418346; batch adversarial loss: 0.647901\n",
      "epoch 40; iter: 0; batch classifier loss: 0.442276; batch adversarial loss: 0.648062\n",
      "epoch 41; iter: 0; batch classifier loss: 0.464094; batch adversarial loss: 0.640032\n",
      "epoch 42; iter: 0; batch classifier loss: 0.436089; batch adversarial loss: 0.634327\n",
      "epoch 43; iter: 0; batch classifier loss: 0.318225; batch adversarial loss: 0.638087\n",
      "epoch 44; iter: 0; batch classifier loss: 0.426542; batch adversarial loss: 0.650284\n",
      "epoch 45; iter: 0; batch classifier loss: 0.422804; batch adversarial loss: 0.650384\n",
      "epoch 46; iter: 0; batch classifier loss: 0.396255; batch adversarial loss: 0.636948\n",
      "epoch 47; iter: 0; batch classifier loss: 0.386070; batch adversarial loss: 0.628563\n",
      "epoch 48; iter: 0; batch classifier loss: 0.399084; batch adversarial loss: 0.647416\n",
      "epoch 49; iter: 0; batch classifier loss: 0.415940; batch adversarial loss: 0.634319\n",
      "epoch 50; iter: 0; batch classifier loss: 0.403274; batch adversarial loss: 0.648793\n",
      "epoch 51; iter: 0; batch classifier loss: 0.448602; batch adversarial loss: 0.633269\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354511; batch adversarial loss: 0.644421\n",
      "epoch 53; iter: 0; batch classifier loss: 0.377261; batch adversarial loss: 0.607245\n",
      "epoch 54; iter: 0; batch classifier loss: 0.409198; batch adversarial loss: 0.622149\n",
      "epoch 55; iter: 0; batch classifier loss: 0.443533; batch adversarial loss: 0.634912\n",
      "epoch 56; iter: 0; batch classifier loss: 0.409313; batch adversarial loss: 0.626180\n",
      "epoch 57; iter: 0; batch classifier loss: 0.364461; batch adversarial loss: 0.643740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.499631; batch adversarial loss: 0.615476\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371928; batch adversarial loss: 0.623749\n",
      "epoch 60; iter: 0; batch classifier loss: 0.286974; batch adversarial loss: 0.641282\n",
      "epoch 61; iter: 0; batch classifier loss: 0.363233; batch adversarial loss: 0.627916\n",
      "epoch 62; iter: 0; batch classifier loss: 0.430094; batch adversarial loss: 0.615114\n",
      "epoch 63; iter: 0; batch classifier loss: 0.512363; batch adversarial loss: 0.628462\n",
      "epoch 64; iter: 0; batch classifier loss: 0.438329; batch adversarial loss: 0.611868\n",
      "epoch 65; iter: 0; batch classifier loss: 0.450794; batch adversarial loss: 0.610325\n",
      "epoch 66; iter: 0; batch classifier loss: 0.437652; batch adversarial loss: 0.630236\n",
      "epoch 67; iter: 0; batch classifier loss: 0.391164; batch adversarial loss: 0.627507\n",
      "epoch 68; iter: 0; batch classifier loss: 0.406102; batch adversarial loss: 0.604987\n",
      "epoch 69; iter: 0; batch classifier loss: 0.513067; batch adversarial loss: 0.610892\n",
      "epoch 70; iter: 0; batch classifier loss: 0.399601; batch adversarial loss: 0.614823\n",
      "epoch 71; iter: 0; batch classifier loss: 0.404420; batch adversarial loss: 0.623907\n",
      "epoch 72; iter: 0; batch classifier loss: 0.415778; batch adversarial loss: 0.600925\n",
      "epoch 73; iter: 0; batch classifier loss: 0.420607; batch adversarial loss: 0.626835\n",
      "epoch 74; iter: 0; batch classifier loss: 0.455453; batch adversarial loss: 0.608863\n",
      "epoch 75; iter: 0; batch classifier loss: 0.367030; batch adversarial loss: 0.653486\n",
      "epoch 76; iter: 0; batch classifier loss: 0.376433; batch adversarial loss: 0.630231\n",
      "epoch 77; iter: 0; batch classifier loss: 0.396266; batch adversarial loss: 0.620063\n",
      "epoch 78; iter: 0; batch classifier loss: 0.369702; batch adversarial loss: 0.611991\n",
      "epoch 79; iter: 0; batch classifier loss: 0.429233; batch adversarial loss: 0.586872\n",
      "epoch 0; iter: 0; batch classifier loss: 0.902699; batch adversarial loss: 0.651920\n",
      "epoch 1; iter: 0; batch classifier loss: 0.831874; batch adversarial loss: 0.648698\n",
      "epoch 2; iter: 0; batch classifier loss: 0.709713; batch adversarial loss: 0.648598\n",
      "epoch 3; iter: 0; batch classifier loss: 0.694158; batch adversarial loss: 0.652614\n",
      "epoch 4; iter: 0; batch classifier loss: 0.646492; batch adversarial loss: 0.636097\n",
      "epoch 5; iter: 0; batch classifier loss: 0.567505; batch adversarial loss: 0.624395\n",
      "epoch 6; iter: 0; batch classifier loss: 0.518434; batch adversarial loss: 0.631360\n",
      "epoch 7; iter: 0; batch classifier loss: 0.538203; batch adversarial loss: 0.609269\n",
      "epoch 8; iter: 0; batch classifier loss: 0.493477; batch adversarial loss: 0.609384\n",
      "epoch 9; iter: 0; batch classifier loss: 0.616785; batch adversarial loss: 0.611145\n",
      "epoch 10; iter: 0; batch classifier loss: 0.410876; batch adversarial loss: 0.626876\n",
      "epoch 11; iter: 0; batch classifier loss: 0.515848; batch adversarial loss: 0.605581\n",
      "epoch 12; iter: 0; batch classifier loss: 0.448744; batch adversarial loss: 0.626442\n",
      "epoch 13; iter: 0; batch classifier loss: 0.411860; batch adversarial loss: 0.577890\n",
      "epoch 14; iter: 0; batch classifier loss: 0.468444; batch adversarial loss: 0.623181\n",
      "epoch 15; iter: 0; batch classifier loss: 0.556829; batch adversarial loss: 0.587267\n",
      "epoch 16; iter: 0; batch classifier loss: 0.409666; batch adversarial loss: 0.608089\n",
      "epoch 17; iter: 0; batch classifier loss: 0.278964; batch adversarial loss: 0.586559\n",
      "epoch 18; iter: 0; batch classifier loss: 0.399902; batch adversarial loss: 0.640290\n",
      "epoch 19; iter: 0; batch classifier loss: 0.436586; batch adversarial loss: 0.580352\n",
      "epoch 20; iter: 0; batch classifier loss: 0.363970; batch adversarial loss: 0.600054\n",
      "epoch 21; iter: 0; batch classifier loss: 0.481151; batch adversarial loss: 0.571502\n",
      "epoch 22; iter: 0; batch classifier loss: 0.382556; batch adversarial loss: 0.609528\n",
      "epoch 23; iter: 0; batch classifier loss: 0.324488; batch adversarial loss: 0.593108\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370977; batch adversarial loss: 0.599326\n",
      "epoch 25; iter: 0; batch classifier loss: 0.260566; batch adversarial loss: 0.578928\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410206; batch adversarial loss: 0.616894\n",
      "epoch 27; iter: 0; batch classifier loss: 0.401066; batch adversarial loss: 0.582855\n",
      "epoch 28; iter: 0; batch classifier loss: 0.370877; batch adversarial loss: 0.589988\n",
      "epoch 29; iter: 0; batch classifier loss: 0.398265; batch adversarial loss: 0.577822\n",
      "epoch 30; iter: 0; batch classifier loss: 0.289724; batch adversarial loss: 0.606478\n",
      "epoch 31; iter: 0; batch classifier loss: 0.343818; batch adversarial loss: 0.575161\n",
      "epoch 32; iter: 0; batch classifier loss: 0.387593; batch adversarial loss: 0.601639\n",
      "epoch 33; iter: 0; batch classifier loss: 0.313160; batch adversarial loss: 0.606259\n",
      "epoch 34; iter: 0; batch classifier loss: 0.278771; batch adversarial loss: 0.598816\n",
      "epoch 35; iter: 0; batch classifier loss: 0.326591; batch adversarial loss: 0.607906\n",
      "epoch 36; iter: 0; batch classifier loss: 0.306170; batch adversarial loss: 0.546064\n",
      "epoch 37; iter: 0; batch classifier loss: 0.291074; batch adversarial loss: 0.569209\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286188; batch adversarial loss: 0.553021\n",
      "epoch 39; iter: 0; batch classifier loss: 0.329969; batch adversarial loss: 0.602827\n",
      "epoch 0; iter: 0; batch classifier loss: 0.677279; batch adversarial loss: 0.890891\n",
      "epoch 1; iter: 0; batch classifier loss: 0.642579; batch adversarial loss: 0.840420\n",
      "epoch 2; iter: 0; batch classifier loss: 0.562280; batch adversarial loss: 0.842188\n",
      "epoch 3; iter: 0; batch classifier loss: 0.541642; batch adversarial loss: 0.924659\n",
      "epoch 4; iter: 0; batch classifier loss: 0.569800; batch adversarial loss: 0.893814\n",
      "epoch 5; iter: 0; batch classifier loss: 0.571326; batch adversarial loss: 0.881761\n",
      "epoch 6; iter: 0; batch classifier loss: 0.513896; batch adversarial loss: 0.886555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.518413; batch adversarial loss: 0.906303\n",
      "epoch 8; iter: 0; batch classifier loss: 0.456701; batch adversarial loss: 0.862511\n",
      "epoch 9; iter: 0; batch classifier loss: 0.600910; batch adversarial loss: 0.931940\n",
      "epoch 10; iter: 0; batch classifier loss: 0.603170; batch adversarial loss: 0.928838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.499109; batch adversarial loss: 0.893857\n",
      "epoch 12; iter: 0; batch classifier loss: 0.413458; batch adversarial loss: 0.876901\n",
      "epoch 13; iter: 0; batch classifier loss: 0.330893; batch adversarial loss: 0.861475\n",
      "epoch 14; iter: 0; batch classifier loss: 0.475334; batch adversarial loss: 0.852960\n",
      "epoch 15; iter: 0; batch classifier loss: 0.554868; batch adversarial loss: 0.868076\n",
      "epoch 16; iter: 0; batch classifier loss: 0.687234; batch adversarial loss: 0.841514\n",
      "epoch 17; iter: 0; batch classifier loss: 0.625396; batch adversarial loss: 0.854427\n",
      "epoch 18; iter: 0; batch classifier loss: 0.459999; batch adversarial loss: 0.846337\n",
      "epoch 19; iter: 0; batch classifier loss: 0.548174; batch adversarial loss: 0.855730\n",
      "epoch 20; iter: 0; batch classifier loss: 0.451087; batch adversarial loss: 0.868287\n",
      "epoch 21; iter: 0; batch classifier loss: 0.660538; batch adversarial loss: 0.829288\n",
      "epoch 22; iter: 0; batch classifier loss: 0.692981; batch adversarial loss: 0.835425\n",
      "epoch 23; iter: 0; batch classifier loss: 0.608118; batch adversarial loss: 0.835269\n",
      "epoch 24; iter: 0; batch classifier loss: 0.590615; batch adversarial loss: 0.816088\n",
      "epoch 25; iter: 0; batch classifier loss: 0.702481; batch adversarial loss: 0.823450\n",
      "epoch 26; iter: 0; batch classifier loss: 0.583968; batch adversarial loss: 0.804089\n",
      "epoch 27; iter: 0; batch classifier loss: 0.521928; batch adversarial loss: 0.800403\n",
      "epoch 28; iter: 0; batch classifier loss: 0.458150; batch adversarial loss: 0.796654\n",
      "epoch 29; iter: 0; batch classifier loss: 0.687515; batch adversarial loss: 0.776321\n",
      "epoch 30; iter: 0; batch classifier loss: 0.561530; batch adversarial loss: 0.780196\n",
      "epoch 31; iter: 0; batch classifier loss: 0.591554; batch adversarial loss: 0.779562\n",
      "epoch 32; iter: 0; batch classifier loss: 0.475349; batch adversarial loss: 0.774813\n",
      "epoch 33; iter: 0; batch classifier loss: 0.633070; batch adversarial loss: 0.756369\n",
      "epoch 34; iter: 0; batch classifier loss: 0.604374; batch adversarial loss: 0.750906\n",
      "epoch 35; iter: 0; batch classifier loss: 0.546936; batch adversarial loss: 0.744182\n",
      "epoch 36; iter: 0; batch classifier loss: 0.681184; batch adversarial loss: 0.727966\n",
      "epoch 37; iter: 0; batch classifier loss: 0.646055; batch adversarial loss: 0.728178\n",
      "epoch 38; iter: 0; batch classifier loss: 0.711746; batch adversarial loss: 0.716446\n",
      "epoch 39; iter: 0; batch classifier loss: 0.802931; batch adversarial loss: 0.723318\n",
      "epoch 0; iter: 0; batch classifier loss: 0.709450; batch adversarial loss: 0.737245\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734636; batch adversarial loss: 0.743459\n",
      "epoch 2; iter: 0; batch classifier loss: 0.692742; batch adversarial loss: 0.734156\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659687; batch adversarial loss: 0.750036\n",
      "epoch 4; iter: 0; batch classifier loss: 0.647811; batch adversarial loss: 0.718889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.613036; batch adversarial loss: 0.747766\n",
      "epoch 6; iter: 0; batch classifier loss: 0.552393; batch adversarial loss: 0.735910\n",
      "epoch 7; iter: 0; batch classifier loss: 0.558300; batch adversarial loss: 0.735175\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561889; batch adversarial loss: 0.736757\n",
      "epoch 9; iter: 0; batch classifier loss: 0.565843; batch adversarial loss: 0.729016\n",
      "epoch 10; iter: 0; batch classifier loss: 0.541491; batch adversarial loss: 0.733103\n",
      "epoch 11; iter: 0; batch classifier loss: 0.514431; batch adversarial loss: 0.723977\n",
      "epoch 12; iter: 0; batch classifier loss: 0.527878; batch adversarial loss: 0.714288\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520933; batch adversarial loss: 0.727885\n",
      "epoch 14; iter: 0; batch classifier loss: 0.451925; batch adversarial loss: 0.713900\n",
      "epoch 15; iter: 0; batch classifier loss: 0.494796; batch adversarial loss: 0.724708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.472835; batch adversarial loss: 0.716286\n",
      "epoch 17; iter: 0; batch classifier loss: 0.507663; batch adversarial loss: 0.726224\n",
      "epoch 18; iter: 0; batch classifier loss: 0.466713; batch adversarial loss: 0.724128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.470269; batch adversarial loss: 0.714350\n",
      "epoch 20; iter: 0; batch classifier loss: 0.485265; batch adversarial loss: 0.715397\n",
      "epoch 21; iter: 0; batch classifier loss: 0.477539; batch adversarial loss: 0.703696\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484493; batch adversarial loss: 0.713366\n",
      "epoch 23; iter: 0; batch classifier loss: 0.483731; batch adversarial loss: 0.708842\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468467; batch adversarial loss: 0.696846\n",
      "epoch 25; iter: 0; batch classifier loss: 0.472036; batch adversarial loss: 0.695949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.483403; batch adversarial loss: 0.697754\n",
      "epoch 27; iter: 0; batch classifier loss: 0.475128; batch adversarial loss: 0.700561\n",
      "epoch 28; iter: 0; batch classifier loss: 0.432524; batch adversarial loss: 0.695009\n",
      "epoch 29; iter: 0; batch classifier loss: 0.451669; batch adversarial loss: 0.686615\n",
      "epoch 30; iter: 0; batch classifier loss: 0.484180; batch adversarial loss: 0.691027\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441631; batch adversarial loss: 0.686146\n",
      "epoch 32; iter: 0; batch classifier loss: 0.445498; batch adversarial loss: 0.683137\n",
      "epoch 33; iter: 0; batch classifier loss: 0.425646; batch adversarial loss: 0.685805\n",
      "epoch 34; iter: 0; batch classifier loss: 0.475270; batch adversarial loss: 0.686278\n",
      "epoch 35; iter: 0; batch classifier loss: 0.442753; batch adversarial loss: 0.680503\n",
      "epoch 36; iter: 0; batch classifier loss: 0.497472; batch adversarial loss: 0.696285\n",
      "epoch 37; iter: 0; batch classifier loss: 0.442415; batch adversarial loss: 0.674694\n",
      "epoch 38; iter: 0; batch classifier loss: 0.438411; batch adversarial loss: 0.674445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.489793; batch adversarial loss: 0.681204\n",
      "epoch 0; iter: 0; batch classifier loss: 0.718782; batch adversarial loss: 0.599978\n",
      "epoch 1; iter: 0; batch classifier loss: 0.641185; batch adversarial loss: 0.624227\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624965; batch adversarial loss: 0.637832\n",
      "epoch 3; iter: 0; batch classifier loss: 0.613947; batch adversarial loss: 0.614153\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557135; batch adversarial loss: 0.650082\n",
      "epoch 5; iter: 0; batch classifier loss: 0.574234; batch adversarial loss: 0.649729\n",
      "epoch 6; iter: 0; batch classifier loss: 0.539374; batch adversarial loss: 0.623998\n",
      "epoch 7; iter: 0; batch classifier loss: 0.542067; batch adversarial loss: 0.638755\n",
      "epoch 8; iter: 0; batch classifier loss: 0.467247; batch adversarial loss: 0.655307\n",
      "epoch 9; iter: 0; batch classifier loss: 0.496575; batch adversarial loss: 0.618299\n",
      "epoch 10; iter: 0; batch classifier loss: 0.450603; batch adversarial loss: 0.618179\n",
      "epoch 11; iter: 0; batch classifier loss: 0.438985; batch adversarial loss: 0.596332\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385016; batch adversarial loss: 0.599238\n",
      "epoch 13; iter: 0; batch classifier loss: 0.456755; batch adversarial loss: 0.631653\n",
      "epoch 14; iter: 0; batch classifier loss: 0.435825; batch adversarial loss: 0.634358\n",
      "epoch 15; iter: 0; batch classifier loss: 0.370720; batch adversarial loss: 0.656676\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408324; batch adversarial loss: 0.641224\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470824; batch adversarial loss: 0.656564\n",
      "epoch 18; iter: 0; batch classifier loss: 0.375055; batch adversarial loss: 0.662097\n",
      "epoch 19; iter: 0; batch classifier loss: 0.336451; batch adversarial loss: 0.725439\n",
      "epoch 20; iter: 0; batch classifier loss: 0.356731; batch adversarial loss: 0.672357\n",
      "epoch 21; iter: 0; batch classifier loss: 0.346416; batch adversarial loss: 0.650603\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399560; batch adversarial loss: 0.617715\n",
      "epoch 23; iter: 0; batch classifier loss: 0.362215; batch adversarial loss: 0.667541\n",
      "epoch 24; iter: 0; batch classifier loss: 0.379290; batch adversarial loss: 0.618834\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345863; batch adversarial loss: 0.630589\n",
      "epoch 26; iter: 0; batch classifier loss: 0.332518; batch adversarial loss: 0.658684\n",
      "epoch 27; iter: 0; batch classifier loss: 0.309624; batch adversarial loss: 0.637098\n",
      "epoch 28; iter: 0; batch classifier loss: 0.317126; batch adversarial loss: 0.620379\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323720; batch adversarial loss: 0.582950\n",
      "epoch 30; iter: 0; batch classifier loss: 0.383803; batch adversarial loss: 0.649574\n",
      "epoch 31; iter: 0; batch classifier loss: 0.360324; batch adversarial loss: 0.631275\n",
      "epoch 32; iter: 0; batch classifier loss: 0.390757; batch adversarial loss: 0.654171\n",
      "epoch 33; iter: 0; batch classifier loss: 0.373791; batch adversarial loss: 0.663965\n",
      "epoch 34; iter: 0; batch classifier loss: 0.367678; batch adversarial loss: 0.642668\n",
      "epoch 35; iter: 0; batch classifier loss: 0.299491; batch adversarial loss: 0.630961\n",
      "epoch 36; iter: 0; batch classifier loss: 0.356382; batch adversarial loss: 0.604995\n",
      "epoch 37; iter: 0; batch classifier loss: 0.351297; batch adversarial loss: 0.622258\n",
      "epoch 38; iter: 0; batch classifier loss: 0.286782; batch adversarial loss: 0.646294\n",
      "epoch 39; iter: 0; batch classifier loss: 0.370692; batch adversarial loss: 0.640321\n",
      "epoch 0; iter: 0; batch classifier loss: 0.783161; batch adversarial loss: 0.964887\n",
      "epoch 1; iter: 0; batch classifier loss: 0.764563; batch adversarial loss: 0.969943\n",
      "epoch 2; iter: 0; batch classifier loss: 0.681320; batch adversarial loss: 1.086367\n",
      "epoch 3; iter: 0; batch classifier loss: 0.627954; batch adversarial loss: 1.105629\n",
      "epoch 4; iter: 0; batch classifier loss: 0.622247; batch adversarial loss: 1.066142\n",
      "epoch 5; iter: 0; batch classifier loss: 0.667400; batch adversarial loss: 1.131205\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584171; batch adversarial loss: 1.242018\n",
      "epoch 7; iter: 0; batch classifier loss: 0.648154; batch adversarial loss: 1.099228\n",
      "epoch 8; iter: 0; batch classifier loss: 0.541631; batch adversarial loss: 1.206200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.758270; batch adversarial loss: 1.217757\n",
      "epoch 10; iter: 0; batch classifier loss: 0.632906; batch adversarial loss: 1.128851\n",
      "epoch 11; iter: 0; batch classifier loss: 0.673676; batch adversarial loss: 1.155278\n",
      "epoch 12; iter: 0; batch classifier loss: 0.544061; batch adversarial loss: 1.063257\n",
      "epoch 13; iter: 0; batch classifier loss: 0.591200; batch adversarial loss: 1.082071\n",
      "epoch 14; iter: 0; batch classifier loss: 0.765060; batch adversarial loss: 1.218742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.701423; batch adversarial loss: 1.080374\n",
      "epoch 16; iter: 0; batch classifier loss: 0.855231; batch adversarial loss: 1.151489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.815055; batch adversarial loss: 1.166595\n",
      "epoch 18; iter: 0; batch classifier loss: 0.542465; batch adversarial loss: 1.099128\n",
      "epoch 19; iter: 0; batch classifier loss: 0.661683; batch adversarial loss: 1.168571\n",
      "epoch 20; iter: 0; batch classifier loss: 0.703452; batch adversarial loss: 1.103537\n",
      "epoch 21; iter: 0; batch classifier loss: 0.748541; batch adversarial loss: 1.082551\n",
      "epoch 22; iter: 0; batch classifier loss: 0.617534; batch adversarial loss: 0.976171\n",
      "epoch 23; iter: 0; batch classifier loss: 0.640082; batch adversarial loss: 1.001207\n",
      "epoch 24; iter: 0; batch classifier loss: 0.730032; batch adversarial loss: 1.010311\n",
      "epoch 25; iter: 0; batch classifier loss: 0.675463; batch adversarial loss: 1.065089\n",
      "epoch 26; iter: 0; batch classifier loss: 0.633646; batch adversarial loss: 0.985303\n",
      "epoch 27; iter: 0; batch classifier loss: 0.840413; batch adversarial loss: 1.050333\n",
      "epoch 28; iter: 0; batch classifier loss: 0.709598; batch adversarial loss: 0.997820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.753714; batch adversarial loss: 0.940237\n",
      "epoch 30; iter: 0; batch classifier loss: 0.767418; batch adversarial loss: 0.982454\n",
      "epoch 31; iter: 0; batch classifier loss: 0.702771; batch adversarial loss: 0.970574\n",
      "epoch 32; iter: 0; batch classifier loss: 0.813025; batch adversarial loss: 0.988121\n",
      "epoch 33; iter: 0; batch classifier loss: 0.741720; batch adversarial loss: 0.966593\n",
      "epoch 34; iter: 0; batch classifier loss: 0.833133; batch adversarial loss: 0.981413\n",
      "epoch 35; iter: 0; batch classifier loss: 0.794517; batch adversarial loss: 0.975501\n",
      "epoch 36; iter: 0; batch classifier loss: 0.681718; batch adversarial loss: 0.931309\n",
      "epoch 37; iter: 0; batch classifier loss: 0.869443; batch adversarial loss: 0.929503\n",
      "epoch 38; iter: 0; batch classifier loss: 0.706156; batch adversarial loss: 0.923956\n",
      "epoch 39; iter: 0; batch classifier loss: 0.813973; batch adversarial loss: 0.919001\n",
      "epoch 40; iter: 0; batch classifier loss: 0.897532; batch adversarial loss: 0.915662\n",
      "epoch 41; iter: 0; batch classifier loss: 0.922128; batch adversarial loss: 0.921789\n",
      "epoch 42; iter: 0; batch classifier loss: 0.894479; batch adversarial loss: 0.894562\n",
      "epoch 43; iter: 0; batch classifier loss: 0.818076; batch adversarial loss: 0.885463\n",
      "epoch 44; iter: 0; batch classifier loss: 0.713681; batch adversarial loss: 0.871285\n",
      "epoch 45; iter: 0; batch classifier loss: 0.765808; batch adversarial loss: 0.863896\n",
      "epoch 46; iter: 0; batch classifier loss: 0.762818; batch adversarial loss: 0.861166\n",
      "epoch 47; iter: 0; batch classifier loss: 0.845995; batch adversarial loss: 0.839478\n",
      "epoch 48; iter: 0; batch classifier loss: 0.833713; batch adversarial loss: 0.840019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.740467; batch adversarial loss: 0.836379\n",
      "epoch 50; iter: 0; batch classifier loss: 0.997276; batch adversarial loss: 0.831443\n",
      "epoch 51; iter: 0; batch classifier loss: 0.919356; batch adversarial loss: 0.827554\n",
      "epoch 52; iter: 0; batch classifier loss: 0.614093; batch adversarial loss: 0.804289\n",
      "epoch 53; iter: 0; batch classifier loss: 0.968300; batch adversarial loss: 0.806621\n",
      "epoch 54; iter: 0; batch classifier loss: 0.883883; batch adversarial loss: 0.804166\n",
      "epoch 55; iter: 0; batch classifier loss: 0.929816; batch adversarial loss: 0.791152\n",
      "epoch 56; iter: 0; batch classifier loss: 0.826901; batch adversarial loss: 0.786722\n",
      "epoch 57; iter: 0; batch classifier loss: 0.707033; batch adversarial loss: 0.751011\n",
      "epoch 58; iter: 0; batch classifier loss: 0.835939; batch adversarial loss: 0.775444\n",
      "epoch 59; iter: 0; batch classifier loss: 0.974314; batch adversarial loss: 0.758415\n",
      "epoch 0; iter: 0; batch classifier loss: 0.779700; batch adversarial loss: 0.648695\n",
      "epoch 1; iter: 0; batch classifier loss: 0.730047; batch adversarial loss: 0.629424\n",
      "epoch 2; iter: 0; batch classifier loss: 0.595806; batch adversarial loss: 0.676301\n",
      "epoch 3; iter: 0; batch classifier loss: 0.591239; batch adversarial loss: 0.633765\n",
      "epoch 4; iter: 0; batch classifier loss: 0.523163; batch adversarial loss: 0.702673\n",
      "epoch 5; iter: 0; batch classifier loss: 0.540309; batch adversarial loss: 0.655381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.504498; batch adversarial loss: 0.624791\n",
      "epoch 7; iter: 0; batch classifier loss: 0.526143; batch adversarial loss: 0.631965\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474539; batch adversarial loss: 0.633361\n",
      "epoch 9; iter: 0; batch classifier loss: 0.511527; batch adversarial loss: 0.662242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.375849; batch adversarial loss: 0.626390\n",
      "epoch 11; iter: 0; batch classifier loss: 0.437594; batch adversarial loss: 0.632228\n",
      "epoch 12; iter: 0; batch classifier loss: 0.384535; batch adversarial loss: 0.594587\n",
      "epoch 13; iter: 0; batch classifier loss: 0.361859; batch adversarial loss: 0.555905\n",
      "epoch 14; iter: 0; batch classifier loss: 0.419475; batch adversarial loss: 0.554435\n",
      "epoch 15; iter: 0; batch classifier loss: 0.329198; batch adversarial loss: 0.561416\n",
      "epoch 16; iter: 0; batch classifier loss: 0.344655; batch adversarial loss: 0.630780\n",
      "epoch 17; iter: 0; batch classifier loss: 0.413337; batch adversarial loss: 0.561618\n",
      "epoch 18; iter: 0; batch classifier loss: 0.421405; batch adversarial loss: 0.615498\n",
      "epoch 19; iter: 0; batch classifier loss: 0.384937; batch adversarial loss: 0.672077\n",
      "epoch 20; iter: 0; batch classifier loss: 0.362262; batch adversarial loss: 0.628761\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500944; batch adversarial loss: 0.652787\n",
      "epoch 22; iter: 0; batch classifier loss: 0.376482; batch adversarial loss: 0.634182\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367097; batch adversarial loss: 0.606414\n",
      "epoch 24; iter: 0; batch classifier loss: 0.350160; batch adversarial loss: 0.648050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.439056; batch adversarial loss: 0.682881\n",
      "epoch 26; iter: 0; batch classifier loss: 0.457259; batch adversarial loss: 0.649110\n",
      "epoch 27; iter: 0; batch classifier loss: 0.241565; batch adversarial loss: 0.514759\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.607169\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352686; batch adversarial loss: 0.607225\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406267; batch adversarial loss: 0.636549\n",
      "epoch 31; iter: 0; batch classifier loss: 0.330396; batch adversarial loss: 0.670768\n",
      "epoch 32; iter: 0; batch classifier loss: 0.461397; batch adversarial loss: 0.613417\n",
      "epoch 33; iter: 0; batch classifier loss: 0.311544; batch adversarial loss: 0.605681\n",
      "epoch 34; iter: 0; batch classifier loss: 0.288260; batch adversarial loss: 0.629668\n",
      "epoch 35; iter: 0; batch classifier loss: 0.378369; batch adversarial loss: 0.692878\n",
      "epoch 36; iter: 0; batch classifier loss: 0.272169; batch adversarial loss: 0.587744\n",
      "epoch 37; iter: 0; batch classifier loss: 0.271153; batch adversarial loss: 0.640997\n",
      "epoch 38; iter: 0; batch classifier loss: 0.461363; batch adversarial loss: 0.669934\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315180; batch adversarial loss: 0.586362\n",
      "epoch 40; iter: 0; batch classifier loss: 0.284240; batch adversarial loss: 0.635806\n",
      "epoch 41; iter: 0; batch classifier loss: 0.468422; batch adversarial loss: 0.676962\n",
      "epoch 42; iter: 0; batch classifier loss: 0.443426; batch adversarial loss: 0.674713\n",
      "epoch 43; iter: 0; batch classifier loss: 0.345557; batch adversarial loss: 0.621207\n",
      "epoch 44; iter: 0; batch classifier loss: 0.323323; batch adversarial loss: 0.622847\n",
      "epoch 45; iter: 0; batch classifier loss: 0.328975; batch adversarial loss: 0.663744\n",
      "epoch 46; iter: 0; batch classifier loss: 0.448370; batch adversarial loss: 0.625488\n",
      "epoch 47; iter: 0; batch classifier loss: 0.368516; batch adversarial loss: 0.603249\n",
      "epoch 48; iter: 0; batch classifier loss: 0.314937; batch adversarial loss: 0.601516\n",
      "epoch 49; iter: 0; batch classifier loss: 0.371379; batch adversarial loss: 0.588202\n",
      "epoch 50; iter: 0; batch classifier loss: 0.525032; batch adversarial loss: 0.620442\n",
      "epoch 51; iter: 0; batch classifier loss: 0.398937; batch adversarial loss: 0.629173\n",
      "epoch 52; iter: 0; batch classifier loss: 0.271954; batch adversarial loss: 0.587284\n",
      "epoch 53; iter: 0; batch classifier loss: 0.323883; batch adversarial loss: 0.617621\n",
      "epoch 54; iter: 0; batch classifier loss: 0.326201; batch adversarial loss: 0.592953\n",
      "epoch 55; iter: 0; batch classifier loss: 0.318930; batch adversarial loss: 0.639728\n",
      "epoch 56; iter: 0; batch classifier loss: 0.324169; batch adversarial loss: 0.629188\n",
      "epoch 57; iter: 0; batch classifier loss: 0.320300; batch adversarial loss: 0.598875\n",
      "epoch 58; iter: 0; batch classifier loss: 0.292564; batch adversarial loss: 0.635036\n",
      "epoch 59; iter: 0; batch classifier loss: 0.454476; batch adversarial loss: 0.581134\n",
      "epoch 0; iter: 0; batch classifier loss: 0.755135; batch adversarial loss: 0.713097\n",
      "epoch 1; iter: 0; batch classifier loss: 0.844005; batch adversarial loss: 0.719201\n",
      "epoch 2; iter: 0; batch classifier loss: 0.755309; batch adversarial loss: 0.721674\n",
      "epoch 3; iter: 0; batch classifier loss: 0.789682; batch adversarial loss: 0.721292\n",
      "epoch 4; iter: 0; batch classifier loss: 0.723016; batch adversarial loss: 0.705352\n",
      "epoch 5; iter: 0; batch classifier loss: 0.800682; batch adversarial loss: 0.710914\n",
      "epoch 6; iter: 0; batch classifier loss: 0.768511; batch adversarial loss: 0.728555\n",
      "epoch 7; iter: 0; batch classifier loss: 0.723214; batch adversarial loss: 0.714295\n",
      "epoch 8; iter: 0; batch classifier loss: 0.770666; batch adversarial loss: 0.697939\n",
      "epoch 9; iter: 0; batch classifier loss: 0.735545; batch adversarial loss: 0.701187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.705235; batch adversarial loss: 0.695594\n",
      "epoch 11; iter: 0; batch classifier loss: 0.693116; batch adversarial loss: 0.697051\n",
      "epoch 12; iter: 0; batch classifier loss: 0.693671; batch adversarial loss: 0.686609\n",
      "epoch 13; iter: 0; batch classifier loss: 0.642159; batch adversarial loss: 0.663420\n",
      "epoch 14; iter: 0; batch classifier loss: 0.661199; batch adversarial loss: 0.674019\n",
      "epoch 15; iter: 0; batch classifier loss: 0.602399; batch adversarial loss: 0.677850\n",
      "epoch 16; iter: 0; batch classifier loss: 0.648807; batch adversarial loss: 0.671405\n",
      "epoch 17; iter: 0; batch classifier loss: 0.648181; batch adversarial loss: 0.680490\n",
      "epoch 18; iter: 0; batch classifier loss: 0.613585; batch adversarial loss: 0.669074\n",
      "epoch 19; iter: 0; batch classifier loss: 0.633917; batch adversarial loss: 0.666127\n",
      "epoch 20; iter: 0; batch classifier loss: 0.595949; batch adversarial loss: 0.675298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.630690; batch adversarial loss: 0.650498\n",
      "epoch 22; iter: 0; batch classifier loss: 0.579096; batch adversarial loss: 0.668800\n",
      "epoch 23; iter: 0; batch classifier loss: 0.596344; batch adversarial loss: 0.658895\n",
      "epoch 24; iter: 0; batch classifier loss: 0.591698; batch adversarial loss: 0.677215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.561801; batch adversarial loss: 0.661712\n",
      "epoch 26; iter: 0; batch classifier loss: 0.547784; batch adversarial loss: 0.656353\n",
      "epoch 27; iter: 0; batch classifier loss: 0.546008; batch adversarial loss: 0.646372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.551116; batch adversarial loss: 0.659798\n",
      "epoch 29; iter: 0; batch classifier loss: 0.574084; batch adversarial loss: 0.658105\n",
      "epoch 30; iter: 0; batch classifier loss: 0.513394; batch adversarial loss: 0.668303\n",
      "epoch 31; iter: 0; batch classifier loss: 0.495468; batch adversarial loss: 0.642542\n",
      "epoch 32; iter: 0; batch classifier loss: 0.485615; batch adversarial loss: 0.656383\n",
      "epoch 33; iter: 0; batch classifier loss: 0.516194; batch adversarial loss: 0.659712\n",
      "epoch 34; iter: 0; batch classifier loss: 0.527986; batch adversarial loss: 0.663128\n",
      "epoch 35; iter: 0; batch classifier loss: 0.524976; batch adversarial loss: 0.647480\n",
      "epoch 36; iter: 0; batch classifier loss: 0.483653; batch adversarial loss: 0.644301\n",
      "epoch 37; iter: 0; batch classifier loss: 0.498844; batch adversarial loss: 0.656994\n",
      "epoch 38; iter: 0; batch classifier loss: 0.497342; batch adversarial loss: 0.648391\n",
      "epoch 39; iter: 0; batch classifier loss: 0.516820; batch adversarial loss: 0.640363\n",
      "epoch 40; iter: 0; batch classifier loss: 0.542171; batch adversarial loss: 0.661383\n",
      "epoch 41; iter: 0; batch classifier loss: 0.535239; batch adversarial loss: 0.622038\n",
      "epoch 42; iter: 0; batch classifier loss: 0.500111; batch adversarial loss: 0.660225\n",
      "epoch 43; iter: 0; batch classifier loss: 0.478383; batch adversarial loss: 0.646161\n",
      "epoch 44; iter: 0; batch classifier loss: 0.466753; batch adversarial loss: 0.642746\n",
      "epoch 45; iter: 0; batch classifier loss: 0.463646; batch adversarial loss: 0.647034\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459750; batch adversarial loss: 0.640805\n",
      "epoch 47; iter: 0; batch classifier loss: 0.487241; batch adversarial loss: 0.634550\n",
      "epoch 48; iter: 0; batch classifier loss: 0.438916; batch adversarial loss: 0.655615\n",
      "epoch 49; iter: 0; batch classifier loss: 0.508271; batch adversarial loss: 0.639599\n",
      "epoch 50; iter: 0; batch classifier loss: 0.463665; batch adversarial loss: 0.643176\n",
      "epoch 51; iter: 0; batch classifier loss: 0.508493; batch adversarial loss: 0.628008\n",
      "epoch 52; iter: 0; batch classifier loss: 0.501394; batch adversarial loss: 0.618883\n",
      "epoch 53; iter: 0; batch classifier loss: 0.474975; batch adversarial loss: 0.634552\n",
      "epoch 54; iter: 0; batch classifier loss: 0.473195; batch adversarial loss: 0.648110\n",
      "epoch 55; iter: 0; batch classifier loss: 0.405505; batch adversarial loss: 0.634042\n",
      "epoch 56; iter: 0; batch classifier loss: 0.389633; batch adversarial loss: 0.632944\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421814; batch adversarial loss: 0.653368\n",
      "epoch 58; iter: 0; batch classifier loss: 0.448418; batch adversarial loss: 0.630489\n",
      "epoch 59; iter: 0; batch classifier loss: 0.443881; batch adversarial loss: 0.642476\n",
      "epoch 0; iter: 0; batch classifier loss: 0.717442; batch adversarial loss: 0.885925\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691151; batch adversarial loss: 0.848730\n",
      "epoch 2; iter: 0; batch classifier loss: 0.637950; batch adversarial loss: 0.836435\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617588; batch adversarial loss: 0.789355\n",
      "epoch 4; iter: 0; batch classifier loss: 0.648618; batch adversarial loss: 0.875788\n",
      "epoch 5; iter: 0; batch classifier loss: 0.650340; batch adversarial loss: 0.853483\n",
      "epoch 6; iter: 0; batch classifier loss: 0.633620; batch adversarial loss: 0.855189\n",
      "epoch 7; iter: 0; batch classifier loss: 0.623910; batch adversarial loss: 0.844174\n",
      "epoch 8; iter: 0; batch classifier loss: 0.616320; batch adversarial loss: 0.864983\n",
      "epoch 9; iter: 0; batch classifier loss: 0.643913; batch adversarial loss: 0.873089\n",
      "epoch 10; iter: 0; batch classifier loss: 0.697904; batch adversarial loss: 0.897256\n",
      "epoch 11; iter: 0; batch classifier loss: 0.616608; batch adversarial loss: 0.874527\n",
      "epoch 12; iter: 0; batch classifier loss: 0.613734; batch adversarial loss: 0.850716\n",
      "epoch 13; iter: 0; batch classifier loss: 0.682876; batch adversarial loss: 0.908472\n",
      "epoch 14; iter: 0; batch classifier loss: 0.641421; batch adversarial loss: 0.903022\n",
      "epoch 15; iter: 0; batch classifier loss: 0.633263; batch adversarial loss: 0.905154\n",
      "epoch 16; iter: 0; batch classifier loss: 0.749212; batch adversarial loss: 0.979553\n",
      "epoch 17; iter: 0; batch classifier loss: 0.637904; batch adversarial loss: 0.884223\n",
      "epoch 18; iter: 0; batch classifier loss: 0.645158; batch adversarial loss: 0.849388\n",
      "epoch 19; iter: 0; batch classifier loss: 0.645653; batch adversarial loss: 0.866052\n",
      "epoch 20; iter: 0; batch classifier loss: 0.664316; batch adversarial loss: 0.856066\n",
      "epoch 21; iter: 0; batch classifier loss: 0.650400; batch adversarial loss: 0.861671\n",
      "epoch 22; iter: 0; batch classifier loss: 0.738337; batch adversarial loss: 0.928137\n",
      "epoch 23; iter: 0; batch classifier loss: 0.732713; batch adversarial loss: 0.930297\n",
      "epoch 24; iter: 0; batch classifier loss: 0.714213; batch adversarial loss: 0.912812\n",
      "epoch 25; iter: 0; batch classifier loss: 0.709372; batch adversarial loss: 0.900888\n",
      "epoch 26; iter: 0; batch classifier loss: 0.664760; batch adversarial loss: 0.873479\n",
      "epoch 27; iter: 0; batch classifier loss: 0.732468; batch adversarial loss: 0.881291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.773857; batch adversarial loss: 0.891218\n",
      "epoch 29; iter: 0; batch classifier loss: 0.718249; batch adversarial loss: 0.884207\n",
      "epoch 30; iter: 0; batch classifier loss: 0.726871; batch adversarial loss: 0.903517\n",
      "epoch 31; iter: 0; batch classifier loss: 0.686149; batch adversarial loss: 0.857432\n",
      "epoch 32; iter: 0; batch classifier loss: 0.721442; batch adversarial loss: 0.882810\n",
      "epoch 33; iter: 0; batch classifier loss: 0.694360; batch adversarial loss: 0.880404\n",
      "epoch 34; iter: 0; batch classifier loss: 0.644385; batch adversarial loss: 0.814664\n",
      "epoch 35; iter: 0; batch classifier loss: 0.686921; batch adversarial loss: 0.843489\n",
      "epoch 36; iter: 0; batch classifier loss: 0.732932; batch adversarial loss: 0.888599\n",
      "epoch 37; iter: 0; batch classifier loss: 0.660184; batch adversarial loss: 0.835341\n",
      "epoch 38; iter: 0; batch classifier loss: 0.692174; batch adversarial loss: 0.845859\n",
      "epoch 39; iter: 0; batch classifier loss: 0.714216; batch adversarial loss: 0.858973\n",
      "epoch 40; iter: 0; batch classifier loss: 0.614451; batch adversarial loss: 0.814161\n",
      "epoch 41; iter: 0; batch classifier loss: 0.815138; batch adversarial loss: 0.877302\n",
      "epoch 42; iter: 0; batch classifier loss: 0.845861; batch adversarial loss: 0.879183\n",
      "epoch 43; iter: 0; batch classifier loss: 0.726927; batch adversarial loss: 0.849234\n",
      "epoch 44; iter: 0; batch classifier loss: 0.768084; batch adversarial loss: 0.882191\n",
      "epoch 45; iter: 0; batch classifier loss: 0.754137; batch adversarial loss: 0.852286\n",
      "epoch 46; iter: 0; batch classifier loss: 0.721227; batch adversarial loss: 0.823171\n",
      "epoch 47; iter: 0; batch classifier loss: 0.787293; batch adversarial loss: 0.864960\n",
      "epoch 48; iter: 0; batch classifier loss: 0.798308; batch adversarial loss: 0.849386\n",
      "epoch 49; iter: 0; batch classifier loss: 0.618854; batch adversarial loss: 0.782346\n",
      "epoch 50; iter: 0; batch classifier loss: 0.779742; batch adversarial loss: 0.857528\n",
      "epoch 51; iter: 0; batch classifier loss: 0.788475; batch adversarial loss: 0.829874\n",
      "epoch 52; iter: 0; batch classifier loss: 0.705227; batch adversarial loss: 0.825211\n",
      "epoch 53; iter: 0; batch classifier loss: 0.682359; batch adversarial loss: 0.808832\n",
      "epoch 54; iter: 0; batch classifier loss: 0.634696; batch adversarial loss: 0.777836\n",
      "epoch 55; iter: 0; batch classifier loss: 0.697939; batch adversarial loss: 0.803524\n",
      "epoch 56; iter: 0; batch classifier loss: 0.856437; batch adversarial loss: 0.836305\n",
      "epoch 57; iter: 0; batch classifier loss: 0.680927; batch adversarial loss: 0.761304\n",
      "epoch 58; iter: 0; batch classifier loss: 0.630655; batch adversarial loss: 0.749179\n",
      "epoch 59; iter: 0; batch classifier loss: 0.756750; batch adversarial loss: 0.810223\n",
      "epoch 0; iter: 0; batch classifier loss: 0.570618; batch adversarial loss: 0.673218\n",
      "epoch 1; iter: 0; batch classifier loss: 0.591395; batch adversarial loss: 0.637745\n",
      "epoch 2; iter: 0; batch classifier loss: 0.527947; batch adversarial loss: 0.674327\n",
      "epoch 3; iter: 0; batch classifier loss: 0.489185; batch adversarial loss: 0.659306\n",
      "epoch 4; iter: 0; batch classifier loss: 0.531289; batch adversarial loss: 0.631581\n",
      "epoch 5; iter: 0; batch classifier loss: 0.582482; batch adversarial loss: 0.579280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.436396; batch adversarial loss: 0.666121\n",
      "epoch 7; iter: 0; batch classifier loss: 0.497316; batch adversarial loss: 0.581857\n",
      "epoch 8; iter: 0; batch classifier loss: 0.437601; batch adversarial loss: 0.549310\n",
      "epoch 9; iter: 0; batch classifier loss: 0.387411; batch adversarial loss: 0.551954\n",
      "epoch 10; iter: 0; batch classifier loss: 0.480102; batch adversarial loss: 0.610202\n",
      "epoch 11; iter: 0; batch classifier loss: 0.406316; batch adversarial loss: 0.569909\n",
      "epoch 12; iter: 0; batch classifier loss: 0.432392; batch adversarial loss: 0.581426\n",
      "epoch 13; iter: 0; batch classifier loss: 0.370584; batch adversarial loss: 0.643826\n",
      "epoch 14; iter: 0; batch classifier loss: 0.483964; batch adversarial loss: 0.620447\n",
      "epoch 15; iter: 0; batch classifier loss: 0.519263; batch adversarial loss: 0.675600\n",
      "epoch 16; iter: 0; batch classifier loss: 0.358895; batch adversarial loss: 0.628786\n",
      "epoch 17; iter: 0; batch classifier loss: 0.388859; batch adversarial loss: 0.676009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.333210; batch adversarial loss: 0.680271\n",
      "epoch 19; iter: 0; batch classifier loss: 0.324981; batch adversarial loss: 0.562888\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459754; batch adversarial loss: 0.599935\n",
      "epoch 21; iter: 0; batch classifier loss: 0.294568; batch adversarial loss: 0.699991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.411345; batch adversarial loss: 0.659770\n",
      "epoch 23; iter: 0; batch classifier loss: 0.514130; batch adversarial loss: 0.620122\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440023; batch adversarial loss: 0.670477\n",
      "epoch 25; iter: 0; batch classifier loss: 0.402864; batch adversarial loss: 0.632985\n",
      "epoch 26; iter: 0; batch classifier loss: 0.496768; batch adversarial loss: 0.571238\n",
      "epoch 27; iter: 0; batch classifier loss: 0.379170; batch adversarial loss: 0.571680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.324113; batch adversarial loss: 0.613045\n",
      "epoch 29; iter: 0; batch classifier loss: 0.278173; batch adversarial loss: 0.628581\n",
      "epoch 30; iter: 0; batch classifier loss: 0.352640; batch adversarial loss: 0.605532\n",
      "epoch 31; iter: 0; batch classifier loss: 0.336040; batch adversarial loss: 0.659449\n",
      "epoch 32; iter: 0; batch classifier loss: 0.315258; batch adversarial loss: 0.612252\n",
      "epoch 33; iter: 0; batch classifier loss: 0.358722; batch adversarial loss: 0.603152\n",
      "epoch 34; iter: 0; batch classifier loss: 0.344970; batch adversarial loss: 0.484294\n",
      "epoch 35; iter: 0; batch classifier loss: 0.295644; batch adversarial loss: 0.644966\n",
      "epoch 36; iter: 0; batch classifier loss: 0.280772; batch adversarial loss: 0.622964\n",
      "epoch 37; iter: 0; batch classifier loss: 0.274985; batch adversarial loss: 0.603225\n",
      "epoch 38; iter: 0; batch classifier loss: 0.611592; batch adversarial loss: 0.622032\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336257; batch adversarial loss: 0.632345\n",
      "epoch 40; iter: 0; batch classifier loss: 0.335775; batch adversarial loss: 0.668670\n",
      "epoch 41; iter: 0; batch classifier loss: 0.226918; batch adversarial loss: 0.645120\n",
      "epoch 42; iter: 0; batch classifier loss: 0.296617; batch adversarial loss: 0.595285\n",
      "epoch 43; iter: 0; batch classifier loss: 0.288600; batch adversarial loss: 0.662387\n",
      "epoch 44; iter: 0; batch classifier loss: 0.247632; batch adversarial loss: 0.544230\n",
      "epoch 45; iter: 0; batch classifier loss: 0.370734; batch adversarial loss: 0.529987\n",
      "epoch 46; iter: 0; batch classifier loss: 0.332179; batch adversarial loss: 0.603612\n",
      "epoch 47; iter: 0; batch classifier loss: 0.326880; batch adversarial loss: 0.669765\n",
      "epoch 48; iter: 0; batch classifier loss: 0.416734; batch adversarial loss: 0.599654\n",
      "epoch 49; iter: 0; batch classifier loss: 0.308603; batch adversarial loss: 0.519922\n",
      "epoch 50; iter: 0; batch classifier loss: 0.270945; batch adversarial loss: 0.545756\n",
      "epoch 51; iter: 0; batch classifier loss: 0.286888; batch adversarial loss: 0.570520\n",
      "epoch 52; iter: 0; batch classifier loss: 0.372091; batch adversarial loss: 0.623568\n",
      "epoch 53; iter: 0; batch classifier loss: 0.304162; batch adversarial loss: 0.504774\n",
      "epoch 54; iter: 0; batch classifier loss: 0.320044; batch adversarial loss: 0.561515\n",
      "epoch 55; iter: 0; batch classifier loss: 0.365718; batch adversarial loss: 0.563107\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371076; batch adversarial loss: 0.571355\n",
      "epoch 57; iter: 0; batch classifier loss: 0.252502; batch adversarial loss: 0.575740\n",
      "epoch 58; iter: 0; batch classifier loss: 0.374628; batch adversarial loss: 0.662508\n",
      "epoch 59; iter: 0; batch classifier loss: 0.326717; batch adversarial loss: 0.473260\n",
      "epoch 60; iter: 0; batch classifier loss: 0.205853; batch adversarial loss: 0.527500\n",
      "epoch 61; iter: 0; batch classifier loss: 0.314216; batch adversarial loss: 0.623614\n",
      "epoch 62; iter: 0; batch classifier loss: 0.307697; batch adversarial loss: 0.624633\n",
      "epoch 63; iter: 0; batch classifier loss: 0.193906; batch adversarial loss: 0.625985\n",
      "epoch 64; iter: 0; batch classifier loss: 0.323121; batch adversarial loss: 0.549674\n",
      "epoch 65; iter: 0; batch classifier loss: 0.267424; batch adversarial loss: 0.609146\n",
      "epoch 66; iter: 0; batch classifier loss: 0.262214; batch adversarial loss: 0.640608\n",
      "epoch 67; iter: 0; batch classifier loss: 0.342635; batch adversarial loss: 0.555001\n",
      "epoch 68; iter: 0; batch classifier loss: 0.284278; batch adversarial loss: 0.584495\n",
      "epoch 69; iter: 0; batch classifier loss: 0.351428; batch adversarial loss: 0.497173\n",
      "epoch 70; iter: 0; batch classifier loss: 0.225553; batch adversarial loss: 0.474586\n",
      "epoch 71; iter: 0; batch classifier loss: 0.270833; batch adversarial loss: 0.530041\n",
      "epoch 72; iter: 0; batch classifier loss: 0.276534; batch adversarial loss: 0.521668\n",
      "epoch 73; iter: 0; batch classifier loss: 0.258485; batch adversarial loss: 0.544202\n",
      "epoch 74; iter: 0; batch classifier loss: 0.278850; batch adversarial loss: 0.515714\n",
      "epoch 75; iter: 0; batch classifier loss: 0.368075; batch adversarial loss: 0.521677\n",
      "epoch 76; iter: 0; batch classifier loss: 0.280386; batch adversarial loss: 0.605541\n",
      "epoch 77; iter: 0; batch classifier loss: 0.387926; batch adversarial loss: 0.577433\n",
      "epoch 78; iter: 0; batch classifier loss: 0.216841; batch adversarial loss: 0.599797\n",
      "epoch 79; iter: 0; batch classifier loss: 0.254135; batch adversarial loss: 0.502678\n",
      "epoch 0; iter: 0; batch classifier loss: 0.725925; batch adversarial loss: 0.842334\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647345; batch adversarial loss: 0.875300\n",
      "epoch 2; iter: 0; batch classifier loss: 0.603723; batch adversarial loss: 0.865562\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538372; batch adversarial loss: 0.839946\n",
      "epoch 4; iter: 0; batch classifier loss: 0.558037; batch adversarial loss: 0.837227\n",
      "epoch 5; iter: 0; batch classifier loss: 0.496592; batch adversarial loss: 0.871244\n",
      "epoch 6; iter: 0; batch classifier loss: 0.440347; batch adversarial loss: 0.920173\n",
      "epoch 7; iter: 0; batch classifier loss: 0.324647; batch adversarial loss: 0.952140\n",
      "epoch 8; iter: 0; batch classifier loss: 0.455194; batch adversarial loss: 0.908295\n",
      "epoch 9; iter: 0; batch classifier loss: 0.445037; batch adversarial loss: 0.872977\n",
      "epoch 10; iter: 0; batch classifier loss: 0.481389; batch adversarial loss: 0.884855\n",
      "epoch 11; iter: 0; batch classifier loss: 0.470431; batch adversarial loss: 0.898901\n",
      "epoch 12; iter: 0; batch classifier loss: 0.368141; batch adversarial loss: 0.903129\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546697; batch adversarial loss: 0.867566\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339682; batch adversarial loss: 0.870342\n",
      "epoch 15; iter: 0; batch classifier loss: 0.336325; batch adversarial loss: 0.804431\n",
      "epoch 16; iter: 0; batch classifier loss: 0.411749; batch adversarial loss: 0.817674\n",
      "epoch 17; iter: 0; batch classifier loss: 0.290423; batch adversarial loss: 0.866529\n",
      "epoch 18; iter: 0; batch classifier loss: 0.319057; batch adversarial loss: 0.779053\n",
      "epoch 19; iter: 0; batch classifier loss: 0.294200; batch adversarial loss: 0.795382\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337866; batch adversarial loss: 0.833923\n",
      "epoch 21; iter: 0; batch classifier loss: 0.381079; batch adversarial loss: 0.775385\n",
      "epoch 22; iter: 0; batch classifier loss: 0.314454; batch adversarial loss: 0.772520\n",
      "epoch 23; iter: 0; batch classifier loss: 0.295513; batch adversarial loss: 0.767101\n",
      "epoch 24; iter: 0; batch classifier loss: 0.384118; batch adversarial loss: 0.783827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.311098; batch adversarial loss: 0.767127\n",
      "epoch 26; iter: 0; batch classifier loss: 0.307152; batch adversarial loss: 0.733755\n",
      "epoch 27; iter: 0; batch classifier loss: 0.291617; batch adversarial loss: 0.774065\n",
      "epoch 28; iter: 0; batch classifier loss: 0.316122; batch adversarial loss: 0.736323\n",
      "epoch 29; iter: 0; batch classifier loss: 0.297074; batch adversarial loss: 0.740940\n",
      "epoch 30; iter: 0; batch classifier loss: 0.273010; batch adversarial loss: 0.720443\n",
      "epoch 31; iter: 0; batch classifier loss: 0.239137; batch adversarial loss: 0.734711\n",
      "epoch 32; iter: 0; batch classifier loss: 0.311118; batch adversarial loss: 0.715065\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233754; batch adversarial loss: 0.745094\n",
      "epoch 34; iter: 0; batch classifier loss: 0.292319; batch adversarial loss: 0.730920\n",
      "epoch 35; iter: 0; batch classifier loss: 0.238312; batch adversarial loss: 0.732508\n",
      "epoch 36; iter: 0; batch classifier loss: 0.291104; batch adversarial loss: 0.731249\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363538; batch adversarial loss: 0.729009\n",
      "epoch 38; iter: 0; batch classifier loss: 0.279681; batch adversarial loss: 0.719338\n",
      "epoch 39; iter: 0; batch classifier loss: 0.263362; batch adversarial loss: 0.743335\n",
      "epoch 40; iter: 0; batch classifier loss: 0.259636; batch adversarial loss: 0.736542\n",
      "epoch 41; iter: 0; batch classifier loss: 0.339948; batch adversarial loss: 0.688830\n",
      "epoch 42; iter: 0; batch classifier loss: 0.202974; batch adversarial loss: 0.701461\n",
      "epoch 43; iter: 0; batch classifier loss: 0.247862; batch adversarial loss: 0.661899\n",
      "epoch 44; iter: 0; batch classifier loss: 0.264380; batch adversarial loss: 0.677229\n",
      "epoch 45; iter: 0; batch classifier loss: 0.366469; batch adversarial loss: 0.684052\n",
      "epoch 46; iter: 0; batch classifier loss: 0.307042; batch adversarial loss: 0.707794\n",
      "epoch 47; iter: 0; batch classifier loss: 0.334226; batch adversarial loss: 0.664338\n",
      "epoch 48; iter: 0; batch classifier loss: 0.365064; batch adversarial loss: 0.693857\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228961; batch adversarial loss: 0.684114\n",
      "epoch 50; iter: 0; batch classifier loss: 0.460353; batch adversarial loss: 0.668248\n",
      "epoch 51; iter: 0; batch classifier loss: 0.352371; batch adversarial loss: 0.652017\n",
      "epoch 52; iter: 0; batch classifier loss: 0.356313; batch adversarial loss: 0.651040\n",
      "epoch 53; iter: 0; batch classifier loss: 0.200961; batch adversarial loss: 0.662472\n",
      "epoch 54; iter: 0; batch classifier loss: 0.313869; batch adversarial loss: 0.656929\n",
      "epoch 55; iter: 0; batch classifier loss: 0.208297; batch adversarial loss: 0.630771\n",
      "epoch 56; iter: 0; batch classifier loss: 0.236358; batch adversarial loss: 0.652448\n",
      "epoch 57; iter: 0; batch classifier loss: 0.306818; batch adversarial loss: 0.665374\n",
      "epoch 58; iter: 0; batch classifier loss: 0.145950; batch adversarial loss: 0.648224\n",
      "epoch 59; iter: 0; batch classifier loss: 0.248367; batch adversarial loss: 0.628864\n",
      "epoch 60; iter: 0; batch classifier loss: 0.275361; batch adversarial loss: 0.669003\n",
      "epoch 61; iter: 0; batch classifier loss: 0.380016; batch adversarial loss: 0.626373\n",
      "epoch 62; iter: 0; batch classifier loss: 0.308991; batch adversarial loss: 0.646114\n",
      "epoch 63; iter: 0; batch classifier loss: 0.270461; batch adversarial loss: 0.650146\n",
      "epoch 64; iter: 0; batch classifier loss: 0.209480; batch adversarial loss: 0.610819\n",
      "epoch 65; iter: 0; batch classifier loss: 0.246484; batch adversarial loss: 0.627283\n",
      "epoch 66; iter: 0; batch classifier loss: 0.233601; batch adversarial loss: 0.661935\n",
      "epoch 67; iter: 0; batch classifier loss: 0.200261; batch adversarial loss: 0.625886\n",
      "epoch 68; iter: 0; batch classifier loss: 0.265330; batch adversarial loss: 0.606937\n",
      "epoch 69; iter: 0; batch classifier loss: 0.291771; batch adversarial loss: 0.636616\n",
      "epoch 70; iter: 0; batch classifier loss: 0.289719; batch adversarial loss: 0.657528\n",
      "epoch 71; iter: 0; batch classifier loss: 0.211877; batch adversarial loss: 0.611033\n",
      "epoch 72; iter: 0; batch classifier loss: 0.211726; batch adversarial loss: 0.606270\n",
      "epoch 73; iter: 0; batch classifier loss: 0.252921; batch adversarial loss: 0.587810\n",
      "epoch 74; iter: 0; batch classifier loss: 0.319474; batch adversarial loss: 0.648666\n",
      "epoch 75; iter: 0; batch classifier loss: 0.259896; batch adversarial loss: 0.609024\n",
      "epoch 76; iter: 0; batch classifier loss: 0.277561; batch adversarial loss: 0.647590\n",
      "epoch 77; iter: 0; batch classifier loss: 0.237944; batch adversarial loss: 0.613714\n",
      "epoch 78; iter: 0; batch classifier loss: 0.211393; batch adversarial loss: 0.597613\n",
      "epoch 79; iter: 0; batch classifier loss: 0.304366; batch adversarial loss: 0.595906\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708333; batch adversarial loss: 0.684837\n",
      "epoch 1; iter: 0; batch classifier loss: 0.666365; batch adversarial loss: 0.681023\n",
      "epoch 2; iter: 0; batch classifier loss: 0.654702; batch adversarial loss: 0.689849\n",
      "epoch 3; iter: 0; batch classifier loss: 0.614081; batch adversarial loss: 0.702962\n",
      "epoch 4; iter: 0; batch classifier loss: 0.615578; batch adversarial loss: 0.689898\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594049; batch adversarial loss: 0.666206\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573393; batch adversarial loss: 0.678875\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578152; batch adversarial loss: 0.690078\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569038; batch adversarial loss: 0.670820\n",
      "epoch 9; iter: 0; batch classifier loss: 0.634197; batch adversarial loss: 0.675909\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535084; batch adversarial loss: 0.671516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548881; batch adversarial loss: 0.640285\n",
      "epoch 12; iter: 0; batch classifier loss: 0.570179; batch adversarial loss: 0.656523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.562741; batch adversarial loss: 0.669441\n",
      "epoch 14; iter: 0; batch classifier loss: 0.513674; batch adversarial loss: 0.652556\n",
      "epoch 15; iter: 0; batch classifier loss: 0.499983; batch adversarial loss: 0.659597\n",
      "epoch 16; iter: 0; batch classifier loss: 0.541857; batch adversarial loss: 0.661314\n",
      "epoch 17; iter: 0; batch classifier loss: 0.527925; batch adversarial loss: 0.671780\n",
      "epoch 18; iter: 0; batch classifier loss: 0.492885; batch adversarial loss: 0.650126\n",
      "epoch 19; iter: 0; batch classifier loss: 0.440392; batch adversarial loss: 0.655200\n",
      "epoch 20; iter: 0; batch classifier loss: 0.429373; batch adversarial loss: 0.652347\n",
      "epoch 21; iter: 0; batch classifier loss: 0.522176; batch adversarial loss: 0.659898\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446893; batch adversarial loss: 0.658417\n",
      "epoch 23; iter: 0; batch classifier loss: 0.423051; batch adversarial loss: 0.670590\n",
      "epoch 24; iter: 0; batch classifier loss: 0.440101; batch adversarial loss: 0.642536\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381504; batch adversarial loss: 0.640953\n",
      "epoch 26; iter: 0; batch classifier loss: 0.444942; batch adversarial loss: 0.641068\n",
      "epoch 27; iter: 0; batch classifier loss: 0.497329; batch adversarial loss: 0.670890\n",
      "epoch 28; iter: 0; batch classifier loss: 0.413158; batch adversarial loss: 0.661275\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388712; batch adversarial loss: 0.655296\n",
      "epoch 30; iter: 0; batch classifier loss: 0.464653; batch adversarial loss: 0.644260\n",
      "epoch 31; iter: 0; batch classifier loss: 0.410924; batch adversarial loss: 0.641145\n",
      "epoch 32; iter: 0; batch classifier loss: 0.533388; batch adversarial loss: 0.653929\n",
      "epoch 33; iter: 0; batch classifier loss: 0.365135; batch adversarial loss: 0.662669\n",
      "epoch 34; iter: 0; batch classifier loss: 0.385095; batch adversarial loss: 0.675769\n",
      "epoch 35; iter: 0; batch classifier loss: 0.362845; batch adversarial loss: 0.663880\n",
      "epoch 36; iter: 0; batch classifier loss: 0.379166; batch adversarial loss: 0.652049\n",
      "epoch 37; iter: 0; batch classifier loss: 0.422504; batch adversarial loss: 0.650755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407887; batch adversarial loss: 0.649251\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380232; batch adversarial loss: 0.658221\n",
      "epoch 40; iter: 0; batch classifier loss: 0.401209; batch adversarial loss: 0.623805\n",
      "epoch 41; iter: 0; batch classifier loss: 0.424712; batch adversarial loss: 0.620925\n",
      "epoch 42; iter: 0; batch classifier loss: 0.407111; batch adversarial loss: 0.654615\n",
      "epoch 43; iter: 0; batch classifier loss: 0.461637; batch adversarial loss: 0.656158\n",
      "epoch 44; iter: 0; batch classifier loss: 0.477269; batch adversarial loss: 0.646548\n",
      "epoch 45; iter: 0; batch classifier loss: 0.447577; batch adversarial loss: 0.635972\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392947; batch adversarial loss: 0.648699\n",
      "epoch 47; iter: 0; batch classifier loss: 0.443273; batch adversarial loss: 0.624637\n",
      "epoch 48; iter: 0; batch classifier loss: 0.461973; batch adversarial loss: 0.617979\n",
      "epoch 49; iter: 0; batch classifier loss: 0.374613; batch adversarial loss: 0.616336\n",
      "epoch 50; iter: 0; batch classifier loss: 0.363982; batch adversarial loss: 0.631818\n",
      "epoch 51; iter: 0; batch classifier loss: 0.326278; batch adversarial loss: 0.654844\n",
      "epoch 52; iter: 0; batch classifier loss: 0.386930; batch adversarial loss: 0.610405\n",
      "epoch 53; iter: 0; batch classifier loss: 0.406335; batch adversarial loss: 0.625657\n",
      "epoch 54; iter: 0; batch classifier loss: 0.375416; batch adversarial loss: 0.644447\n",
      "epoch 55; iter: 0; batch classifier loss: 0.352609; batch adversarial loss: 0.644915\n",
      "epoch 56; iter: 0; batch classifier loss: 0.329130; batch adversarial loss: 0.618799\n",
      "epoch 57; iter: 0; batch classifier loss: 0.375222; batch adversarial loss: 0.649518\n",
      "epoch 58; iter: 0; batch classifier loss: 0.412604; batch adversarial loss: 0.635134\n",
      "epoch 59; iter: 0; batch classifier loss: 0.357158; batch adversarial loss: 0.641682\n",
      "epoch 60; iter: 0; batch classifier loss: 0.306276; batch adversarial loss: 0.626735\n",
      "epoch 61; iter: 0; batch classifier loss: 0.373973; batch adversarial loss: 0.635720\n",
      "epoch 62; iter: 0; batch classifier loss: 0.469622; batch adversarial loss: 0.591068\n",
      "epoch 63; iter: 0; batch classifier loss: 0.362410; batch adversarial loss: 0.644127\n",
      "epoch 64; iter: 0; batch classifier loss: 0.365084; batch adversarial loss: 0.643433\n",
      "epoch 65; iter: 0; batch classifier loss: 0.419903; batch adversarial loss: 0.612751\n",
      "epoch 66; iter: 0; batch classifier loss: 0.432739; batch adversarial loss: 0.596936\n",
      "epoch 67; iter: 0; batch classifier loss: 0.369982; batch adversarial loss: 0.638580\n",
      "epoch 68; iter: 0; batch classifier loss: 0.260465; batch adversarial loss: 0.676000\n",
      "epoch 69; iter: 0; batch classifier loss: 0.332050; batch adversarial loss: 0.640996\n",
      "epoch 70; iter: 0; batch classifier loss: 0.352084; batch adversarial loss: 0.596540\n",
      "epoch 71; iter: 0; batch classifier loss: 0.403509; batch adversarial loss: 0.632557\n",
      "epoch 72; iter: 0; batch classifier loss: 0.377448; batch adversarial loss: 0.620546\n",
      "epoch 73; iter: 0; batch classifier loss: 0.432718; batch adversarial loss: 0.611744\n",
      "epoch 74; iter: 0; batch classifier loss: 0.349833; batch adversarial loss: 0.642192\n",
      "epoch 75; iter: 0; batch classifier loss: 0.354390; batch adversarial loss: 0.620240\n",
      "epoch 76; iter: 0; batch classifier loss: 0.328209; batch adversarial loss: 0.600980\n",
      "epoch 77; iter: 0; batch classifier loss: 0.341921; batch adversarial loss: 0.616551\n",
      "epoch 78; iter: 0; batch classifier loss: 0.371008; batch adversarial loss: 0.653099\n",
      "epoch 79; iter: 0; batch classifier loss: 0.346231; batch adversarial loss: 0.651722\n",
      "epoch 0; iter: 0; batch classifier loss: 0.770101; batch adversarial loss: 0.744977\n",
      "epoch 1; iter: 0; batch classifier loss: 0.710440; batch adversarial loss: 0.734338\n",
      "epoch 2; iter: 0; batch classifier loss: 0.669154; batch adversarial loss: 0.748670\n",
      "epoch 3; iter: 0; batch classifier loss: 0.677719; batch adversarial loss: 0.738005\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616402; batch adversarial loss: 0.723090\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590786; batch adversarial loss: 0.747523\n",
      "epoch 6; iter: 0; batch classifier loss: 0.592652; batch adversarial loss: 0.738010\n",
      "epoch 7; iter: 0; batch classifier loss: 0.570490; batch adversarial loss: 0.754114\n",
      "epoch 8; iter: 0; batch classifier loss: 0.557478; batch adversarial loss: 0.738183\n",
      "epoch 9; iter: 0; batch classifier loss: 0.556103; batch adversarial loss: 0.739467\n",
      "epoch 10; iter: 0; batch classifier loss: 0.528021; batch adversarial loss: 0.756276\n",
      "epoch 11; iter: 0; batch classifier loss: 0.599911; batch adversarial loss: 0.705687\n",
      "epoch 12; iter: 0; batch classifier loss: 0.500376; batch adversarial loss: 0.738453\n",
      "epoch 13; iter: 0; batch classifier loss: 0.463961; batch adversarial loss: 0.755686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501652; batch adversarial loss: 0.748396\n",
      "epoch 15; iter: 0; batch classifier loss: 0.438050; batch adversarial loss: 0.748336\n",
      "epoch 16; iter: 0; batch classifier loss: 0.495430; batch adversarial loss: 0.693678\n",
      "epoch 17; iter: 0; batch classifier loss: 0.532330; batch adversarial loss: 0.746213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.417316; batch adversarial loss: 0.735284\n",
      "epoch 19; iter: 0; batch classifier loss: 0.453722; batch adversarial loss: 0.765135\n",
      "epoch 20; iter: 0; batch classifier loss: 0.463358; batch adversarial loss: 0.726298\n",
      "epoch 21; iter: 0; batch classifier loss: 0.377682; batch adversarial loss: 0.728772\n",
      "epoch 22; iter: 0; batch classifier loss: 0.408284; batch adversarial loss: 0.725550\n",
      "epoch 23; iter: 0; batch classifier loss: 0.386849; batch adversarial loss: 0.728201\n",
      "epoch 24; iter: 0; batch classifier loss: 0.429618; batch adversarial loss: 0.728789\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429994; batch adversarial loss: 0.731100\n",
      "epoch 26; iter: 0; batch classifier loss: 0.343097; batch adversarial loss: 0.740847\n",
      "epoch 27; iter: 0; batch classifier loss: 0.365362; batch adversarial loss: 0.726085\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336876; batch adversarial loss: 0.731677\n",
      "epoch 29; iter: 0; batch classifier loss: 0.352979; batch adversarial loss: 0.747150\n",
      "epoch 30; iter: 0; batch classifier loss: 0.398290; batch adversarial loss: 0.707147\n",
      "epoch 31; iter: 0; batch classifier loss: 0.353240; batch adversarial loss: 0.745825\n",
      "epoch 32; iter: 0; batch classifier loss: 0.374686; batch adversarial loss: 0.719840\n",
      "epoch 33; iter: 0; batch classifier loss: 0.374373; batch adversarial loss: 0.694637\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356078; batch adversarial loss: 0.718612\n",
      "epoch 35; iter: 0; batch classifier loss: 0.330267; batch adversarial loss: 0.709554\n",
      "epoch 36; iter: 0; batch classifier loss: 0.322632; batch adversarial loss: 0.744617\n",
      "epoch 37; iter: 0; batch classifier loss: 0.416093; batch adversarial loss: 0.710184\n",
      "epoch 38; iter: 0; batch classifier loss: 0.353352; batch adversarial loss: 0.719424\n",
      "epoch 39; iter: 0; batch classifier loss: 0.359036; batch adversarial loss: 0.736108\n",
      "epoch 40; iter: 0; batch classifier loss: 0.403527; batch adversarial loss: 0.727765\n",
      "epoch 41; iter: 0; batch classifier loss: 0.327089; batch adversarial loss: 0.698528\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387287; batch adversarial loss: 0.696171\n",
      "epoch 43; iter: 0; batch classifier loss: 0.279679; batch adversarial loss: 0.719776\n",
      "epoch 44; iter: 0; batch classifier loss: 0.314404; batch adversarial loss: 0.695991\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289898; batch adversarial loss: 0.701140\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288919; batch adversarial loss: 0.739478\n",
      "epoch 47; iter: 0; batch classifier loss: 0.333709; batch adversarial loss: 0.713044\n",
      "epoch 48; iter: 0; batch classifier loss: 0.280956; batch adversarial loss: 0.701355\n",
      "epoch 49; iter: 0; batch classifier loss: 0.327023; batch adversarial loss: 0.713403\n",
      "epoch 50; iter: 0; batch classifier loss: 0.338796; batch adversarial loss: 0.703819\n",
      "epoch 51; iter: 0; batch classifier loss: 0.345003; batch adversarial loss: 0.700983\n",
      "epoch 52; iter: 0; batch classifier loss: 0.293603; batch adversarial loss: 0.672089\n",
      "epoch 53; iter: 0; batch classifier loss: 0.285645; batch adversarial loss: 0.686960\n",
      "epoch 54; iter: 0; batch classifier loss: 0.359309; batch adversarial loss: 0.664597\n",
      "epoch 55; iter: 0; batch classifier loss: 0.299905; batch adversarial loss: 0.690552\n",
      "epoch 56; iter: 0; batch classifier loss: 0.255971; batch adversarial loss: 0.691186\n",
      "epoch 57; iter: 0; batch classifier loss: 0.311519; batch adversarial loss: 0.686820\n",
      "epoch 58; iter: 0; batch classifier loss: 0.301438; batch adversarial loss: 0.672314\n",
      "epoch 59; iter: 0; batch classifier loss: 0.328276; batch adversarial loss: 0.678346\n",
      "epoch 60; iter: 0; batch classifier loss: 0.274286; batch adversarial loss: 0.701902\n",
      "epoch 61; iter: 0; batch classifier loss: 0.257510; batch adversarial loss: 0.682637\n",
      "epoch 62; iter: 0; batch classifier loss: 0.296524; batch adversarial loss: 0.661259\n",
      "epoch 63; iter: 0; batch classifier loss: 0.352662; batch adversarial loss: 0.671387\n",
      "epoch 64; iter: 0; batch classifier loss: 0.373542; batch adversarial loss: 0.650017\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373964; batch adversarial loss: 0.657163\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366033; batch adversarial loss: 0.672170\n",
      "epoch 67; iter: 0; batch classifier loss: 0.293302; batch adversarial loss: 0.663659\n",
      "epoch 68; iter: 0; batch classifier loss: 0.269983; batch adversarial loss: 0.680571\n",
      "epoch 69; iter: 0; batch classifier loss: 0.328030; batch adversarial loss: 0.628144\n",
      "epoch 70; iter: 0; batch classifier loss: 0.302956; batch adversarial loss: 0.651287\n",
      "epoch 71; iter: 0; batch classifier loss: 0.318868; batch adversarial loss: 0.647380\n",
      "epoch 72; iter: 0; batch classifier loss: 0.261905; batch adversarial loss: 0.660968\n",
      "epoch 73; iter: 0; batch classifier loss: 0.236355; batch adversarial loss: 0.665983\n",
      "epoch 74; iter: 0; batch classifier loss: 0.326666; batch adversarial loss: 0.637810\n",
      "epoch 75; iter: 0; batch classifier loss: 0.304753; batch adversarial loss: 0.666255\n",
      "epoch 76; iter: 0; batch classifier loss: 0.233569; batch adversarial loss: 0.649328\n",
      "epoch 77; iter: 0; batch classifier loss: 0.283218; batch adversarial loss: 0.674320\n",
      "epoch 78; iter: 0; batch classifier loss: 0.259536; batch adversarial loss: 0.661892\n",
      "epoch 79; iter: 0; batch classifier loss: 0.249420; batch adversarial loss: 0.635148\n",
      "\n",
      "=== ADV in-proc (best) w=0.2, e=60, b=64, h=64 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.12000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.09375  0.833333       0.210526  0.894737\n",
       "1    0.854167  0.12000  0.854167       0.602740  0.863014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8696 | DP diff: 0.3922 | EO diff: 0.0208 | combined gap (DP+EO)=0.4130; acc=0.8696\n"
     ]
    }
   ],
   "source": [
    "# Grid-tune AIF360 AdversarialDebiasing for better DP/EO balance and print with report_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "# small search over key knobs; widen if needed\n",
    "ADV_GRID = dict(\n",
    "    adversary_loss_weight=[0.02, 0.05, 0.1, 0.2, 0.3],\n",
    "    num_epochs=[40, 60, 80],\n",
    "    batch_size=[64, 128],\n",
    "    classifier_num_hidden_units=[32, 64]  # size of main net\n",
    ")\n",
    "\n",
    "def run_adv(loss_w=0.1, epochs=50, bs=128, hidden=64, seed=42):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            debias=True,\n",
    "            scope_name=f\"adv_w{loss_w}_e{epochs}_b{bs}_h{hidden}\",\n",
    "            adversary_loss_weight=loss_w,\n",
    "            num_epochs=epochs,\n",
    "            batch_size=bs,\n",
    "            classifier_num_hidden_units=hidden,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "        yhat = pred_te.labels.ravel().astype(int)\n",
    "        scores = getattr(pred_te, \"scores\", None)\n",
    "        if scores is None:\n",
    "            scores = yhat.astype(float)\n",
    "    sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    return yhat, scores\n",
    "\n",
    "# Build once (as you did)\n",
    "bld_tr = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "bld_te = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_test, name=label_name),\n",
    "                  pd.Series(A_test, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "\n",
    "# Search & pick the best by minimizing (DP + EO) with an accuracy floor\n",
    "best = None\n",
    "acc_floor = 0.86  # keep close to your current accuracy; adjust as you like\n",
    "results = []\n",
    "for w in ADV_GRID[\"adversary_loss_weight\"]:\n",
    "    for e in ADV_GRID[\"num_epochs\"]:\n",
    "        for bs in ADV_GRID[\"batch_size\"]:\n",
    "            for h in ADV_GRID[\"classifier_num_hidden_units\"]:\n",
    "                yhat, scores = run_adv(w, e, bs, h)\n",
    "                acc = accuracy_score(y_test, yhat)\n",
    "                dp, eo = fair_metrics(y_test, yhat, A_test, scores, absolute=True)\n",
    "                obj = dp + eo\n",
    "                results.append((obj, acc, dp, eo, w, e, bs, h, yhat, scores))\n",
    "                if (best is None or obj < best[0]) and acc >= acc_floor:\n",
    "                    best = (obj, acc, dp, eo, w, e, bs, h, yhat, scores)\n",
    "\n",
    "# Report best and (optionally) a few runners-up\n",
    "if best is None:\n",
    "    # fallback: take global best even if below floor\n",
    "    best = sorted(results, key=lambda t: t[0])[0]\n",
    "\n",
    "obj, acc, dp, eo, w, e, bs, h, yhat_best, scores_best = best\n",
    "_ = report_model(\n",
    "    f\"ADV in-proc (best) w={w}, e={e}, b={bs}, h={h}\",\n",
    "    y_test, yhat_best, A_test, scores=scores_best,\n",
    "    note=f\"combined gap (DP+EO)={obj:.4f}; acc={acc:.4f}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c29d06c",
   "metadata": {},
   "source": [
    "## Tuned Adversarial Debiasing  \n",
    "\n",
    "### Results overview\n",
    "| Variant                    | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|----------------------------|---------:|--------:|-------------------:|------:|\n",
    "| ADV in-proc (tuned)        | 0.8696   | 0.3922  | 0.0208             | 0.4130 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group reading (Female → 0, Male → 1)\n",
    "- **Selection rate:** Female **0.211** vs Male **0.603** → **large DP gap** (males flagged ≈ **2.9×** as often).  \n",
    "- **TPR (Recall):** Female **0.833** vs Male **0.854** → **near-parity recall** (EO ≈ **0.021**).  \n",
    "- **FPR:** Female **0.094** vs Male **0.120** → slightly more **male** false positives.  \n",
    "- **Per-group accuracy:** Female **0.895**, Male **0.863** → modest difference.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- The tuned adversarial model **successfully equalizes recall** across genders with **minimal EO gap** while keeping accuracy at **0.87**.  \n",
    "- **Selection disparity remains relatively high** (DP ≈ **0.39**) driven by higher male FPR/selection.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
