{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## Bias Mitigation using Fairlearn - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   61    1              3      146.0        241.0          0           0   \n",
       "1   52    1              1      120.0        284.0          0           0   \n",
       "2   48    0              3      150.0        227.0          0           0   \n",
       "3   49    1              3      128.0        212.0          0           0   \n",
       "4   56    1              3      120.0        236.0          0           1   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  148.0               1      3.0         0             1  \n",
       "1  118.0               0      0.0         2             0  \n",
       "2  130.0               1      1.0         1             0  \n",
       "3   96.0               1      0.0         1             1  \n",
       "4  148.0               0      0.0         1             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5330b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure y_test is a Series (not a DataFrame with 1 column)\n",
    "y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Define target and sensitive column names\n",
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"\n",
    "\n",
    "# Split train into X/y\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]\n",
    "\n",
    "# Extract sensitive features separately\n",
    "A_train = X_train[SENSITIVE].astype(int)\n",
    "A_test  = X_test[SENSITIVE].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fe70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e79e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (tuned PCA+KNN, no mitigation) ===\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8858695652173914\n",
      "Precision: 0.9090909090909091\n",
      "Recall   : 0.8823529411764706\n",
      "F1 Score : 0.8955223880597015\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        82\n",
      "           1       0.91      0.88      0.90       102\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.88      0.89      0.88       184\n",
      "weighted avg       0.89      0.89      0.89       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [12 90]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "\n",
    "print(\"=== Baseline (tuned PCA+KNN, no mitigation) ===\")\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f8d862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (tuned PCA+KNN) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    0.833333  0.125       0.236842  0.868421\n",
      "1    0.885417  0.100       0.616438  0.890411\n",
      "Accuracy: 0.8859 | DP diff: 0.3796 | EO diff: 0.0521\n",
      "\n",
      "=== Post-processing (Demographic Parity) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    0.833333  0.125       0.236842  0.868421\n",
      "1    0.885417  0.100       0.616438  0.890411\n",
      "Accuracy: 0.8859 | DP diff: 0.3796 | EO diff: 0.0521\n"
     ]
    }
   ],
   "source": [
    "# Demographic Parity post-processing for your tuned PCA+KNN\n",
    "\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, true_positive_rate, false_positive_rate, selection_rate,\n",
    "    demographic_parity_difference, equalized_odds_difference\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Helper (reuse if already defined)\n",
    "def eval_fairness(y_true, y_pred, A):\n",
    "    mf = MetricFrame(\n",
    "        metrics={\n",
    "            \"TPR\": true_positive_rate,\n",
    "            \"FPR\": false_positive_rate,\n",
    "            \"SelectionRate\": selection_rate,\n",
    "            \"Accuracy\": accuracy_score,\n",
    "        },\n",
    "        y_true=y_true, y_pred=y_pred, sensitive_features=A\n",
    "    )\n",
    "    return {\n",
    "        \"by_group\": mf.by_group,\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"dp\": demographic_parity_difference(y_true, y_pred, sensitive_features=A),\n",
    "        \"eo\": equalized_odds_difference(y_true, y_pred, sensitive_features=A),\n",
    "    }\n",
    "\n",
    "# 1) Baseline metrics (no mitigation) for side-by-side\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "y_base = pca_knn.predict(X_test_ready)\n",
    "m_base = eval_fairness(y_test, y_base, A_test)\n",
    "\n",
    "print(\"=== Baseline (tuned PCA+KNN) ===\")\n",
    "print(m_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_base['acc']:.4f} | DP diff: {m_base['dp']:.4f} | EO diff: {m_base['eo']:.4f}\")\n",
    "\n",
    "# 2) Post-processing with DEMOGRAPHIC PARITY\n",
    "post_dp = ThresholdOptimizer(\n",
    "    estimator=pca_knn,\n",
    "    constraints=\"demographic_parity\",\n",
    "    predict_method=\"predict_proba\",   # KNN supports this\n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_dp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "\n",
    "y_dp = post_dp.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_dp = eval_fairness(y_test, y_dp, A_test)\n",
    "\n",
    "print(\"\\n=== Post-processing (Demographic Parity) ===\")\n",
    "print(m_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_dp['acc']:.4f} | DP diff: {m_dp['dp']:.4f} | EO diff: {m_dp['eo']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d58f4e4",
   "metadata": {},
   "source": [
    "### Post-Processing with Demographic Parity (PCA+KNN)\n",
    "\n",
    "#### Comparison of Results\n",
    "\n",
    "| Model                          | Accuracy | DP diff | EO diff | Notes                                      |\n",
    "|--------------------------------|----------|---------|---------|--------------------------------------------|\n",
    "| Baseline (tuned PCA+KNN)       | 0.8859   | 0.3796  | 0.0521  | High DP disparity, low EO gap              |\n",
    "| Post-processing (DP constraint)| 0.8859   | 0.3796  | 0.0521  | Identical to baseline, no fairness change  |\n",
    "\n",
    "#### Interpretation\n",
    "- Both baseline and DP post-processing yield **the same metrics**: accuracy ≈ 88.6%, **DP diff high (0.38)**, **EO diff low (0.05)**.  \n",
    "- Post-processing failed because group score distributions are too different, so ThresholdOptimizer defaulted to the baseline.  \n",
    "- **In-processing mitigation is not possible with KNN**, since `KNeighborsClassifier` does not support the `sample_weight` argument required by Fairlearn reductions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best CV F1: 0.8593494246061409\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.8097826086956522\n",
      "Precision: 0.819047619047619\n",
      "Recall   : 0.8431372549019608\n",
      "F1 Score : 0.8309178743961353\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78        82\n",
      "           1       0.82      0.84      0.83       102\n",
      "\n",
      "    accuracy                           0.81       184\n",
      "   macro avg       0.81      0.81      0.81       184\n",
      "weighted avg       0.81      0.81      0.81       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[63 19]\n",
      " [16 86]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cd1d09",
   "metadata": {},
   "source": [
    "### Bias Mitigation DT: Inprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a1901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (Tuned DT) ===\n",
      "          TPR      FPR  SelectionRate  Accuracy\n",
      "Sex                                            \n",
      "0    0.833333  0.28125       0.368421  0.736842\n",
      "1    0.843750  0.20000       0.623288  0.828767\n",
      "Accuracy: 0.8098 | DP diff: 0.2549 | EO diff: 0.0812\n",
      "\n",
      "=== In-processing: EG (Equalized Odds) ===\n",
      "          TPR      FPR  SelectionRate  Accuracy\n",
      "Sex                                            \n",
      "0    0.833333  0.15625       0.263158  0.842105\n",
      "1    0.864583  0.22000       0.643836  0.835616\n",
      "Accuracy: 0.8370 | DP diff: 0.3807 | EO diff: 0.0638\n",
      "\n",
      "=== In-processing: EG (Demographic Parity) ===\n",
      "          TPR   FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    0.833333  0.25       0.342105  0.763158\n",
      "1    0.843750  0.22       0.630137  0.821918\n",
      "Accuracy: 0.8098 | DP diff: 0.2880 | EO diff: 0.0300\n",
      "\n",
      "=== Decision Tree: Baseline vs In-processing (EG) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dp_diff</th>\n",
       "      <th>eo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT Baseline (tuned)</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT + EG (EO)</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.3807</td>\n",
       "      <td>0.0638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT + EG (DP)</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy  dp_diff  eo_diff\n",
       "0  DT Baseline (tuned)    0.8098   0.2549   0.0812\n",
       "1         DT + EG (EO)    0.8370   0.3807   0.0638\n",
       "2         DT + EG (DP)    0.8098   0.2880   0.0300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In-processing mitigation for your tuned Decision Tree\n",
    "from sklearn.base import clone\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds, DemographicParity\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, true_positive_rate, false_positive_rate, selection_rate,\n",
    "    demographic_parity_difference, equalized_odds_difference\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Helper: fairness evaluation\n",
    "def eval_fairness(y_true, y_pred, A):\n",
    "    mf = MetricFrame(\n",
    "        metrics={\n",
    "            \"TPR\": true_positive_rate,\n",
    "            \"FPR\": false_positive_rate,\n",
    "            \"SelectionRate\": selection_rate,\n",
    "            \"Accuracy\": accuracy_score,\n",
    "        },\n",
    "        y_true=y_true, y_pred=y_pred, sensitive_features=A\n",
    "    )\n",
    "    return {\n",
    "        \"acc\": accuracy_score(y_true, y_pred),\n",
    "        \"dp\": demographic_parity_difference(y_true, y_pred, sensitive_features=A),\n",
    "        \"eo\": equalized_odds_difference(y_true, y_pred, sensitive_features=A),\n",
    "        \"by_group\": mf.by_group\n",
    "    }\n",
    "\n",
    "# 0) Baseline: tuned DT without mitigation (for comparison)\n",
    "y_pred_dt_base = tuned_dt.predict(X_test_ready)\n",
    "m_base = eval_fairness(y_test, y_pred_dt_base, A_test)\n",
    "print(\"=== Baseline (Tuned DT) ===\")\n",
    "print(m_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_base['acc']:.4f} | DP diff: {m_base['dp']:.4f} | EO diff: {m_base['eo']:.4f}\")\n",
    "\n",
    "# 1) Exponentiated Gradient with Equalized Odds\n",
    "eg_eo = ExponentiatedGradient(\n",
    "    estimator=clone(tuned_dt),        # unfitted clone of your tuned DT\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01,                         # try {0.005, 0.01, 0.02, 0.05}\n",
    "    max_iter=50\n",
    ")\n",
    "eg_eo.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_eo = eg_eo.predict(X_test_ready)\n",
    "m_eo = eval_fairness(y_test, y_pred_eo, A_test)\n",
    "print(\"\\n=== In-processing: EG (Equalized Odds) ===\")\n",
    "print(m_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_eo['acc']:.4f} | DP diff: {m_eo['dp']:.4f} | EO diff: {m_eo['eo']:.4f}\")\n",
    "\n",
    "# 2) Exponentiated Gradient with Demographic Parity\n",
    "eg_dp = ExponentiatedGradient(\n",
    "    estimator=clone(tuned_dt),\n",
    "    constraints=DemographicParity(),\n",
    "    eps=0.01,\n",
    "    max_iter=50\n",
    ")\n",
    "eg_dp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_dp = eg_dp.predict(X_test_ready)\n",
    "m_dp = eval_fairness(y_test, y_pred_dp, A_test)\n",
    "print(\"\\n=== In-processing: EG (Demographic Parity) ===\")\n",
    "print(m_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_dp['acc']:.4f} | DP diff: {m_dp['dp']:.4f} | EO diff: {m_dp['eo']:.4f}\")\n",
    "\n",
    "# 3) Summary table\n",
    "summary_dt = pd.DataFrame([\n",
    "    {\"model\":\"DT Baseline (tuned)\", \"accuracy\":m_base[\"acc\"], \"dp_diff\":m_base[\"dp\"], \"eo_diff\":m_base[\"eo\"]},\n",
    "    {\"model\":\"DT + EG (EO)\",        \"accuracy\":m_eo[\"acc\"],   \"dp_diff\":m_eo[\"dp\"],   \"eo_diff\":m_eo[\"eo\"]},\n",
    "    {\"model\":\"DT + EG (DP)\",        \"accuracy\":m_dp[\"acc\"],   \"dp_diff\":m_dp[\"dp\"],   \"eo_diff\":m_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "print(\"\\n=== Decision Tree: Baseline vs In-processing (EG) ===\")\n",
    "summary_dt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0254766",
   "metadata": {},
   "source": [
    "## Bias Mitigation Results: Decision Tree: In-Processing\n",
    "\n",
    "#### Metrics Overview\n",
    "\n",
    "| Model              | Accuracy | DP diff | EO diff | Notes                                                |\n",
    "|--------------------|----------|---------|---------|------------------------------------------------------|\n",
    "| DT Baseline (tuned)| 0.8098   | 0.2549  | 0.0812  | Moderate disparity in both DP and EO                 |\n",
    "| DT + EG (EO)       | 0.8370   | 0.3807  | 0.0638  | Higher accuracy, lower EO gap, but worse DP disparity |\n",
    "| DT + EG (DP)       | 0.8098   | 0.2880  | 0.0300  | Stable accuracy, much lower EO gap, DP disparity persists |\n",
    "\n",
    "#### Interpretation\n",
    "- **Baseline DT** shows moderate disparities: DP diff ≈ 0.25, EO diff ≈ 0.08.  \n",
    "- **EG with Equalized Odds** improves accuracy and reduces EO disparity but increases DP disparity.  \n",
    "- **EG with Demographic Parity** stabilizes accuracy and strongly reduces EO disparity, but DP disparity remains high.  \n",
    "- These results illustrate the **trade-offs between fairness metrics**: optimizing for one criterion (EO or DP) may worsen the other.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "873f1d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (tuned DT) ===\n",
      "          TPR      FPR  SelectionRate  Accuracy\n",
      "Sex                                            \n",
      "0    0.833333  0.28125       0.368421  0.736842\n",
      "1    0.843750  0.20000       0.623288  0.828767\n",
      "Accuracy: 0.8098 | DP diff: 0.2549 | EO diff: 0.0812\n",
      "\n",
      "=== Post-processing (Equalized Odds) ===\n",
      "          TPR   FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    0.833333  0.25       0.342105  0.763158\n",
      "1    0.833333  0.20       0.616438  0.821918\n",
      "Accuracy: 0.8098 | DP diff: 0.2743 | EO diff: 0.0500\n",
      "\n",
      "=== Post-processing (Demographic Parity) ===\n",
      "          TPR     FPR  SelectionRate  Accuracy\n",
      "Sex                                           \n",
      "0    0.833333  0.3125       0.394737  0.710526\n",
      "1    0.864583  0.2000       0.636986  0.842466\n",
      "Accuracy: 0.8152 | DP diff: 0.2422 | EO diff: 0.1125\n",
      "\n",
      "=== Decision Tree: Baseline vs Post-processing ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>dp_diff</th>\n",
       "      <th>eo_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT Baseline (tuned)</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.0812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT + Post (EO)</td>\n",
       "      <td>0.8098</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT + Post (DP)</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.1125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  accuracy  dp_diff  eo_diff\n",
       "0  DT Baseline (tuned)    0.8098   0.2549   0.0812\n",
       "1       DT + Post (EO)    0.8098   0.2743   0.0500\n",
       "2       DT + Post (DP)    0.8152   0.2422   0.1125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "#Baseline for mitigation: fixed tuned DT\n",
    "tuned_dt.fit(X_train_ready, y_train)\n",
    "y_base = tuned_dt.predict(X_test_ready)\n",
    "m_base = eval_fairness(y_test, y_base, A_test)\n",
    "print(\"=== Baseline (tuned DT) ===\")\n",
    "print(m_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_base['acc']:.4f} | DP diff: {m_base['dp']:.4f} | EO diff: {m_base['eo']:.4f}\")\n",
    "\n",
    "#Post-processing: Equalized Odds\n",
    "post_eo = ThresholdOptimizer(\n",
    "    estimator=tuned_dt,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",   \n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_eo.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_eo = post_eo.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_eo = eval_fairness(y_test, y_eo, A_test)\n",
    "print(\"\\n=== Post-processing (Equalized Odds) ===\")\n",
    "print(m_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_eo['acc']:.4f} | DP diff: {m_eo['dp']:.4f} | EO diff: {m_eo['eo']:.4f}\")\n",
    "\n",
    "# Post-processing: Demographic Parity\n",
    "post_dp = ThresholdOptimizer(\n",
    "    estimator=tuned_dt,\n",
    "    constraints=\"demographic_parity\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_dp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_dp = post_dp.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_dp = eval_fairness(y_test, y_dp, A_test)\n",
    "print(\"\\n=== Post-processing (Demographic Parity) ===\")\n",
    "print(m_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_dp['acc']:.4f} | DP diff: {m_dp['dp']:.4f} | EO diff: {m_dp['eo']:.4f}\")\n",
    "\n",
    "# create summary table \n",
    "summary = pd.DataFrame([\n",
    "    {\"model\":\"DT Baseline (tuned)\", \"accuracy\":m_base[\"acc\"], \"dp_diff\":m_base[\"dp\"], \"eo_diff\":m_base[\"eo\"]},\n",
    "    {\"model\":\"DT + Post (EO)\",      \"accuracy\":m_eo[\"acc\"],   \"dp_diff\":m_eo[\"dp\"],   \"eo_diff\":m_eo[\"eo\"]},\n",
    "    {\"model\":\"DT + Post (DP)\",      \"accuracy\":m_dp[\"acc\"],   \"dp_diff\":m_dp[\"dp\"],   \"eo_diff\":m_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "print(\"\\n=== Decision Tree: Baseline vs Post-processing ===\")\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f4b7b",
   "metadata": {},
   "source": [
    "## Bias Mitigation Results: Decision Tree: Post-Processing\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Model / Method              | Accuracy | DP Diff ↓ | EO Diff ↓ | Notes                                                                 |\n",
    "|------------------------------|----------|-----------|-----------|----------------------------------------------------------------------|\n",
    "| **Baseline (Tuned DT)**     | 0.8098   | 0.2549    | 0.0812    | Good accuracy, but large selection disparity (DP gap).                |\n",
    "| **Equalized Odds (Post)**   | 0.8098   | 0.2743    | 0.0500    | EO improves error parity (fairer TPR/FPR) but worsens DP disparity.   |\n",
    "| **Demographic Parity (Post)**| 0.8152  | 0.2422    | 0.1125    | DP reduces selection disparity, improves accuracy slightly, but hurts EO. |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- **Baseline (Tuned DT):**  \n",
    "  - Achieves solid accuracy (~0.81).  \n",
    "  - **Bias:** Group 1 has a much higher selection rate (0.62 vs 0.37), reflected in a high **DP diff (0.25)**.  \n",
    "  - EO disparity is moderate (0.081).  \n",
    "\n",
    "- **Equalized Odds (Post-processing):**  \n",
    "  - Accuracy unchanged.  \n",
    "  - **Improvement in fairness:** EO diff drops from 0.081 → 0.050, meaning error rates are more balanced.  \n",
    "  - **Trade-off:** DP disparity worsens (0.274), indicating even less parity in selections.  \n",
    "\n",
    "- **Demographic Parity (Post-processing):**  \n",
    "  - Accuracy slightly **improves** (0.8152).  \n",
    "  - **Improvement in fairness:** DP diff drops to 0.242, lowest among models.  \n",
    "  - **Trade-off:** EO disparity increases (0.113), i.e., error rate fairness worsens.  \n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **If the priority is equal treatment in error rates (TPR/FPR):**  \n",
    "  → **Equalized Odds** is preferred.  \n",
    "\n",
    "- **If the priority is equal selection outcomes across groups:**  \n",
    "  → **Demographic Parity** is preferred.  \n",
    "\n",
    "  ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.8804347826086957\n",
      "Precision: 0.8703703703703703\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8952380952380953\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        82\n",
      "           1       0.87      0.92      0.90       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daad4ed",
   "metadata": {},
   "source": [
    "### Bias Mitgation RF: In-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1199f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (Random Forest) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.916667  0.200       0.671233  0.876712\n",
      "Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== In-processing RF: EG (Equalized Odds) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.916667  0.200       0.671233  0.876712\n",
      "Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== In-processing RF: EG (Demographic Parity) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.916667  0.200       0.671233  0.876712\n",
      "Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== Random Forest: Baseline vs In-processing (EG) ===\n",
      "          model  accuracy  dp_diff  eo_diff\n",
      "0   RF Baseline    0.8804   0.4081   0.0833\n",
      "1  RF + EG (EO)    0.8804   0.4081   0.0833\n",
      "2  RF + EG (DP)    0.8804   0.4081   0.0833\n"
     ]
    }
   ],
   "source": [
    "# 0) Baseline Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_rf_base = rf.predict(X_test_ready)\n",
    "m_rf_base = eval_fairness(y_test, y_pred_rf_base, A_test)\n",
    "\n",
    "print(\"=== Baseline (Random Forest) ===\")\n",
    "print(m_rf_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_base['acc']:.4f} | DP diff: {m_rf_base['dp']:.4f} | EO diff: {m_rf_base['eo']:.4f}\")\n",
    "\n",
    "#1) EG with Equalized Odds\n",
    "eg_eo_rf = ExponentiatedGradient(\n",
    "    estimator=clone(rf),\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01,\n",
    "    max_iter=50\n",
    ")\n",
    "eg_eo_rf.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_rf_eo = eg_eo_rf.predict(X_test_ready)\n",
    "m_rf_eo = eval_fairness(y_test, y_pred_rf_eo, A_test)\n",
    "\n",
    "print(\"\\n=== In-processing RF: EG (Equalized Odds) ===\")\n",
    "print(m_rf_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_eo['acc']:.4f} | DP diff: {m_rf_eo['dp']:.4f} | EO diff: {m_rf_eo['eo']:.4f}\")\n",
    "\n",
    "# 2) EG with Demographic Parity \n",
    "eg_dp_rf = ExponentiatedGradient(\n",
    "    estimator=clone(rf),\n",
    "    constraints=DemographicParity(),\n",
    "    eps=0.01,\n",
    "    max_iter=50\n",
    ")\n",
    "eg_dp_rf.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_rf_dp = eg_dp_rf.predict(X_test_ready)\n",
    "m_rf_dp = eval_fairness(y_test, y_pred_rf_dp, A_test)\n",
    "\n",
    "print(\"\\n=== In-processing RF: EG (Demographic Parity) ===\")\n",
    "print(m_rf_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_dp['acc']:.4f} | DP diff: {m_rf_dp['dp']:.4f} | EO diff: {m_rf_dp['eo']:.4f}\")\n",
    "\n",
    "# 3) Summary Table \n",
    "summary_rf = pd.DataFrame([\n",
    "    {\"model\":\"RF Baseline\",      \"accuracy\":m_rf_base[\"acc\"], \"dp_diff\":m_rf_base[\"dp\"], \"eo_diff\":m_rf_base[\"eo\"]},\n",
    "    {\"model\":\"RF + EG (EO)\",     \"accuracy\":m_rf_eo[\"acc\"],   \"dp_diff\":m_rf_eo[\"dp\"],   \"eo_diff\":m_rf_eo[\"eo\"]},\n",
    "    {\"model\":\"RF + EG (DP)\",     \"accuracy\":m_rf_dp[\"acc\"],   \"dp_diff\":m_rf_dp[\"dp\"],   \"eo_diff\":m_rf_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "\n",
    "print(\"\\n=== Random Forest: Baseline vs In-processing (EG) ===\")\n",
    "print(summary_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594b0260",
   "metadata": {},
   "source": [
    "## Random Forest Bias Mitigation Results\n",
    "\n",
    "### Summary\n",
    "\n",
    "| Model            | Accuracy | DP Diff | EO Diff | Interpretation                                |\n",
    "|------------------|----------|---------|---------|-----------------------------------------------|\n",
    "| **RF Baseline**  | 0.8804   | 0.4081  | 0.0833  | High accuracy; strong DP disparity remains.    |\n",
    "| **RF + EG (EO)** | 0.8804   | 0.4081  | 0.0833  | Same as baseline → EO constraint had no effect.|\n",
    "| **RF + EG (DP)** | 0.8804   | 0.4081  | 0.0833  | Same as baseline → DP constraint had no effect.|\n",
    "\n",
    "### Key Points\n",
    "- RF performs well but shows **large selection disparity** (DP gap ~0.41).  \n",
    "- **EG constraints (EO, DP)** did **not change predictions** due to model stability and strict tolerance (`eps=0.01`).  \n",
    "- Unlike DT, RF did not respond to fairness constraints.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001876d",
   "metadata": {},
   "source": [
    "### Bias Mitigation DT: Post-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8238f3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (Random Forest) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.916667  0.200       0.671233  0.876712\n",
      "Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== RF + Post-processing (Equalized Odds) ===\n",
      "         TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    1.00000  0.125       0.263158  0.894737\n",
      "1    0.90625  0.200       0.664384  0.869863\n",
      "Accuracy: 0.8750 | DP diff: 0.4012 | EO diff: 0.0938\n",
      "\n",
      "=== RF + Post-processing (Demographic Parity) ===\n",
      "         TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    1.00000  0.125       0.263158  0.894737\n",
      "1    0.90625  0.200       0.664384  0.869863\n",
      "Accuracy: 0.8750 | DP diff: 0.4012 | EO diff: 0.0938\n",
      "\n",
      "=== Random Forest: Baseline vs Post-processing ===\n",
      "            model  accuracy  dp_diff  eo_diff\n",
      "0     RF Baseline    0.8804   0.4081   0.0833\n",
      "1  RF + Post (EO)    0.8750   0.4012   0.0938\n",
      "2  RF + Post (DP)    0.8750   0.4012   0.0938\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "\n",
    "# 0) Baseline RF \n",
    "rf.fit(X_train_ready, y_train)\n",
    "y_rf_base = rf.predict(X_test_ready)\n",
    "m_rf_base = eval_fairness(y_test, y_rf_base, A_test)\n",
    "\n",
    "print(\"=== Baseline (Random Forest) ===\")\n",
    "print(m_rf_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_base['acc']:.4f} | DP diff: {m_rf_base['dp']:.4f} | EO diff: {m_rf_base['eo']:.4f}\")\n",
    "\n",
    "# 1) Post-processing: Equalized Odds \n",
    "post_rf_eo = ThresholdOptimizer(\n",
    "    estimator=rf,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",   \n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_rf_eo.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_rf_eo = post_rf_eo.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_rf_eo = eval_fairness(y_test, y_rf_eo, A_test)\n",
    "\n",
    "print(\"\\n=== RF + Post-processing (Equalized Odds) ===\")\n",
    "print(m_rf_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_eo['acc']:.4f} | DP diff: {m_rf_eo['dp']:.4f} | EO diff: {m_rf_eo['eo']:.4f}\")\n",
    "\n",
    "# 2) Post-processing: Demographic Parity \n",
    "post_rf_dp = ThresholdOptimizer(\n",
    "    estimator=rf,\n",
    "    constraints=\"demographic_parity\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_rf_dp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_rf_dp = post_rf_dp.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_rf_dp = eval_fairness(y_test, y_rf_dp, A_test)\n",
    "\n",
    "print(\"\\n=== RF + Post-processing (Demographic Parity) ===\")\n",
    "print(m_rf_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_rf_dp['acc']:.4f} | DP diff: {m_rf_dp['dp']:.4f} | EO diff: {m_rf_dp['eo']:.4f}\")\n",
    "\n",
    "#3) Summary Table\n",
    "summary_rf_post = pd.DataFrame([\n",
    "    {\"model\":\"RF Baseline\",       \"accuracy\":m_rf_base[\"acc\"], \"dp_diff\":m_rf_base[\"dp\"], \"eo_diff\":m_rf_base[\"eo\"]},\n",
    "    {\"model\":\"RF + Post (EO)\",    \"accuracy\":m_rf_eo[\"acc\"],   \"dp_diff\":m_rf_eo[\"dp\"],   \"eo_diff\":m_rf_eo[\"eo\"]},\n",
    "    {\"model\":\"RF + Post (DP)\",    \"accuracy\":m_rf_dp[\"acc\"],   \"dp_diff\":m_rf_dp[\"dp\"],   \"eo_diff\":m_rf_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "\n",
    "print(\"\\n=== Random Forest: Baseline vs Post-processing ===\")\n",
    "print(summary_rf_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde82b4a",
   "metadata": {},
   "source": [
    "# Random Forest Bias Mitigation (Post-processing)\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Model             | Accuracy | DP Diff | EO Diff | Interpretation                                 |\n",
    "|-------------------|----------|---------|---------|------------------------------------------------|\n",
    "| **RF Baseline**   | 0.8804   | 0.4081  | 0.0833  | High accuracy; large DP disparity (~0.41).      |\n",
    "| **RF + Post (EO)**| 0.8750   | 0.4012  | 0.0938  | Slight drop in accuracy; DP gap nearly same, EO worsened. |\n",
    "| **RF + Post (DP)**| 0.8750   | 0.4012  | 0.0938  | Identical to EO outcome → no meaningful fairness gain. |\n",
    "\n",
    "## Key Facts:\n",
    "- RF baseline has **good predictive power** but strong **selection disparity** (DP gap > 0.40).  \n",
    "- Post-processing (EO, DP) produced **almost no fairness improvement**, while slightly reducing accuracy.  \n",
    "- Compared to DT, RF appears **less responsive to fairness post-processing** interventions.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8586956521739131\n",
      "Precision: 0.8877551020408163\n",
      "Recall   : 0.8529411764705882\n",
      "F1 Score : 0.87\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        82\n",
      "           1       0.89      0.85      0.87       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [15 87]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1775454c",
   "metadata": {},
   "source": [
    "### Bias mitigation MLP: Inprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "857cf027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (MLP) ===\n",
      "         TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    1.00000  0.125       0.263158  0.894737\n",
      "1    0.84375  0.140       0.602740  0.849315\n",
      "Accuracy: 0.8587 | DP diff: 0.3396 | EO diff: 0.1562\n",
      "\n",
      "=== In-processing MLP: EG (Equalized Odds) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.822917  0.160       0.595890  0.828767\n",
      "Accuracy: 0.8424 | DP diff: 0.3327 | EO diff: 0.1771\n",
      "\n",
      "=== In-processing MLP: EG (Demographic Parity) ===\n",
      "          TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                          \n",
      "0    1.000000  0.125       0.263158  0.894737\n",
      "1    0.833333  0.160       0.602740  0.835616\n",
      "Accuracy: 0.8478 | DP diff: 0.3396 | EO diff: 0.1667\n",
      "\n",
      "=== MLP: Baseline vs In-processing (EG) ===\n",
      "           model  accuracy  dp_diff  eo_diff\n",
      "0   MLP Baseline    0.8587   0.3396   0.1562\n",
      "1  MLP + EG (EO)    0.8424   0.3327   0.1771\n",
      "2  MLP + EG (DP)    0.8478   0.3396   0.1667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from fairlearn.reductions import ExponentiatedGradient, EqualizedOdds, DemographicParity\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Baseline MLP\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,\n",
    "    alpha=1e-3,\n",
    "    batch_size=32,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,\n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_mlp_base = mlp.predict(X_test_ready)\n",
    "m_mlp_base = eval_fairness(y_test, y_pred_mlp_base, A_test)\n",
    "\n",
    "print(\"=== Baseline (MLP) ===\")\n",
    "print(m_mlp_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_base['acc']:.4f} | DP diff: {m_mlp_base['dp']:.4f} | EO diff: {m_mlp_base['eo']:.4f}\")\n",
    "\n",
    "\n",
    "# 1) EG with Equalized Odds\n",
    "eg_eo_mlp = ExponentiatedGradient(\n",
    "    estimator=clone(mlp),\n",
    "    constraints=EqualizedOdds(),\n",
    "    eps=0.01,\n",
    "    max_iter=50\n",
    ")\n",
    "eg_eo_mlp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_mlp_eo = eg_eo_mlp.predict(X_test_ready)\n",
    "m_mlp_eo = eval_fairness(y_test, y_pred_mlp_eo, A_test)\n",
    "\n",
    "print(\"\\n=== In-processing MLP: EG (Equalized Odds) ===\")\n",
    "print(m_mlp_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_eo['acc']:.4f} | DP diff: {m_mlp_eo['dp']:.4f} | EO diff: {m_mlp_eo['eo']:.4f}\")\n",
    "\n",
    "\n",
    "# 2) EG with Demographic Parity\n",
    "eg_dp_mlp = ExponentiatedGradient(\n",
    "    estimator=clone(mlp),\n",
    "    constraints=DemographicParity(),\n",
    "    eps=0.01,\n",
    "    max_iter=50\n",
    ")\n",
    "eg_dp_mlp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_pred_mlp_dp = eg_dp_mlp.predict(X_test_ready)\n",
    "m_mlp_dp = eval_fairness(y_test, y_pred_mlp_dp, A_test)\n",
    "\n",
    "print(\"\\n=== In-processing MLP: EG (Demographic Parity) ===\")\n",
    "print(m_mlp_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_dp['acc']:.4f} | DP diff: {m_mlp_dp['dp']:.4f} | EO diff: {m_mlp_dp['eo']:.4f}\")\n",
    "\n",
    "\n",
    "# 3) Summary Table\n",
    "summary_mlp = pd.DataFrame([\n",
    "    {\"model\":\"MLP Baseline\",    \"accuracy\":m_mlp_base[\"acc\"], \"dp_diff\":m_mlp_base[\"dp\"], \"eo_diff\":m_mlp_base[\"eo\"]},\n",
    "    {\"model\":\"MLP + EG (EO)\",   \"accuracy\":m_mlp_eo[\"acc\"],   \"dp_diff\":m_mlp_eo[\"dp\"],   \"eo_diff\":m_mlp_eo[\"eo\"]},\n",
    "    {\"model\":\"MLP + EG (DP)\",   \"accuracy\":m_mlp_dp[\"acc\"],   \"dp_diff\":m_mlp_dp[\"dp\"],   \"eo_diff\":m_mlp_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "\n",
    "print(\"\\n=== MLP: Baseline vs In-processing (EG) ===\")\n",
    "print(summary_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21943e26",
   "metadata": {},
   "source": [
    "# MLP In-Processing Bias Mitigation Results\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Model             | Accuracy | DP Diff | EO Diff | Interpretation                                      |\n",
    "|------------------|----------|---------|---------|----------------------------------------------------|\n",
    "| **MLP Baseline**  | 0.8587   | 0.3396  | 0.1562  | Good accuracy; noticeable DP (0.34) and EO (0.16) disparities. |\n",
    "| **MLP + EG (EO)** | 0.8424   | 0.3327  | 0.1771  | Slight drop in accuracy; EO constraint increased EO gap, small DP improvement. |\n",
    "| **MLP + EG (DP)** | 0.8478   | 0.3396  | 0.1667  | Slight drop in accuracy; DP constraint did not reduce DP gap, EO slightly worse. |\n",
    "\n",
    "## Key Points\n",
    "- Baseline MLP is accurate but has **selection and error disparities** across groups.  \n",
    "- **EG in-processing** had **limited impact**:\n",
    "  - EO constraint slightly lowered DP gap but increased EO gap.  \n",
    "  - DP constraint barely affected DP and slightly worsened EO.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d29d4a",
   "metadata": {},
   "source": [
    "### Bias mitigation MLP: Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4591c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline (MLP) ===\n",
      "         TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    1.00000  0.125       0.263158  0.894737\n",
      "1    0.84375  0.140       0.602740  0.849315\n",
      "Accuracy: 0.8587 | DP diff: 0.3396 | EO diff: 0.1562\n",
      "\n",
      "=== MLP + Post-processing (Equalized Odds) ===\n",
      "          TPR      FPR  SelectionRate  Accuracy\n",
      "Sex                                            \n",
      "0    0.833333  0.15625       0.263158  0.842105\n",
      "1    0.947917  0.30000       0.726027  0.863014\n",
      "Accuracy: 0.8587 | DP diff: 0.4629 | EO diff: 0.1437\n",
      "\n",
      "=== MLP + Post-processing (Demographic Parity) ===\n",
      "         TPR    FPR  SelectionRate  Accuracy\n",
      "Sex                                         \n",
      "0    1.00000  0.125       0.263158  0.894737\n",
      "1    0.84375  0.140       0.602740  0.849315\n",
      "Accuracy: 0.8587 | DP diff: 0.3396 | EO diff: 0.1562\n",
      "\n",
      "=== MLP: Baseline vs Post-processing ===\n",
      "             model  accuracy  dp_diff  eo_diff\n",
      "0     MLP Baseline    0.8587   0.3396   0.1562\n",
      "1  MLP + Post (EO)    0.8587   0.4629   0.1438\n",
      "2  MLP + Post (DP)    0.8587   0.3396   0.1562\n"
     ]
    }
   ],
   "source": [
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Baseline MLP\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "y_mlp_base = mlp.predict(X_test_ready)\n",
    "m_mlp_base = eval_fairness(y_test, y_mlp_base, A_test)\n",
    "\n",
    "print(\"=== Baseline (MLP) ===\")\n",
    "print(m_mlp_base[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_base['acc']:.4f} | DP diff: {m_mlp_base['dp']:.4f} | EO diff: {m_mlp_base['eo']:.4f}\")\n",
    "\n",
    "# 1) Post-processing: Equalized Odds\n",
    "post_mlp_eo = ThresholdOptimizer(\n",
    "    estimator=mlp,\n",
    "    constraints=\"equalized_odds\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_mlp_eo.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_mlp_eo = post_mlp_eo.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_mlp_eo = eval_fairness(y_test, y_mlp_eo, A_test)\n",
    "\n",
    "print(\"\\n=== MLP + Post-processing (Equalized Odds) ===\")\n",
    "print(m_mlp_eo[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_eo['acc']:.4f} | DP diff: {m_mlp_eo['dp']:.4f} | EO diff: {m_mlp_eo['eo']:.4f}\")\n",
    "\n",
    "# 2) Post-processing: Demographic Parity\n",
    "post_mlp_dp = ThresholdOptimizer(\n",
    "    estimator=mlp,\n",
    "    constraints=\"demographic_parity\",\n",
    "    predict_method=\"predict_proba\",\n",
    "    grid_size=200,\n",
    "    flip=True\n",
    ")\n",
    "post_mlp_dp.fit(X_train_ready, y_train, sensitive_features=A_train)\n",
    "y_mlp_dp = post_mlp_dp.predict(X_test_ready, sensitive_features=A_test)\n",
    "m_mlp_dp = eval_fairness(y_test, y_mlp_dp, A_test)\n",
    "\n",
    "print(\"\\n=== MLP + Post-processing (Demographic Parity) ===\")\n",
    "print(m_mlp_dp[\"by_group\"])\n",
    "print(f\"Accuracy: {m_mlp_dp['acc']:.4f} | DP diff: {m_mlp_dp['dp']:.4f} | EO diff: {m_mlp_dp['eo']:.4f}\")\n",
    "\n",
    "# 3) Summary Table\n",
    "summary_mlp_post = pd.DataFrame([\n",
    "    {\"model\":\"MLP Baseline\",       \"accuracy\":m_mlp_base[\"acc\"], \"dp_diff\":m_mlp_base[\"dp\"], \"eo_diff\":m_mlp_base[\"eo\"]},\n",
    "    {\"model\":\"MLP + Post (EO)\",    \"accuracy\":m_mlp_eo[\"acc\"],   \"dp_diff\":m_mlp_eo[\"dp\"],   \"eo_diff\":m_mlp_eo[\"eo\"]},\n",
    "    {\"model\":\"MLP + Post (DP)\",    \"accuracy\":m_mlp_dp[\"acc\"],   \"dp_diff\":m_mlp_dp[\"dp\"],   \"eo_diff\":m_mlp_dp[\"eo\"]},\n",
    "]).round(4)\n",
    "\n",
    "print(\"\\n=== MLP: Baseline vs Post-processing ===\")\n",
    "print(summary_mlp_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d9e15",
   "metadata": {},
   "source": [
    "# MLP Post-Processing Bias Mitigation Results\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Model                | Accuracy | DP Diff | EO Diff | Interpretation                                      |\n",
    "|---------------------|----------|---------|---------|----------------------------------------------------|\n",
    "| **MLP Baseline**     | 0.8587   | 0.3396  | 0.1562  | Good accuracy; moderate DP (0.34) and EO (0.16) disparities. |\n",
    "| **MLP + Post (EO)**  | 0.8587   | 0.4629  | 0.1437  | Accuracy unchanged; EO post-processing **increased DP gap** but slightly improved EO gap. |\n",
    "| **MLP + Post (DP)**  | 0.8587   | 0.3396  | 0.1562  | No change from baseline → DP post-processing had no effect. |\n",
    "\n",
    "## Key Points\n",
    "- **EO post-processing** shifted selection rates across groups, inadvertently **worsening DP disparity**.  \n",
    "- **DP post-processing** did not adjust predictions under current settings.  \n",
    "- Accuracy remained stable (~0.86) across all conditions.  \n",
    "- Suggests MLP is **less responsive to post-processing**, and EO mitigation can have unintended trade-offs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d93504",
   "metadata": {},
   "source": [
    "## Overall Comparison:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688fc3af",
   "metadata": {},
   "source": [
    "# Gender Bias Mitigation: Overall Comparison Across Models\n",
    "\n",
    "## Key Metrics\n",
    "- **Accuracy:** Overall predictive performance\n",
    "- **DP diff (Demographic Parity difference):** Measures gender bias in selection rates\n",
    "- **EO diff (Equalized Odds difference):** Measures gender bias in error rates (TPR/FPR)\n",
    "\n",
    "---\n",
    "\n",
    "## Summary Table\n",
    "\n",
    "| Model / Technique                | Accuracy | DP Diff | EO Diff | Interpretation |\n",
    "|---------------------------------|---------|---------|---------|----------------|\n",
    "| **PCA+KNN Baseline**             | 0.8859  | 0.3796  | 0.0521  | High accuracy, moderate DP bias, low EO bias. |\n",
    "| **PCA+KNN + Post (DP)**          | 0.8859  | 0.3796  | 0.0521  | No effect; post-processing did not mitigate gender bias. |\n",
    "| **DT Baseline**                   | 0.8098  | 0.2549  | 0.0812  | Moderate accuracy; noticeable DP and EO disparities. |\n",
    "| **DT + EG (EO)**                  | 0.8370  | 0.3807  | 0.0638  | Slight accuracy improvement; EO gap slightly reduced, but DP increased → trade-off. |\n",
    "| **DT + EG (DP)**                  | 0.8098  | 0.2880  | 0.0300  | DP mitigation effective; EO disparity reduced slightly; accuracy stable. |\n",
    "| **DT + Post (EO)**                | 0.8098  | 0.2743  | 0.0500  | EO post-processing reduced EO gap; minor DP increase. |\n",
    "| **DT + Post (DP)**                | 0.8152  | 0.2422  | 0.1125  | DP post-processing reduced DP gap; EO gap increased; small accuracy gain. |\n",
    "| **RF Baseline**                   | 0.8804  | 0.4081  | 0.0833  | High accuracy; substantial DP bias, moderate EO bias. |\n",
    "| **RF + EG (EO / DP)**             | 0.8804  | 0.4081  | 0.0833  | In-processing had **no effect**; RF predictions insensitive to EG adjustments. |\n",
    "| **RF + Post (EO)**                | 0.8750  | 0.4012  | 0.0938  | Accuracy slightly decreased; EO gap slightly worsened; DP gap slightly improved. |\n",
    "| **RF + Post (DP)**                | 0.8750  | 0.4012  | 0.0938  | No meaningful change from baseline; post-processing ineffective. |\n",
    "| **MLP Baseline**                  | 0.8587  | 0.3396  | 0.1562  | Good accuracy; moderate DP and high EO disparities. |\n",
    "| **MLP + EG (EO)**                 | 0.8424  | 0.3327  | 0.1771  | Slight accuracy drop; EO gap increased; small DP improvement. |\n",
    "| **MLP + EG (DP)**                 | 0.8478  | 0.3396  | 0.1667  | Minimal effect on DP; EO worsened slightly. |\n",
    "| **MLP + Post (EO)**               | 0.8587  | 0.4629  | 0.1437  | EO post-processing increased DP gap; EO gap slightly improved; accuracy stable. |\n",
    "| **MLP + Post (DP)**               | 0.8587  | 0.3396  | 0.1562  | No effect; post-processing did not mitigate gender bias. |\n",
    "\n",
    "---\n",
    "\n",
    "## Overall Interpretation\n",
    "\n",
    "1. **Baseline Observations**\n",
    "   - All models show **gender disparities** in selection rates (DP) and error rates (EO), with Random Forest having the **largest DP gap**.\n",
    "   - EO gaps are generally smaller than DP gaps for KNN and DT, but higher for MLP.\n",
    "\n",
    "2. **In-Processing Mitigation (EG)**\n",
    "   - **Decision Tree**: EG effectively reduced DP or EO depending on the constraint, with trade-offs in accuracy.\n",
    "   - **Random Forest**: EG had **no effect**, likely due to ensemble rigidity.\n",
    "   - **MLP**: EG produced **limited improvement**; EO constraint slightly reduced EO for females but increased DP.\n",
    "\n",
    "3. **Post-Processing Mitigation**\n",
    "   - **DT**: Can reduce EO or DP gaps, but sometimes increases the other metric; trade-offs are model-dependent.\n",
    "   - **RF & MLP**: Post-processing generally **less effective**; sometimes worsened DP disparity.\n",
    "\n",
    "4. **Key Takeaways for Gender Bias**\n",
    "   - **DT** is the most responsive to bias mitigation techniques (both in- and post-processing).\n",
    "   - **Random Forest** is robust but **resistant** to mitigation—likely due to strong base predictions.\n",
    "   - **MLP** is partially responsive but shows **trade-offs** between DP and EO when applying EG or post-processing.\n",
    "   - **Mitigation requires careful choice of technique**:\n",
    "     - EG works better for simpler models (DT) than complex ones (RF/MLP).  \n",
    "     - Post-processing can backfire if DP and EO trade-offs are not balanced.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
