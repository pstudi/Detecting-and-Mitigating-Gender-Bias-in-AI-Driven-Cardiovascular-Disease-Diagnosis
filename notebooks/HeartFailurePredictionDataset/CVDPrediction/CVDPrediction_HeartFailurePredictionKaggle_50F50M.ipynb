{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   61    1              3      146.0        241.0          0           0   \n",
       "1   39    1              1      130.0        215.0          0           0   \n",
       "2   60    0              0      150.0        240.0          0           0   \n",
       "3   49    1              3      128.0        212.0          0           0   \n",
       "4   50    0              2      140.0        288.0          0           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  148.0               1      3.0         0             1  \n",
       "1  120.0               0      0.0         2             0  \n",
       "2  171.0               0      0.9         2             0  \n",
       "3   96.0               1      0.0         1             1  \n",
       "4  140.0               1      0.0         1             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_50_50.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2a2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbc36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e35ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6436b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.8043478260869565\n",
      "Precision: 0.8586956521739131\n",
      "Recall   : 0.7745098039215687\n",
      "F1 Score : 0.8144329896907216\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79        82\n",
      "           1       0.86      0.77      0.81       102\n",
      "\n",
      "    accuracy                           0.80       184\n",
      "   macro avg       0.80      0.81      0.80       184\n",
      "weighted avg       0.81      0.80      0.80       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[69 13]\n",
      " [23 79]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.7663043478260869\n",
      "Precision: 0.8172043010752689\n",
      "Recall   : 0.7450980392156863\n",
      "F1 Score : 0.7794871794871795\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75        82\n",
      "           1       0.82      0.75      0.78       102\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.77      0.77      0.77       184\n",
      "weighted avg       0.77      0.77      0.77       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65 17]\n",
      " [26 76]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61267d66",
   "metadata": {},
   "source": [
    "## KNN Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 80.4%  \n",
    "- **Precision**: 85.9%  \n",
    "- **Recall**: 77.5%  \n",
    "- **F1 Score**: 81.4%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 69           | 13           |\n",
    "| **Actual: 1** | 23           | 79           |\n",
    "\n",
    "### Interpretation\n",
    "- The model shows **strong precision (86%)**, meaning most predicted CVD cases are correct.  \n",
    "- **Recall (77.5%)** indicates that some CVD patients are still missed (**23 false negatives**).  \n",
    "- Non-CVD cases are identified with solid accuracy (84%), with **13 false positives**.  \n",
    "- Overall, this KNN model achieves **balanced performance**, leaning slightly toward precision while still maintaining reasonable recall.  \n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 76.6%  \n",
    "- **Precision**: 81.7%  \n",
    "- **Recall**: 74.5%  \n",
    "- **F1 Score**: 77.9%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 65           | 17           |\n",
    "| **Actual: 1** | 26           | 76           |\n",
    "\n",
    "### Interpretation\n",
    "- The Decision Tree achieves **precision of 82%**, showing that positive (CVD) predictions are mostly correct.  \n",
    "- **Recall is lower (74.5%)**, with **26 CVD cases missed** (false negatives).  \n",
    "- Non-CVD patients are correctly identified 79% of the time, though **17 false positives** occurred.  \n",
    "- Overall, this model delivers **moderate performance**, but its lower accuracy and recall compared to other configurations suggest limitations in sensitivity.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Best CV F1: 0.905773457143949\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.8791208791208791\n",
      "Recall   : 0.7843137254901961\n",
      "F1 Score : 0.8290155440414507\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        82\n",
      "           1       0.88      0.78      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.83      0.82       184\n",
      "weighted avg       0.83      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [22 80]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f9c24",
   "metadata": {},
   "source": [
    "## KNN (Best Params) Model Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Metric**: Manhattan  \n",
    "- **Neighbors**: 5  \n",
    "- **Weights**: Distance  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 82.1%  \n",
    "- **Precision**: 87.9%  \n",
    "- **Recall**: 78.4%  \n",
    "- **F1 Score**: 82.9%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 71           | 11           |\n",
    "| **Actual: 1** | 22           | 80           |\n",
    "\n",
    "### Interpretation\n",
    "- The tuned KNN achieves **the best balance so far**, improving accuracy (82.1%) and F1 score (82.9%).  \n",
    "- **Precision is high (87.9%)**, meaning positive (CVD) predictions are very reliable.  \n",
    "- **Recall (78.4%)** indicates that most CVD cases are detected, though **22 patients are still missed** (false negatives).  \n",
    "- For non-CVD cases, performance is also strong, with **87% correctly identified** and only **11 false positives**.  \n",
    "- Overall, this tuned KNN provides a **robust and well-balanced trade-off** between precision and recall, making it more effective than the baseline configuration.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 12 | Explained variance retained: 0.969\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.875\n",
      "Precision: 0.9247311827956989\n",
      "Recall   : 0.8431372549019608\n",
      "F1 Score : 0.882051282051282\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.87        82\n",
      "           1       0.92      0.84      0.88       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.87      0.88      0.87       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[75  7]\n",
      " [16 86]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941812d1",
   "metadata": {},
   "source": [
    "## KNN Model Comparison (Baseline vs Tuned vs PCA)\n",
    "\n",
    "| Model                     | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline KNN**           | 0.804    | 0.859     | 0.775  | 0.814    | Solid starting point; 23 false negatives and 13 false positives. |\n",
    "| **Tuned KNN (best params)**| 0.821    | 0.879     | 0.784  | 0.829    | Improved precision and slightly higher recall; 22 false negatives and 11 false positives. |\n",
    "| **Tuned KNN + PCA (12 comps)** | 0.875 | 0.925     | 0.843  | 0.882    | Best performer: highest accuracy, precision, and recall; only 16 false negatives and 7 false positives. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline KNN** provides balanced performance but misses 23 CVD cases, limiting sensitivity.  \n",
    "- **Tuned KNN** improves precision and recall slightly, showing a better trade-off with fewer errors.  \n",
    "- **Tuned KNN with PCA** clearly outperforms both:  \n",
    "  - **Accuracy jumps to 87.5%** (+7% over baseline).  \n",
    "  - **Precision (92.5%) and recall (84.3%)** both increase, leading to fewer false negatives (16) and false positives (7).  \n",
    "  - This makes it the **most reliable and robust KNN configuration** for detecting CVD.  \n",
    "\n",
    "➡️ **Conclusion**: The **Tuned KNN with PCA** is the best variant, combining strong sensitivity with excellent precision and overall predictive power.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c71ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA+KNN model → pca_knn.pkl\n",
      "Saved predictions → HeartFailureData_50_50_PCA_KNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"pca_knn.pkl\"\n",
    "joblib.dump(pca_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from PCA+KNN\n",
    "y_pred_knn = pca_knn.predict(X_test_ready)\n",
    "y_prob_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_knn,\n",
    "    \"y_pred\": y_pred_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_50_50_PCA_KNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "\n",
    "print(f\"Saved PCA+KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best CV F1: 0.8758095173030324\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.7336956521739131\n",
      "Precision: 0.7912087912087912\n",
      "Recall   : 0.7058823529411765\n",
      "F1 Score : 0.7461139896373057\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72        82\n",
      "           1       0.79      0.71      0.75       102\n",
      "\n",
      "    accuracy                           0.73       184\n",
      "   macro avg       0.73      0.74      0.73       184\n",
      "weighted avg       0.74      0.73      0.73       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[63 19]\n",
      " [30 72]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f44a59",
   "metadata": {},
   "source": [
    "## Decision Tree (Best Params) Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 73.4%  \n",
    "- **Precision**: 79.1%  \n",
    "- **Recall**: 70.6%  \n",
    "- **F1 Score**: 74.6%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 63           | 19           |\n",
    "| **Actual: 1** | 30           | 72           |\n",
    "\n",
    "### Interpretation\n",
    "- The tuned Decision Tree achieves **moderate precision (79%)**, meaning most predicted CVD cases are correct.  \n",
    "- **Recall is weaker (71%)**, with **30 CVD cases missed** (false negatives), which is a notable limitation in medical applications.  \n",
    "- Non-CVD cases are recognized with fair accuracy (77%), though **19 healthy patients** were misclassified as CVD (false positives).  \n",
    "- Both accuracy (73%) and F1 score (75%) are relatively **lower compared to other Decision Tree variant**, suggesting that this parameter set does not generalize well.  \n",
    "\n",
    "➡️ Overall, this tuned Decision Tree provides **limited performance**, with recall being too low for reliable use in CVD detection. It is less suitable compared to recall-focused alternatives.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'entropy', 'max_depth': 6, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Stage A — Best CV F1: 0.8800000000000001\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV F1: 0.8800\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.896551724137931\n",
      "Recall   : 0.7647058823529411\n",
      "F1 Score : 0.8253968253968254\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.82        82\n",
      "           1       0.90      0.76      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.83      0.82       184\n",
      "weighted avg       0.83      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [24 78]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# bias toward simpler trees with class_weight=\"balanced\" \n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",    # balanced focus\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV F1:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# cost-complexity pruning\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  \n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    f1_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, f1_cv))\n",
    "\n",
    "best_alpha, best_cv_f1 = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV F1: {best_cv_f1:.4f}\")\n",
    "\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluate on test set \n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0555f0",
   "metadata": {},
   "source": [
    "## Alternative Tuned & Pruned Decision Tree Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Criterion**: Entropy  \n",
    "- **Max Depth**: 6  \n",
    "- **Min Samples Split**: 5  \n",
    "- **Min Samples Leaf**: 4  \n",
    "- **Min Impurity Decrease**: 0.0  \n",
    "- **Pruning (ccp_alpha)**: 0.0  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 82.1%  \n",
    "- **Precision**: 89.7%  \n",
    "- **Recall**: 76.5%  \n",
    "- **F1 Score**: 82.5%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 73           | 9            |\n",
    "| **Actual: 1** | 24           | 78           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **very strong precision (89.7%)**, showing that most predicted CVD cases are correct.  \n",
    "- **Recall is moderate (76.5%)**, meaning **24 CVD patients are missed** (false negatives).  \n",
    "- Non-CVD patients are well detected (89% recall), with only **9 false positives**, indicating strong reliability in ruling out healthy cases.  \n",
    "- Both accuracy (82.1%) and F1 score (82.5%) show this model is **one of the better Decision Tree configurations**, offering a good balance.  \n",
    "- Pruning keeps the model simpler and more interpretable while maintaining competitive performance.  \n",
    "\n",
    "➡️ Overall, this **tuned & pruned Decision Tree** provides a **robust balance** between precision and recall, making it a reliable and interpretable option for CVD detection, though it still sacrifices some sensitivity compared to recall-optimized variants.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f870f69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 3}, 'criterion': 'entropy', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.9633\n",
      "Stage B — Best ccp_alpha: 0.035320 | CV Recall: 0.9650\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7880434782608695\n",
      "Precision: 0.7404580152671756\n",
      "Recall   : 0.9509803921568627\n",
      "F1 Score : 0.8326180257510729\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.59      0.71        82\n",
      "           1       0.74      0.95      0.83       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.82      0.77      0.77       184\n",
      "weighted avg       0.81      0.79      0.78       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[48 34]\n",
      " [ 5 97]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34270f4",
   "metadata": {},
   "source": [
    "## Alternative Tuned & Pruned Decision Tree (Recall-focused) Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Criterion**: Entropy  \n",
    "- **Max Depth**: 4  \n",
    "- **Min Samples Split**: 5  \n",
    "- **Min Samples Leaf**: 6  \n",
    "- **Class Weights**: {0: 1, 1: 3} (favoring CVD cases)  \n",
    "- **Min Impurity Decrease**: 0.0  \n",
    "- **Pruning (ccp_alpha)**: 0.0353  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 78.8%  \n",
    "- **Precision**: 74.0%  \n",
    "- **Recall**: 95.1%  \n",
    "- **F1 Score**: 83.3%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 48           | 34           |\n",
    "| **Actual: 1** | 5            | 97           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **very high recall (95.1%)**, meaning nearly all CVD cases are detected (**only 5 false negatives**).  \n",
    "- **Precision is lower (74%)**, indicating a higher number of false alarms (**34 non-CVD patients misclassified as CVD**).  \n",
    "- Accuracy (78.8%) is moderate, reflecting the trade-off between strong sensitivity and reduced specificity.  \n",
    "- The weighted class setting biases the model toward detecting positives, which explains the high sensitivity but lower precision.  \n",
    "- This configuration is **recall-focused**, making it highly suitable when the main priority is to avoid missed diagnoses, even at the cost of more false positives.  \n",
    "\n",
    "➡️ Overall, this **recall-optimized DT** is a good choice for medical screening, as it minimizes the risk of undetected CVD cases. However, it does so by accepting a substantial increase in false positives, which may lead to additional follow-up checks for healthy patients.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d1b01",
   "metadata": {},
   "source": [
    "## Decision Tree Model Comparison\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|--------------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline DT**                      | 0.766    | 0.817     | 0.745  | 0.779    | Balanced but modest; 26 false negatives, 17 false positives. |\n",
    "| **Tuned DT (best params)**           | 0.734    | 0.791     | 0.706  | 0.746    | Weakest variant; recall drops further (30 missed CVD cases). |\n",
    "| **Alt. Tuned & Pruned DT (Balanced)**| 0.821    | 0.897     | 0.765  | 0.825    | Strongest balanced model; high precision, fewer false positives (9), but 24 false negatives. |\n",
    "| **Alt. Tuned & Pruned DT (Recall-focused)** | 0.788 | 0.740 | 0.951  | 0.833    | Best recall (95%); only 5 missed CVD cases, but many false positives (34). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline DT** provides moderate, balanced performance but is outperformed by the pruned alternatives.  \n",
    "- **Tuned DT (best params)** performs the weakest overall, with reduced accuracy and recall, making it the least suitable.  \n",
    "- **Alt. Tuned & Pruned DT (Balanced)** offers the **best trade-off**: highest accuracy (82.1%), very high precision (89.7%), and stable recall (76.5%). False positives are kept low (9), avoiding excessive misclassification of healthy patients.  \n",
    "- **Alt. Tuned & Pruned DT (Recall-focused)** minimizes missed CVD cases (95% recall) but at the cost of precision (74%) and a surge in false positives (34). This may burden healthcare systems with unnecessary follow-ups and cause anxiety for many healthy patients.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The **Alt. Tuned & Pruned DT (Balanced)** is the preferred model.  \n",
    "It achieves the **highest accuracy and strong precision**, while maintaining a reasonable recall. Importantly, it keeps the number of false alarms **very low (only 9)**, which is crucial in medical screening: A balanced model ensures a **reliable detection rate** without overwhelming the system or patients with excessive misclassifications.  \n",
    "\n",
    "➡️ This makes the **balanced DT** the most practical and trustworthy option for CVD detection.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e58f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Alternative DT tuning → alt_tuned_pruned_DT.pkl\n",
      "Saved predictions → HeartFailureData_50_50_AltTunedDT_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing DT Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"alt_tuned_pruned_DT.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from Decision Tree \n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_dt,\n",
    "    \"y_pred\": y_pred_dt\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_50_50_AltTunedDT_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Alternative DT tuning → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.8315217391304348\n",
      "Precision: 0.8585858585858586\n",
      "Recall   : 0.8333333333333334\n",
      "F1 Score : 0.845771144278607\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        82\n",
      "           1       0.86      0.83      0.85       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.83      0.83      0.83       184\n",
      "weighted avg       0.83      0.83      0.83       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [17 85]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad5f962",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 83.2%  \n",
    "- **Precision**: 85.9%  \n",
    "- **Recall**: 83.3%  \n",
    "- **F1 Score**: 84.6%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 68           | 14           |\n",
    "| **Actual: 1** | 17           | 85           |\n",
    "\n",
    "### Interpretation\n",
    "- The Random Forest model achieves **strong and balanced performance** across all metrics.  \n",
    "- **Precision (85.9%)** indicates that most predicted CVD cases are correct, while **recall (83.3%)** shows that the majority of true CVD cases are detected.  \n",
    "- **17 CVD cases are missed** (false negatives), while **14 healthy patients are misclassified as CVD** (false positives).  \n",
    "- Both classes are represented fairly evenly:  \n",
    "  - Non-CVD detection: 68 out of 82 correctly classified (83%).  \n",
    "  - CVD detection: 85 out of 102 correctly classified (83%).  \n",
    "- The model demonstrates **consistency** with no major imbalance between sensitivity and precision, making it reliable for practical use.  \n",
    "\n",
    "➡️ Overall, this Random Forest configuration provides a **robust and well-balanced trade-off**, achieving high accuracy while keeping both false positives and false negatives at manageable levels.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 0.8, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV F1: 0.9166666666666667\n",
      "=== Tuned Random Forest Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.8556701030927835\n",
      "Recall   : 0.8137254901960784\n",
      "F1 Score : 0.8341708542713567\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80        82\n",
      "           1       0.86      0.81      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.82      0.82       184\n",
      "weighted avg       0.82      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [19 83]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning\n",
    "\n",
    "# 1) GridSearchCV over impactful RF params\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",          \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "# 2) Evaluate best RF \n",
    "y_pred_tuned_rf = best_rf.predict(X_test_ready)\n",
    "y_prob_tuned_rf = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "evaluate_model(y_test, y_pred_tuned_rf, \"Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1630de8",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|--------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline RF**    | 0.832    | 0.859     | 0.833  | 0.846    | Strong and balanced; 17 false negatives, 14 false positives. |\n",
    "| **Tuned RF**       | 0.821    | 0.856     | 0.814  | 0.834    | Slightly lower performance; 19 false negatives, 14 false positives. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline RF** shows **very balanced performance** with high precision (85.9%) and recall (83.3%), achieving solid overall accuracy (83.2%).  \n",
    "  - Correctly identifies **85 of 102 CVD cases**, missing 17.  \n",
    "  - Correctly classifies **68 of 82 non-CVD cases**, with 14 false alarms.  \n",
    "\n",
    "- **Tuned RF** delivers **similar but slightly weaker results**: accuracy falls to 82.1%, recall drops slightly to 81.4%, and F1 decreases to 83.4%.  \n",
    "  - It misses a few more CVD cases (**19 false negatives**) while keeping false positives unchanged (14).  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The **Baseline Random Forest** is the stronger option here, offering the **best balance of sensitivity and precision**.  \n",
    "Tuning did not lead to improvement — instead, it slightly reduced both recall and accuracy. This suggests that the **default Random Forest is already well-suited** for this dataset, providing a reliable trade-off between correctly identifying CVD patients and minimizing false alarms.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0adf6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved RF → rf.pkl\n",
      "Saved predictions → HeartFailureData_50_50_RF_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing RF Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"rf.pkl\"\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from RF\n",
    "rf.fit(X_train_ready, y_train)\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_rf,\n",
    "    \"y_pred\": y_pred_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_50_50_RF_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved RF → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.7880434782608695\n",
      "Precision: 0.8620689655172413\n",
      "Recall   : 0.7352941176470589\n",
      "F1 Score : 0.7936507936507936\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78        82\n",
      "           1       0.86      0.74      0.79       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.79      0.79      0.79       184\n",
      "weighted avg       0.80      0.79      0.79       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [27 75]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "y_prob = mlp.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ba0da",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 78.8%  \n",
    "- **Precision**: 86.2%  \n",
    "- **Recall**: 73.5%  \n",
    "- **F1 Score**: 79.4%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 70           | 12           |\n",
    "| **Actual: 1** | 27           | 75           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **high precision (86%)**, meaning most positive (CVD) predictions are correct.  \n",
    "- **Recall is lower (73.5%)**, with **27 CVD cases missed** (false negatives), showing reduced sensitivity.  \n",
    "- Non-CVD cases are well identified (**85% recall**), with **12 false positives**.  \n",
    "- Overall performance (accuracy 78.8%, F1 79.4%) indicates the model leans more toward **precision** than recall, making it conservative in detecting positives.  \n",
    "\n",
    "➡️ While this MLP is reliable when predicting CVD, it sacrifices sensitivity and may fail to capture a significant portion of true cases, which limits its usefulness in medical screening.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d72c0",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8478260869565217\n",
      "Precision: 0.9021739130434783\n",
      "Recall   : 0.8137254901960784\n",
      "F1 Score : 0.8556701030927835\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84        82\n",
      "           1       0.90      0.81      0.86       102\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.85      0.85      0.85       184\n",
      "weighted avg       0.85      0.85      0.85       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [19 83]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96130844",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – Adam + EarlyStopping) Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 84.8%  \n",
    "- **Precision**: 90.2%  \n",
    "- **Recall**: 81.4%  \n",
    "- **F1 Score**: 85.6%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 73           | 9            |\n",
    "| **Actual: 1** | 19           | 83           |\n",
    "\n",
    "### Interpretation\n",
    "- This model achieves **the strongest performance among MLP variants tested so far**, with accuracy of **84.8%** and an F1 score of **85.6%**.  \n",
    "- **Precision is very high (90.2%)**, meaning that when the model predicts CVD, it is usually correct.  \n",
    "- **Recall (81.4%)** shows that most CVD cases are detected, though **19 patients were missed** (false negatives).  \n",
    "- Non-CVD patients are also well recognized (89% correctly identified), with only **9 false positives**.  \n",
    "- The use of **Adam with EarlyStopping** prevents overfitting and provides a strong balance between sensitivity and precision.  \n",
    "\n",
    "➡️ Overall, this MLP configuration is **robust and reliable**, offering a balanced trade-off: it reduces false alarms while still detecting the majority of true CVD cases. This makes it a strong candidate for practical use.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP (LBFGS)  Evaluation ===\n",
      "Accuracy : 0.7934782608695652\n",
      "Precision: 0.8478260869565217\n",
      "Recall   : 0.7647058823529411\n",
      "F1 Score : 0.8041237113402062\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78        82\n",
      "           1       0.85      0.76      0.80       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.79      0.80      0.79       184\n",
      "weighted avg       0.80      0.79      0.79       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [24 78]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_lbfgs, \"MLP (LBFGS) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d70b13",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – LBFGS) Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 79.3%  \n",
    "- **Precision**: 84.8%  \n",
    "- **Recall**: 76.5%  \n",
    "- **F1 Score**: 80.4%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 68           | 14           |\n",
    "| **Actual: 1** | 24           | 78           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **good precision (84.8%)**, so most predicted CVD cases are correct.  \n",
    "- **Recall is weaker (76.5%)**, resulting in **24 missed CVD cases** (false negatives).  \n",
    "- For non-CVD patients, 68 out of 82 are classified correctly (83%), while **14 false positives** occur.  \n",
    "- With accuracy of 79.3% and F1 score of 80.4%, this version shows **modest performance** compared to other MLP configurations.  \n",
    "- The LBFGS optimizer does not provide clear advantages here, as both sensitivity and accuracy remain limited.  \n",
    "\n",
    "➡️ Overall, the **MLP (LBFGS)** performs reliably but is **less competitive** than the Adam + EarlyStopping variant, which delivers higher accuracy and recall.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8960261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'batch_size': 16, 'alpha': 0.001, 'activation': 'relu'}\n",
      "=== Best MLP Evaluation ===\n",
      "Accuracy : 0.8532608695652174\n",
      "Precision: 0.9120879120879121\n",
      "Recall   : 0.8137254901960784\n",
      "F1 Score : 0.8601036269430051\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        82\n",
      "           1       0.91      0.81      0.86       102\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.85      0.86      0.85       184\n",
      "weighted avg       0.86      0.85      0.85       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  8]\n",
      " [19 83]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Improved MLP pipeline: recall-first tuning  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, recall_score, fbeta_score, make_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# 1) Recall-first search (Adam + early_stopping)\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # uses internal 15% validation\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=20,\n",
    "    max_iter=2000,                # allow convergence\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# multi-metric scoring; refit on recall-oriented F-beta\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "recallfirst_best_mlp = rs.best_estimator_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "\n",
    "# 2) Evaluation\n",
    "y_prob = recallfirst_best_mlp.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred_best_mlp = recallfirst_best_mlp.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_best_mlp, model_name=f\"Best MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6c276",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison\n",
    "\n",
    "| Model                      | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline MLP**            | 0.788    | 0.862     | 0.735  | 0.794    | Decent baseline; 27 false negatives, 12 false positives. |\n",
    "| **MLP (Adam + EarlyStopping)** | 0.848 | 0.902     | 0.814  | 0.856    | Strong variant; fewer false negatives (19) and false positives (9). |\n",
    "| **MLP (LBFGS)**             | 0.793    | 0.848     | 0.765  | 0.804    | Modest performance; 24 false negatives, 14 false positives. |\n",
    "| **Best Tuned MLP**          | 0.853    | 0.912     | 0.814  | 0.860    | Best performer; highest accuracy and precision, only 19 false negatives and 8 false positives. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline MLP** provides a reasonable starting point but struggles with recall (73.5%), missing many CVD cases.  \n",
    "- **MLP (Adam + EarlyStopping)** improves across all metrics, achieving better balance and stability, thanks to overfitting prevention.  \n",
    "- **MLP (LBFGS)** performs similarly to the baseline but does not offer clear improvements, showing that this optimizer is less effective for the dataset.  \n",
    "- **Best Tuned MLP** delivers the **strongest results**, with the highest accuracy (85.3%) and precision (91.2%), while keeping recall solid at 81.4%. It minimizes both false negatives and false positives, making it the most reliable variant.  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The **Best Tuned MLP** is the most effective configuration, offering the **highest accuracy and precision** with stable recall, making it well-suited for CVD detection.  \n",
    "The **Adam + EarlyStopping** model follows closely and is also a strong choice, while the **Baseline** and **LBFGS** variants underperform in comparison.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a5c9e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recall First Tuned MLP→ RecallFirstTunedMLP.pkl\n",
      "Saved predictions → HeartFailureData_50_50_RecallFirstTunedMLP_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing MLP Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"RecallFirstTunedMLP.pkl\"\n",
    "joblib.dump(recallfirst_best_mlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from MLP\n",
    "y_prob = recallfirst_best_mlp.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred_best_mlp = recallfirst_best_mlp.predict(X_test_ready)\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_mlp,\n",
    "    \"y_pred\": y_pred_mlp\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_50_50_RecallFirstTunedMLP_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Recall First Tuned MLP→ {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
