{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   61    1              3      146.0        241.0          0           0   \n",
       "1   52    1              1      120.0        284.0          0           0   \n",
       "2   48    0              3      150.0        227.0          0           0   \n",
       "3   49    1              3      128.0        212.0          0           0   \n",
       "4   56    1              3      120.0        236.0          0           1   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  148.0               1      3.0         0             1  \n",
       "1  118.0               0      0.0         2             0  \n",
       "2  130.0               1      1.0         1             0  \n",
       "3   96.0               1      0.0         1             1  \n",
       "4  148.0               0      0.0         1             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fe70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.8369565217391305\n",
      "Precision: 0.875\n",
      "Recall   : 0.8235294117647058\n",
      "F1 Score : 0.8484848484848485\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82        82\n",
      "           1       0.88      0.82      0.85       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.84      0.84       184\n",
      "weighted avg       0.84      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [18 84]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.8152173913043478\n",
      "Precision: 0.8469387755102041\n",
      "Recall   : 0.8137254901960784\n",
      "F1 Score : 0.83\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.82      0.80        82\n",
      "           1       0.85      0.81      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.81      0.82      0.81       184\n",
      "weighted avg       0.82      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[67 15]\n",
      " [19 83]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]   \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b2c36",
   "metadata": {},
   "source": [
    "### KNN Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 83.7%  \n",
    "- **Precision**: 87.5%  \n",
    "- **Recall**: **82.4%**  \n",
    "- **F1 Score**: 84.8%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 70           | 12           |\n",
    "| **Actual: 1** | 18           | 84           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **18**  \n",
    "- **True Positives (correct CVD detections)**: **84**  \n",
    "- **Recall (class 1 / CVD)** = 84 / (84 + 18) = **82.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Precision** is strong (87.5%), indicating most positive predictions are correct.  \n",
    "- **Recall** at 82.4% shows the model captures most positive cases while missing some (18 FN).  \n",
    "- The error profile is balanced, with moderate **FP (12)** and **FN (18)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Decision Tree Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 81.5%  \n",
    "- **Precision**: 84.7%  \n",
    "- **Recall**: **81.4%**  \n",
    "- **F1 Score**: 83.0%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 67           | 15           |\n",
    "| **Actual: 1** | 19           | 83           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **19**  \n",
    "- **True Positives (correct CVD detections)**: **83**  \n",
    "- **Recall (class 1 / CVD)** = 83 / (83 + 19) = **81.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- **Precision** above 80% suggests positive flags are generally reliable.  \n",
    "- **Recall** at 81.4% indicates solid sensitivity with **19 missed positives (FN)**.  \n",
    "- Errors are split between **FP (15)** and **FN (19)**, reflecting a moderately conservative decision boundary.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 25, 'weights': 'distance'}\n",
      "Best CV F1: 0.8909542505768512\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8641304347826086\n",
      "Precision: 0.9139784946236559\n",
      "Recall   : 0.8333333333333334\n",
      "F1 Score : 0.8717948717948718\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86        82\n",
      "           1       0.91      0.83      0.87       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.87      0.86       184\n",
      "weighted avg       0.87      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  8]\n",
      " [17 85]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bacde5",
   "metadata": {},
   "source": [
    "### Tuned KNN (best params) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 86.4%  \n",
    "- **Precision**: 91.4%  \n",
    "- **Recall**: **83.3%**  \n",
    "- **F1 Score**: 87.2%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 74           | 8            |\n",
    "| **Actual: 1** | 17           | 85           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **17**  \n",
    "- **True Positives (correct CVD detections)**: **85**  \n",
    "- **Recall (class 1 / CVD)** = 85 / (85 + 17) = **83.3%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model is **precision-leaning**: high precision (91.4%) indicates most positive predictions are correct.  \n",
    "- **Recall at 83.3%** shows it captures most positives, though **some cases are missed (17 FN)**.  \n",
    "- Errors are distributed as a modest number of **false positives (8)** and **false negatives (17)**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 12 | Explained variance retained: 0.967\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8858695652173914\n",
      "Precision: 0.9090909090909091\n",
      "Recall   : 0.8823529411764706\n",
      "F1 Score : 0.8955223880597015\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        82\n",
      "           1       0.91      0.88      0.90       102\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.88      0.89      0.88       184\n",
      "weighted avg       0.89      0.89      0.89       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [12 90]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559179e",
   "metadata": {},
   "source": [
    "### KNN (best params) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 88.6%  \n",
    "- **Precision**: 90.9%  \n",
    "- **Recall**: **88.2%**  \n",
    "- **F1 Score**: 89.6%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 73           | 9            |\n",
    "| **Actual: 1** | 12           | 90           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **12**  \n",
    "- **True Positives (correct CVD detections)**: **90**  \n",
    "- **Recall (class 1 / CVD)** = 90 / (90 + 12) = **88.2%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model shows **strong, balanced performance** with **slightly higher precision** than recall, indicating confident positive predictions while capturing most positive cases.  \n",
    "- Errors are dominated by a modest number of **false negatives (12)** and **false positives (9)**, consistent with a balanced operating point.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**: Appropriate for scenarios requiring a **good balance of sensitivity and precision**.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b6f364",
   "metadata": {},
   "source": [
    "## KNN Model Comparison\n",
    "\n",
    "| Model                         | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline KNN**              | 0.837    | 0.875     | 0.824  | 0.848    | Decent balance, but more false negatives (18) |\n",
    "| **KNN (Best Params)**         | 0.864    | 0.914     | 0.833  | 0.872    | Higher precision, fewer false positives (8), stable recall |\n",
    "| **KNN (Best Params + PCA)**   | 0.886    | 0.909     | 0.882  | 0.896    | Best overall: higher recall, fewer false negatives (12), strong balance |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline KNN**: Good starting point but recall is limited.  \n",
    "- **Tuned KNN**: Improves accuracy and precision, reduces false positives.  \n",
    "- **KNN with PCA**: Highest accuracy and F1, with the best trade-off between recall and precision.  \n",
    "\n",
    "➡️ **KNN with PCA** is the most robust version, achieving the best overall performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afed75b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA+KNN model → pca_knn.pkl\n",
      "Saved predictions → HeartFailureData_75M25F_PCA_KNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"pca_knn.pkl\"\n",
    "joblib.dump(pca_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from PCA+KNN\n",
    "y_pred_knn = pca_knn.predict(X_test_ready)\n",
    "y_prob_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_knn,\n",
    "    \"y_pred\": y_pred_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75M25F_PCA_KNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "\n",
    "print(f\"Saved PCA+KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best CV F1: 0.8593494246061409\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.8097826086956522\n",
      "Precision: 0.819047619047619\n",
      "Recall   : 0.8431372549019608\n",
      "F1 Score : 0.8309178743961353\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78        82\n",
      "           1       0.82      0.84      0.83       102\n",
      "\n",
      "    accuracy                           0.81       184\n",
      "   macro avg       0.81      0.81      0.81       184\n",
      "weighted avg       0.81      0.81      0.81       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[63 19]\n",
      " [16 86]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905a3c5",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (best params) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 81.0%  \n",
    "- **Precision**: 81.9%  \n",
    "- **Recall**: **84.3%**  \n",
    "- **F1 Score**: 83.1%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 63           | 19           |\n",
    "| **Actual: 1** | 16           | 86           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **16**  \n",
    "- **True Positives (correct CVD detections)**: **86**  \n",
    "- **Recall (class 1 / CVD)** = 86 / (86 + 16) = **84.3%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model shows **solid sensitivity** for class 1, correctly identifying most positive cases (TP=86) while missing some (FN=16).  \n",
    "- **Precision above 80%** indicates a good proportion of predicted positives are correct, limiting unnecessary follow-ups.  \n",
    "- Overall, the metrics suggest a **slightly recall-leaning** operating point with balanced performance.\n",
    "\n",
    "---\n",
    "\n",
    "**Conclusion**: Appropriate when **catching positive cases** is important while keeping precision reasonable.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 20}\n",
      "Stage A — Best CV F1: 0.8633333333333333\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV F1: 0.8633\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.8043478260869565\n",
      "Precision: 0.851063829787234\n",
      "Recall   : 0.7843137254901961\n",
      "F1 Score : 0.8163265306122449\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79        82\n",
      "           1       0.85      0.78      0.82       102\n",
      "\n",
      "    accuracy                           0.80       184\n",
      "   macro avg       0.80      0.81      0.80       184\n",
      "weighted avg       0.81      0.80      0.80       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [22 80]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# bias toward simpler trees with class_weight=\"balanced\" \n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",    # balanced focus\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV F1:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# cost-complexity pruning\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  \n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    f1_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, f1_cv))\n",
    "\n",
    "best_alpha, best_cv_f1 = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV F1: {best_cv_f1:.4f}\")\n",
    "\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluate on test set \n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67852f8",
   "metadata": {},
   "source": [
    "### Decision Tree (Tuned & Pruned) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 80.4%  \n",
    "- **Precision**: 85.1%  \n",
    "- **Recall**: **78.4%**  \n",
    "- **F1 Score**: 81.6%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 68           | 14           |\n",
    "| **Actual: 1** | 22           | 80           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **22**  \n",
    "- **True Positives (correct CVD detections)**: **80**  \n",
    "- **Recall (class 1 / CVD)** = 80 / (80 + 22) = **78.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- This DT is **precision-leaning**: higher precision (85.1%) than recall (78.4%) means it’s more conservative with positive predictions, at the cost of **more missed positives (22 FN)**.  \n",
    "- Class 0 is identified reasonably well (TN=68), but false positives (14) remain. Overall, performance is **moderate**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c01579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'entropy', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.97\n",
      "Stage B — Best ccp_alpha: 0.006006 | CV Recall: 0.9717\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7880434782608695\n",
      "Precision: 0.7692307692307693\n",
      "Recall   : 0.8823529411764706\n",
      "F1 Score : 0.821917808219178\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.67      0.74        82\n",
      "           1       0.77      0.88      0.82       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.80      0.78      0.78       184\n",
      "weighted avg       0.79      0.79      0.78       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[55 27]\n",
      " [12 90]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67118cbe",
   "metadata": {},
   "source": [
    "## Decision Tree Model Comparison\n",
    "\n",
    "| Model                                      | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|--------------------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline Decision Tree**                  | 0.815    | 0.847     | 0.814  | 0.830    | Balanced but moderate errors (15 FP, 19 FN). |\n",
    "| **Tuned Decision Tree (best params)**       | 0.810    | 0.819     | 0.843  | 0.831    | Recall improves slightly, but precision drops; more false positives (19). |\n",
    "| **Alt. Tuned & Pruned DT (Recall-focused)** | 0.788    | 0.769     | 0.882  | 0.822    | Highest recall, but lowest precision; many false positives (27), fewer false negatives (12). |\n",
    "| **Alt. Tuned & Pruned DT (Balanced)**       | 0.804    | 0.851     | 0.784  | 0.816    | Strong precision, fewer false positives (14), but recall is lower, meaning more missed cases (22). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline DT** provides the most stable and balanced performance (Acc 81.5%, Prec 84.7%, Rec 81.4%).  \n",
    "- **Tuned DT** raises recall slightly (+3%) but loses precision, so the net gain is limited.  \n",
    "- **Alt. DT (Recall-focused)** achieves the **highest recall (88.2%)**, but the trade-off in **accuracy (78.8%)** and **precision (76.9%)** is too steep, generating many false positives (27).  \n",
    "- **Alt. DT (Balanced)** improves precision to 85.1% with fewer false alarms, but its recall (78.4%) drops too much, missing more true cases (22).  \n",
    "\n",
    "---\n",
    "\n",
    "➡️ **Conclusion**: The **Recall-focused DT** cannot be recommended despite its sensitivity, since its trade-off is too costly. For a practical choice, the **Baseline DT** remains the most balanced, while **KNN with PCA** (Acc 88.6%, Rec 88.2%) actually outperforms all DT variants in both recall and accuracy.  But for fairness evaluation, the **Tuned Decision Tree** is chosen. It offers a favorable balance by **improving recall**—critical in CVD prediction—while accuracy and precision only decrease slightly compared to the baseline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eefbde4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned Decision Tree → tuned_dt.tpkl\n",
      "Saved predictions → HeartFailureData_75M25F_TunedDT_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing DT Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"tuned_dt.tpkl\"\n",
    "joblib.dump(tuned_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from Decision Tree \n",
    "y_pred_dt = y_pred_dt_best\n",
    "y_prob_dt = y_prob_dt_best\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_dt,\n",
    "    \"y_pred\": y_pred_dt\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75M25F_TunedDT_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned Decision Tree → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.8804347826086957\n",
      "Precision: 0.8703703703703703\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8952380952380953\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        82\n",
      "           1       0.87      0.92      0.90       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d28aa4",
   "metadata": {},
   "source": [
    "## Random Forest Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics \n",
    "\n",
    "- **Accuracy**: 88.0%  \n",
    "- **Precision**: 87.0%  \n",
    "- **Recall**: **92.2%**  \n",
    "- **F1 Score**: 89.5%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 68           | 14           |\n",
    "| **Actual: 1** | 8            | 94           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **8**  \n",
    "- **True Positives (correct CVD detections)**: **94**  \n",
    "- **Recall (class 1 / CVD)** = 94 / (94 + 8) = **92.2%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The Random Forest is **recall-oriented for CVD (class 1)**: it catches most positives (only 8 FN).  \n",
    "- Trade-off: **more false positives** on class 0 (14 FP), consistent with strong recall and slightly lower precision.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "- This Random Forest is a **strong baseline** with **high sensitivity** and solid precision.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best CV F1: 0.9133333333333333\n",
      "=== Tuned Random Forest Evaluation ===\n",
      "Accuracy : 0.842391304347826\n",
      "Precision: 0.8348623853211009\n",
      "Recall   : 0.8921568627450981\n",
      "F1 Score : 0.8625592417061612\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82        82\n",
      "           1       0.83      0.89      0.86       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.84      0.84       184\n",
      "weighted avg       0.84      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[64 18]\n",
      " [11 91]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning\n",
    "\n",
    "# 1) GridSearchCV over impactful RF params\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",          \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "# 2) Evaluate best RF \n",
    "y_pred = best_rf.predict(X_test_ready)\n",
    "y_prob = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "evaluate_model(y_test, y_pred, \"Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b4e9b",
   "metadata": {},
   "source": [
    "### Tuned Random Forest Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "- **Accuracy**: 84.2%  \n",
    "- **Precision**: 83.5%  \n",
    "- **Recall**: **89.2%**  \n",
    "- **F1 Score**: 86.3%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 64           | 18           |\n",
    "| **Actual: 1** | 11           | 91           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **11**  \n",
    "- **True Positives (correct CVD detections)**: **91**  \n",
    "- **Recall (class 1 / CVD)** = 91 / (91 + 11) = **89.2%**\n",
    "\n",
    "---\n",
    "\n",
    "➡️ **Interpretation**: The tuned Random Forest achieves strong overall performance, with particularly high **recall**, which is crucial in CVD prediction to avoid missed cases. Although the number of false positives (18) is moderate, the model correctly identifies the majority of CVD cases, making it a suitable candidate for fairness evaluation.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11f127",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison\n",
    "\n",
    "| Model                      | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline RF**             | 0.880    | 0.870     | 0.922  | 0.895    | Strong performance; high recall (92.2%) with balanced precision; only 8 false negatives. |\n",
    "| **Tuned RF (best params)**  | 0.842    | 0.835     | 0.892  | 0.863    | Recall remains strong (89.2%) but accuracy and precision drop; more false positives (18). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline RF** achieves **the strongest overall balance**: high accuracy (88.0%) and excellent recall (92.2%), minimizing missed CVD cases.  \n",
    "- **Tuned RF** keeps recall fairly high but suffers in accuracy (-4%) and precision (-3.5%), making it less reliable.  \n",
    "- Unlike DT, tuning **did not improve performance** — the baseline RF is already optimized enough for this dataset.  \n",
    "\n",
    "---\n",
    "\n",
    "### Ranking\n",
    "1. **Baseline RF** – Best choice: excellent recall, solid accuracy, and reliable F1.  \n",
    "2. **Tuned RF** – Still performs well, but worse than baseline due to extra false positives.  \n",
    "\n",
    "➡️ **Conclusion**: Random Forest is one of the **top-performing models** overall, comparable to **KNN with PCA**. Both achieve high recall and accuracy, which is crucial for CVD detection.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf7a6cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Baseline RF → baseline_rf.pkl\n",
      "Saved predictions → HeartFailureData_75M25F_BaselineRF_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing RF Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"baseline_rf.pkl\"\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from Random Forest\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_rf,\n",
    "    \"y_pred\": y_pred_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75M25F_BaselineRF_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Baseline RF → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.8043478260869565\n",
      "Precision: 0.8235294117647058\n",
      "Recall   : 0.8235294117647058\n",
      "F1 Score : 0.8235294117647058\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        82\n",
      "           1       0.82      0.82      0.82       102\n",
      "\n",
      "    accuracy                           0.80       184\n",
      "   macro avg       0.80      0.80      0.80       184\n",
      "weighted avg       0.80      0.80      0.80       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[64 18]\n",
      " [18 84]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "y_prob = mlp.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7442324",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 80.4%  \n",
    "- **Precision**: 82.4%  \n",
    "- **Recall**: **82.4%**  \n",
    "- **F1 Score**: 82.4%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 64           | 18           |\n",
    "| **Actual: 1** | 18           | 84           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **18**  \n",
    "- **True Positives (correct CVD detections)**: **84**  \n",
    "- **Recall (class 1 / CVD)** = 84 / (84 + 18) = **82.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model operates at a **balanced point**: precision and recall are essentially equal, suggesting symmetric treatment of positive predictions and missed cases.  \n",
    "- The error profile shows **18 false negatives** and **18 false positives**, indicating a relatively even trade-off between missing positives and raising false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8586956521739131\n",
      "Precision: 0.8877551020408163\n",
      "Recall   : 0.8529411764705882\n",
      "F1 Score : 0.87\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        82\n",
      "           1       0.89      0.85      0.87       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [15 87]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8410073",
   "metadata": {},
   "source": [
    "### MLP (Adam + EarlyStopping) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 85.9%  \n",
    "- **Precision**: 88.8%  \n",
    "- **Recall**: **85.3%**  \n",
    "- **F1 Score**: 87.0%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 71           | 11           |\n",
    "| **Actual: 1** | 15           | 87           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **15**  \n",
    "- **True Positives (correct CVD detections)**: **87**  \n",
    "- **Recall (class 1 / CVD)** = 87 / (87 + 15) = **85.3%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model operates at a **slightly precision-leaning** point: positive predictions are generally reliable while still capturing most positives.  \n",
    "- The error profile shows **balanced but non-trivial** false negatives (15) and false positives (11), indicating a fairly even trade-off between missing positives and triggering false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP (LBFGS)  Evaluation ===\n",
      "Accuracy : 0.8097826086956522\n",
      "Precision: 0.8316831683168316\n",
      "Recall   : 0.8235294117647058\n",
      "F1 Score : 0.8275862068965517\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.79        82\n",
      "           1       0.83      0.82      0.83       102\n",
      "\n",
      "    accuracy                           0.81       184\n",
      "   macro avg       0.81      0.81      0.81       184\n",
      "weighted avg       0.81      0.81      0.81       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[65 17]\n",
      " [18 84]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_lbfgs, \"MLP (LBFGS) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c9101e",
   "metadata": {},
   "source": [
    "### MLP (LBFGS) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 81.0%  \n",
    "- **Precision**: 83.2%  \n",
    "- **Recall**: **82.4%**  \n",
    "- **F1 Score**: 82.8%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 65           | 17           |\n",
    "| **Actual: 1** | 18           | 84           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **18**  \n",
    "- **True Positives (correct CVD detections)**: **84**  \n",
    "- **Recall (class 1 / CVD)** = 84 / (84 + 18) = **82.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model operates at a **balanced point**, with precision and recall both around the low 80s.  \n",
    "- Errors are relatively even: **17 false positives** and **18 false negatives**, indicating a symmetric trade-off between missed positives and false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.0001, 'hidden_layer_sizes': (128,), 'batch_size': 16, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "=== Best MLP Evaluation ===\n",
      "Accuracy : 0.8478260869565217\n",
      "Precision: 0.87\n",
      "Recall   : 0.8529411764705882\n",
      "F1 Score : 0.8613861386138614\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83        82\n",
      "           1       0.87      0.85      0.86       102\n",
      "\n",
      "    accuracy                           0.85       184\n",
      "   macro avg       0.85      0.85      0.85       184\n",
      "weighted avg       0.85      0.85      0.85       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[69 13]\n",
      " [15 87]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Improved MLP pipeline: recall-first tuning  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, recall_score, fbeta_score, make_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# 1) Recall-first search (Adam + early_stopping)\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # uses internal 15% validation\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=20,\n",
    "    max_iter=2000,                \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# multi-metric scoring; refit on recall-oriented F-beta\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "recall_best_mlp = rs.best_estimator_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "\n",
    "# 2) Evaluation\n",
    "y_prob = recall_best_mlp.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred_best_mlp = recall_best_mlp.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_best_mlp, model_name=f\"Best MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f6a1b",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison\n",
    "\n",
    "| Model                     | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline MLP**           | 0.804    | 0.824     | 0.824  | 0.824    | Moderate performance; balanced but weaker than other models (18 FP, 18 FN). |\n",
    "| **MLP (Adam + EarlyStopping)** | 0.859 | 0.888     | 0.853  | 0.870    | Strongest variant; higher accuracy and F1, reduced errors (11 FP, 15 FN). |\n",
    "| **MLP (LBFGS)**            | 0.810    | 0.832     | 0.824  | 0.828    | Similar to baseline; small improvements but still modest overall. |\n",
    "| **Best MLP (Grid Search)** | 0.848    | 0.870     | 0.853  | 0.861    | Well-optimized; close to EarlyStopping variant, but slightly lower accuracy. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline MLP** starts off with modest performance (~80% across all metrics), weaker compared to tree-based and KNN models.  \n",
    "- **MLP with Adam + EarlyStopping** performs **best overall** (Acc 85.9%, F1 0.87), showing improved stability and reduced overfitting.  \n",
    "- **MLP with LBFGS** brings little benefit compared to the baseline, suggesting this optimizer is not well-suited here.  \n",
    "- **Best MLP (Grid Search)** is competitive (Acc 84.8%, F1 0.861) and confirms that tuning improves MLP, but still slightly underperforms compared to the **Adam + EarlyStopping** variant.  \n",
    "\n",
    "--\n",
    "\n",
    "➡️ **Conclusion**: MLP can be tuned to perform decently, but even its best variants do not surpass **Random Forest** or **KNN with PCA**, which both achieve higher recall and accuracy. For fairness evaluation **MLP (Adam + EarlyStopping)** is the choice to proceed with.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "901f65e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Adam MLP→ adamMLP.pkl\n",
      "Saved predictions → HeartFailureData_75M25F_AdamMLP_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing MLP Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"adamMLP.pkl\"\n",
    "joblib.dump(adammlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from MLP\n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_mlp,\n",
    "    \"y_pred\": y_pred_mlp\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75M25F_AdamMLP_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Adam MLP→ {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
