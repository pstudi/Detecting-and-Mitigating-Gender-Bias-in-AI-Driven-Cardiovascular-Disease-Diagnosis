{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Mendeley Dataset (Source: https://data.mendeley.com/datasets/dzz48mvjht/1)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chestpain</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>serumcholestrol</th>\n",
       "      <th>fastingbloodsugar</th>\n",
       "      <th>restingrelectro</th>\n",
       "      <th>maxheartrate</th>\n",
       "      <th>exerciseangia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>noofmajorvessels</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>346.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>625</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>621</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  age  gender  chestpain  restingBP  serumcholestrol  \\\n",
       "0        151   20       1          1        170            352.0   \n",
       "1        373   51       1          2        176            346.0   \n",
       "2        625   60       0          0        131            164.0   \n",
       "3        621   67       0          1        172            461.0   \n",
       "4        469   74       0          2        127            420.0   \n",
       "\n",
       "   fastingbloodsugar  restingrelectro  maxheartrate  exerciseangia  oldpeak  \\\n",
       "0                  1                0           138              0      1.4   \n",
       "1                  0                2           160              1      2.0   \n",
       "2                  0                0            86              1      2.3   \n",
       "3                  0                1           134              0      0.8   \n",
       "4                  0                2           113              1      2.7   \n",
       "\n",
       "   slope  noofmajorvessels  target  \n",
       "0      1                 0       1  \n",
       "1      3                 3       1  \n",
       "2      1                 2       0  \n",
       "3      1                 1       0  \n",
       "4      2                 1       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_50_50.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"target\"\n",
    "SENSITIVE = \"gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['gender','chestpain','fastingbloodsugar','restingrelectro','exerciseangia','slope','noofmajorvessels']\n",
    "continuous_cols  = ['age','restingBP','serumcholestrol','maxheartrate','oldpeak']\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALE NUMERIC FEATURES ONLY \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1) fit scaler on TRAIN numeric columns only\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# 2) transform TEST with the same scaler\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) reassemble: raw categoricals + scaled numerics\n",
    "X_train_scaled = pd.concat([X_train[categorical_cols].reset_index(drop=True),\n",
    "                            X_train_num_scaled.reset_index(drop=True)], axis=1)\n",
    "X_test_scaled  = pd.concat([X_test[categorical_cols].reset_index(drop=True),\n",
    "                            X_test_num_scaled.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 22) (200, 22)\n"
     ]
    }
   ],
   "source": [
    "#onehot encode categorical, keep scaled numeric as is\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train_scaled[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train_scaled.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test_scaled.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_scaled[continuous_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_scaled[continuous_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.91\n",
      "Precision: 0.9454545454545454\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9203539823008849\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        84\n",
      "           1       0.95      0.90      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.91      0.91      0.91       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.945\n",
      "Precision: 0.9487179487179487\n",
      "Recall   : 0.9568965517241379\n",
      "F1 Score : 0.9527896995708155\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        84\n",
      "           1       0.95      0.96      0.95       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [  5 111]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d74d04",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.910  \n",
    "- **Precision:** 0.945  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.920  \n",
    "\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 78           | 6            |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed CVD)  \n",
    "- **False positives:** **6** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "High precision with solid recall; a moderate number of missed CVD cases (FN=12) and few false alarms (FP=6).\n",
    "\n",
    "---\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.945  \n",
    "- **Precision:** 0.949  \n",
    "- **Recall:** **0.957**  \n",
    "- **F1 Score:** 0.953  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 78           | 6            |\n",
    "| **Actual: 1** | 5            | 111          |\n",
    "\n",
    "- **False negatives:** **5** (missed CVD)  \n",
    "- **False positives:** **6** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "Strong, balanced results with **very high recall** and **few missed cases** (FN=5), while keeping false positives low.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Best CV F1: 0.959481418757759\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.935\n",
      "Precision: 0.963963963963964\n",
      "Recall   : 0.9224137931034483\n",
      "F1 Score : 0.9427312775330396\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        84\n",
      "           1       0.96      0.92      0.94       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.93      0.94      0.93       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80   4]\n",
      " [  9 107]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaff5c7",
   "metadata": {},
   "source": [
    "## KNN (Best Params)\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.935  \n",
    "- **Precision:** 0.964  \n",
    "- **Recall:** **0.922**  \n",
    "- **F1 Score:** 0.943  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 80           | 4            |\n",
    "| **Actual: 1** | 9            | 107          |\n",
    "\n",
    "- **False negatives:** **9** (missed CVD)  \n",
    "- **False positives:** **4** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned KNN achieves **very high precision** with **strong recall**, yielding few false alarms and a modest number of missed CVD cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 15 | Explained variance retained: 0.966\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.92\n",
      "Precision: 0.9716981132075472\n",
      "Recall   : 0.8879310344827587\n",
      "F1 Score : 0.9279279279279279\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91        84\n",
      "           1       0.97      0.89      0.93       116\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.93      0.92       200\n",
      "weighted avg       0.93      0.92      0.92       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 81   3]\n",
      " [ 13 103]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62921f88",
   "metadata": {},
   "source": [
    "### PCA + KNN\n",
    "\n",
    "**PCA components:** 15  \n",
    "**Explained variance retained:** **0.966**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.920  \n",
    "- **Precision:** 0.972  \n",
    "- **Recall:** **0.888**  \n",
    "- **F1 Score:** 0.928  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 81           | 3            |\n",
    "| **Actual: 1** | 13           | 103          |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "Dimensionality reduction to 15 components preserves **96.6%** of variance and yields a model that **prioritizes precision** (very few false alarms) with **good but lower recall** (some missed CVD cases).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e1d05",
   "metadata": {},
   "source": [
    "# KNN Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "## 1. Baseline KNN\n",
    "- **Accuracy**: 0.91  \n",
    "- **Precision**: 0.945  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.920  \n",
    "- **Confusion Matrix**: [[78, 6], [12, 104]]\n",
    "\n",
    "**Interpretation:**  \n",
    "Balanced model with high precision and solid accuracy. Recall is just under 90%, which means 12 CVD-positive patients were missed. Good, but slightly below the desired sensitivity for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Best KNN (Tuned: `n_neighbors=1`, `metric=manhattan`, `weights=uniform`)\n",
    "- **Accuracy**: **0.935 (highest)**  \n",
    "- **Precision**: 0.964  \n",
    "- **Recall**: **0.922 (highest)**  \n",
    "- **F1**: **0.943 (highest)**  \n",
    "- **Confusion Matrix**: [[80, 4], [9, 107]]\n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned KNN is clearly the strongest variant: recall increases to ~92%, reducing missed positives to 9. Accuracy and F1 are also the best among the three, while precision remains very high. This is the **best-balanced KNN** for CVD diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. PCA + KNN (15 components, 96.6% variance retained)\n",
    "- **Accuracy**: 0.92  \n",
    "- **Precision**: **0.972 (highest)**  \n",
    "- **Recall**: 0.888 (lowest)  \n",
    "- **F1**: 0.928  \n",
    "- **Confusion Matrix**: [[81, 3], [13, 103]]\n",
    "\n",
    "**Interpretation:**  \n",
    "This version achieves excellent precision but sacrifices recall, dropping to ~89% (13 missed positives). PCA helps with dimensionality reduction but in this case reduces sensitivity. Not ideal when recall is the top priority.\n",
    "\n",
    "---\n",
    "\n",
    "###  Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|--------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Best KNN (tuned)** | **0.935** | 0.964     | **0.922** | **0.943** | **9** |\n",
    "| Baseline KNN       | 0.91     | 0.945     | 0.897  | 0.920 | 12 |\n",
    "| PCA + KNN          | 0.92     | **0.972** | 0.888  | 0.928 | 13 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- **Best KNN (tuned)** is the top choice: highest recall (92%), accuracy, and F1. Best suited for diagnosis where sensitivity is critical.  \n",
    "- **Baseline KNN** performs decently but misses more positives.  \n",
    "- **PCA + KNN** over-optimizes for precision but at the expense of recall, making it less suitable for medical screening tasks.  \n",
    "\n",
    "**Decision within the KNN family:** Use the **tuned KNN** for CVD diagnosis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bf66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned KNN model → knn_best_model.pkl\n",
      "Saved predictions → MendeleyData_50_50_KNN_best_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series (not a DataFrame)\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"knn_best_model.pkl\"\n",
    "joblib.dump(best_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_knn_best \n",
    "y_prob = y_prob_knn_best \n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob,\n",
    "    \"y_pred\": y_pred\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_50_50_KNN_best_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best CV F1: 0.95\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.95\n",
      "Precision: 0.9568965517241379\n",
      "Recall   : 0.9568965517241379\n",
      "F1 Score : 0.9568965517241379\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        84\n",
      "           1       0.96      0.96      0.96       116\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.95       200\n",
      "weighted avg       0.95      0.95      0.95       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 79   5]\n",
      " [  5 111]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3506f65",
   "metadata": {},
   "source": [
    "## Decision Tree: Tuned\n",
    "\n",
    "**Best DT params**: `{'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 1, 'min_samples_split': 2}`  \n",
    "**Best CV F1**: **0.95**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.950  \n",
    "- **Precision:** 0.957  \n",
    "- **Recall:** **0.957**  \n",
    "- **F1 Score:** 0.957  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 79           | 5            |\n",
    "| **Actual: 1** | 5            | 111          |\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "This tuned tree shows **excellent, symmetric performance**: high precision and recall (~0.957) with a **balanced error profile** (5 FN, 5 FP). Specificity (~0.941) remains strong while maintaining high sensitivity, making this a **robust screening model** with low risk of missed CVD and limited false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 6, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.9466666666666667\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9467\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.94\n",
      "Precision: 0.9333333333333333\n",
      "Recall   : 0.9655172413793104\n",
      "F1 Score : 0.9491525423728814\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93        84\n",
      "           1       0.93      0.97      0.95       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 76   8]\n",
      " [  4 112]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# Stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0fdb1",
   "metadata": {},
   "source": [
    "### Decision Tree: Alternative Tuned & Pruned\n",
    "\n",
    "**Stage A — Best simple DT params**: `{'criterion': 'gini', 'max_depth': 6, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5}`  \n",
    "**Stage A — Best CV Recall**: **0.9467**  \n",
    "**Stage B — Best `ccp_alpha`**: **0.000000** | **CV Recall**: **0.9467**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.940  \n",
    "- **Precision:** 0.933  \n",
    "- **Recall:** **0.966**  \n",
    "- **F1 Score:** 0.949  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 76           | 8            |\n",
    "| **Actual: 1** | 4            | 112          |\n",
    "\n",
    "- **False negatives (missed CVD):** **4**  \n",
    "- **False positives (healthy flagged):** **8**  \n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "The pruned decision tree is tuned toward **high sensitivity**, capturing nearly all CVD cases (**recall ≈ 0.966**) with **very few misses** (4 FN). This comes with a **modest** number of false positives (8 FP), reflected in **specificity ≈ 0.905** and **precision ≈ 0.933**. Overall performance is **well balanced** (F1 ≈ 0.949, balanced accuracy ≈ 0.936), suitable when **avoiding missed CVD** is a priority.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5f0a06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'entropy', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.97\n",
      "Stage B — Best ccp_alpha: 0.020588 | CV Recall: 0.9850\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.935\n",
      "Precision: 0.963963963963964\n",
      "Recall   : 0.9224137931034483\n",
      "F1 Score : 0.9427312775330396\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        84\n",
      "           1       0.96      0.92      0.94       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.93      0.94      0.93       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80   4]\n",
      " [  9 107]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_classweight_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred_alt_classweight = alt_classweight_best_dt.predict(X_test_ready)               \n",
    "y_prob_alt_classweight = alt_classweight_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bcbaf8",
   "metadata": {},
   "source": [
    "### Decision Tree Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline Decision Tree\n",
    "- **Accuracy**: 0.945  \n",
    "- **Precision**: 0.949  \n",
    "- **Recall**: 0.957  \n",
    "- **F1**: 0.953  \n",
    "- **Confusion Matrix**: [[78, 6], [5, 111]]\n",
    "\n",
    "**Interpretation:**  \n",
    "A strong baseline: very high recall (~96%), excellent accuracy and precision. Misses only 5 positives. Already a highly reliable model for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Decision Tree (`criterion='entropy', max_depth=7, min_samples_split=2, min_samples_leaf=1`)\n",
    "- **Accuracy**: **0.950**  \n",
    "- **Precision**: 0.957  \n",
    "- **Recall**: 0.957  \n",
    "- **F1**: **0.957**  \n",
    "- **Confusion Matrix**: [[79, 5], [5, 111]]\n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned DT performs almost identically to the baseline, with slightly stronger balance in accuracy and F1. Still misses 5 positives. Very stable and strong, but not clearly superior in recall.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Alternative Tuned & Pruned DT (`gini`, `max_depth=6`, `min_samples_leaf=2`)**\n",
    "- **Accuracy**: 0.940  \n",
    "- **Precision**: 0.933  \n",
    "- **Recall**: **0.966 (highest among balanced models)**  \n",
    "- **F1**: 0.949  \n",
    "- **Confusion Matrix**: [[76, 8], [4, 112]]\n",
    "\n",
    "**Interpretation:**  \n",
    "This model achieves the **best recall (~97%)** among the balanced DTs, missing only 4 positives. Accuracy (94%) and precision (93%) remain strong, making it the most **clinically useful compromise** between sensitivity and overall reliability.  \n",
    "➡️ **Recommended Decision Tree variant.**\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Class-Weighted Tuned & Pruned DT (`class_weight={0:1, 1:4}`, `max_depth=4`, `min_samples_leaf=6`)\n",
    "- **Accuracy**: 0.825 (lowest)  \n",
    "- **Precision**: 0.776 (lowest)  \n",
    "- **Recall**: **0.983 (highest overall)**  \n",
    "- **F1**: 0.867  \n",
    "- **Confusion Matrix**: [[51, 33], [2, 114]]\n",
    "\n",
    "**Interpretation:**  \n",
    "Maximizes recall (~98%) with only 2 missed positives. However, accuracy drops sharply (~82%) and false positives increase drastically (33). Too aggressive for diagnosis — more suitable for broad screening.\n",
    "\n",
    "---\n",
    "\n",
    "###  Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|--------------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| Class-Weighted Tuned & Pruned DT     | 0.825    | 0.776     | **0.983** | 0.867 | **2** |\n",
    "| **Alt. Tuned & Pruned DT**           | **0.940**    | **0.933**     | **0.966**  | 0.949 | 4 |\n",
    "| Tuned DT (best params)               | **0.950** | 0.957     | 0.957  | 0.957 | 5 |\n",
    "| Baseline DT                          | 0.945    | 0.949     | 0.957  | 0.953 | 5 |\n",
    "\n",
    "---\n",
    "\n",
    "###  Final Takeaway\n",
    "- **Alt. Tuned & Pruned DT** is the **recommended model**: recall is very high (97%), while accuracy (94%) and precision (93%) remain strong. It offers the best balance for diagnosis.  \n",
    "- **Class-Weighted DT** achieves maximum recall but sacrifices too much accuracy/precision — better for screening.  \n",
    "- **Tuned DT** and **Baseline DT** are also strong, but slightly less sensitive (miss 5 positives instead of 4).  \n",
    "\n",
    " **Final Decision:** For diagnosis, choose the **Alt. Tuned & Pruned Decision Tree**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf663b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned pruned DT model → alt_tuned_pruned_dt_model.pkl\n",
      "Saved predictions → MendeleyData_50_50_DT_pruned_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"alt_tuned_pruned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "# Use tuned predictions/probabilities from the best estimator\n",
    "y_pred = y_pred_dt\n",
    "y_prob = y_prob_dt \n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\": y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_50_50_DT_pruned_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned pruned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.94\n",
      "Precision: 0.9482758620689655\n",
      "Recall   : 0.9482758620689655\n",
      "F1 Score : 0.9482758620689655\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        84\n",
      "           1       0.95      0.95      0.95       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [  6 110]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248f091",
   "metadata": {},
   "source": [
    "### Random Forest — Evaluation \n",
    "\n",
    "### Metrics\n",
    "- **Accuracy:** 0.940  \n",
    "- **Precision (PPV):** 0.948  \n",
    "- **Recall:** **0.948**  \n",
    "- **F1 Score:** 0.948  \n",
    "\n",
    "**Classification Report (per class)**\n",
    "- Class **0**: precision 0.93, recall 0.93, f1 0.93  \n",
    "- Class **1**: precision 0.95, recall 0.95, f1 0.95  \n",
    "\n",
    "**Confusion Matrix**\n",
    "|               | Pred 0 | Pred 1 |\n",
    "|--------------:|-------:|-------:|\n",
    "| **Actual 0**  | 78     | 6      |\n",
    "| **Actual 1**  | 6      | 110    |\n",
    "\n",
    "\n",
    "### Interpretation\n",
    "- The model is **well-calibrated*: high and symmetric **precision** and **recall** for the positive class, with **balanced errors** across classes.\n",
    "- **Clinical impact**: only **6 missed CVD cases** (FN), while keeping **false alarms** at **6**—a favorable trade-off for CVD diasgnosis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV Recall: 0.9800000000000001\n",
      "=== Random Forest (best) Evaluation ===\n",
      "Accuracy : 0.94\n",
      "Precision: 0.9482758620689655\n",
      "Recall   : 0.9482758620689655\n",
      "F1 Score : 0.9482758620689655\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        84\n",
      "           1       0.95      0.95      0.95       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.94      0.94       200\n",
      "weighted avg       0.94      0.94      0.94       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [  6 110]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",     # recall-focused\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV Recall:\", grid.best_score_)\n",
    "\n",
    "# Evaluate best RF \n",
    "y_pred_rf_tuned = best_rf.predict(X_test_ready)\n",
    "y_prob_rf_tuned = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf_tuned, \"Random Forest (best)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9742a5",
   "metadata": {},
   "source": [
    "### Random Forest Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline Random Forest\n",
    "- **Accuracy**: 0.94  \n",
    "- **Precision**: 0.948  \n",
    "- **Recall**: 0.948  \n",
    "- **F1**: 0.948  \n",
    "- **Confusion Matrix**: [[78, 6], [6, 110]]\n",
    "\n",
    "**Interpretation:**  \n",
    "An excellent baseline: accuracy, precision, recall, and F1 are all ~95%. Only 6 false negatives (missed CVD cases). Very strong overall balance.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Random Forest (Best Params: `n_estimators=200`, `max_features='sqrt'`, `max_depth=None`)\n",
    "- **Accuracy**: 0.94  \n",
    "- **Precision**: 0.948  \n",
    "- **Recall**: 0.948  \n",
    "- **F1**: 0.948  \n",
    "- **Confusion Matrix**: [[78, 6], [6, 110]]\n",
    "\n",
    "**Interpretation:**  \n",
    "Despite extensive tuning, performance is **identical to the baseline RF**. The recall-focused cross-validation suggested high potential (CV recall ≈ 98%), but on the test set the tuned model converged to the same results as the baseline. This suggests that the RF is already robust, and further tuning did not yield measurable gains on this dataset.\n",
    "\n",
    "---\n",
    "\n",
    "###  Final Takeaway\n",
    "- Both the **Baseline RF** and **Tuned RF** deliver **excellent, identical performance**: ~95% recall and only 6 missed positives.  \n",
    "- Hyperparameter tuning did not improve generalization, showing that the **default RF setup is already optimal** for this dataset.  \n",
    "- **Clinical decision:** Random Forest is a **highly reliable model family** here — strong recall, precision, and overall accuracy.  \n",
    "\n",
    "➡️ Between the two, either can be chosen; practically, the **Baseline RF** is simpler and equally effective - therefore we will save the baseline model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Baseline RF model → rf_baseline_model.pkl\n",
      "Saved predictions → MendeleyData_50_50_baselineRF_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned Random Forest Results for fairness evaluation\n",
    "\n",
    "# Save tuned Random Forest model\n",
    "model_filename = \"rf_baseline_model.pkl\"\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_rf \n",
    "y_prob = y_prob_rf \n",
    "\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\" :y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_50_50_baselineRF_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Baseline RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.92\n",
      "Precision: 0.9464285714285714\n",
      "Recall   : 0.9137931034482759\n",
      "F1 Score : 0.9298245614035088\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91        84\n",
      "           1       0.95      0.91      0.93       116\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [ 10 106]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978071f",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) — Evaluation \n",
    "\n",
    "### Metrics\n",
    "- **Accuracy:** 0.920  \n",
    "- **Precision (PPV):** 0.946  \n",
    "- **Recall (Sensitivity):** **0.914**  \n",
    "- **F1 Score:** 0.930  \n",
    "- **Support:** 0→84 (negative), 1→116 (positive)\n",
    "\n",
    "**Classification Report (per class)**\n",
    "- Class **0**: precision 0.89, recall 0.93, f1 0.91  \n",
    "- Class **1**: precision 0.95, recall 0.91, f1 0.93  \n",
    "- **Macro / Weighted avg:** ~0.92 across the board → balanced performance\n",
    "\n",
    "**Confusion Matrix**\n",
    "|               | Pred 0 | Pred 1 |\n",
    "|--------------:|-------:|-------:|\n",
    "| **Actual 0**  | 78     | 6      |\n",
    "| **Actual 1**  | 10     | 106    |\n",
    "\n",
    "### Interpretation\n",
    "- **Strong, balanced performance** with high precision and solid recall; errors are well controlled across classes.\n",
    "- **Clinical impact:** **10** missed CVD cases (FN) and **6** false alarms (FP), which is a reasonable trade-off for CVD screening.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df8a33fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.915\n",
      "Precision: 0.9459459459459459\n",
      "Recall   : 0.9051724137931034\n",
      "F1 Score : 0.9251101321585903\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        84\n",
      "           1       0.95      0.91      0.93       116\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.91      0.92      0.91       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [ 11 105]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.895\n",
      "Precision: 0.9279279279279279\n",
      "Recall   : 0.8879310344827587\n",
      "F1 Score : 0.9074889867841409\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        84\n",
      "           1       0.93      0.89      0.91       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.89      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 76   8]\n",
      " [ 13 103]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_lbfgs, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.0003, 'hidden_layer_sizes': (128,), 'batch_size': 32, 'alpha': 0.0003, 'activation': 'relu'}\n",
      "Best CV F-beta (β=2): 0.9617\n",
      "Corresponding CV Recall: 0.9600\n",
      "Corresponding CV F1: 0.9646\n",
      "=== Best MLP (Adam) Evaluation ===\n",
      "Accuracy : 0.925\n",
      "Precision: 0.954954954954955\n",
      "Recall   : 0.9137931034482759\n",
      "F1 Score : 0.933920704845815\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        84\n",
      "           1       0.95      0.91      0.93       116\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.92      0.93      0.92       200\n",
      "weighted avg       0.93      0.93      0.93       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 79   5]\n",
      " [ 10 106]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall-first MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, recall_score, fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# 1) Base model: Adam\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=False,      \n",
    "    max_iter=1000,             # observed full convergence at 1000\n",
    "    tol=1e-4,                  # default; tighten if you like (e.g., 1e-5)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "# Optional: summarize CV metrics for the selected config\n",
    "best_idx = rs.best_index_\n",
    "cvres = rs.cv_results_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "print(f\"Corresponding CV Recall: {cvres['mean_test_recall'][best_idx]:.4f}\")\n",
    "print(f\"Corresponding CV F1: {cvres['mean_test_f1'][best_idx]:.4f}\")\n",
    "\n",
    "# 2) Evaluate on test \n",
    "recall_first_y_pred = best_mlp.predict(X_test_ready)\n",
    "recall_first_y_prob = best_mlp.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, recall_first_y_pred, model_name=\"Best MLP (Adam)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe26d301",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline MLP (Adam)\n",
    "- **Accuracy**: 0.92  \n",
    "- **Precision**: 0.946  \n",
    "- **Recall**: 0.914  \n",
    "- **F1**: 0.930  \n",
    "- **Confusion Matrix**: [[78, 6], [10, 106]]\n",
    "\n",
    "**Interpretation:**  \n",
    "A solid model with good balance. Recall (~91%) means 10 positives are missed. Accuracy and precision are both strong. Good baseline, but not the top performer in sensitivity.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. MLP (Adam + EarlyStopping)\n",
    "- **Accuracy**: 0.915  \n",
    "- **Precision**: 0.946  \n",
    "- **Recall**: 0.905  \n",
    "- **F1**: 0.925  \n",
    "- **Confusion Matrix**: [[78, 6], [11, 105]]\n",
    "\n",
    "**Interpretation:**  \n",
    "Recall drops slightly (~90.5%), with 11 missed positives. Performance is stable, but slightly weaker than the baseline Adam MLP. The benefit is better generalization control (avoiding overfitting), but at the cost of a bit of sensitivity.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. MLP (LBFGS Solver, `tanh`)\n",
    "- **Accuracy**: 0.895 (lowest)  \n",
    "- **Precision**: 0.928  \n",
    "- **Recall**: 0.888 (lowest)  \n",
    "- **F1**: 0.907  \n",
    "- **Confusion Matrix**: [[76, 8], [13, 103]]\n",
    "\n",
    "**Interpretation:**  \n",
    "This configuration underperforms: lowest recall (~89%) and accuracy. It misses 13 positives, which is not ideal for diagnosis. Shows that LBFGS+tanh is less suited for this dataset compared to Adam.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Best MLP (Tuned Adam: `hidden_layer_sizes=(128,)`, `relu`, `alpha=0.0003`)\n",
    "- **Accuracy**: **0.925 (highest)**  \n",
    "- **Precision**: **0.955 (highest)**  \n",
    "- **Recall**: 0.914  \n",
    "- **F1**: **0.934 (highest)**  \n",
    "- **Confusion Matrix**: [[79, 5], [10, 106]]\n",
    "\n",
    "**Interpretation:**  \n",
    "This tuned model is the strongest performer: excellent precision (95.5%), very high recall (~91%), and the best F1 overall (0.934). It misses 10 positives, same as baseline, but overall balance is superior.  \n",
    "➡️ **Best-performing MLP variant.**\n",
    "\n",
    "---\n",
    "\n",
    "###  Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                         | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|-------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| Baseline MLP (Adam)           | 0.920    | 0.946     | 0.914  | 0.930 | 10 |\n",
    "| Best MLP (Adam, tuned relu)   | **0.925**| **0.955** | 0.914  | **0.934** | 10 |\n",
    "| MLP (Adam + EarlyStopping)    | 0.915    | 0.946     | 0.905  | 0.925 | 11 |\n",
    "| MLP (LBFGS, tanh)             | 0.895    | 0.928     | **0.888 (lowest)** | 0.907 | 13 |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "- **Best MLP (Adam, tuned relu)** is the **recommended MLP variant**: it combines strong recall (~91%) with the best overall balance (highest precision, accuracy, and F1).  \n",
    "- **Baseline MLP (Adam)** is also reliable, only slightly weaker in overall metrics.  \n",
    "- **MLP with EarlyStopping** trades a bit of recall for regularization stability.  \n",
    "- **LBFGS (tanh)** underperforms — lower recall and accuracy, making it the weakest option here.  \n",
    "\n",
    " **Final Decision within MLP family:** Choose the **Tuned Adam MLP (relu, 128 hidden units)** for diagnosis.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved recall-first tuned MLP model → recall_first_tuned_mlp.pkl\n",
      "Saved predictions → MendeleyData_50_50_MLP_recallfirst_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Recall-First Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned MLP model\n",
    "model_filename = \"recall_first_tuned_mlp.pkl\"\n",
    "joblib.dump(best_mlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and use predictions from the recall-first MLP\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred_mlp = recall_first_y_pred\n",
    "y_prob_mlp = recall_first_y_prob\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred_mlp,\n",
    "    \"y_prob\": y_prob_mlp\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_50_50_MLP_recallfirst_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved recall-first tuned MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
