{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Mendeley Dataset (Source: https://data.mendeley.com/datasets/dzz48mvjht/1)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chestpain</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>serumcholestrol</th>\n",
       "      <th>fastingbloodsugar</th>\n",
       "      <th>restingrelectro</th>\n",
       "      <th>maxheartrate</th>\n",
       "      <th>exerciseangia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>noofmajorvessels</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>291.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>506</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>530</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>684</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>191</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  age  gender  chestpain  restingBP  serumcholestrol  \\\n",
       "0        744   20       1          0        137            291.0   \n",
       "1          6   33       1          0         97            354.0   \n",
       "2        506   65       1          0        127            258.0   \n",
       "3        530   24       0          0        136            164.0   \n",
       "4        684   80       0          1        191            433.0   \n",
       "\n",
       "   fastingbloodsugar  restingrelectro  maxheartrate  exerciseangia  oldpeak  \\\n",
       "0                  0                0           131              1      3.8   \n",
       "1                  0                0           160              0      2.1   \n",
       "2                  0                0           158              0      4.1   \n",
       "3                  0                0            91              1      1.8   \n",
       "4                  1                1           154              1      3.2   \n",
       "\n",
       "   slope  noofmajorvessels  target  \n",
       "0      1                 0       0  \n",
       "1      2                 1       0  \n",
       "2      1                 3       0  \n",
       "3      1                 1       0  \n",
       "4      3                 3       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_25M_75F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"target\"\n",
    "SENSITIVE = \"Gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['gender','chestpain','fastingbloodsugar','restingrelectro','exerciseangia','slope','noofmajorvessels']\n",
    "continuous_cols  = ['age','restingBP','serumcholestrol','maxheartrate','oldpeak']\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train numeric means (≈0):\n",
      "age               -0.0\n",
      "restingBP          0.0\n",
      "serumcholestrol   -0.0\n",
      "maxheartrate      -0.0\n",
      "oldpeak            0.0\n",
      "dtype: float64\n",
      "\n",
      "Train numeric stds (≈1):\n",
      "age                1.0\n",
      "restingBP          1.0\n",
      "serumcholestrol    1.0\n",
      "maxheartrate       1.0\n",
      "oldpeak            1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SCALE NUMERIC FEATURES ONLY \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1) fit scaler on TRAIN numeric columns only\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# 2) transform TEST with the same scaler\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) reassemble: raw categoricals + scaled numerics\n",
    "X_train_scaled = pd.concat([X_train[categorical_cols].reset_index(drop=True),\n",
    "                            X_train_num_scaled.reset_index(drop=True)], axis=1)\n",
    "X_test_scaled  = pd.concat([X_test[categorical_cols].reset_index(drop=True),\n",
    "                            X_test_num_scaled.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# OPTIONAL: quick sanity checks\n",
    "print(\"Train numeric means (≈0):\")\n",
    "print(X_train_scaled[continuous_cols].mean().round(3))\n",
    "print(\"\\nTrain numeric stds (≈1):\")\n",
    "print(X_train_scaled[continuous_cols].std(ddof=0).round(3))\n",
    "\n",
    "# save for later steps\n",
    "X_train_scaled.to_csv(\"data_subsets/train_75M_25F_scaled_only.csv\", index=False)\n",
    "#X_test_scaled.to_csv(\"data_splits/X_test_scaled_only.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 22) (200, 22)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode categoricals, keep scaled numerics as is \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train_scaled[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train_scaled.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test_scaled.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_scaled[continuous_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_scaled[continuous_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.89\n",
      "Precision: 0.9122807017543859\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9043478260869565\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        84\n",
      "           1       0.91      0.90      0.90       116\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 74  10]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.9\n",
      "Precision: 0.9444444444444444\n",
      "Recall   : 0.8793103448275862\n",
      "F1 Score : 0.9107142857142857\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89        84\n",
      "           1       0.94      0.88      0.91       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [ 14 102]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]     \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c7391d",
   "metadata": {},
   "source": [
    "## KNN\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.890  \n",
    "- **Precision:** 0.912  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.904  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 74           | 10           |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed CVD)  \n",
    "- **False positives:** **10** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "Balanced performance with **high precision** and **good recall**; a moderate number of missed CVD cases and false alarms.\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.900  \n",
    "- **Precision:** 0.944  \n",
    "- **Recall:** **0.879**  \n",
    "- **F1 Score:** 0.911  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 78           | 6            |\n",
    "| **Actual: 1** | 14           | 102          |\n",
    "\n",
    "- **False negatives:** **14** (missed CVD)  \n",
    "- **False positives:** **6** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "Strong **precision** with slightly lower recall; fewer false alarms but more missed CVD cases.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}\n",
      "Best CV F1: 0.978150785738024\n",
      "=== KNN (best params Evaluation ===\n",
      "Accuracy : 0.895\n",
      "Precision: 0.9279279279279279\n",
      "Recall   : 0.8879310344827587\n",
      "F1 Score : 0.9074889867841409\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        84\n",
      "           1       0.93      0.89      0.91       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.89      0.90      0.89       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 76   8]\n",
      " [ 13 103]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit on your READY features\n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491c4a54",
   "metadata": {},
   "source": [
    "### KNN: Tuned\n",
    "\n",
    "**Best KNN params**: `{'metric': 'manhattan', 'n_neighbors': 1, 'weights': 'uniform'}`  \n",
    "**Best CV F1**: **0.9782**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.895  \n",
    "- **Precision:** 0.928  \n",
    "- **Recall:** **0.888**  \n",
    "- **F1 Score:** 0.907  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 76           | 8            |\n",
    "| **Actual: 1** | 13           | 103          |\n",
    "\n",
    "- **False negatives:** **13** (missed CVD)  \n",
    "- **False positives:** **8** (healthy flagged)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "The tuned KNN with a 0.5 threshold achieves **high precision** and **strong recall**, indicating few false alarms alongside a **manageable number of missed CVD cases**. This reflects a balanced operating point suitable for screening.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 15 | Explained variance retained: 0.966\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.88\n",
      "Precision: 0.9107142857142857\n",
      "Recall   : 0.8793103448275862\n",
      "F1 Score : 0.8947368421052632\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86        84\n",
      "           1       0.91      0.88      0.89       116\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 74  10]\n",
      " [ 14 102]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc2764f",
   "metadata": {},
   "source": [
    "### PCA + KNN\n",
    "\n",
    "**PCA components:** 15  \n",
    "**Explained variance retained:** **0.966**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.880  \n",
    "- **Precision:** 0.911  \n",
    "- **Recall:** **0.879**  \n",
    "- **F1 Score:** 0.895  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 74           | 10           |\n",
    "| **Actual: 1** | 14           | 102          |\n",
    "\n",
    "- **False negatives:** **14** (missed CVD)  \n",
    "- **False positives:** **10** (healthy flagged)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "Reducing dimensionality to 15 components preserves **96.6%** of variance and yields **balanced performance**: high precision with **good** (though not maximal) recall. The error profile (FN=14, FP=10) suggests a moderate tendency to **miss some CVD cases** while keeping false alarms controlled. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5772f424",
   "metadata": {},
   "source": [
    "# KNN Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "## 1. Baseline KNN\n",
    "- **Accuracy**: 0.89  \n",
    "- **Precision**: 0.91  \n",
    "- **Recall**: **0.90** (highest)  \n",
    "- **F1**: 0.90  \n",
    "- **Confusion Matrix**: [[74, 10], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "This model achieves the **highest recall** of all variants (~90%), meaning it misses the fewest CVD-positive patients (FN = 12). For medical diagnosis, this is crucial — better to flag more patients for further testing than to overlook cases.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Best KNN (Tuned Params: `n_neighbors=1`, `metric=manhattan`, `weights=uniform`)\n",
    "- **Accuracy**: 0.895  \n",
    "- **Precision**: **0.93** (highest)  \n",
    "- **Recall**: 0.89  \n",
    "- **F1**: **0.91**  \n",
    "- **Confusion Matrix**: [[76, 8], [13, 103]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Tuning improves precision and F1 slightly but recall **drops below the baseline**. This model is more conservative (fewer false positives) but misses **more true CVD cases** (FN = 13). In a clinical setting, that trade-off may not be acceptable if sensitivity is the main concern.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. PCA + KNN (15 Components, 96.6% Variance Retained)\n",
    "- **Accuracy**: 0.88  \n",
    "- **Precision**: 0.91  \n",
    "- **Recall**: 0.88 (lowest)  \n",
    "- **F1**: 0.89  \n",
    "- **Confusion Matrix**: [[74, 10], [14, 102]]\n",
    "\n",
    "**Interpretation**:  \n",
    "PCA reduces recall further (FN = 14). While dimensionality reduction retains most variance, it seems to lose subtle discriminative information critical for catching all positive cases. This makes it the **least favorable** for medical diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview Table \n",
    "\n",
    "| Model                  | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|-------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Baseline KNN**        | 0.89     | 0.91      | **0.90** | 0.90 | **12** |\n",
    "| Best KNN (Tuned Params) | 0.895    | **0.93**  | 0.89   | **0.91** | 13 |\n",
    "| PCA + KNN (15 comps)    | 0.88     | 0.91      | 0.88   | 0.89 | 14 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- **Baseline KNN** is the most clinically appropriate choice, as it maximizes **recall** and minimizes missed diagnoses.  \n",
    "- **Best KNN (tuned)** offers higher precision and F1, but at the cost of slightly lower recall — more CVD patients would be missed.  \n",
    "- **PCA+KNN** performs worst in terms of recall and should be avoided for diagnosis-focused tasks.  \n",
    "\n",
    "For **CVD screening**, we prioritize catching every possible case (high recall), even if it means accepting some false alarms. Thus, **Baseline KNN** is the preferred model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3ac7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved KNN model → knn_model.pkl\n",
      "Saved predictions → MendeleyData_75F25M_KNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save KNN model\n",
    "model_filename = \"knn_model.pkl\"\n",
    "joblib.dump(knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and use KNN predictions/probabilities\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = knn.predict(X_test_ready)\n",
    "y_prob = knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_knn\": y_pred,\n",
    "    \"y_prob_knn\": y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75F25M_KNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Best CV F1: 0.9766666666666668\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.9\n",
      "Precision: 0.9\n",
      "Recall   : 0.9310344827586207\n",
      "F1 Score : 0.9152542372881356\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        84\n",
      "           1       0.90      0.93      0.92       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.89      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 72  12]\n",
      " [  8 108]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc58563",
   "metadata": {},
   "source": [
    "### Decision Tree: Tuned\n",
    "\n",
    "**Best DT params**: `{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}`  \n",
    "**Best CV F1**: **0.9767**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.900  \n",
    "- **Precision:** 0.900  \n",
    "- **Recall:** **0.931**  \n",
    "- **F1 Score:** 0.915  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 72           | 12           |\n",
    "| **Actual: 1** | 8            | 108          |\n",
    "\n",
    "- **False negatives (missed CVD):** **8**  \n",
    "- **False positives (healthy flagged):** **12**  \n",
    "- **Specificity (class 0):** ~0.857 (72/84)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "- The model is tuned toward **high sensitivity**, capturing most CVD cases (**recall ≈ 0.931**) with **8** misses.\n",
    "- **Precision = 0.90** indicates a **moderate false-positive burden** (**12** cases), a common trade-off when prioritizing recall.\n",
    "- Overall **accuracy (0.90)** and **F1 (0.915)** reflect a balanced setup suitable when **avoiding missed CVD** is more critical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 5, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "Stage A — Best CV Recall: 0.97\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9700\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.9\n",
      "Precision: 0.9\n",
      "Recall   : 0.9310344827586207\n",
      "F1 Score : 0.9152542372881356\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        84\n",
      "           1       0.90      0.93      0.92       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.89      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 72  12]\n",
      " [  8 108]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1] \n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e00f10",
   "metadata": {},
   "source": [
    "## Decision Tree: Alternative Tuned & Pruned\n",
    "\n",
    "**Stage A — Best simple DT params**: `{'criterion': 'gini', 'max_depth': 5, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 10}`  \n",
    "**Stage A — Best CV Recall**: **0.9700**  \n",
    "**Stage B — Best `ccp_alpha`**: **0.000000** | **CV Recall**: **0.9700**\n",
    "\n",
    "---\n",
    "\n",
    "### Test Evaluation\n",
    "- **Accuracy:** 0.900  \n",
    "- **Precision:** 0.900  \n",
    "- **Recall:** **0.931**  \n",
    "- **F1 Score:** 0.915  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 72           | 12           |\n",
    "| **Actual: 1** | 8            | 108          |\n",
    "\n",
    "- **False negatives:** **8** (missed CVD)  \n",
    "- **False positives:** **12** (healthy flagged)  \n",
    "\n",
    "**Interpretation:**  \n",
    "The pruned DT emphasizes **high recall**—it captures most CVD cases (FN=8)—with **moderate precision** and some increase in false positives (FP=12). This model suits scenarios where **missing CVD is costlier** than extra follow-ups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4620f277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 6, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Stage A — Best CV Recall: 0.9817\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9817\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.9\n",
      "Precision: 0.8934426229508197\n",
      "Recall   : 0.9396551724137931\n",
      "F1 Score : 0.9159663865546218\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88        84\n",
      "           1       0.89      0.94      0.92       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.89      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 71  13]\n",
      " [  7 109]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c12e2",
   "metadata": {},
   "source": [
    "### Decision Tree Model Comparison (CVD Diagnosis) \n",
    "\n",
    "### 1. Baseline Decision Tree\n",
    "- **Accuracy**: 0.90  \n",
    "- **Precision**: **0.94** (highest)  \n",
    "- **Recall**: 0.879 (lowest)  \n",
    "- **F1**: 0.911  \n",
    "- **Confusion Matrix**: [[78, 6], [14, 102]]\n",
    "\n",
    "**Interpretation**:  \n",
    "High precision but lower recall (misses 14 CVD patients). Not ideal for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Decision Tree (Best Params: `gini`, `max_depth=5`, `min_samples_split=10`, `min_samples_leaf=1`)\n",
    "- **Accuracy**: 0.90  \n",
    "- **Precision**: 0.90  \n",
    "- **Recall**: 0.931  \n",
    "- **F1**: 0.915  \n",
    "- **Confusion Matrix**: [[72, 12], [8, 108]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Much better balance — recall improves to ~93%, halving false negatives compared to the baseline.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Alternative Tuned & Pruned DT (same params, simplified tree)\n",
    "- **Accuracy**: 0.90  \n",
    "- **Precision**: 0.90  \n",
    "- **Recall**: 0.931  \n",
    "- **F1**: 0.915  \n",
    "- **Confusion Matrix**: [[72, 12], [8, 108]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Matches the tuned DT in performance but is simpler and more interpretable. Strong candidate for clinical deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Class-Weighted Tuned & Pruned DT (`class_weight={0:1, 1:4}`)\n",
    "- **Accuracy**: 0.90  \n",
    "- **Precision**: 0.893  \n",
    "- **Recall**: **0.940 (highest)**  \n",
    "- **F1**: 0.916  \n",
    "- **Confusion Matrix**: [[71, 13], [7, 109]]\n",
    "\n",
    "**Interpretation**:  \n",
    "This model achieves the **highest recall** (~94%), missing only 7 CVD patients. Precision drops slightly compared to others (more false positives), but for diagnosis this is an acceptable trade-off. This makes it the **best DT for sensitivity**.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                                   | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|-----------------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Class-Weighted Tuned & Pruned DT**    | 0.90     | 0.893     | **0.940** | 0.916 | **7** |\n",
    "| Tuned DT                                | 0.90     | 0.90      | 0.931 | 0.915 | 8 |\n",
    "| Alt. Tuned & Pruned DT                  | 0.90     | 0.90      | 0.931 | 0.915 | 8 |\n",
    "| Baseline DT                             | 0.90     | **0.94**  | 0.879 | 0.911 | 14 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- The **class-weighted DT** is the **best choice for diagnosis**: it maximizes recall (94%) while keeping reasonable precision.  \n",
    "- The **tuned & pruned DTs** are close runners-up, still strong options with ~93% recall and better balance.  \n",
    "- The **baseline DT** has the highest precision but unacceptably low recall for medical screening.  \n",
    "\n",
    "**Recommended for CVD diagnosis: Class-Weighted Tuned & Pruned DT** — best recall, fewer missed cases, still interpretable.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac238ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved class weighted tuned DT model → class_weighted_tuned_dt_model.pkl\n",
      "Saved predictions → MendeleyData_75F25M_DT_classweightedtuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"class_weighted_tuned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true_dt = y_test.to_numpy().ravel() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test).ravel()\n",
    "y_pred_dt = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob_dt = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true_dt), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true_dt,\n",
    "    \"y_pred_dt\": y_pred_dt,\n",
    "    \"y_prob_dt\": y_prob_dt\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75F25M_DT_classweightedtuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved class weighted tuned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.925\n",
      "Precision: 0.9469026548672567\n",
      "Recall   : 0.9224137931034483\n",
      "F1 Score : 0.9344978165938864\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91        84\n",
      "           1       0.95      0.92      0.93       116\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.92      0.93      0.92       200\n",
      "weighted avg       0.93      0.93      0.93       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [  9 107]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c16756",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.925  \n",
    "- **Precision:** 0.947  \n",
    "- **Recall:** **0.922**  \n",
    "- **F1 Score:** 0.934  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 78           | 6            |\n",
    "| **Actual: 1** | 9            | 107          |\n",
    "\n",
    "- **False negatives:** **9** (missed CVD)  \n",
    "- **False positives:** **6** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "The model shows **strong overall performance** with **high precision** and **good recall**, indicating few false alarms and a manageable number of missed CVD cases. This is a balanced setup for CVD screening.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV Recall: 0.9866666666666667\n",
      "=== Random Forest (best) Evaluation ===\n",
      "Accuracy : 0.91\n",
      "Precision: 0.9298245614035088\n",
      "Recall   : 0.9137931034482759\n",
      "F1 Score : 0.9217391304347826\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        84\n",
      "           1       0.93      0.91      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.91      0.91      0.91       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 76   8]\n",
      " [ 10 106]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",     # recall-focused\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV Recall:\", grid.best_score_)\n",
    "\n",
    "# Evaluate best RF \n",
    "y_pred_rf = best_rf.predict(X_test_ready)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest (best)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536dc2d9",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison (CVD Diagnosis) \n",
    "\n",
    "### 1. Baseline Random Forest\n",
    "- **Accuracy**: 0.925 (highest overall)  \n",
    "- **Precision**: **0.947** (highest)  \n",
    "- **Recall**: **0.922** (highest of RF models)  \n",
    "- **F1**: 0.934 (highest overall)  \n",
    "- **Confusion Matrix**: [[78, 6], [9, 107]]\n",
    "\n",
    "**Interpretation**:  \n",
    "The baseline RF is excellent: it achieves both high recall (~92%) and very high precision (~95%). It misses only 9 CVD-positive patients, fewer than most KNNs and DTs. Strong all-around model for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Random Forest (Best Params: `n_estimators=200`, `max_features='sqrt'`, `min_samples_split=2`, `min_samples_leaf=1`)\n",
    "- **Accuracy**: 0.91  \n",
    "- **Precision**: 0.930  \n",
    "- **Recall**: 0.914  \n",
    "- **F1**: 0.922  \n",
    "- **Confusion Matrix**: [[76, 8], [10, 106]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Tuning improves cross-validation recall, but in evaluation the recall is slightly lower than baseline (~91%). It misses 10 positives (vs. 9 for baseline). Still strong, but baseline edges it out in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview Table \n",
    "\n",
    "| Model                  | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|-------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Baseline RF**         | **0.925** | **0.947** | **0.922** | **0.934** | **9** |\n",
    "| Tuned RF                | 0.910    | 0.930     | 0.914  | 0.922 | 10 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- The **baseline Random Forest** is the best performer: it combines the **highest recall (92%)**, **highest precision (95%)**, and **highest F1**. It misses just 9 positives.  \n",
    "- The **tuned RF** is slightly weaker in both recall and precision, even though it looked promising during CV.  \n",
    "\n",
    "**Recommended for CVD diagnosis (within RF family): Baseline Random Forest** — it maximizes sensitivity without sacrificing precision.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Baseline RF model → rf_model.pkl\n",
      "Saved predictions → MendeleyData_75F25M_RF_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save best Random Forest Results for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save Random Forest model\n",
    "model_filename = \"rf_model.pkl\"\n",
    "joblib.dump(rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true_rf = y_test.to_numpy().ravel() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test).ravel()\n",
    "rf.fit(X_train_ready, y_train)\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true_rf), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true_rf,\n",
    "    \"y_pred_rf\": y_pred_rf,\n",
    "    \"y_prob\": y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75F25M_RF_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Baseline RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.885\n",
      "Precision: 0.9043478260869565\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9004329004329005\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86        84\n",
      "           1       0.90      0.90      0.90       116\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 73  11]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "y_prob_mlp = mlp.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39554c4",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP)\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.885  \n",
    "- **Precision:** 0.904  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.900  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 73           | 11           |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed CVD)  \n",
    "- **False positives:** **11** (healthy flagged)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "The MLP delivers **balanced performance near 0.90** across precision, recall, and F1. It **captures most CVD cases** while keeping false alarms moderate (11).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fde3cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.895\n",
      "Precision: 0.9130434782608695\n",
      "Recall   : 0.9051724137931034\n",
      "F1 Score : 0.9090909090909091\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88        84\n",
      "           1       0.91      0.91      0.91       116\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 74  10]\n",
      " [ 11 105]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP)- LBFGS solver Evaluation ===\n",
      "Accuracy : 0.885\n",
      "Precision: 0.8842975206611571\n",
      "Recall   : 0.9224137931034483\n",
      "F1 Score : 0.9029535864978903\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        84\n",
      "           1       0.88      0.92      0.90       116\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.88      0.88       200\n",
      "weighted avg       0.89      0.89      0.88       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 70  14]\n",
      " [  9 107]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_lbfgs, \"Multilayer Perceptron (MLP)- LBFGS solver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc09ca5",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) - LBFGS solver\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.885  \n",
    "- **Precision:** 0.884  \n",
    "- **Recall:** **0.922**  \n",
    "- **F1 Score:** 0.903  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 70           | 14           |\n",
    "| **Actual: 1** | 9            | 107          |\n",
    "\n",
    "- **False negatives:** **9** (missed CVD)  \n",
    "- **False positives:** **14** (healthy flagged)  \n",
    "- **Specificity (class 0):** ~0.833 (70/84)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "The MLP emphasizes **high recall** (≈0.922), capturing most CVD cases with **few misses** (FN=9). This comes with a **moderate false-positive rate** (FP=14), reflected in precision (0.884). \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'batch_size': 32, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Best CV F-beta (β=2): 0.9766\n",
      "Corresponding CV Recall: 0.9767\n",
      "Corresponding CV F1: 0.9767\n",
      "=== Best MLP (Adam) Evaluation ===\n",
      "Accuracy : 0.905\n",
      "Precision: 0.9292035398230089\n",
      "Recall   : 0.9051724137931034\n",
      "F1 Score : 0.9170305676855895\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89        84\n",
      "           1       0.93      0.91      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 76   8]\n",
      " [ 11 105]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall-first MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, recall_score, fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# 1) Base model: Adam\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=False,      \n",
    "    max_iter=1000,             # observed full convergence at 1000\n",
    "    tol=1e-4,                  # default; tighten if you like (e.g., 1e-5)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "# Optional: summarize CV metrics for the selected config\n",
    "best_idx = rs.best_index_\n",
    "cvres = rs.cv_results_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "print(f\"Corresponding CV Recall: {cvres['mean_test_recall'][best_idx]:.4f}\")\n",
    "print(f\"Corresponding CV F1: {cvres['mean_test_f1'][best_idx]:.4f}\")\n",
    "\n",
    "# 2) Evaluate on test \n",
    "y_pred = best_mlp.predict(X_test_ready)\n",
    "y_prob = best_mlp.predict_proba(X_test_ready)[:, 1]  # probability of positive class\n",
    "\n",
    "evaluate_model(y_test, y_pred, model_name=\"Best MLP (Adam)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af55724",
   "metadata": {},
   "source": [
    "### MLP (Adam): Tuned\n",
    "\n",
    "**Best MLP params**: `{'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'batch_size': 32, 'alpha': 0.001, 'activation': 'tanh'}`  \n",
    "**Best CV F-beta (β=2)**: **0.9766** | **CV Recall**: **0.9767** | **CV F1**: **0.9767**\n",
    "\n",
    "---\n",
    "\n",
    "### Test Evaluation\n",
    "- **Accuracy:** 0.905  \n",
    "- **Precision:** 0.929  \n",
    "- **Recall:** **0.905**  \n",
    "- **F1 Score:** 0.917  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 76           | 8            |\n",
    "| **Actual: 1** | 11           | 105          |\n",
    "\n",
    "- **False negatives:** **11** (missed CVD)  \n",
    "- **False positives:** **8** (healthy flagged)\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretation\n",
    "The tuned MLP achieves **strong, balanced performance**: high **recall (≈0.905)** captures most CVD cases, while **precision (≈0.929)** keeps false alarms modest. The error profile (FN=11, FP=8) reflects a sensible screening trade-off. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec3c45",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline MLP (default solver)\n",
    "- **Accuracy**: 0.885  \n",
    "- **Precision**: 0.904  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.900  \n",
    "- **Confusion Matrix**: [[73, 11], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Decent baseline, but recall is under 90%. Misses 12 CVD cases.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. MLP (Adam + EarlyStopping)\n",
    "- **Accuracy**: 0.895  \n",
    "- **Precision**: 0.913  \n",
    "- **Recall**: 0.905  \n",
    "- **F1**: 0.909  \n",
    "- **Confusion Matrix**: [[74, 10], [11, 105]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Improves recall slightly over baseline (to ~91%) while keeping decent precision. Misses 11 positives. Early stopping helped prevent overfitting, making this a stable improvement.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. MLP (LBFGS Solver)\n",
    "- **Accuracy**: 0.885  \n",
    "- **Precision**: 0.884  \n",
    "- **Recall**: **0.922** (highest)  \n",
    "- **F1**: 0.903  \n",
    "- **Confusion Matrix**: [[70, 14], [9, 107]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Best recall (~92%), missing only 9 positives. Precision is lower (more false positives), but this is acceptable in diagnosis. Strongest for sensitivity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Best MLP (Tuned Adam, `(64,32)` hidden layers, `tanh`, `alpha=0.001`, `batch=32`, `lr=0.001`)\n",
    "- **Accuracy**: 0.905  \n",
    "- **Precision**: **0.929**  \n",
    "- **Recall**: 0.905  \n",
    "- **F1**: **0.917**  \n",
    "- **Confusion Matrix**: [[76, 8], [11, 105]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Best overall balance: accuracy 91%, recall 91%, precision 93%. Misses 11 positives — same as EarlyStopping, but with higher precision and F1.\n",
    "\n",
    "---\n",
    "\n",
    "## Overview Table\n",
    "\n",
    "| Model                         | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|--------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **MLP (LBFGS Solver)**         | 0.885    | 0.884     | **0.922** | 0.903 | **9** |\n",
    "| Best MLP (Adam, tuned)         | 0.905    | **0.929** | 0.905  | **0.917** | 11 |\n",
    "| MLP (Adam + EarlyStopping)     | 0.895    | 0.913     | 0.905  | 0.909 | 11 |\n",
    "| Baseline MLP                   | 0.885    | 0.904     | 0.897  | 0.900 | 12 |\n",
    "\n",
    "---\n",
    "\n",
    "###  Final Takeaway\n",
    "- **MLP (LBFGS Solver)** is the best for recall (92%), ideal for diagnosis where sensitivity is critical.  \n",
    "- **Best MLP (Adam, tuned)** provides the strongest overall balance (accuracy, precision, F1) with still solid recall.  \n",
    "- **MLP (Adam + EarlyStopping)** improves stability and recall over baseline but lags slightly behind tuned Adam.  \n",
    "- **Baseline MLP** is the weakest.  \n",
    "\n",
    "**For diagnosis: LBFGS MLP is most sensitive; for balance: tuned Adam is strongest.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lbfgs MLP model →  mlp_lbfgs.pkl\n",
      "Saved predictions → MendeleyData_75F25M_MLP_lbfgs_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Recall-First Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned MLP model\n",
    "model_filename = \" mlp_lbfgs.pkl\"\n",
    "joblib.dump(mlp_lbfgs, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready) # from tuned MLP predictions\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_lbfgs\": y_pred,\n",
    "    \"y_prob_lbfgs\" : y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75F25M_MLP_lbfgs_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved lbfgs MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
