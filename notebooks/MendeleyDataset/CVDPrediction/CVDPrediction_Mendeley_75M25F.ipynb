{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Mendeley Dataset (Source: https://data.mendeley.com/datasets/dzz48mvjht/1)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chestpain</th>\n",
       "      <th>restingBP</th>\n",
       "      <th>serumcholestrol</th>\n",
       "      <th>fastingbloodsugar</th>\n",
       "      <th>restingrelectro</th>\n",
       "      <th>maxheartrate</th>\n",
       "      <th>exerciseangia</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>noofmajorvessels</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>713</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>328.877508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>234</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  age  gender  chestpain  restingBP  serumcholestrol  \\\n",
       "0         71   77       1          1        125       135.000000   \n",
       "1        139   23       1          3        143       221.000000   \n",
       "2        589   21       1          0        126       139.000000   \n",
       "3        713   53       1          2        171       328.877508   \n",
       "4        234   69       1          1        120       231.000000   \n",
       "\n",
       "   fastingbloodsugar  restingrelectro  maxheartrate  exerciseangia  oldpeak  \\\n",
       "0                  0                0           100              0      1.8   \n",
       "1                  0                0           152              1      2.0   \n",
       "2                  0                0           150              1      1.4   \n",
       "3                  0                1           147              0      5.3   \n",
       "4                  0                0            77              0      4.4   \n",
       "\n",
       "   slope  noofmajorvessels  target  \n",
       "0      2                 1       0  \n",
       "1      2                 0       0  \n",
       "2      2                 1       0  \n",
       "3      3                 3       1  \n",
       "4      2                 0       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"target\"\n",
    "SENSITIVE = \"gender\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['gender','chestpain','fastingbloodsugar','restingrelectro','exerciseangia','slope','noofmajorvessels']\n",
    "continuous_cols  = ['age','restingBP','serumcholestrol','maxheartrate','oldpeak']\n",
    "\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train numeric means (≈0):\n",
      "age                0.0\n",
      "restingBP          0.0\n",
      "serumcholestrol    0.0\n",
      "maxheartrate       0.0\n",
      "oldpeak            0.0\n",
      "dtype: float64\n",
      "\n",
      "Train numeric stds (≈1):\n",
      "age                1.0\n",
      "restingBP          1.0\n",
      "serumcholestrol    1.0\n",
      "maxheartrate       1.0\n",
      "oldpeak            1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# SCALE NUMERIC FEATURES ONLY \n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# 1) fit scaler on TRAIN numeric columns only\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "# 2) transform TEST with the same scaler\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# 3) reassemble: raw categoricals + scaled numerics\n",
    "X_train_scaled = pd.concat([X_train[categorical_cols].reset_index(drop=True),\n",
    "                            X_train_num_scaled.reset_index(drop=True)], axis=1)\n",
    "X_test_scaled  = pd.concat([X_test[categorical_cols].reset_index(drop=True),\n",
    "                            X_test_num_scaled.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# OPTIONAL: quick sanity checks\n",
    "print(\"Train numeric means (≈0):\")\n",
    "print(X_train_scaled[continuous_cols].mean().round(3))\n",
    "print(\"\\nTrain numeric stds (≈1):\")\n",
    "print(X_train_scaled[continuous_cols].std(ddof=0).round(3))\n",
    "\n",
    "# save for later steps\n",
    "X_train_scaled.to_csv(\"data_subsets/train_75M_25F_scaled_only.csv\", index=False)\n",
    "#X_test_scaled.to_csv(\"data_splits/X_test_scaled_only.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 22) (200, 22)\n"
     ]
    }
   ],
   "source": [
    "# --- ONE-HOT ENCODE CATEGORICALS; KEEP SCALED NUMERICS AS-IS ---\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# categorical_cols and continuous_cols already defined\n",
    "# X_train_scaled, X_test_scaled already created\n",
    "\n",
    "# 1) fit encoder on TRAIN categoricals only\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train_scaled[categorical_cols])\n",
    "\n",
    "# 2) transform TRAIN and TEST\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train_scaled.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test_scaled[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test_scaled.index\n",
    ")\n",
    "\n",
    "# 3) concatenate: encoded categoricals + scaled numerics\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_scaled[continuous_cols]], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_scaled[continuous_cols]],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.91\n",
      "Precision: 0.9454545454545454\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9203539823008849\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        84\n",
      "           1       0.95      0.90      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.91      0.91      0.91       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 78   6]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.89\n",
      "Precision: 0.9351851851851852\n",
      "Recall   : 0.8706896551724138\n",
      "F1 Score : 0.9017857142857143\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88        84\n",
      "           1       0.94      0.87      0.90       116\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.89      0.89      0.89       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 77   7]\n",
      " [ 15 101]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_ready, y_train)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test_ready)\n",
    "y_prob_dt = dt.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394b7c8",
   "metadata": {},
   "source": [
    "## KNN: Evaluation\n",
    "\n",
    "- **Accuracy:** 0.910  \n",
    "- **Precision:** 0.945  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.920  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 78           | 6            |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed CVD)  \n",
    "- **False positives:** **6** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "High precision with strong recall; few false alarms and a modest number of missed CVD cases. Suitable when both correctness of positive flags and avoiding misses matter.\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree: Evaluation\n",
    "\n",
    "- **Accuracy:** 0.890  \n",
    "- **Precision:** 0.935  \n",
    "- **Recall:** **0.871**  \n",
    "- **F1 Score:** 0.902  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 77           | 7            |\n",
    "| **Actual: 1** | 15           | 101          |\n",
    "\n",
    "- **False negatives:** **15** (missed CVD)  \n",
    "- **False positives:** **7** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "Good overall performance with solid precision and slightly lower recall; a few more missed CVD cases relative to its positives. Appropriate when controlling false alarms while maintaining reasonable sensitivity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 8, 'weights': 'distance'}\n",
      "Best CV F1: 0.9360741590062324\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.93\n",
      "Precision: 0.9722222222222222\n",
      "Recall   : 0.9051724137931034\n",
      "F1 Score : 0.9375\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        84\n",
      "           1       0.97      0.91      0.94       116\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.93      0.93      0.93       200\n",
      "weighted avg       0.93      0.93      0.93       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 81   3]\n",
      " [ 11 105]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda9588",
   "metadata": {},
   "source": [
    "## KNN: Tuned\n",
    "\n",
    "**Best KNN params**: `{'metric': 'manhattan', 'n_neighbors': 8, 'weights': 'distance'}`  \n",
    "**Best CV F1**: **0.9361**\n",
    "\n",
    "---\n",
    "\n",
    "### KNN (Best Params)\n",
    "- **Accuracy:** 0.930  \n",
    "- **Precision:** 0.972  \n",
    "- **Recall:** **0.905**  \n",
    "- **F1 Score:** 0.938  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 81           | 3            |\n",
    "| **Actual: 1** | 11           | 105          |\n",
    "\n",
    "- **False negatives:** **11** (missed positives)  \n",
    "- **False positives:** **3** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "This tuned KNN delivers **very high precision** with **strong recall**, yielding few false alarms and a manageable number of missed cases. The model setup is suitable when **correct positive identification** is prioritized while still **capturing most true cases**. Consider calibration and fairness checks before deployment.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 15 | Explained variance retained: 0.965\n",
      "=== PCA+KNN Evaluation ===\n",
      "Accuracy : 0.915\n",
      "Precision: 0.9541284403669725\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9244444444444444\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        84\n",
      "           1       0.95      0.90      0.92       116\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.91      0.92      0.91       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 79   5]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# 1) PCA + KNN pipeline \n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "#2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_pca_knn, \"PCA+KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37338bcf",
   "metadata": {},
   "source": [
    "## PCA + KNN\n",
    "\n",
    "**PCA components:** 15  \n",
    "**Explained variance retained:** **0.965**\n",
    "\n",
    "---\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.915  \n",
    "- **Precision:** 0.954  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.924  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 79           | 5            |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed positives)  \n",
    "- **False positives:** **5** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "Dimensionality reduction to 15 components retains **96.5%** of variance while maintaining **strong precision** and **good recall**. The model produces **few false alarms** and a **manageable number of misses**, indicating a balanced operating point with potential gains in stability and efficiency.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff84c7",
   "metadata": {},
   "source": [
    "# KNN Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "## 1. Baseline KNN\n",
    "- **Accuracy**: 0.91  \n",
    "- **Precision**: 0.945  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.920  \n",
    "- **Confusion Matrix**: [[78, 6], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Strong precision (~95%) and balanced performance overall. Recall is just under 90%, meaning 12 CVD-positive patients were missed. This makes it good, but not the most sensitive option.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Best KNN (Tuned: `n_neighbors=8`, `metric=manhattan`, `weights=distance`)\n",
    "- **Accuracy**: **0.93 (highest)**  \n",
    "- **Precision**: **0.972 (highest)**  \n",
    "- **Recall**: **0.905 (highest)**  \n",
    "- **F1**: **0.938 (highest)**  \n",
    "- **Confusion Matrix**: [[81, 3], [11, 105]]\n",
    "\n",
    "**Interpretation**:  \n",
    "The tuned KNN is the strongest performer overall: it improves both accuracy and F1, while recall increases to ~91%. It misses only 11 positives (slightly better than baseline) and greatly reduces false positives (just 3). This is the **best-balanced KNN**, with high sensitivity and outstanding precision.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. PCA + KNN (15 components, 96.5% variance retained)\n",
    "- **Accuracy**: 0.915  \n",
    "- **Precision**: 0.954  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.924  \n",
    "- **Confusion Matrix**: [[79, 5], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Very close to baseline KNN. Accuracy and precision are slightly higher, but recall remains the same (~90%). Dimensionality reduction does not improve sensitivity, suggesting PCA does not add value here (dataset likely not high-dimensional enough).\n",
    "\n",
    "---\n",
    "\n",
    "## Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                 | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Best KNN (Tuned)**  | **0.93** | **0.972** | **0.905** | **0.938** | 11 |\n",
    "| Baseline KNN          | 0.91     | 0.945     | 0.897  | 0.920 | 12 |\n",
    "| PCA + KNN             | 0.915    | 0.954     | 0.897  | 0.924 | 12 |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Takeaway\n",
    "- **Best KNN (tuned)** is the clear winner: it has the **highest recall (~91%)**, **highest accuracy**, and **highest precision**, making it the most reliable choice for diagnosis.  \n",
    "- **Baseline KNN** and **PCA+KNN** are very close, with recall just under 90% (12 missed positives). PCA does not meaningfully improve performance.  \n",
    "- For CVD diagnosis, where **sensitivity matters most**, the **Tuned KNN** provides the best balance: it improves recall slightly while significantly boosting overall reliability.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bf66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned KNN model → knn_best_model.pkl\n",
      "Saved predictions → MendeleyData_75M25F_KNN_best_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series (not a DataFrame)\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"knn_best_model.pkl\"\n",
    "joblib.dump(best_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = best_knn.predict(X_test_ready)\n",
    "y_prob = best_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob,\n",
    "    \"y_pred\": y_pred\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75M25F_KNN_best_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best CV F1: 0.9233333333333332\n",
      "=== Tuned Decision Tree Evaluation ===\n",
      "Accuracy : 0.905\n",
      "Precision: 0.907563025210084\n",
      "Recall   : 0.9310344827586207\n",
      "F1 Score : 0.9191489361702128\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88        84\n",
      "           1       0.91      0.93      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.91      0.90       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 73  11]\n",
      " [  8 108]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = best_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc161c",
   "metadata": {},
   "source": [
    "## Decision Tree: Tuned\n",
    "\n",
    "**Best DT params**: `{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}`  \n",
    "**Best CV F1**: **0.9233**\n",
    "\n",
    "---\n",
    "\n",
    "### Tuned Decision Tree\n",
    "- **Accuracy:** 0.905  \n",
    "- **Precision:** 0.908  \n",
    "- **Recall:** **0.931**  \n",
    "- **F1 Score:** 0.919  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 73           | 11           |\n",
    "| **Actual: 1** | 8            | 108          |\n",
    "\n",
    "- **False negatives:** **8** (missed CVD)  \n",
    "- **False positives:** **11** (healthy flagged)  \n",
    "\n",
    "**Interpretation (general):**  \n",
    "The model emphasizes **high recall**, capturing most CVD cases while keeping precision solid. The error profile shows **few missed cases** (FN=8) and a **manageable number of false alarms** (FP=11). This model is suitable when **avoiding missed CVD** is a priority. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.9199999999999999\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9200\n",
      "=== Alternative Tuned & Pruned DT Evaluation ===\n",
      "Accuracy : 0.88\n",
      "Precision: 0.8709677419354839\n",
      "Recall   : 0.9310344827586207\n",
      "F1 Score : 0.9\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        84\n",
      "           1       0.87      0.93      0.90       116\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.87      0.88       200\n",
      "weighted avg       0.88      0.88      0.88       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 68  16]\n",
      " [  8 108]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Stage A: bias toward simpler trees with class_weight=\"balanced\"\n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",        # recall-focused search\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV Recall:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# Stage B: cost-complexity pruning on the best simple DT\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  # include no-pruning baseline\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    # recall-focused CV\n",
    "    recall_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, recall_cv))\n",
    "\n",
    "best_alpha, best_cv_recall = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "# Final model fit with the chosen ccp_alpha\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned DT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b261e",
   "metadata": {},
   "source": [
    "### Decision Tree: Tuned & Pruned (Alternative)\n",
    "\n",
    "**Stage A — Best simple DT params**: `{'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}`  \n",
    "**Stage A — Best CV Recall**: **0.9200**  \n",
    "**Stage B — Best `ccp_alpha`**: **0.000000** (no extra pruning) | **CV Recall**: **0.9200**\n",
    "\n",
    "---\n",
    "\n",
    "### Test Evaluation\n",
    "- **Accuracy:** 0.880  \n",
    "- **Precision:** 0.871  \n",
    "- **Recall:** **0.931**  \n",
    "- **F1 Score:** 0.900  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 68           | 16           |\n",
    "| **Actual: 1** | 8            | 108          |\n",
    "\n",
    "- **False negatives:** **8** (missed CVD)  \n",
    "- **False positives:** **16** (healthy flagged)  \n",
    "\n",
    "**Summary:**  \n",
    "This DT is tuned for **high recall** (captures ~93% of CVD cases), accepting more **false positives** (specificity ≈ 0.81). Suitable when **missing CVD is costlier** than extra follow-ups.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a300b640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'gini', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 6, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.965\n",
      "Stage B — Best ccp_alpha: 0.016578 | CV Recall: 0.9700\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.81\n",
      "Precision: 0.7635135135135135\n",
      "Recall   : 0.9741379310344828\n",
      "F1 Score : 0.8560606060606061\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.58      0.72        84\n",
      "           1       0.76      0.97      0.86       116\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.85      0.78      0.79       200\n",
      "weighted avg       0.84      0.81      0.80       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 49  35]\n",
      " [  3 113]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef22548",
   "metadata": {},
   "source": [
    "## Decision Tree Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline Decision Tree\n",
    "- **Accuracy**: 0.89  \n",
    "- **Precision**: **0.935** (highest)  \n",
    "- **Recall**: 0.871 (lowest)  \n",
    "- **F1**: 0.902  \n",
    "- **Confusion Matrix**: [[77, 7], [15, 101]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Strong precision but weak recall — misses 15 positives. Too risky for diagnosis because it overlooks too many patients with CVD.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Decision Tree (`gini`, `max_depth=5`, `min_samples_split=2`, `min_samples_leaf=1`)\n",
    "- **Accuracy**: 0.905  \n",
    "- **Precision**: 0.908  \n",
    "- **Recall**: 0.931  \n",
    "- **F1**: 0.919  \n",
    "- **Confusion Matrix**: [[73, 11], [8, 108]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Balanced and reliable: recall improves significantly to ~93%, reducing missed positives to just 8. Excellent trade-off for diagnosis, since accuracy and precision remain strong. This is the **most practical model** for deployment.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Alternative Tuned & Pruned DT (`gini`, `max_depth=4`, `min_samples_split=5`, `min_samples_leaf=4`)\n",
    "- **Accuracy**: 0.88  \n",
    "- **Precision**: 0.871  \n",
    "- **Recall**: 0.931  \n",
    "- **F1**: 0.900  \n",
    "- **Confusion Matrix**: [[68, 16], [8, 108]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Recall stays high (~93%), but accuracy and precision drop. Still misses only 8 positives, but generates more false alarms (16 false positives). Good for sensitivity, weaker for balance.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Class-Weighted Tuned & Pruned DT (`class_weight={0:1, 1:4}`, `max_depth=4`, `min_samples_leaf=6`)\n",
    "- **Accuracy**: 0.81 (lowest)  \n",
    "- **Precision**: 0.764 (lowest)  \n",
    "- **Recall**: **0.974 (highest)**  \n",
    "- **F1**: 0.856  \n",
    "- **Confusion Matrix**: [[49, 35], [3, 113]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Outstanding recall — only 3 missed positives (best sensitivity). But this comes at a **huge cost**: accuracy drops by nearly 10%, and false positives rise sharply (35 healthy patients misclassified). The recall gain (~5%) does not justify the >9% drop in accuracy. Too aggressive for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|--------------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Class-Weighted Tuned & Pruned DT** | 0.81     | 0.764     | **0.974** | 0.856 | **3** |\n",
    "| Tuned DT                             | 0.905    | 0.908     | 0.931 | 0.919 | 8 |\n",
    "| Alt. Tuned & Pruned DT               | 0.88     | 0.871     | 0.931 | 0.900 | 8 |\n",
    "| Baseline DT                          | 0.89     | **0.935** | 0.871 | 0.902 | 15 |\n",
    "\n",
    "---\n",
    "\n",
    "## Final Takeaway\n",
    "- **Class-Weighted DT**: Achieves the highest recall (97%) but sacrifices too much accuracy and precision.  \n",
    "- **Tuned DT**: Best **balanced option** — high recall (~93%), strong accuracy (91%), and reasonable precision. This makes it the most **clinically appropriate** choice.  \n",
    "- **Alt. Tuned & Pruned DT**: Similar recall but weaker balance due to lower accuracy and more false positives.  \n",
    "- **Baseline DT**: High precision but misses too many positives, unsuitable for diagnosis.  \n",
    "\n",
    "**Decision:** For **screening-only scenarios** where every possible positive must be flagged, the Class-Weighted DT could be considered.  \n",
    "**But for diagnosis, the Tuned DT is clearly the better choice** — it maintains very high recall without sacrificing reliability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf663b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned DT model → tuned_dt_model.pkl\n",
      "Saved predictions → MendeleyData_75M25F_DT_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save tuned Decision Tree model\n",
    "model_filename = \"tuned_dt_model.pkl\"\n",
    "joblib.dump(best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "# Use tuned predictions/probabilities from the best estimator\n",
    "y_pred = y_pred_dt_best\n",
    "y_prob = y_prob_dt_best\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_dt\": y_pred,\n",
    "    \"y_prob\": y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75M25F_DT_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned DT model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.945\n",
      "Precision: 0.9646017699115044\n",
      "Recall   : 0.9396551724137931\n",
      "F1 Score : 0.9519650655021834\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94        84\n",
      "           1       0.96      0.94      0.95       116\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.94      0.95      0.94       200\n",
      "weighted avg       0.95      0.94      0.95       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80   4]\n",
      " [  7 109]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5888ca",
   "metadata": {},
   "source": [
    "## Random Forest: Baseline\n",
    "\n",
    "---\n",
    "\n",
    "### Baseline Random Forest\n",
    "- **Accuracy:** 0.945  \n",
    "- **Precision:** 0.965  \n",
    "- **Recall:** **0.940**  \n",
    "- **F1 Score:** 0.952  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 80           | 4            |\n",
    "| **Actual: 1** | 7            | 109          |\n",
    "\n",
    "- **False negatives:** **7** (missed CVD)  \n",
    "- **False positives:** **4** (healthy flagged)  \n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**\n",
    "- Strong overall performance; **detects most CVD cases** (7 missed).\n",
    "- **Very few false alarms** (4), precision is high.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': 8, 'max_features': 0.8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV Recall: 0.97\n",
      "=== Random Forest (best) Evaluation ===\n",
      "Accuracy : 0.955\n",
      "Precision: 0.9652173913043478\n",
      "Recall   : 0.9568965517241379\n",
      "F1 Score : 0.961038961038961\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95        84\n",
      "           1       0.97      0.96      0.96       116\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.95       200\n",
      "weighted avg       0.96      0.95      0.96       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80   4]\n",
      " [  5 111]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",     # recall-focused\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV Recall:\", grid.best_score_)\n",
    "\n",
    "# Evaluate best RF \n",
    "y_pred_rf = best_rf.predict(X_test_ready)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest (best)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309008bf",
   "metadata": {},
   "source": [
    "### Random Forest: Tuned\n",
    "\n",
    "**Best RF params**: `{'class_weight': None, 'max_depth': 8, 'max_features': 0.8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}`  \n",
    "**Best CV Recall**: **0.9700**\n",
    "\n",
    "---\n",
    "\n",
    "### Random Forest (Best)\n",
    "- **Accuracy:** 0.955  \n",
    "- **Precision:** 0.965  \n",
    "- **Recall:** **0.957**  \n",
    "- **F1 Score:** 0.961  \n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 80           | 4            |\n",
    "| **Actual: 1** | 5            | 111          |\n",
    "\n",
    "- **False negatives:** **5** (missed CVD)  \n",
    "- **False positives:** **4** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "The tuned model achieves **high recall** and **strong precision**, indicating it captures most CVD cases with very few false alarms. Error rates are balanced across classes, suggesting a reliable setup for CVD screening.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2648331",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline Random Forest\n",
    "- **Accuracy**: 0.945  \n",
    "- **Precision**: 0.965  \n",
    "- **Recall**: 0.940  \n",
    "- **F1**: 0.952  \n",
    "- **Confusion Matrix**: [[80, 4], [7, 109]]\n",
    "\n",
    "**Interpretation**:  \n",
    "An excellent baseline model: very high recall (~94%), strong accuracy (~95%), and nearly perfect precision (~96%). It misses only 7 positives, making it already highly reliable for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tuned Random Forest (Best Params: `n_estimators=200`, `max_depth=8`, `max_features=0.8`)\n",
    "- **Accuracy**: **0.955 (highest)**  \n",
    "- **Precision**: 0.965  \n",
    "- **Recall**: **0.957 (highest)**  \n",
    "- **F1**: **0.961 (highest)**  \n",
    "- **Confusion Matrix**: [[80, 4], [5, 111]]\n",
    "\n",
    "**Interpretation**:  \n",
    "The tuned RF improves recall further to ~96%, missing only 5 positives (down from 7). Accuracy and F1 also increase slightly. It maintains the same excellent precision (~96%). This is a **clear upgrade** over the baseline and one of the best-performing models overall.\n",
    "\n",
    "---\n",
    "\n",
    "###  Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model              | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|---------------------|----------|-----------|--------|------|-----------------|\n",
    "| **Tuned RF**       | **0.955** | 0.965     | **0.957** | **0.961** | **5** |\n",
    "| Baseline RF        | 0.945    | **0.965** | 0.940  | 0.952 | 7 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- **Tuned RF** is the superior model: it achieves the **highest recall (~96%)**, **highest accuracy (~96%)**, and **highest F1**. It misses only 5 CVD-positive patients, making it one of the strongest candidates overall.  \n",
    "- **Baseline RF** is already excellent, but slightly less sensitive (recall ~94%, 7 missed positives).  \n",
    "- For CVD diagnosis where recall is the priority, the **Tuned Random Forest is the best choice**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a4cdd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned RF model → tuned_rf_model.pkl\n",
      "Saved predictions → MendeleyData_75M25F_RF_tuned_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned Random Forest Results\n",
    "\n",
    "# Save tuned Random Forest model\n",
    "model_filename = \"tuned_rf_model.pkl\"\n",
    "joblib.dump(best_rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_rf  # from best_rf.predict(X_test_ready)\n",
    "y_prob = y_prob_rf\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred_rf_tuned\": y_pred,\n",
    "    \"y_prob\" :y_prob_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75M25F_RF_tuned_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved tuned RF model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.905\n",
      "Precision: 0.9369369369369369\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9162995594713657\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        84\n",
      "           1       0.94      0.90      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.90      0.91      0.90       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 77   7]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725a8fc",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP)\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.905  \n",
    "- **Precision:** 0.937  \n",
    "- **Recall:** **0.897**  \n",
    "- **F1 Score:** 0.916  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 77           | 7            |\n",
    "| **Actual: 1** | 12           | 104          |\n",
    "\n",
    "- **False negatives:** **12** (missed CVD)  \n",
    "- **False positives:** **7** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "The MLP shows **high precision** and **good recall**, indicating few false alarms and a manageable number of missed cases. This is a balanced setup for CVD screening.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b123b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.91\n",
      "Precision: 0.9224137931034483\n",
      "Recall   : 0.9224137931034483\n",
      "F1 Score : 0.9224137931034483\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        84\n",
      "           1       0.92      0.92      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.91      0.91      0.91       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 75   9]\n",
      " [  9 107]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.92\n",
      "Precision: 0.923728813559322\n",
      "Recall   : 0.9396551724137931\n",
      "F1 Score : 0.9316239316239316\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        84\n",
      "           1       0.92      0.94      0.93       116\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.92      0.92      0.92       200\n",
      "weighted avg       0.92      0.92      0.92       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 75   9]\n",
      " [  7 109]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_lbfgs, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1d516",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) - LBFGS solver\n",
    "\n",
    "### Evaluation\n",
    "- **Accuracy:** 0.920  \n",
    "- **Precision:** 0.924  \n",
    "- **Recall:** **0.940**  \n",
    "- **F1 Score:** 0.932  \n",
    "- **Support:** 0→84, 1→116\n",
    "\n",
    "**Confusion Matrix**  \n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 75           | 9            |\n",
    "| **Actual: 1** | 7            | 109          |\n",
    "\n",
    "- **False negatives:** **7** (missed CVD)  \n",
    "- **False positives:** **9** (healthy flagged)\n",
    "\n",
    "**Interpretation:**  \n",
    "The model prioritizes **high recall**, catching most CVD cases while keeping **precision** strong. The error profile (FN=7, FP=9) suggests a balanced MLP suitable for CVD screening. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8739f9",
   "metadata": {},
   "source": [
    "### Further Improvement MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "505c3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.0001, 'hidden_layer_sizes': (128,), 'batch_size': 16, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Best CV F-beta (β=2): 0.9492\n",
      "Corresponding CV Recall: 0.9500\n",
      "Corresponding CV F1: 0.9484\n",
      "=== Best MLP (Adam) Evaluation ===\n",
      "Accuracy : 0.905\n",
      "Precision: 0.9369369369369369\n",
      "Recall   : 0.896551724137931\n",
      "F1 Score : 0.9162995594713657\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89        84\n",
      "           1       0.94      0.90      0.92       116\n",
      "\n",
      "    accuracy                           0.91       200\n",
      "   macro avg       0.90      0.91      0.90       200\n",
      "weighted avg       0.91      0.91      0.91       200\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 77   7]\n",
      " [ 12 104]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall-first MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, recall_score, fbeta_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "# 1) Base model: Adam\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=False,      \n",
    "    max_iter=1000,             # observed full convergence at 1000\n",
    "    tol=1e-4,                  # default; tighten if you like (e.g., 1e-5)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "best_mlp = rs.best_estimator_\n",
    "\n",
    "# summarize CV metrics for the selected config\n",
    "best_idx = rs.best_index_\n",
    "cvres = rs.cv_results_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "print(f\"Best CV F-beta (β=2): {rs.best_score_:.4f}\")\n",
    "print(f\"Corresponding CV Recall: {cvres['mean_test_recall'][best_idx]:.4f}\")\n",
    "print(f\"Corresponding CV F1: {cvres['mean_test_f1'][best_idx]:.4f}\")\n",
    "\n",
    "# 2) Evaluate on test \n",
    "y_pred = best_mlp.predict(X_test_ready)\n",
    "y_prob = best_mlp.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred, model_name=\"Best MLP (Adam)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746022a3",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison (CVD Diagnosis) – Recall Priority\n",
    "\n",
    "### 1. Baseline MLP (Adam, default settings)\n",
    "- **Accuracy**: 0.905  \n",
    "- **Precision**: 0.937  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.916  \n",
    "- **Confusion Matrix**: [[77, 7], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Solid balance between accuracy and precision. However, recall is just under 90% (12 missed positives), which makes it slightly weaker for diagnosis.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. MLP (Adam + EarlyStopping)\n",
    "- **Accuracy**: 0.91  \n",
    "- **Precision**: 0.922  \n",
    "- **Recall**: 0.922  \n",
    "- **F1**: 0.922  \n",
    "- **Confusion Matrix**: [[75, 9], [9, 107]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Improves recall to ~92%, reducing missed positives to 9. Accuracy remains strong, though precision drops slightly compared to baseline. A good trade-off: more sensitive while still balanced.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **MLP (LBFGS Solver, hidden_layer_sizes=(64,32), tanh activation)**\n",
    "- **Accuracy**: 0.92  \n",
    "- **Precision**: 0.924  \n",
    "- **Recall**: **0.940 (highest)**  \n",
    "- **F1**: 0.932  \n",
    "- **Confusion Matrix**: [[75, 9], [7, 109]]\n",
    "\n",
    "**Interpretation**:  \n",
    "This LBFGS-based MLP achieves the **highest recall (94%)**, missing only 7 positives. Accuracy and F1 are also the best among the MLPs. It is the **best-performing MLP configuration** for CVD diagnosis in your experiments.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Best MLP (Adam, tuned params: `hidden_layer_sizes=(128,)`, `relu`, `alpha=0.0001`, `batch=16`, `lr=0.0001`)\n",
    "- **Accuracy**: 0.905  \n",
    "- **Precision**: 0.937  \n",
    "- **Recall**: 0.897  \n",
    "- **F1**: 0.916  \n",
    "- **Confusion Matrix**: [[77, 7], [12, 104]]\n",
    "\n",
    "**Interpretation**:  \n",
    "Despite hyperparameter tuning, performance mirrors the baseline MLP. Recall stays at ~90%, which is weaker than both EarlyStopping and LBFGS models.\n",
    "\n",
    "---\n",
    "\n",
    "###  Overview Table (Ranked by Recall Priority)\n",
    "\n",
    "| Model                               | Accuracy | Precision | Recall | F1   | FN (Missed CVD) |\n",
    "|-------------------------------------|----------|-----------|--------|------|-----------------|\n",
    "| **MLP (LBFGS Solver, best)**        | 0.92     | 0.924     | **0.940** | 0.932 | **7** |\n",
    "| MLP (Adam + EarlyStopping)          | 0.91     | 0.922     | 0.922  | 0.922 | 9 |\n",
    "| Baseline MLP (Adam)                 | 0.905    | 0.937     | 0.897  | 0.916 | 12 |\n",
    "| Tuned MLP (Adam, relu, 128 units)   | 0.905    | 0.937     | 0.897  | 0.916 | 12 |\n",
    "\n",
    "---\n",
    "\n",
    "### Final Takeaway\n",
    "- **MLP (LBFGS Solver, hidden_layer_sizes=(64,32), tanh activation)** is the **best-performing MLP model**: it combines the **highest recall (94%)** with strong accuracy (92%) and F1.  \n",
    "- **MLP with EarlyStopping** also performs well (~92% recall), a safer choice than baseline.  \n",
    "- **Baseline MLP** and **Tuned Adam MLP** perform similarly, but their recall (~90%) is weaker for diagnosis.  \n",
    "\n",
    " **Recommendation within the MLP family:** The **LBFGS MLP** is the top choice for CVD diagnosis.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90d43d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lbfgs MLP model → mlp_lbfgs.pkl\n",
      "Saved predictions → MendeleyData_75M25F_MLP_lbfgs_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Tuned MLP Results\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Save MLP model\n",
    "model_filename =  \"mlp_lbfgs.pkl\"\n",
    "joblib.dump(mlp_lbfgs, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true and y_pred\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "y_pred = y_pred_lbfgs # from tuned MLP predictions\n",
    "y_prob = y_prob_lbfgs\n",
    "\n",
    "# Optional gender column if present in test set\n",
    "if isinstance(X_test, pd.DataFrame) and \"gender\" in X_test.columns:\n",
    "    gender_vals = X_test[\"gender\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    \"gender\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"y_prob\" : y_prob\n",
    "})\n",
    "\n",
    "preds_filename = \"MendeleyData_75M25F_MLP_lbfgs_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved lbfgs MLP model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
