{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## Bias Mitigation using AIF360 - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>146.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   61    1              3      146.0        241.0          0           0   \n",
       "1   52    1              1      120.0        284.0          0           0   \n",
       "2   48    0              3      150.0        227.0          0           0   \n",
       "3   49    1              3      128.0        212.0          0           0   \n",
       "4   56    1              3      120.0        236.0          0           1   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  148.0               1      3.0         0             1  \n",
       "1  118.0               0      0.0         2             0  \n",
       "2  130.0               1      1.0         1             0  \n",
       "3   96.0               1      0.0         1             1  \n",
       "4  148.0               0      0.0         1             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_75M_25F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "749ae738",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fe70d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9f63a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e79e02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01e449c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sensitive attribute arrays - after creating X_train_ready and X_test_ready\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()  # 1=Male, 0=Female\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42dd1caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\inFairness\\utils\\ndcg.py:37: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  vect_normalized_discounted_cumulative_gain = vmap(\n",
      "C:\\Users\\patri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\inFairness\\utils\\ndcg.py:48: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.vmap` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.vmap` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  monte_carlo_vect_ndcg = vmap(vect_normalized_discounted_cumulative_gain, in_dims=(0,))\n"
     ]
    }
   ],
   "source": [
    "# setup for AIF360\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from sklearn.base import clone\n",
    "from IPython.display import display \n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "# Config \n",
    "protected_attr = \"Sex\"  # 1=Male, 0=Female\n",
    "PRIV_VALUE = 1          # privileged = Male\n",
    "label_name = \"label\"\n",
    "favorable_label, unfavorable_label = 1, 0\n",
    "privileged_groups   = [{protected_attr: PRIV_VALUE}]\n",
    "unprivileged_groups = [{protected_attr: 1 - PRIV_VALUE}]\n",
    "\n",
    "# Ensure 1-D ints for targets\n",
    "y_train = np.asarray(y_train).astype(int).ravel()\n",
    "y_test  = np.asarray(y_test).astype(int).ravel()\n",
    "\n",
    "# Sensitive attribute arrays\n",
    "A_train = X_train[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "A_test  = X_test[\"Sex\"].astype(int).to_numpy().ravel()\n",
    "\n",
    "def _to_bld(y, A):\n",
    "    y = (y.values if hasattr(y,'values') else np.asarray(y)).ravel()\n",
    "    A = (A.values if hasattr(A,'values') else np.asarray(A)).ravel()\n",
    "    df = pd.DataFrame({\"dummy\": np.zeros(len(y)), label_name: y, protected_attr: A})\n",
    "    return BinaryLabelDataset(\n",
    "        df=df,\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "def fair_metrics(y_true, y_pred, A, y_scores=None, absolute=True):\n",
    "    \"\"\"AIF360-based DP and EO (equal opportunity) differences.\"\"\"\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    if y_scores is not None:\n",
    "        p.scores = np.asarray(y_scores).reshape(-1, 1)\n",
    "    cm = ClassificationMetric(\n",
    "        t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.equal_opportunity_difference()\n",
    "    return (abs(dp), abs(eo)) if absolute else (dp, eo)\n",
    "\n",
    "def get_scores(model, X):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        z = model.decision_function(X)\n",
    "        return (z - z.min()) / (z.max() - z.min() + 1e-12)\n",
    "    return model.predict(X).astype(float)\n",
    "\n",
    "def selection_rate(y_pred, positive=1):\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    return np.mean(y_pred == positive)\n",
    "\n",
    "def per_group_table(y_true, y_pred, A, positive=1, group_name=\"Sex\"):\n",
    "    \"\"\"Keeps your existing API (positive=...), uses sklearn metrics.\"\"\"\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    A = np.asarray(A).ravel()\n",
    "    rows = []\n",
    "    for g in np.unique(A):\n",
    "        idx = (A == g)\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0, 1]).ravel()\n",
    "        tpr = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        fpr = fp / (fp + tn) if (fp + tn) else 0.0\n",
    "        rec = recall_score(yt, yp, pos_label=positive)   # equals TPR for binary\n",
    "        sr  = selection_rate(yp, positive=positive)\n",
    "        acc = accuracy_score(yt, yp)\n",
    "        rows.append({group_name: g, \"TPR\": tpr, \"FPR\": fpr,\n",
    "                     \"Recall\": rec, \"SelectionRate\": sr, \"Accuracy\": acc})\n",
    "    return pd.DataFrame(rows).set_index(group_name)\n",
    "\n",
    "def aif_diffs(y_true, y_pred, A, *, abs_vals=True):\n",
    "    \"\"\"Alternative disparities (AIF360): DP and average odds difference.\"\"\"\n",
    "    t = _to_bld(y_true, A)\n",
    "    p = _to_bld(y_pred, A)\n",
    "    cm = ClassificationMetric(\n",
    "        t, p,\n",
    "        privileged_groups=privileged_groups,\n",
    "        unprivileged_groups=unprivileged_groups\n",
    "    )\n",
    "    dp = cm.statistical_parity_difference()\n",
    "    eo = cm.average_odds_difference()   # avg of TPR/FPR diffs\n",
    "    if abs_vals:\n",
    "        dp, eo = abs(dp), abs(eo)\n",
    "    return dp, eo\n",
    "\n",
    "def print_row(title, acc, dp, eo, note=\"\"):\n",
    "    print(f\"{title:>24s} | Acc {acc:.4f} | DP {dp:.4f} | EO {eo:.4f} {('|' if note else '')} {note}\")\n",
    "\n",
    "# to print a model cleanly (fixed call sites)\n",
    "def report_model(name, y_true, y_pred, A, scores=None, note=\"\"):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    dp, eo = fair_metrics(y_true, y_pred, A, y_scores=scores, absolute=True)  # no pos_label here\n",
    "    tbl = per_group_table(y_true, y_pred, A, positive=favorable_label, group_name=\"Sex\").round(6)\n",
    "    \n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    display(tbl)\n",
    "    print(f\"Overall -> Accuracy: {acc:.4f} | DP diff: {dp:.4f} | EO diff: {eo:.4f}\"\n",
    "          + (f\" | {note}\" if note else \"\"))\n",
    "    \n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"DP diff\": dp, \"EO diff\": eo}\n",
    "\n",
    "# Pre: compute reweighing weights ONCE on TRAIN\n",
    "_bld_train = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name],\n",
    "    protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label,\n",
    "    unfavorable_label=unfavorable_label\n",
    ")\n",
    "_rw = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                 privileged_groups=privileged_groups).fit(_bld_train)\n",
    "_rw_weights = _rw.transform(_bld_train).instance_weights.ravel()\n",
    "\n",
    "# Turn weights into a resampled training set\n",
    "def resample_by_weights(X, y, A, weights, n_samples=None, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    Xn = np.asarray(X); yn = np.asarray(y).ravel(); An = np.asarray(A).ravel()\n",
    "    w = np.clip(np.asarray(weights, dtype=float), 1e-12, None)\n",
    "    p = w / w.sum()\n",
    "    n = n_samples or len(yn)\n",
    "    idx = rng.choice(len(yn), size=n, replace=True, p=p)\n",
    "    return Xn[idx], yn[idx], An[idx]\n",
    "\n",
    "Xrw, yrw, Arw = resample_by_weights(\n",
    "    X_train_ready, y_train, A_train, _rw_weights,\n",
    "    n_samples=len(y_train), random_state=42\n",
    ")\n",
    "\n",
    "# Post: make a small TRAIN-based calibration split (no test leakage)\n",
    "trn_X, cal_X, trn_y, cal_y, trn_A, cal_A = train_test_split(\n",
    "    X_train_ready, y_train, A_train, test_size=0.12, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "# Make types consistent to avoid the PCA warning \n",
    "X_test_np = np.asarray(X_test_ready)\n",
    "trn_X_np  = np.asarray(trn_X)\n",
    "cal_X_np  = np.asarray(cal_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf61beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function \n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### PCA-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 12 | Explained variance retained: 0.967\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8858695652173914\n",
      "Precision: 0.9090909090909091\n",
      "Recall   : 0.8823529411764706\n",
      "F1 Score : 0.8955223880597015\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        82\n",
      "           1       0.91      0.88      0.90       102\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.88      0.89      0.88       184\n",
      "weighted avg       0.89      0.89      0.89       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [12 90]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Best CV F1: 0.8593494246061409\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.8097826086956522\n",
      "Precision: 0.819047619047619\n",
      "Recall   : 0.8431372549019608\n",
      "F1 Score : 0.8309178743961353\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78        82\n",
      "           1       0.82      0.84      0.83       102\n",
      "\n",
      "    accuracy                           0.81       184\n",
      "   macro avg       0.81      0.81      0.81       184\n",
      "weighted avg       0.81      0.81      0.81       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[63 19]\n",
      " [16 86]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.8804347826086957\n",
      "Precision: 0.8703703703703703\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8952380952380953\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86        82\n",
      "           1       0.87      0.92      0.90       102\n",
      "\n",
      "    accuracy                           0.88       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.88      0.88      0.88       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b60cc9",
   "metadata": {},
   "source": [
    "### Adam MLP + Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8586956521739131\n",
      "Precision: 0.8877551020408163\n",
      "Recall   : 0.8529411764705882\n",
      "F1 Score : 0.87\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85        82\n",
      "           1       0.89      0.85      0.87       102\n",
      "\n",
      "    accuracy                           0.86       184\n",
      "   macro avg       0.86      0.86      0.86       184\n",
      "weighted avg       0.86      0.86      0.86       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [15 87]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a762eb02",
   "metadata": {},
   "source": [
    "### Bias Mitigation AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e771c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: install AIF360\n",
    "# Uncomment the next line if running locally for the first time\n",
    "#!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de3c1689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIF360 version: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "import aif360\n",
    "print(\"AIF360 version:\", aif360.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99a4a6",
   "metadata": {},
   "source": [
    "### Bias Mitigation AIF 360 - KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9616d2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - KNN baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    0.833333  0.125  0.833333       0.236842  0.868421\n",
       "1    0.885417  0.100  0.885417       0.616438  0.890411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8859 | DP diff: 0.3796 | EO diff: 0.0521\n",
      "\n",
      "=== KNN pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.14000</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TPR      FPR   Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.00000  0.09375  1.00000       0.236842  0.921053\n",
       "1    0.84375  0.14000  0.84375       0.602740  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8641 | DP diff: 0.3659 | EO diff: 0.1562 | resampled by AIF360 weights\n",
      "\n",
      "=== KNN post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.890411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    0.833333  0.125  0.833333       0.236842  0.868421\n",
       "1    0.885417  0.100  0.885417       0.616438  0.890411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8859 | DP diff: 0.3796 | EO diff: 0.0521 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn KNN Baseline for AIF360 bias mitigation\n",
    "knn_base = pca_knn\n",
    "\n",
    "yhat_knn_base   = knn_base.predict(X_test_ready)         \n",
    "scores_knn_base = get_scores(knn_base, X_test_ready)\n",
    "\n",
    "res_knn_base = report_model(\"Fairlearn - KNN baseline\", y_test, yhat_knn_base, A_test, scores=scores_knn_base)\n",
    "\n",
    "\n",
    "#Pre (Reweighing)\n",
    "knn_pre        = clone(pca_knn).fit(Xrw, yrw)\n",
    "yhat_knn_pre   = knn_pre.predict(X_test_ready)\n",
    "scores_knn_pre = get_scores(knn_pre, X_test_ready)\n",
    "res_knn_pre    = report_model(\"KNN pre: Reweigh\",\n",
    "                              y_test, yhat_knn_pre, A_test,\n",
    "                              scores=scores_knn_pre,\n",
    "                              note=\"resampled by AIF360 weights\")\n",
    "\n",
    "#Post (Equalized Odds)\n",
    "cal_scores_knn   = get_scores(knn_base, cal_X_np)  # baseline KNN on CAL\n",
    "post_knn = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups)\n",
    "post_knn.fit(_to_bld(cal_y, cal_A),\n",
    "             _to_bld((cal_scores_knn >= 0.5).astype(int), cal_A))\n",
    "\n",
    "pred_knn_post_bld = post_knn.predict(_to_bld((scores_knn_base >= 0.5).astype(int), A_test))\n",
    "yhat_knn_post     = pred_knn_post_bld.labels.ravel().astype(int)\n",
    "\n",
    "res_knn_post = report_model(\"KNN post: EqOdds\",\n",
    "                            y_test, yhat_knn_post, A_test,\n",
    "                            scores=scores_knn_base,\n",
    "                            note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f9b33",
   "metadata": {},
   "source": [
    "## KNN + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8859   | 0.3796  | **0.0521**        | **0.4317** |\n",
    "| Pre: Reweigh        | 0.8641   | **0.3659** | 0.1562         | 0.5221 |\n",
    "| Post: EqualizedOdds | 0.8859   | 0.3796  | **0.0521**        | **0.4317** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.237**, 1 **0.616** → DP gap **0.380**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.885** → recall gap **0.052** (quite small).  \n",
    "- **FPR:** 0 **0.125**, 1 **0.100**.  \n",
    "- **Note:** High accuracy and already good EO, but selection disparity remains.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.237**, 1 **0.603** → DP improves slightly to **0.366**.  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.844** → EO gap increases to **0.156**.  \n",
    "- **FPR:** 0 **0.094**, 1 **0.140** (both ↑).  \n",
    "- **Note:** Some DP improvement, but EO worsens and accuracy drops modestly.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.237**, 1 **0.616** → DP gap **0.380** (same as baseline).  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.885** → EO gap unchanged (**0.052**).  \n",
    "- **FPR:** 0 **0.125**, 1 **0.100** (same as baseline).  \n",
    "- **Note:** Identical to baseline — no fairness gains.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Baseline** already strikes the best balance (small EO, higher accuracy).  \n",
    "- **Pre: Reweigh** reduces DP a bit but worsens EO and lowers accuracy.  \n",
    "- **Post: EqOdds** does not change results in this setup.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64ab072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - DT baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.28125</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.623288</td>\n",
       "      <td>0.828767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.28125  0.833333       0.368421  0.736842\n",
       "1    0.843750  0.20000  0.843750       0.623288  0.828767"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8098 | DP diff: 0.2549 | EO diff: 0.0104\n",
      "\n",
      "=== DT pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.582192</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR   FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                   \n",
       "0    1.000000  0.25  1.000000       0.368421  0.789474\n",
       "1    0.802083  0.16  0.802083       0.582192  0.815068"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8098 | DP diff: 0.2138 | EO diff: 0.1979 | resampled by AIF360 weights\n",
      "\n",
      "=== DT post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.636986</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    0.833333  0.375  0.833333       0.447368  0.657895\n",
       "1    0.864583  0.200  0.864583       0.636986  0.842466"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8043 | DP diff: 0.1896 | EO diff: 0.0312 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn DT Baseline for AIF360 bias mitigation\n",
    "dt_base = tuned_dt\n",
    "\n",
    "yhat_dt_base   = dt_base.predict(X_test_ready)         \n",
    "scores_dt_base = get_scores(dt_base, X_test_ready)\n",
    "\n",
    "res_dt_base = report_model(\"Fairlearn - DT baseline\", y_test, yhat_dt_base, A_test, scores=scores_dt_base)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "dt_pre = clone(tuned_dt).fit(Xrw, yrw)\n",
    "yhat_dt_pre = dt_pre.predict(X_test_np)\n",
    "scores_dt_pre = get_scores(dt_pre, X_test_np)\n",
    "_ = report_model(\"DT pre: Reweigh\", y_test, yhat_dt_pre, A_test, scores=scores_dt_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_dt = get_scores(dt_base, cal_X_np)\n",
    "post_dt = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_dt.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_dt >= 0.5).astype(int), cal_A))\n",
    "yhat_dt_post = post_dt.predict(_to_bld((scores_dt_base >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"DT post: EqOdds\", y_test, yhat_dt_post, A_test, scores=scores_dt_base,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d907a5",
   "metadata": {},
   "source": [
    "## DT + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8098   | 0.2549  | **0.0104**        | **0.2653** |\n",
    "| Pre: Reweigh        | 0.8098   | 0.2138  | 0.1979            | 0.4117 |\n",
    "| Post: EqualizedOdds | 0.8043   | **0.1896** | 0.0312          | 0.2208 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group reading (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.369**, 1 **0.624** → DP gap **0.255**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.844** → EO gap **0.010** (excellent parity).  \n",
    "- **FPR:** 0 **0.281**, 1 **0.200** (higher for females).  \n",
    "- **Note:** High balance overall; smallest EO and decent accuracy.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.368**, 1 **0.582** → DP improves to **0.214**.  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.802** → EO worsens to **0.198**.  \n",
    "- **FPR:** 0 **0.250**, 1 **0.160**.  \n",
    "- **Note:** Best DP vs. baseline, but EO gap widens significantly.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.447**, 1 **0.637** → DP improves further to **0.190**.  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.865** → EO gap **0.031** (still small).  \n",
    "- **FPR:** 0 **0.375** (↑), 1 **0.200** (≈ baseline).  \n",
    "- **Note:** Strong DP improvement, EO still low, but accuracy slightly reduced.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most balanced overall:** **Post: EqOdds**, with the lowest combined gap (DP+EO ≈ 0.221).  \n",
    "- **Baseline** already has excellent EO (≈0.01) and good accuracy but higher DP.  \n",
    "- **Pre: Reweigh** reduces DP but significantly harms EO parity.  \n",
    "- **Takeaway:** Post-processing seems the more effective fairness strategy for DT here, though baseline is also competitive thanks to its minimal EO gap.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a886023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - RF baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.000000  0.125  1.000000       0.263158  0.894737\n",
       "1    0.916667  0.200  0.916667       0.671233  0.876712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== RF pre: Reweigh (sample_weight) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.000000  0.125  1.000000       0.263158  0.894737\n",
       "1    0.916667  0.200  0.916667       0.671233  0.876712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8804 | DP diff: 0.4081 | EO diff: 0.0833\n",
      "\n",
      "=== RF post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.671233</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.15625  1.000000       0.289474  0.868421\n",
       "1    0.916667  0.20000  0.916667       0.671233  0.876712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8750 | DP diff: 0.3818 | EO diff: 0.0833 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "# Random Forest (RF) with AIF360\n",
    "\n",
    "# -get Fairlearn baseline\n",
    "yhat_rf_base    = rf.predict(X_test_ready)\n",
    "scores_rf_base  = get_scores(rf, X_test_ready)\n",
    "res_rf_base     = report_model(\"Fairlearn - RF baseline\", y_test, yhat_rf_base, A_test, scores=scores_rf_base)\n",
    "\n",
    "# Pre (Reweighing via sample_weight)\n",
    "rf_pre          = clone(rf).fit(X_train_ready, y_train, sample_weight=_rw_weights)\n",
    "yhat_rf_pre     = rf_pre.predict(X_test_ready)\n",
    "scores_rf_pre   = get_scores(rf_pre, X_test_ready)\n",
    "res_rf_pre      = report_model(\"RF pre: Reweigh (sample_weight)\",\n",
    "                               y_test, yhat_rf_pre, A_test, scores=scores_rf_pre)\n",
    "\n",
    "# Post (Equalized Odds) learned on CAL\n",
    "cal_scores_rf   = get_scores(rf, cal_X_np)  # baseline rf on calibration split\n",
    "post_rf = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                               unprivileged_groups=unprivileged_groups)\n",
    "post_rf.fit(_to_bld(cal_y, cal_A),\n",
    "            _to_bld((cal_scores_rf >= 0.5).astype(int), cal_A))\n",
    "\n",
    "pred_rf_post_bld = post_rf.predict(_to_bld((scores_rf_base >= 0.5).astype(int), A_test))\n",
    "yhat_rf_post     = pred_rf_post_bld.labels.ravel().astype(int)\n",
    "\n",
    "res_rf_post = report_model(\"RF post: EqOdds\",\n",
    "                           y_test, yhat_rf_post, A_test,\n",
    "                           scores=scores_rf_base,\n",
    "                           note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64d0610",
   "metadata": {},
   "source": [
    "## RF + AIF360 \n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8804   | 0.4081  | **0.0833**        | 0.4914 |\n",
    "| Pre: Reweigh        | 0.8804   | 0.4081  | **0.0833**        | 0.4914 |\n",
    "| Post: EqualizedOdds | 0.8750   | **0.3818** | **0.0833**      | **0.4651** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.263**, 1 **0.671** → DP gap **0.408** (large).  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.917** → EO gap **0.083** (small).  \n",
    "- **FPR:** 0 **0.125**, 1 **0.200**.  \n",
    "- **Note:** High accuracy, EO relatively low, but strong selection disparity.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** unchanged → DP **0.408**.  \n",
    "- **TPR (Recall):** unchanged (**1.000 vs 0.917**) → EO **0.083**.  \n",
    "- **FPR:** unchanged.  \n",
    "- **Note:** Exactly the same as baseline due to sample weighting.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.289**, 1 **0.671** → DP improves slightly to **0.382**.  \n",
    "- **TPR (Recall):** unchanged (**1.000 vs 0.917**) → EO **0.083**.  \n",
    "- **FPR:** 0 **0.156**, 1 **0.200** (female FPR ↑).  \n",
    "- **Note:** Accuracy drops a bit (0.875 vs 0.880), fairness slightly improved on DP, EO unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall:** **Post: EqOdds** achieves the lowest combined gap (DP+EO ≈ 0.465), though at a minor accuracy cost.  \n",
    "- **Baseline** already gives good EO parity but with higher DP disparity.  \n",
    "- **Pre: Reweigh** has no effect in this configuration.  \n",
    "- **Takeaway:** RF baseline is strong, but post-processing offers a marginal DP improvement without hurting EO.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f76d783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fairlearn - MLP baseline ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.84375</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         TPR    FPR   Recall  SelectionRate  Accuracy\n",
       "Sex                                                  \n",
       "0    1.00000  0.125  1.00000       0.263158  0.894737\n",
       "1    0.84375  0.140  0.84375       0.602740  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8587 | DP diff: 0.3396 | EO diff: 0.1562\n",
      "\n",
      "=== MLP pre: Reweigh ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.20000</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.650685</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.15625  1.000000       0.289474  0.868421\n",
       "1    0.885417  0.20000  0.885417       0.650685  0.856164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8587 | DP diff: 0.3612 | EO diff: 0.1146 | resampled by AIF360 weights\n",
      "\n",
      "=== MLP post: EqOdds ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.595890</td>\n",
       "      <td>0.787671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR    FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                    \n",
       "0    1.000000  0.125  1.000000       0.263158  0.894737\n",
       "1    0.791667  0.220  0.791667       0.595890  0.787671"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8098 | DP diff: 0.3327 | EO diff: 0.2083 | calibrated on held-out TRAIN\n"
     ]
    }
   ],
   "source": [
    "#get the Fairlearn MLP Baseline for AIF360 bias mitigation\n",
    "mlp_base = adammlp\n",
    "yhat_mlp_base   = mlp_base.predict(X_test_ready)         \n",
    "scores_mlp_base = get_scores(mlp_base, X_test_ready)\n",
    "\n",
    "res_mlp_base = report_model(\"Fairlearn - MLP baseline\", y_test, yhat_mlp_base, A_test, scores=scores_mlp_base)\n",
    "\n",
    "# Pre (Reweighing)\n",
    "mlp_pre = clone(adammlp).fit(Xrw, yrw)\n",
    "yhat_mlp_pre = mlp_pre.predict(X_test_np)\n",
    "scores_mlp_pre = get_scores(mlp_pre, X_test_np)\n",
    "_ = report_model(\"MLP pre: Reweigh\", y_test, yhat_mlp_pre, A_test, scores=scores_mlp_pre,\n",
    "                 note=\"resampled by AIF360 weights\")\n",
    "\n",
    "# Post (Equalized Odds)\n",
    "cal_scores_mlp = get_scores(mlp_base, cal_X_np)\n",
    "post_mlp = EqOddsPostprocessing(privileged_groups=privileged_groups,\n",
    "                                unprivileged_groups=unprivileged_groups)\n",
    "post_mlp.fit(_to_bld(cal_y, cal_A),\n",
    "             _to_bld((cal_scores_mlp >= 0.5).astype(int), cal_A))\n",
    "yhat_mlp_post = post_mlp.predict(_to_bld((scores_mlp_base >= 0.5).astype(int), A_test)).labels.ravel().astype(int)\n",
    "_ = report_model(\"MLP post: EqOdds\", y_test, yhat_mlp_post, A_test, scores=scores_mlp_base,\n",
    "                 note=\"calibrated on held-out TRAIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712a7a1",
   "metadata": {},
   "source": [
    "## MLP + AIF360\n",
    "\n",
    "### Results overview\n",
    "| Variant             | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|---------------------|---------:|--------:|------------------:|------:|\n",
    "| Baseline            | 0.8587   | **0.3396** | 0.1562          | 0.4958 |\n",
    "| Pre: Reweigh        | 0.8587   | 0.3612  | **0.1146**        | **0.4758** |\n",
    "| Post: EqualizedOdds | 0.8098   | 0.3327  | 0.2083            | 0.5410 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### Baseline\n",
    "- **Selection rate:** 0 **0.263**, 1 **0.603** → DP gap **0.340**.  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.844** → EO gap **0.156**.  \n",
    "- **FPR:** 0 **0.125**, 1 **0.140**.  \n",
    "- **Note:** Highest accuracy, with moderate DP disparity and a noticeable EO gap.\n",
    "\n",
    "#### Pre-processing: Reweigh\n",
    "- **Selection rate:** 0 **0.289**, 1 **0.651** → DP worsens slightly to **0.361**.  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.885** → **best EO** (**0.115**).  \n",
    "- **FPR:** 0 **0.156**, 1 **0.200** (both ↑ compared to baseline).  \n",
    "- **Note:** Improves EO but increases DP a bit; accuracy unchanged.\n",
    "\n",
    "#### Post-processing: Equalized Odds\n",
    "- **Selection rate:** 0 **0.263**, 1 **0.596** → DP **0.333** (slightly better than baseline).  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.792** → EO worsens to **0.208**.  \n",
    "- **FPR:** 0 **0.125**, 1 **0.220** (female parity maintained, male ↑ sharply).  \n",
    "- **Note:** Accuracy drops most (0.810); DP improved, but EO worsened.\n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **Most fair overall (lowest DP+EO):** **Pre: Reweigh** (≈0.476) — best EO, but slightly worse DP.  \n",
    "- **Baseline** remains strong in accuracy and a decent fairness balance.  \n",
    "- **Post: EqOdds** sacrifices accuracy and EO, despite a small DP improvement.  \n",
    "\n",
    "For MLP, **Reweighing** appears to be the most effective trade-off, prioritizing equal opportunity while keeping accuracy high.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce511e42",
   "metadata": {},
   "source": [
    "First fairness mitigation: pre- and post-processing was performed on the designated best performing models (KNN, DT, RF, MLP) for CVD prediction.  In addition, these results are compared to a fairness-aware in-processing model - Adversarial Debiasing offered by AIF360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66355777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_1188\\3615687400.py:10: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\patri\\AppData\\Local\\Temp\\ipykernel_1188\\3615687400.py:11: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735763; batch adversarial loss: 0.681147\n",
      "epoch 1; iter: 0; batch classifier loss: 0.677662; batch adversarial loss: 0.682407\n",
      "epoch 2; iter: 0; batch classifier loss: 0.607165; batch adversarial loss: 0.679510\n",
      "epoch 3; iter: 0; batch classifier loss: 0.569618; batch adversarial loss: 0.679133\n",
      "epoch 4; iter: 0; batch classifier loss: 0.505279; batch adversarial loss: 0.676523\n",
      "epoch 5; iter: 0; batch classifier loss: 0.493380; batch adversarial loss: 0.680220\n",
      "epoch 6; iter: 0; batch classifier loss: 0.475112; batch adversarial loss: 0.675369\n",
      "epoch 7; iter: 0; batch classifier loss: 0.466881; batch adversarial loss: 0.674108\n",
      "epoch 8; iter: 0; batch classifier loss: 0.373924; batch adversarial loss: 0.667348\n",
      "epoch 9; iter: 0; batch classifier loss: 0.396961; batch adversarial loss: 0.669007\n",
      "epoch 10; iter: 0; batch classifier loss: 0.365351; batch adversarial loss: 0.665717\n",
      "epoch 11; iter: 0; batch classifier loss: 0.420213; batch adversarial loss: 0.663562\n",
      "epoch 12; iter: 0; batch classifier loss: 0.354387; batch adversarial loss: 0.672283\n",
      "epoch 13; iter: 0; batch classifier loss: 0.427244; batch adversarial loss: 0.669910\n",
      "epoch 14; iter: 0; batch classifier loss: 0.352616; batch adversarial loss: 0.662156\n",
      "epoch 15; iter: 0; batch classifier loss: 0.314048; batch adversarial loss: 0.656817\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360816; batch adversarial loss: 0.663770\n",
      "epoch 17; iter: 0; batch classifier loss: 0.327919; batch adversarial loss: 0.654452\n",
      "epoch 18; iter: 0; batch classifier loss: 0.356109; batch adversarial loss: 0.663891\n",
      "epoch 19; iter: 0; batch classifier loss: 0.486234; batch adversarial loss: 0.652489\n",
      "epoch 20; iter: 0; batch classifier loss: 0.327905; batch adversarial loss: 0.654067\n",
      "epoch 21; iter: 0; batch classifier loss: 0.328325; batch adversarial loss: 0.662840\n",
      "epoch 22; iter: 0; batch classifier loss: 0.268828; batch adversarial loss: 0.650423\n",
      "epoch 23; iter: 0; batch classifier loss: 0.334604; batch adversarial loss: 0.641406\n",
      "epoch 24; iter: 0; batch classifier loss: 0.293802; batch adversarial loss: 0.659397\n",
      "epoch 25; iter: 0; batch classifier loss: 0.361483; batch adversarial loss: 0.649668\n",
      "epoch 26; iter: 0; batch classifier loss: 0.291269; batch adversarial loss: 0.646194\n",
      "epoch 27; iter: 0; batch classifier loss: 0.297438; batch adversarial loss: 0.636979\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336963; batch adversarial loss: 0.643534\n",
      "epoch 29; iter: 0; batch classifier loss: 0.337456; batch adversarial loss: 0.646159\n",
      "epoch 30; iter: 0; batch classifier loss: 0.324548; batch adversarial loss: 0.628688\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352242; batch adversarial loss: 0.643462\n",
      "epoch 32; iter: 0; batch classifier loss: 0.322010; batch adversarial loss: 0.640469\n",
      "epoch 33; iter: 0; batch classifier loss: 0.310559; batch adversarial loss: 0.646774\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393029; batch adversarial loss: 0.634461\n",
      "epoch 35; iter: 0; batch classifier loss: 0.295336; batch adversarial loss: 0.636375\n",
      "epoch 36; iter: 0; batch classifier loss: 0.373282; batch adversarial loss: 0.637880\n",
      "epoch 37; iter: 0; batch classifier loss: 0.255998; batch adversarial loss: 0.637755\n",
      "epoch 38; iter: 0; batch classifier loss: 0.249127; batch adversarial loss: 0.640268\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321173; batch adversarial loss: 0.620721\n",
      "epoch 40; iter: 0; batch classifier loss: 0.365201; batch adversarial loss: 0.628345\n",
      "epoch 41; iter: 0; batch classifier loss: 0.316920; batch adversarial loss: 0.643330\n",
      "epoch 42; iter: 0; batch classifier loss: 0.298161; batch adversarial loss: 0.630800\n",
      "epoch 43; iter: 0; batch classifier loss: 0.349693; batch adversarial loss: 0.615623\n",
      "epoch 44; iter: 0; batch classifier loss: 0.243959; batch adversarial loss: 0.642254\n",
      "epoch 45; iter: 0; batch classifier loss: 0.268342; batch adversarial loss: 0.649164\n",
      "epoch 46; iter: 0; batch classifier loss: 0.253377; batch adversarial loss: 0.658396\n",
      "epoch 47; iter: 0; batch classifier loss: 0.299090; batch adversarial loss: 0.628899\n",
      "epoch 48; iter: 0; batch classifier loss: 0.358684; batch adversarial loss: 0.645760\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270118; batch adversarial loss: 0.608374\n",
      "\n",
      "=== ADV in-proc (AIF360) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.868421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.575342</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    1.000000  0.15625  1.000000       0.289474  0.868421\n",
       "1    0.822917  0.10000  0.822917       0.575342  0.849315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8533 | DP diff: 0.2859 | EO diff: 0.1771 | trained on X_train_ready\n"
     ]
    }
   ],
   "source": [
    "#Adversarial Debiasing - In-processing by AIF360\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "    # TF1 graph mode - required by AIF360's implementation \n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "    # Build AIF360 datasets with FEATURES + label + sensitive attribute\n",
    "    bld_tr = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "            pd.Series(y_train, name=label_name),\n",
    "            pd.Series(A_train, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    bld_te = BinaryLabelDataset(\n",
    "        df=pd.concat([\n",
    "            pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "            pd.Series(y_test, name=label_name),\n",
    "            pd.Series(A_test, name=protected_attr)\n",
    "        ], axis=1),\n",
    "        label_names=[label_name],\n",
    "        protected_attribute_names=[protected_attr],\n",
    "        favorable_label=favorable_label,\n",
    "        unfavorable_label=unfavorable_label\n",
    "    )\n",
    "\n",
    "    # Train + predict inside a TF1 session\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            scope_name=\"adv_debias\",\n",
    "            debias=True,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "\n",
    "        # Extract labels and (if available) scores\n",
    "        yhat_adv = pred_te.labels.ravel().astype(int)\n",
    "        scores_adv = getattr(pred_te, \"scores\", None)\n",
    "        if scores_adv is None:\n",
    "            scores_adv = yhat_adv.astype(float)\n",
    "\n",
    "    # Clean up TF graph\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    sess.close()\n",
    "\n",
    "    # Same structured output as other models\n",
    "    _ = report_model(\n",
    "        \"ADV in-proc (AIF360)\",\n",
    "        y_test, yhat_adv, A_test,\n",
    "        scores=scores_adv,\n",
    "        note=\"trained on X_train_ready\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"AdversarialDebiasing skipped:\", type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c7b8",
   "metadata": {},
   "source": [
    "## ADV In-processing (AIF360)\n",
    "\n",
    "### Results overview\n",
    "| Variant        | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|----------------|---------:|--------:|------------------:|------:|\n",
    "| ADV in-proc    | 0.8533   | **0.2859** | 0.1771          | 0.4630 |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### ADV in-proc\n",
    "- **Selection rate:** 0 **0.289**, 1 **0.575** → DP gap **0.286** (moderate).  \n",
    "- **TPR (Recall):** 0 **1.000**, 1 **0.823** → EO gap **0.177** (females perfectly recalled, males lower).  \n",
    "- **FPR:** 0 **0.156**, 1 **0.100** (female higher).  \n",
    "- **Accuracy:** Female **0.868**, Male **0.849** → both solid, female slightly higher.  \n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **DP disparity improves** notably (0.286 vs ~0.38 in earlier ADV runs).  \n",
    "- **EO gap worsens** (0.177 vs ~0.03 previously), as female recall is perfect while male recall lags.  \n",
    "- **Accuracy (0.853)** is competitive, only slightly below prior ADV results.  \n",
    "- **Interpretation:** This configuration balances selection rates better, but trades off by creating a larger recall disparity between sexes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e29721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.807135; batch adversarial loss: 0.665331\n",
      "epoch 1; iter: 0; batch classifier loss: 0.762230; batch adversarial loss: 0.647444\n",
      "epoch 2; iter: 0; batch classifier loss: 0.676140; batch adversarial loss: 0.644139\n",
      "epoch 3; iter: 0; batch classifier loss: 0.622245; batch adversarial loss: 0.697847\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550433; batch adversarial loss: 0.640313\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569255; batch adversarial loss: 0.632424\n",
      "epoch 6; iter: 0; batch classifier loss: 0.603947; batch adversarial loss: 0.642563\n",
      "epoch 7; iter: 0; batch classifier loss: 0.535557; batch adversarial loss: 0.613861\n",
      "epoch 8; iter: 0; batch classifier loss: 0.468385; batch adversarial loss: 0.641418\n",
      "epoch 9; iter: 0; batch classifier loss: 0.601277; batch adversarial loss: 0.613495\n",
      "epoch 10; iter: 0; batch classifier loss: 0.393018; batch adversarial loss: 0.597638\n",
      "epoch 11; iter: 0; batch classifier loss: 0.394670; batch adversarial loss: 0.625879\n",
      "epoch 12; iter: 0; batch classifier loss: 0.482194; batch adversarial loss: 0.611951\n",
      "epoch 13; iter: 0; batch classifier loss: 0.432137; batch adversarial loss: 0.665050\n",
      "epoch 14; iter: 0; batch classifier loss: 0.308033; batch adversarial loss: 0.653957\n",
      "epoch 15; iter: 0; batch classifier loss: 0.363185; batch adversarial loss: 0.656118\n",
      "epoch 16; iter: 0; batch classifier loss: 0.360785; batch adversarial loss: 0.609296\n",
      "epoch 17; iter: 0; batch classifier loss: 0.492435; batch adversarial loss: 0.588004\n",
      "epoch 18; iter: 0; batch classifier loss: 0.390091; batch adversarial loss: 0.643560\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366477; batch adversarial loss: 0.598641\n",
      "epoch 20; iter: 0; batch classifier loss: 0.457598; batch adversarial loss: 0.647550\n",
      "epoch 21; iter: 0; batch classifier loss: 0.342344; batch adversarial loss: 0.667002\n",
      "epoch 22; iter: 0; batch classifier loss: 0.323432; batch adversarial loss: 0.621225\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398633; batch adversarial loss: 0.576381\n",
      "epoch 24; iter: 0; batch classifier loss: 0.289026; batch adversarial loss: 0.620054\n",
      "epoch 25; iter: 0; batch classifier loss: 0.309935; batch adversarial loss: 0.590962\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352231; batch adversarial loss: 0.580652\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389751; batch adversarial loss: 0.587729\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387430; batch adversarial loss: 0.611599\n",
      "epoch 29; iter: 0; batch classifier loss: 0.429742; batch adversarial loss: 0.603063\n",
      "epoch 30; iter: 0; batch classifier loss: 0.252193; batch adversarial loss: 0.649301\n",
      "epoch 31; iter: 0; batch classifier loss: 0.317876; batch adversarial loss: 0.607654\n",
      "epoch 32; iter: 0; batch classifier loss: 0.378859; batch adversarial loss: 0.588687\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356075; batch adversarial loss: 0.620802\n",
      "epoch 34; iter: 0; batch classifier loss: 0.358377; batch adversarial loss: 0.671857\n",
      "epoch 35; iter: 0; batch classifier loss: 0.381351; batch adversarial loss: 0.631631\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360551; batch adversarial loss: 0.682220\n",
      "epoch 37; iter: 0; batch classifier loss: 0.426205; batch adversarial loss: 0.596105\n",
      "epoch 38; iter: 0; batch classifier loss: 0.386809; batch adversarial loss: 0.565876\n",
      "epoch 39; iter: 0; batch classifier loss: 0.280971; batch adversarial loss: 0.685609\n",
      "epoch 0; iter: 0; batch classifier loss: 0.701747; batch adversarial loss: 0.675198\n",
      "epoch 1; iter: 0; batch classifier loss: 0.668853; batch adversarial loss: 0.681319\n",
      "epoch 2; iter: 0; batch classifier loss: 0.590934; batch adversarial loss: 0.631671\n",
      "epoch 3; iter: 0; batch classifier loss: 0.547540; batch adversarial loss: 0.668953\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532926; batch adversarial loss: 0.626614\n",
      "epoch 5; iter: 0; batch classifier loss: 0.508153; batch adversarial loss: 0.580226\n",
      "epoch 6; iter: 0; batch classifier loss: 0.501261; batch adversarial loss: 0.636093\n",
      "epoch 7; iter: 0; batch classifier loss: 0.437944; batch adversarial loss: 0.728794\n",
      "epoch 8; iter: 0; batch classifier loss: 0.404311; batch adversarial loss: 0.674466\n",
      "epoch 9; iter: 0; batch classifier loss: 0.368033; batch adversarial loss: 0.657275\n",
      "epoch 10; iter: 0; batch classifier loss: 0.475538; batch adversarial loss: 0.665108\n",
      "epoch 11; iter: 0; batch classifier loss: 0.389317; batch adversarial loss: 0.686072\n",
      "epoch 12; iter: 0; batch classifier loss: 0.383474; batch adversarial loss: 0.659709\n",
      "epoch 13; iter: 0; batch classifier loss: 0.460597; batch adversarial loss: 0.690187\n",
      "epoch 14; iter: 0; batch classifier loss: 0.343879; batch adversarial loss: 0.575554\n",
      "epoch 15; iter: 0; batch classifier loss: 0.431975; batch adversarial loss: 0.607581\n",
      "epoch 16; iter: 0; batch classifier loss: 0.273074; batch adversarial loss: 0.592570\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365202; batch adversarial loss: 0.597459\n",
      "epoch 18; iter: 0; batch classifier loss: 0.384815; batch adversarial loss: 0.605877\n",
      "epoch 19; iter: 0; batch classifier loss: 0.276514; batch adversarial loss: 0.596601\n",
      "epoch 20; iter: 0; batch classifier loss: 0.443534; batch adversarial loss: 0.621525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295020; batch adversarial loss: 0.579468\n",
      "epoch 22; iter: 0; batch classifier loss: 0.373148; batch adversarial loss: 0.682492\n",
      "epoch 23; iter: 0; batch classifier loss: 0.388203; batch adversarial loss: 0.577498\n",
      "epoch 24; iter: 0; batch classifier loss: 0.323959; batch adversarial loss: 0.678271\n",
      "epoch 25; iter: 0; batch classifier loss: 0.442145; batch adversarial loss: 0.623848\n",
      "epoch 26; iter: 0; batch classifier loss: 0.271434; batch adversarial loss: 0.644808\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316094; batch adversarial loss: 0.617359\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390502; batch adversarial loss: 0.641374\n",
      "epoch 29; iter: 0; batch classifier loss: 0.317478; batch adversarial loss: 0.617274\n",
      "epoch 30; iter: 0; batch classifier loss: 0.406403; batch adversarial loss: 0.612991\n",
      "epoch 31; iter: 0; batch classifier loss: 0.412101; batch adversarial loss: 0.557875\n",
      "epoch 32; iter: 0; batch classifier loss: 0.380681; batch adversarial loss: 0.660000\n",
      "epoch 33; iter: 0; batch classifier loss: 0.282502; batch adversarial loss: 0.643420\n",
      "epoch 34; iter: 0; batch classifier loss: 0.432202; batch adversarial loss: 0.655156\n",
      "epoch 35; iter: 0; batch classifier loss: 0.277578; batch adversarial loss: 0.652554\n",
      "epoch 36; iter: 0; batch classifier loss: 0.279664; batch adversarial loss: 0.618983\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363959; batch adversarial loss: 0.618725\n",
      "epoch 38; iter: 0; batch classifier loss: 0.273112; batch adversarial loss: 0.618433\n",
      "epoch 39; iter: 0; batch classifier loss: 0.355491; batch adversarial loss: 0.603318\n",
      "epoch 0; iter: 0; batch classifier loss: 0.734163; batch adversarial loss: 0.828524\n",
      "epoch 1; iter: 0; batch classifier loss: 0.681356; batch adversarial loss: 0.792976\n",
      "epoch 2; iter: 0; batch classifier loss: 0.697187; batch adversarial loss: 0.769762\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652404; batch adversarial loss: 0.749901\n",
      "epoch 4; iter: 0; batch classifier loss: 0.647880; batch adversarial loss: 0.772451\n",
      "epoch 5; iter: 0; batch classifier loss: 0.643456; batch adversarial loss: 0.752473\n",
      "epoch 6; iter: 0; batch classifier loss: 0.624764; batch adversarial loss: 0.773980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.625092; batch adversarial loss: 0.744028\n",
      "epoch 8; iter: 0; batch classifier loss: 0.633492; batch adversarial loss: 0.755709\n",
      "epoch 9; iter: 0; batch classifier loss: 0.560308; batch adversarial loss: 0.770872\n",
      "epoch 10; iter: 0; batch classifier loss: 0.558289; batch adversarial loss: 0.772856\n",
      "epoch 11; iter: 0; batch classifier loss: 0.551242; batch adversarial loss: 0.747191\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572138; batch adversarial loss: 0.760423\n",
      "epoch 13; iter: 0; batch classifier loss: 0.550819; batch adversarial loss: 0.790667\n",
      "epoch 14; iter: 0; batch classifier loss: 0.495641; batch adversarial loss: 0.741844\n",
      "epoch 15; iter: 0; batch classifier loss: 0.538810; batch adversarial loss: 0.773467\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475861; batch adversarial loss: 0.746334\n",
      "epoch 17; iter: 0; batch classifier loss: 0.533059; batch adversarial loss: 0.768112\n",
      "epoch 18; iter: 0; batch classifier loss: 0.519436; batch adversarial loss: 0.791292\n",
      "epoch 19; iter: 0; batch classifier loss: 0.558191; batch adversarial loss: 0.727028\n",
      "epoch 20; iter: 0; batch classifier loss: 0.467500; batch adversarial loss: 0.754129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.483101; batch adversarial loss: 0.762440\n",
      "epoch 22; iter: 0; batch classifier loss: 0.486926; batch adversarial loss: 0.756131\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479337; batch adversarial loss: 0.753358\n",
      "epoch 24; iter: 0; batch classifier loss: 0.498510; batch adversarial loss: 0.771361\n",
      "epoch 25; iter: 0; batch classifier loss: 0.455678; batch adversarial loss: 0.760366\n",
      "epoch 26; iter: 0; batch classifier loss: 0.497646; batch adversarial loss: 0.733535\n",
      "epoch 27; iter: 0; batch classifier loss: 0.445055; batch adversarial loss: 0.729612\n",
      "epoch 28; iter: 0; batch classifier loss: 0.446169; batch adversarial loss: 0.735004\n",
      "epoch 29; iter: 0; batch classifier loss: 0.566727; batch adversarial loss: 0.771965\n",
      "epoch 30; iter: 0; batch classifier loss: 0.475374; batch adversarial loss: 0.751009\n",
      "epoch 31; iter: 0; batch classifier loss: 0.522008; batch adversarial loss: 0.720595\n",
      "epoch 32; iter: 0; batch classifier loss: 0.421252; batch adversarial loss: 0.743383\n",
      "epoch 33; iter: 0; batch classifier loss: 0.515753; batch adversarial loss: 0.773428\n",
      "epoch 34; iter: 0; batch classifier loss: 0.496563; batch adversarial loss: 0.701099\n",
      "epoch 35; iter: 0; batch classifier loss: 0.507196; batch adversarial loss: 0.744165\n",
      "epoch 36; iter: 0; batch classifier loss: 0.496356; batch adversarial loss: 0.755635\n",
      "epoch 37; iter: 0; batch classifier loss: 0.458642; batch adversarial loss: 0.730352\n",
      "epoch 38; iter: 0; batch classifier loss: 0.530147; batch adversarial loss: 0.749432\n",
      "epoch 39; iter: 0; batch classifier loss: 0.432642; batch adversarial loss: 0.740355\n",
      "epoch 0; iter: 0; batch classifier loss: 0.787067; batch adversarial loss: 0.856317\n",
      "epoch 1; iter: 0; batch classifier loss: 0.747853; batch adversarial loss: 0.863774\n",
      "epoch 2; iter: 0; batch classifier loss: 0.706907; batch adversarial loss: 0.848414\n",
      "epoch 3; iter: 0; batch classifier loss: 0.642587; batch adversarial loss: 0.808496\n",
      "epoch 4; iter: 0; batch classifier loss: 0.653220; batch adversarial loss: 0.859749\n",
      "epoch 5; iter: 0; batch classifier loss: 0.590162; batch adversarial loss: 0.824527\n",
      "epoch 6; iter: 0; batch classifier loss: 0.535032; batch adversarial loss: 0.841377\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573985; batch adversarial loss: 0.841112\n",
      "epoch 8; iter: 0; batch classifier loss: 0.546449; batch adversarial loss: 0.797200\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462759; batch adversarial loss: 0.859846\n",
      "epoch 10; iter: 0; batch classifier loss: 0.444890; batch adversarial loss: 0.877624\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491736; batch adversarial loss: 0.857509\n",
      "epoch 12; iter: 0; batch classifier loss: 0.507140; batch adversarial loss: 0.846690\n",
      "epoch 13; iter: 0; batch classifier loss: 0.419818; batch adversarial loss: 0.889749\n",
      "epoch 14; iter: 0; batch classifier loss: 0.488436; batch adversarial loss: 0.856961\n",
      "epoch 15; iter: 0; batch classifier loss: 0.508955; batch adversarial loss: 0.830513\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489036; batch adversarial loss: 0.850480\n",
      "epoch 17; iter: 0; batch classifier loss: 0.442346; batch adversarial loss: 0.887435\n",
      "epoch 18; iter: 0; batch classifier loss: 0.455096; batch adversarial loss: 0.856943\n",
      "epoch 19; iter: 0; batch classifier loss: 0.420933; batch adversarial loss: 0.855001\n",
      "epoch 20; iter: 0; batch classifier loss: 0.414803; batch adversarial loss: 0.845176\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416646; batch adversarial loss: 0.836169\n",
      "epoch 22; iter: 0; batch classifier loss: 0.365741; batch adversarial loss: 0.857285\n",
      "epoch 23; iter: 0; batch classifier loss: 0.396413; batch adversarial loss: 0.818436\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400672; batch adversarial loss: 0.842032\n",
      "epoch 25; iter: 0; batch classifier loss: 0.328914; batch adversarial loss: 0.809274\n",
      "epoch 26; iter: 0; batch classifier loss: 0.378575; batch adversarial loss: 0.784083\n",
      "epoch 27; iter: 0; batch classifier loss: 0.403219; batch adversarial loss: 0.806704\n",
      "epoch 28; iter: 0; batch classifier loss: 0.461186; batch adversarial loss: 0.803932\n",
      "epoch 29; iter: 0; batch classifier loss: 0.354156; batch adversarial loss: 0.814613\n",
      "epoch 30; iter: 0; batch classifier loss: 0.431321; batch adversarial loss: 0.802683\n",
      "epoch 31; iter: 0; batch classifier loss: 0.373560; batch adversarial loss: 0.796548\n",
      "epoch 32; iter: 0; batch classifier loss: 0.435283; batch adversarial loss: 0.810100\n",
      "epoch 33; iter: 0; batch classifier loss: 0.383052; batch adversarial loss: 0.804886\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352822; batch adversarial loss: 0.766833\n",
      "epoch 35; iter: 0; batch classifier loss: 0.380660; batch adversarial loss: 0.791072\n",
      "epoch 36; iter: 0; batch classifier loss: 0.313120; batch adversarial loss: 0.790515\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346370; batch adversarial loss: 0.796860\n",
      "epoch 38; iter: 0; batch classifier loss: 0.338415; batch adversarial loss: 0.785633\n",
      "epoch 39; iter: 0; batch classifier loss: 0.306888; batch adversarial loss: 0.784098\n",
      "epoch 0; iter: 0; batch classifier loss: 0.780959; batch adversarial loss: 0.632146\n",
      "epoch 1; iter: 0; batch classifier loss: 0.613004; batch adversarial loss: 0.596387\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589068; batch adversarial loss: 0.648771\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538929; batch adversarial loss: 0.601455\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548692; batch adversarial loss: 0.634170\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565929; batch adversarial loss: 0.608049\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487815; batch adversarial loss: 0.593888\n",
      "epoch 7; iter: 0; batch classifier loss: 0.532118; batch adversarial loss: 0.628957\n",
      "epoch 8; iter: 0; batch classifier loss: 0.424634; batch adversarial loss: 0.611634\n",
      "epoch 9; iter: 0; batch classifier loss: 0.465742; batch adversarial loss: 0.618578\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537767; batch adversarial loss: 0.590107\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429957; batch adversarial loss: 0.556957\n",
      "epoch 12; iter: 0; batch classifier loss: 0.325248; batch adversarial loss: 0.542133\n",
      "epoch 13; iter: 0; batch classifier loss: 0.312244; batch adversarial loss: 0.637947\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390211; batch adversarial loss: 0.589318\n",
      "epoch 15; iter: 0; batch classifier loss: 0.368451; batch adversarial loss: 0.577305\n",
      "epoch 16; iter: 0; batch classifier loss: 0.417530; batch adversarial loss: 0.609986\n",
      "epoch 17; iter: 0; batch classifier loss: 0.583697; batch adversarial loss: 0.559023\n",
      "epoch 18; iter: 0; batch classifier loss: 0.346485; batch adversarial loss: 0.610950\n",
      "epoch 19; iter: 0; batch classifier loss: 0.402730; batch adversarial loss: 0.609742\n",
      "epoch 20; iter: 0; batch classifier loss: 0.493000; batch adversarial loss: 0.573136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.537512; batch adversarial loss: 0.571379\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318511; batch adversarial loss: 0.673594\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373491; batch adversarial loss: 0.587651\n",
      "epoch 24; iter: 0; batch classifier loss: 0.314925; batch adversarial loss: 0.619150\n",
      "epoch 25; iter: 0; batch classifier loss: 0.446430; batch adversarial loss: 0.566610\n",
      "epoch 26; iter: 0; batch classifier loss: 0.399307; batch adversarial loss: 0.585396\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352417; batch adversarial loss: 0.561910\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362064; batch adversarial loss: 0.659128\n",
      "epoch 29; iter: 0; batch classifier loss: 0.354296; batch adversarial loss: 0.610645\n",
      "epoch 30; iter: 0; batch classifier loss: 0.331824; batch adversarial loss: 0.653657\n",
      "epoch 31; iter: 0; batch classifier loss: 0.508462; batch adversarial loss: 0.635960\n",
      "epoch 32; iter: 0; batch classifier loss: 0.281479; batch adversarial loss: 0.590823\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380195; batch adversarial loss: 0.527292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.389333; batch adversarial loss: 0.573766\n",
      "epoch 35; iter: 0; batch classifier loss: 0.285145; batch adversarial loss: 0.684201\n",
      "epoch 36; iter: 0; batch classifier loss: 0.269650; batch adversarial loss: 0.656227\n",
      "epoch 37; iter: 0; batch classifier loss: 0.281098; batch adversarial loss: 0.579316\n",
      "epoch 38; iter: 0; batch classifier loss: 0.198237; batch adversarial loss: 0.608157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321145; batch adversarial loss: 0.595179\n",
      "epoch 40; iter: 0; batch classifier loss: 0.269029; batch adversarial loss: 0.587805\n",
      "epoch 41; iter: 0; batch classifier loss: 0.258432; batch adversarial loss: 0.583897\n",
      "epoch 42; iter: 0; batch classifier loss: 0.316469; batch adversarial loss: 0.632545\n",
      "epoch 43; iter: 0; batch classifier loss: 0.204328; batch adversarial loss: 0.624248\n",
      "epoch 44; iter: 0; batch classifier loss: 0.396988; batch adversarial loss: 0.541240\n",
      "epoch 45; iter: 0; batch classifier loss: 0.236520; batch adversarial loss: 0.611683\n",
      "epoch 46; iter: 0; batch classifier loss: 0.291693; batch adversarial loss: 0.616101\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357536; batch adversarial loss: 0.632472\n",
      "epoch 48; iter: 0; batch classifier loss: 0.313082; batch adversarial loss: 0.555460\n",
      "epoch 49; iter: 0; batch classifier loss: 0.364323; batch adversarial loss: 0.614273\n",
      "epoch 50; iter: 0; batch classifier loss: 0.287539; batch adversarial loss: 0.555729\n",
      "epoch 51; iter: 0; batch classifier loss: 0.278818; batch adversarial loss: 0.504788\n",
      "epoch 52; iter: 0; batch classifier loss: 0.399687; batch adversarial loss: 0.612910\n",
      "epoch 53; iter: 0; batch classifier loss: 0.344759; batch adversarial loss: 0.616651\n",
      "epoch 54; iter: 0; batch classifier loss: 0.276689; batch adversarial loss: 0.658741\n",
      "epoch 55; iter: 0; batch classifier loss: 0.241252; batch adversarial loss: 0.695327\n",
      "epoch 56; iter: 0; batch classifier loss: 0.241173; batch adversarial loss: 0.565951\n",
      "epoch 57; iter: 0; batch classifier loss: 0.257866; batch adversarial loss: 0.486758\n",
      "epoch 58; iter: 0; batch classifier loss: 0.322082; batch adversarial loss: 0.599904\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356354; batch adversarial loss: 0.692404\n",
      "epoch 0; iter: 0; batch classifier loss: 0.774595; batch adversarial loss: 0.616450\n",
      "epoch 1; iter: 0; batch classifier loss: 0.706088; batch adversarial loss: 0.625631\n",
      "epoch 2; iter: 0; batch classifier loss: 0.641127; batch adversarial loss: 0.609244\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534860; batch adversarial loss: 0.634792\n",
      "epoch 4; iter: 0; batch classifier loss: 0.562256; batch adversarial loss: 0.600941\n",
      "epoch 5; iter: 0; batch classifier loss: 0.527243; batch adversarial loss: 0.602775\n",
      "epoch 6; iter: 0; batch classifier loss: 0.509799; batch adversarial loss: 0.600159\n",
      "epoch 7; iter: 0; batch classifier loss: 0.379952; batch adversarial loss: 0.637789\n",
      "epoch 8; iter: 0; batch classifier loss: 0.507046; batch adversarial loss: 0.605202\n",
      "epoch 9; iter: 0; batch classifier loss: 0.320538; batch adversarial loss: 0.632278\n",
      "epoch 10; iter: 0; batch classifier loss: 0.402026; batch adversarial loss: 0.591893\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414317; batch adversarial loss: 0.571846\n",
      "epoch 12; iter: 0; batch classifier loss: 0.474562; batch adversarial loss: 0.606045\n",
      "epoch 13; iter: 0; batch classifier loss: 0.417926; batch adversarial loss: 0.631740\n",
      "epoch 14; iter: 0; batch classifier loss: 0.339915; batch adversarial loss: 0.626020\n",
      "epoch 15; iter: 0; batch classifier loss: 0.373117; batch adversarial loss: 0.597514\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356935; batch adversarial loss: 0.552936\n",
      "epoch 17; iter: 0; batch classifier loss: 0.269077; batch adversarial loss: 0.594100\n",
      "epoch 18; iter: 0; batch classifier loss: 0.284396; batch adversarial loss: 0.624257\n",
      "epoch 19; iter: 0; batch classifier loss: 0.346184; batch adversarial loss: 0.588236\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426309; batch adversarial loss: 0.550909\n",
      "epoch 21; iter: 0; batch classifier loss: 0.300719; batch adversarial loss: 0.561631\n",
      "epoch 22; iter: 0; batch classifier loss: 0.329821; batch adversarial loss: 0.595183\n",
      "epoch 23; iter: 0; batch classifier loss: 0.410618; batch adversarial loss: 0.652968\n",
      "epoch 24; iter: 0; batch classifier loss: 0.296726; batch adversarial loss: 0.560901\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409547; batch adversarial loss: 0.622510\n",
      "epoch 26; iter: 0; batch classifier loss: 0.363085; batch adversarial loss: 0.617959\n",
      "epoch 27; iter: 0; batch classifier loss: 0.261622; batch adversarial loss: 0.588550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.349095; batch adversarial loss: 0.647417\n",
      "epoch 29; iter: 0; batch classifier loss: 0.275743; batch adversarial loss: 0.604472\n",
      "epoch 30; iter: 0; batch classifier loss: 0.217011; batch adversarial loss: 0.577253\n",
      "epoch 31; iter: 0; batch classifier loss: 0.436149; batch adversarial loss: 0.557042\n",
      "epoch 32; iter: 0; batch classifier loss: 0.367375; batch adversarial loss: 0.613601\n",
      "epoch 33; iter: 0; batch classifier loss: 0.363295; batch adversarial loss: 0.601036\n",
      "epoch 34; iter: 0; batch classifier loss: 0.222089; batch adversarial loss: 0.568171\n",
      "epoch 35; iter: 0; batch classifier loss: 0.239454; batch adversarial loss: 0.540355\n",
      "epoch 36; iter: 0; batch classifier loss: 0.340451; batch adversarial loss: 0.624169\n",
      "epoch 37; iter: 0; batch classifier loss: 0.252187; batch adversarial loss: 0.652006\n",
      "epoch 38; iter: 0; batch classifier loss: 0.377921; batch adversarial loss: 0.638535\n",
      "epoch 39; iter: 0; batch classifier loss: 0.236597; batch adversarial loss: 0.628175\n",
      "epoch 40; iter: 0; batch classifier loss: 0.316751; batch adversarial loss: 0.591792\n",
      "epoch 41; iter: 0; batch classifier loss: 0.414404; batch adversarial loss: 0.588465\n",
      "epoch 42; iter: 0; batch classifier loss: 0.345200; batch adversarial loss: 0.639022\n",
      "epoch 43; iter: 0; batch classifier loss: 0.268843; batch adversarial loss: 0.605783\n",
      "epoch 44; iter: 0; batch classifier loss: 0.293767; batch adversarial loss: 0.527817\n",
      "epoch 45; iter: 0; batch classifier loss: 0.292812; batch adversarial loss: 0.645519\n",
      "epoch 46; iter: 0; batch classifier loss: 0.281289; batch adversarial loss: 0.613549\n",
      "epoch 47; iter: 0; batch classifier loss: 0.266640; batch adversarial loss: 0.570074\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332042; batch adversarial loss: 0.513350\n",
      "epoch 49; iter: 0; batch classifier loss: 0.219068; batch adversarial loss: 0.639785\n",
      "epoch 50; iter: 0; batch classifier loss: 0.262526; batch adversarial loss: 0.626463\n",
      "epoch 51; iter: 0; batch classifier loss: 0.350601; batch adversarial loss: 0.649756\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238146; batch adversarial loss: 0.567683\n",
      "epoch 53; iter: 0; batch classifier loss: 0.327962; batch adversarial loss: 0.675431\n",
      "epoch 54; iter: 0; batch classifier loss: 0.173288; batch adversarial loss: 0.547340\n",
      "epoch 55; iter: 0; batch classifier loss: 0.351157; batch adversarial loss: 0.602398\n",
      "epoch 56; iter: 0; batch classifier loss: 0.336451; batch adversarial loss: 0.686150\n",
      "epoch 57; iter: 0; batch classifier loss: 0.221125; batch adversarial loss: 0.591497\n",
      "epoch 58; iter: 0; batch classifier loss: 0.187344; batch adversarial loss: 0.615813\n",
      "epoch 59; iter: 0; batch classifier loss: 0.310095; batch adversarial loss: 0.571123\n",
      "epoch 0; iter: 0; batch classifier loss: 0.707497; batch adversarial loss: 0.616279\n",
      "epoch 1; iter: 0; batch classifier loss: 0.680207; batch adversarial loss: 0.584053\n",
      "epoch 2; iter: 0; batch classifier loss: 0.689300; batch adversarial loss: 0.625238\n",
      "epoch 3; iter: 0; batch classifier loss: 0.654191; batch adversarial loss: 0.613500\n",
      "epoch 4; iter: 0; batch classifier loss: 0.621279; batch adversarial loss: 0.583818\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614107; batch adversarial loss: 0.620046\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584782; batch adversarial loss: 0.591204\n",
      "epoch 7; iter: 0; batch classifier loss: 0.578609; batch adversarial loss: 0.592096\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561352; batch adversarial loss: 0.592918\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505444; batch adversarial loss: 0.594242\n",
      "epoch 10; iter: 0; batch classifier loss: 0.557797; batch adversarial loss: 0.574797\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519392; batch adversarial loss: 0.588009\n",
      "epoch 12; iter: 0; batch classifier loss: 0.538045; batch adversarial loss: 0.553108\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553613; batch adversarial loss: 0.615019\n",
      "epoch 14; iter: 0; batch classifier loss: 0.511897; batch adversarial loss: 0.542372\n",
      "epoch 15; iter: 0; batch classifier loss: 0.449019; batch adversarial loss: 0.610684\n",
      "epoch 16; iter: 0; batch classifier loss: 0.504615; batch adversarial loss: 0.623998\n",
      "epoch 17; iter: 0; batch classifier loss: 0.508526; batch adversarial loss: 0.580704\n",
      "epoch 18; iter: 0; batch classifier loss: 0.476670; batch adversarial loss: 0.576472\n",
      "epoch 19; iter: 0; batch classifier loss: 0.469798; batch adversarial loss: 0.581137\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436177; batch adversarial loss: 0.588596\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453575; batch adversarial loss: 0.584394\n",
      "epoch 22; iter: 0; batch classifier loss: 0.457240; batch adversarial loss: 0.586292\n",
      "epoch 23; iter: 0; batch classifier loss: 0.482996; batch adversarial loss: 0.585839\n",
      "epoch 24; iter: 0; batch classifier loss: 0.433262; batch adversarial loss: 0.599694\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357957; batch adversarial loss: 0.565425\n",
      "epoch 26; iter: 0; batch classifier loss: 0.417945; batch adversarial loss: 0.537767\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448251; batch adversarial loss: 0.599290\n",
      "epoch 28; iter: 0; batch classifier loss: 0.416267; batch adversarial loss: 0.582083\n",
      "epoch 29; iter: 0; batch classifier loss: 0.415766; batch adversarial loss: 0.557998\n",
      "epoch 30; iter: 0; batch classifier loss: 0.401856; batch adversarial loss: 0.606951\n",
      "epoch 31; iter: 0; batch classifier loss: 0.481840; batch adversarial loss: 0.575944\n",
      "epoch 32; iter: 0; batch classifier loss: 0.441123; batch adversarial loss: 0.587236\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380694; batch adversarial loss: 0.583526\n",
      "epoch 34; iter: 0; batch classifier loss: 0.398664; batch adversarial loss: 0.593089\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405846; batch adversarial loss: 0.541955\n",
      "epoch 36; iter: 0; batch classifier loss: 0.472793; batch adversarial loss: 0.566302\n",
      "epoch 37; iter: 0; batch classifier loss: 0.375308; batch adversarial loss: 0.558502\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418352; batch adversarial loss: 0.575220\n",
      "epoch 39; iter: 0; batch classifier loss: 0.361741; batch adversarial loss: 0.599820\n",
      "epoch 40; iter: 0; batch classifier loss: 0.384621; batch adversarial loss: 0.572350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.395974; batch adversarial loss: 0.577773\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411488; batch adversarial loss: 0.580769\n",
      "epoch 43; iter: 0; batch classifier loss: 0.399976; batch adversarial loss: 0.600580\n",
      "epoch 44; iter: 0; batch classifier loss: 0.336766; batch adversarial loss: 0.584119\n",
      "epoch 45; iter: 0; batch classifier loss: 0.362924; batch adversarial loss: 0.620517\n",
      "epoch 46; iter: 0; batch classifier loss: 0.341772; batch adversarial loss: 0.577986\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341446; batch adversarial loss: 0.603995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.360718; batch adversarial loss: 0.582687\n",
      "epoch 49; iter: 0; batch classifier loss: 0.298956; batch adversarial loss: 0.595166\n",
      "epoch 50; iter: 0; batch classifier loss: 0.368247; batch adversarial loss: 0.548319\n",
      "epoch 51; iter: 0; batch classifier loss: 0.383878; batch adversarial loss: 0.575732\n",
      "epoch 52; iter: 0; batch classifier loss: 0.359113; batch adversarial loss: 0.582731\n",
      "epoch 53; iter: 0; batch classifier loss: 0.324367; batch adversarial loss: 0.590189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.369865; batch adversarial loss: 0.539757\n",
      "epoch 55; iter: 0; batch classifier loss: 0.347692; batch adversarial loss: 0.589453\n",
      "epoch 56; iter: 0; batch classifier loss: 0.356078; batch adversarial loss: 0.556192\n",
      "epoch 57; iter: 0; batch classifier loss: 0.347472; batch adversarial loss: 0.577355\n",
      "epoch 58; iter: 0; batch classifier loss: 0.343595; batch adversarial loss: 0.568581\n",
      "epoch 59; iter: 0; batch classifier loss: 0.275557; batch adversarial loss: 0.554093\n",
      "epoch 0; iter: 0; batch classifier loss: 0.864067; batch adversarial loss: 0.647188\n",
      "epoch 1; iter: 0; batch classifier loss: 0.824738; batch adversarial loss: 0.623351\n",
      "epoch 2; iter: 0; batch classifier loss: 0.773432; batch adversarial loss: 0.611150\n",
      "epoch 3; iter: 0; batch classifier loss: 0.695440; batch adversarial loss: 0.610070\n",
      "epoch 4; iter: 0; batch classifier loss: 0.708164; batch adversarial loss: 0.647869\n",
      "epoch 5; iter: 0; batch classifier loss: 0.618735; batch adversarial loss: 0.625431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.627329; batch adversarial loss: 0.660980\n",
      "epoch 7; iter: 0; batch classifier loss: 0.573201; batch adversarial loss: 0.633846\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549773; batch adversarial loss: 0.638964\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520802; batch adversarial loss: 0.622023\n",
      "epoch 10; iter: 0; batch classifier loss: 0.523187; batch adversarial loss: 0.620290\n",
      "epoch 11; iter: 0; batch classifier loss: 0.482980; batch adversarial loss: 0.627148\n",
      "epoch 12; iter: 0; batch classifier loss: 0.454719; batch adversarial loss: 0.655450\n",
      "epoch 13; iter: 0; batch classifier loss: 0.473862; batch adversarial loss: 0.589686\n",
      "epoch 14; iter: 0; batch classifier loss: 0.450482; batch adversarial loss: 0.635880\n",
      "epoch 15; iter: 0; batch classifier loss: 0.469648; batch adversarial loss: 0.610191\n",
      "epoch 16; iter: 0; batch classifier loss: 0.374108; batch adversarial loss: 0.638491\n",
      "epoch 17; iter: 0; batch classifier loss: 0.408031; batch adversarial loss: 0.598290\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389965; batch adversarial loss: 0.643967\n",
      "epoch 19; iter: 0; batch classifier loss: 0.361709; batch adversarial loss: 0.646774\n",
      "epoch 20; iter: 0; batch classifier loss: 0.341130; batch adversarial loss: 0.640708\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409608; batch adversarial loss: 0.644775\n",
      "epoch 22; iter: 0; batch classifier loss: 0.331630; batch adversarial loss: 0.605351\n",
      "epoch 23; iter: 0; batch classifier loss: 0.337494; batch adversarial loss: 0.623254\n",
      "epoch 24; iter: 0; batch classifier loss: 0.360903; batch adversarial loss: 0.610560\n",
      "epoch 25; iter: 0; batch classifier loss: 0.314242; batch adversarial loss: 0.605241\n",
      "epoch 26; iter: 0; batch classifier loss: 0.355936; batch adversarial loss: 0.627720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.308284; batch adversarial loss: 0.622035\n",
      "epoch 28; iter: 0; batch classifier loss: 0.362460; batch adversarial loss: 0.631703\n",
      "epoch 29; iter: 0; batch classifier loss: 0.328312; batch adversarial loss: 0.596423\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435930; batch adversarial loss: 0.661181\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379844; batch adversarial loss: 0.641491\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320149; batch adversarial loss: 0.608141\n",
      "epoch 33; iter: 0; batch classifier loss: 0.234027; batch adversarial loss: 0.548259\n",
      "epoch 34; iter: 0; batch classifier loss: 0.428375; batch adversarial loss: 0.599108\n",
      "epoch 35; iter: 0; batch classifier loss: 0.248084; batch adversarial loss: 0.617890\n",
      "epoch 36; iter: 0; batch classifier loss: 0.329622; batch adversarial loss: 0.604094\n",
      "epoch 37; iter: 0; batch classifier loss: 0.289197; batch adversarial loss: 0.658180\n",
      "epoch 38; iter: 0; batch classifier loss: 0.316129; batch adversarial loss: 0.627913\n",
      "epoch 39; iter: 0; batch classifier loss: 0.349726; batch adversarial loss: 0.617232\n",
      "epoch 40; iter: 0; batch classifier loss: 0.315331; batch adversarial loss: 0.619565\n",
      "epoch 41; iter: 0; batch classifier loss: 0.247906; batch adversarial loss: 0.658470\n",
      "epoch 42; iter: 0; batch classifier loss: 0.374015; batch adversarial loss: 0.648234\n",
      "epoch 43; iter: 0; batch classifier loss: 0.382181; batch adversarial loss: 0.597847\n",
      "epoch 44; iter: 0; batch classifier loss: 0.263179; batch adversarial loss: 0.619057\n",
      "epoch 45; iter: 0; batch classifier loss: 0.306457; batch adversarial loss: 0.636567\n",
      "epoch 46; iter: 0; batch classifier loss: 0.291059; batch adversarial loss: 0.565249\n",
      "epoch 47; iter: 0; batch classifier loss: 0.331447; batch adversarial loss: 0.589238\n",
      "epoch 48; iter: 0; batch classifier loss: 0.340461; batch adversarial loss: 0.636092\n",
      "epoch 49; iter: 0; batch classifier loss: 0.411020; batch adversarial loss: 0.596375\n",
      "epoch 50; iter: 0; batch classifier loss: 0.307790; batch adversarial loss: 0.607256\n",
      "epoch 51; iter: 0; batch classifier loss: 0.314453; batch adversarial loss: 0.548110\n",
      "epoch 52; iter: 0; batch classifier loss: 0.384937; batch adversarial loss: 0.598787\n",
      "epoch 53; iter: 0; batch classifier loss: 0.358898; batch adversarial loss: 0.672601\n",
      "epoch 54; iter: 0; batch classifier loss: 0.277772; batch adversarial loss: 0.621549\n",
      "epoch 55; iter: 0; batch classifier loss: 0.291442; batch adversarial loss: 0.678637\n",
      "epoch 56; iter: 0; batch classifier loss: 0.350577; batch adversarial loss: 0.630672\n",
      "epoch 57; iter: 0; batch classifier loss: 0.245890; batch adversarial loss: 0.624041\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328524; batch adversarial loss: 0.600773\n",
      "epoch 59; iter: 0; batch classifier loss: 0.349827; batch adversarial loss: 0.596358\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790978; batch adversarial loss: 0.788552\n",
      "epoch 1; iter: 0; batch classifier loss: 0.704835; batch adversarial loss: 0.785870\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708083; batch adversarial loss: 0.754052\n",
      "epoch 3; iter: 0; batch classifier loss: 0.610492; batch adversarial loss: 0.765338\n",
      "epoch 4; iter: 0; batch classifier loss: 0.550700; batch adversarial loss: 0.845255\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579688; batch adversarial loss: 0.732619\n",
      "epoch 6; iter: 0; batch classifier loss: 0.573788; batch adversarial loss: 0.680446\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498243; batch adversarial loss: 0.699506\n",
      "epoch 8; iter: 0; batch classifier loss: 0.494996; batch adversarial loss: 0.777106\n",
      "epoch 9; iter: 0; batch classifier loss: 0.530556; batch adversarial loss: 0.776937\n",
      "epoch 10; iter: 0; batch classifier loss: 0.550719; batch adversarial loss: 0.730591\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505516; batch adversarial loss: 0.758178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.418473; batch adversarial loss: 0.728560\n",
      "epoch 13; iter: 0; batch classifier loss: 0.540926; batch adversarial loss: 0.766869\n",
      "epoch 14; iter: 0; batch classifier loss: 0.436805; batch adversarial loss: 0.735979\n",
      "epoch 15; iter: 0; batch classifier loss: 0.436860; batch adversarial loss: 0.750292\n",
      "epoch 16; iter: 0; batch classifier loss: 0.556464; batch adversarial loss: 0.713225\n",
      "epoch 17; iter: 0; batch classifier loss: 0.467913; batch adversarial loss: 0.741895\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398770; batch adversarial loss: 0.688831\n",
      "epoch 19; iter: 0; batch classifier loss: 0.455164; batch adversarial loss: 0.734880\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378301; batch adversarial loss: 0.743456\n",
      "epoch 21; iter: 0; batch classifier loss: 0.363297; batch adversarial loss: 0.724035\n",
      "epoch 22; iter: 0; batch classifier loss: 0.408306; batch adversarial loss: 0.711045\n",
      "epoch 23; iter: 0; batch classifier loss: 0.464958; batch adversarial loss: 0.699116\n",
      "epoch 24; iter: 0; batch classifier loss: 0.486555; batch adversarial loss: 0.703219\n",
      "epoch 25; iter: 0; batch classifier loss: 0.261230; batch adversarial loss: 0.685502\n",
      "epoch 26; iter: 0; batch classifier loss: 0.388603; batch adversarial loss: 0.705603\n",
      "epoch 27; iter: 0; batch classifier loss: 0.414603; batch adversarial loss: 0.710056\n",
      "epoch 28; iter: 0; batch classifier loss: 0.342803; batch adversarial loss: 0.714975\n",
      "epoch 29; iter: 0; batch classifier loss: 0.388076; batch adversarial loss: 0.731916\n",
      "epoch 30; iter: 0; batch classifier loss: 0.351213; batch adversarial loss: 0.716730\n",
      "epoch 31; iter: 0; batch classifier loss: 0.562720; batch adversarial loss: 0.672732\n",
      "epoch 32; iter: 0; batch classifier loss: 0.459843; batch adversarial loss: 0.715003\n",
      "epoch 33; iter: 0; batch classifier loss: 0.368064; batch adversarial loss: 0.702033\n",
      "epoch 34; iter: 0; batch classifier loss: 0.307943; batch adversarial loss: 0.675673\n",
      "epoch 35; iter: 0; batch classifier loss: 0.333003; batch adversarial loss: 0.653326\n",
      "epoch 36; iter: 0; batch classifier loss: 0.376292; batch adversarial loss: 0.661021\n",
      "epoch 37; iter: 0; batch classifier loss: 0.327999; batch adversarial loss: 0.667832\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355085; batch adversarial loss: 0.692491\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268087; batch adversarial loss: 0.647404\n",
      "epoch 40; iter: 0; batch classifier loss: 0.317915; batch adversarial loss: 0.635282\n",
      "epoch 41; iter: 0; batch classifier loss: 0.415058; batch adversarial loss: 0.680761\n",
      "epoch 42; iter: 0; batch classifier loss: 0.360882; batch adversarial loss: 0.660387\n",
      "epoch 43; iter: 0; batch classifier loss: 0.328474; batch adversarial loss: 0.706759\n",
      "epoch 44; iter: 0; batch classifier loss: 0.270983; batch adversarial loss: 0.625656\n",
      "epoch 45; iter: 0; batch classifier loss: 0.354826; batch adversarial loss: 0.663643\n",
      "epoch 46; iter: 0; batch classifier loss: 0.328559; batch adversarial loss: 0.647561\n",
      "epoch 47; iter: 0; batch classifier loss: 0.278862; batch adversarial loss: 0.643188\n",
      "epoch 48; iter: 0; batch classifier loss: 0.287255; batch adversarial loss: 0.620906\n",
      "epoch 49; iter: 0; batch classifier loss: 0.336545; batch adversarial loss: 0.604628\n",
      "epoch 50; iter: 0; batch classifier loss: 0.274685; batch adversarial loss: 0.642550\n",
      "epoch 51; iter: 0; batch classifier loss: 0.301055; batch adversarial loss: 0.631840\n",
      "epoch 52; iter: 0; batch classifier loss: 0.373138; batch adversarial loss: 0.635267\n",
      "epoch 53; iter: 0; batch classifier loss: 0.495466; batch adversarial loss: 0.620389\n",
      "epoch 54; iter: 0; batch classifier loss: 0.319238; batch adversarial loss: 0.594179\n",
      "epoch 55; iter: 0; batch classifier loss: 0.299133; batch adversarial loss: 0.635873\n",
      "epoch 56; iter: 0; batch classifier loss: 0.419148; batch adversarial loss: 0.631493\n",
      "epoch 57; iter: 0; batch classifier loss: 0.421184; batch adversarial loss: 0.646286\n",
      "epoch 58; iter: 0; batch classifier loss: 0.402839; batch adversarial loss: 0.653321\n",
      "epoch 59; iter: 0; batch classifier loss: 0.314331; batch adversarial loss: 0.646820\n",
      "epoch 60; iter: 0; batch classifier loss: 0.366999; batch adversarial loss: 0.580110\n",
      "epoch 61; iter: 0; batch classifier loss: 0.245383; batch adversarial loss: 0.600549\n",
      "epoch 62; iter: 0; batch classifier loss: 0.379836; batch adversarial loss: 0.577523\n",
      "epoch 63; iter: 0; batch classifier loss: 0.315829; batch adversarial loss: 0.633014\n",
      "epoch 64; iter: 0; batch classifier loss: 0.405362; batch adversarial loss: 0.619058\n",
      "epoch 65; iter: 0; batch classifier loss: 0.369397; batch adversarial loss: 0.595014\n",
      "epoch 66; iter: 0; batch classifier loss: 0.367683; batch adversarial loss: 0.583859\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251762; batch adversarial loss: 0.619785\n",
      "epoch 68; iter: 0; batch classifier loss: 0.193326; batch adversarial loss: 0.556095\n",
      "epoch 69; iter: 0; batch classifier loss: 0.441355; batch adversarial loss: 0.596320\n",
      "epoch 70; iter: 0; batch classifier loss: 0.278904; batch adversarial loss: 0.597170\n",
      "epoch 71; iter: 0; batch classifier loss: 0.285502; batch adversarial loss: 0.638878\n",
      "epoch 72; iter: 0; batch classifier loss: 0.320001; batch adversarial loss: 0.615866\n",
      "epoch 73; iter: 0; batch classifier loss: 0.238576; batch adversarial loss: 0.593069\n",
      "epoch 74; iter: 0; batch classifier loss: 0.250839; batch adversarial loss: 0.617752\n",
      "epoch 75; iter: 0; batch classifier loss: 0.259136; batch adversarial loss: 0.587017\n",
      "epoch 76; iter: 0; batch classifier loss: 0.317998; batch adversarial loss: 0.512345\n",
      "epoch 77; iter: 0; batch classifier loss: 0.326629; batch adversarial loss: 0.605419\n",
      "epoch 78; iter: 0; batch classifier loss: 0.256954; batch adversarial loss: 0.594966\n",
      "epoch 79; iter: 0; batch classifier loss: 0.273428; batch adversarial loss: 0.561422\n",
      "epoch 0; iter: 0; batch classifier loss: 0.698867; batch adversarial loss: 0.640442\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603791; batch adversarial loss: 0.615533\n",
      "epoch 2; iter: 0; batch classifier loss: 0.572651; batch adversarial loss: 0.682084\n",
      "epoch 3; iter: 0; batch classifier loss: 0.530142; batch adversarial loss: 0.644101\n",
      "epoch 4; iter: 0; batch classifier loss: 0.469775; batch adversarial loss: 0.626245\n",
      "epoch 5; iter: 0; batch classifier loss: 0.454294; batch adversarial loss: 0.643394\n",
      "epoch 6; iter: 0; batch classifier loss: 0.482939; batch adversarial loss: 0.649784\n",
      "epoch 7; iter: 0; batch classifier loss: 0.376632; batch adversarial loss: 0.603461\n",
      "epoch 8; iter: 0; batch classifier loss: 0.322888; batch adversarial loss: 0.594375\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489358; batch adversarial loss: 0.643220\n",
      "epoch 10; iter: 0; batch classifier loss: 0.366608; batch adversarial loss: 0.608471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.435296; batch adversarial loss: 0.568500\n",
      "epoch 12; iter: 0; batch classifier loss: 0.347206; batch adversarial loss: 0.654368\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396363; batch adversarial loss: 0.607190\n",
      "epoch 14; iter: 0; batch classifier loss: 0.399762; batch adversarial loss: 0.645461\n",
      "epoch 15; iter: 0; batch classifier loss: 0.311089; batch adversarial loss: 0.606432\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402908; batch adversarial loss: 0.581489\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348873; batch adversarial loss: 0.646009\n",
      "epoch 18; iter: 0; batch classifier loss: 0.350186; batch adversarial loss: 0.639930\n",
      "epoch 19; iter: 0; batch classifier loss: 0.256631; batch adversarial loss: 0.585570\n",
      "epoch 20; iter: 0; batch classifier loss: 0.325600; batch adversarial loss: 0.561708\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389487; batch adversarial loss: 0.626196\n",
      "epoch 22; iter: 0; batch classifier loss: 0.333946; batch adversarial loss: 0.635463\n",
      "epoch 23; iter: 0; batch classifier loss: 0.394756; batch adversarial loss: 0.578103\n",
      "epoch 24; iter: 0; batch classifier loss: 0.315722; batch adversarial loss: 0.644372\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396882; batch adversarial loss: 0.587604\n",
      "epoch 26; iter: 0; batch classifier loss: 0.365812; batch adversarial loss: 0.591685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.253426; batch adversarial loss: 0.629451\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347636; batch adversarial loss: 0.604685\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324993; batch adversarial loss: 0.630953\n",
      "epoch 30; iter: 0; batch classifier loss: 0.499393; batch adversarial loss: 0.546520\n",
      "epoch 31; iter: 0; batch classifier loss: 0.304561; batch adversarial loss: 0.586308\n",
      "epoch 32; iter: 0; batch classifier loss: 0.284012; batch adversarial loss: 0.590163\n",
      "epoch 33; iter: 0; batch classifier loss: 0.294492; batch adversarial loss: 0.606868\n",
      "epoch 34; iter: 0; batch classifier loss: 0.279936; batch adversarial loss: 0.674187\n",
      "epoch 35; iter: 0; batch classifier loss: 0.264351; batch adversarial loss: 0.538220\n",
      "epoch 36; iter: 0; batch classifier loss: 0.231868; batch adversarial loss: 0.658299\n",
      "epoch 37; iter: 0; batch classifier loss: 0.256462; batch adversarial loss: 0.594756\n",
      "epoch 38; iter: 0; batch classifier loss: 0.322264; batch adversarial loss: 0.613719\n",
      "epoch 39; iter: 0; batch classifier loss: 0.241493; batch adversarial loss: 0.549346\n",
      "epoch 40; iter: 0; batch classifier loss: 0.278389; batch adversarial loss: 0.545350\n",
      "epoch 41; iter: 0; batch classifier loss: 0.299820; batch adversarial loss: 0.555648\n",
      "epoch 42; iter: 0; batch classifier loss: 0.385174; batch adversarial loss: 0.590854\n",
      "epoch 43; iter: 0; batch classifier loss: 0.354687; batch adversarial loss: 0.524660\n",
      "epoch 44; iter: 0; batch classifier loss: 0.163529; batch adversarial loss: 0.630099\n",
      "epoch 45; iter: 0; batch classifier loss: 0.282671; batch adversarial loss: 0.556511\n",
      "epoch 46; iter: 0; batch classifier loss: 0.378269; batch adversarial loss: 0.550452\n",
      "epoch 47; iter: 0; batch classifier loss: 0.289842; batch adversarial loss: 0.606777\n",
      "epoch 48; iter: 0; batch classifier loss: 0.286969; batch adversarial loss: 0.612469\n",
      "epoch 49; iter: 0; batch classifier loss: 0.313316; batch adversarial loss: 0.546995\n",
      "epoch 50; iter: 0; batch classifier loss: 0.263297; batch adversarial loss: 0.607212\n",
      "epoch 51; iter: 0; batch classifier loss: 0.324272; batch adversarial loss: 0.664945\n",
      "epoch 52; iter: 0; batch classifier loss: 0.338981; batch adversarial loss: 0.631491\n",
      "epoch 53; iter: 0; batch classifier loss: 0.336721; batch adversarial loss: 0.640115\n",
      "epoch 54; iter: 0; batch classifier loss: 0.310775; batch adversarial loss: 0.540491\n",
      "epoch 55; iter: 0; batch classifier loss: 0.212826; batch adversarial loss: 0.593567\n",
      "epoch 56; iter: 0; batch classifier loss: 0.210594; batch adversarial loss: 0.593801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.232406; batch adversarial loss: 0.603168\n",
      "epoch 58; iter: 0; batch classifier loss: 0.315755; batch adversarial loss: 0.634147\n",
      "epoch 59; iter: 0; batch classifier loss: 0.346000; batch adversarial loss: 0.584122\n",
      "epoch 60; iter: 0; batch classifier loss: 0.396794; batch adversarial loss: 0.666787\n",
      "epoch 61; iter: 0; batch classifier loss: 0.230280; batch adversarial loss: 0.515842\n",
      "epoch 62; iter: 0; batch classifier loss: 0.216762; batch adversarial loss: 0.607555\n",
      "epoch 63; iter: 0; batch classifier loss: 0.270034; batch adversarial loss: 0.652729\n",
      "epoch 64; iter: 0; batch classifier loss: 0.222593; batch adversarial loss: 0.645186\n",
      "epoch 65; iter: 0; batch classifier loss: 0.271373; batch adversarial loss: 0.593268\n",
      "epoch 66; iter: 0; batch classifier loss: 0.244372; batch adversarial loss: 0.617243\n",
      "epoch 67; iter: 0; batch classifier loss: 0.284169; batch adversarial loss: 0.576550\n",
      "epoch 68; iter: 0; batch classifier loss: 0.151301; batch adversarial loss: 0.595456\n",
      "epoch 69; iter: 0; batch classifier loss: 0.205340; batch adversarial loss: 0.551736\n",
      "epoch 70; iter: 0; batch classifier loss: 0.342524; batch adversarial loss: 0.618004\n",
      "epoch 71; iter: 0; batch classifier loss: 0.262964; batch adversarial loss: 0.563228\n",
      "epoch 72; iter: 0; batch classifier loss: 0.212548; batch adversarial loss: 0.581756\n",
      "epoch 73; iter: 0; batch classifier loss: 0.256465; batch adversarial loss: 0.562533\n",
      "epoch 74; iter: 0; batch classifier loss: 0.292759; batch adversarial loss: 0.644869\n",
      "epoch 75; iter: 0; batch classifier loss: 0.405988; batch adversarial loss: 0.697459\n",
      "epoch 76; iter: 0; batch classifier loss: 0.181062; batch adversarial loss: 0.572512\n",
      "epoch 77; iter: 0; batch classifier loss: 0.276138; batch adversarial loss: 0.604579\n",
      "epoch 78; iter: 0; batch classifier loss: 0.263039; batch adversarial loss: 0.551949\n",
      "epoch 79; iter: 0; batch classifier loss: 0.253953; batch adversarial loss: 0.638447\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653360; batch adversarial loss: 0.673468\n",
      "epoch 1; iter: 0; batch classifier loss: 0.655867; batch adversarial loss: 0.665540\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617309; batch adversarial loss: 0.657464\n",
      "epoch 3; iter: 0; batch classifier loss: 0.605900; batch adversarial loss: 0.655102\n",
      "epoch 4; iter: 0; batch classifier loss: 0.609503; batch adversarial loss: 0.649048\n",
      "epoch 5; iter: 0; batch classifier loss: 0.573580; batch adversarial loss: 0.648431\n",
      "epoch 6; iter: 0; batch classifier loss: 0.557017; batch adversarial loss: 0.646742\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561480; batch adversarial loss: 0.652823\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581252; batch adversarial loss: 0.648047\n",
      "epoch 9; iter: 0; batch classifier loss: 0.529641; batch adversarial loss: 0.634617\n",
      "epoch 10; iter: 0; batch classifier loss: 0.522744; batch adversarial loss: 0.658459\n",
      "epoch 11; iter: 0; batch classifier loss: 0.495525; batch adversarial loss: 0.646388\n",
      "epoch 12; iter: 0; batch classifier loss: 0.594120; batch adversarial loss: 0.612595\n",
      "epoch 13; iter: 0; batch classifier loss: 0.491863; batch adversarial loss: 0.654575\n",
      "epoch 14; iter: 0; batch classifier loss: 0.413765; batch adversarial loss: 0.663504\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520837; batch adversarial loss: 0.640283\n",
      "epoch 16; iter: 0; batch classifier loss: 0.560810; batch adversarial loss: 0.621773\n",
      "epoch 17; iter: 0; batch classifier loss: 0.472220; batch adversarial loss: 0.624108\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438744; batch adversarial loss: 0.618508\n",
      "epoch 19; iter: 0; batch classifier loss: 0.416804; batch adversarial loss: 0.646482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.459306; batch adversarial loss: 0.643993\n",
      "epoch 21; iter: 0; batch classifier loss: 0.417496; batch adversarial loss: 0.627921\n",
      "epoch 22; iter: 0; batch classifier loss: 0.452987; batch adversarial loss: 0.645068\n",
      "epoch 23; iter: 0; batch classifier loss: 0.493053; batch adversarial loss: 0.626694\n",
      "epoch 24; iter: 0; batch classifier loss: 0.457419; batch adversarial loss: 0.618628\n",
      "epoch 25; iter: 0; batch classifier loss: 0.395195; batch adversarial loss: 0.630337\n",
      "epoch 26; iter: 0; batch classifier loss: 0.498610; batch adversarial loss: 0.607675\n",
      "epoch 27; iter: 0; batch classifier loss: 0.388025; batch adversarial loss: 0.609535\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395289; batch adversarial loss: 0.660007\n",
      "epoch 29; iter: 0; batch classifier loss: 0.408946; batch adversarial loss: 0.643813\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410187; batch adversarial loss: 0.607826\n",
      "epoch 31; iter: 0; batch classifier loss: 0.402695; batch adversarial loss: 0.628627\n",
      "epoch 32; iter: 0; batch classifier loss: 0.426028; batch adversarial loss: 0.651115\n",
      "epoch 33; iter: 0; batch classifier loss: 0.393747; batch adversarial loss: 0.623852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.360093; batch adversarial loss: 0.645425\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398830; batch adversarial loss: 0.643333\n",
      "epoch 36; iter: 0; batch classifier loss: 0.357634; batch adversarial loss: 0.628162\n",
      "epoch 37; iter: 0; batch classifier loss: 0.334376; batch adversarial loss: 0.619440\n",
      "epoch 38; iter: 0; batch classifier loss: 0.347020; batch adversarial loss: 0.615392\n",
      "epoch 39; iter: 0; batch classifier loss: 0.350412; batch adversarial loss: 0.602290\n",
      "epoch 40; iter: 0; batch classifier loss: 0.430980; batch adversarial loss: 0.626254\n",
      "epoch 41; iter: 0; batch classifier loss: 0.357449; batch adversarial loss: 0.625986\n",
      "epoch 42; iter: 0; batch classifier loss: 0.389861; batch adversarial loss: 0.611804\n",
      "epoch 43; iter: 0; batch classifier loss: 0.362595; batch adversarial loss: 0.620317\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365513; batch adversarial loss: 0.618309\n",
      "epoch 45; iter: 0; batch classifier loss: 0.356312; batch adversarial loss: 0.629950\n",
      "epoch 46; iter: 0; batch classifier loss: 0.365034; batch adversarial loss: 0.623601\n",
      "epoch 47; iter: 0; batch classifier loss: 0.421307; batch adversarial loss: 0.620353\n",
      "epoch 48; iter: 0; batch classifier loss: 0.348638; batch adversarial loss: 0.621336\n",
      "epoch 49; iter: 0; batch classifier loss: 0.361004; batch adversarial loss: 0.626560\n",
      "epoch 50; iter: 0; batch classifier loss: 0.353096; batch adversarial loss: 0.616438\n",
      "epoch 51; iter: 0; batch classifier loss: 0.374126; batch adversarial loss: 0.614083\n",
      "epoch 52; iter: 0; batch classifier loss: 0.309015; batch adversarial loss: 0.619563\n",
      "epoch 53; iter: 0; batch classifier loss: 0.348393; batch adversarial loss: 0.616983\n",
      "epoch 54; iter: 0; batch classifier loss: 0.284919; batch adversarial loss: 0.569376\n",
      "epoch 55; iter: 0; batch classifier loss: 0.360442; batch adversarial loss: 0.604577\n",
      "epoch 56; iter: 0; batch classifier loss: 0.472924; batch adversarial loss: 0.617468\n",
      "epoch 57; iter: 0; batch classifier loss: 0.401552; batch adversarial loss: 0.584175\n",
      "epoch 58; iter: 0; batch classifier loss: 0.279455; batch adversarial loss: 0.600447\n",
      "epoch 59; iter: 0; batch classifier loss: 0.336844; batch adversarial loss: 0.625552\n",
      "epoch 60; iter: 0; batch classifier loss: 0.386383; batch adversarial loss: 0.617543\n",
      "epoch 61; iter: 0; batch classifier loss: 0.396432; batch adversarial loss: 0.590554\n",
      "epoch 62; iter: 0; batch classifier loss: 0.338079; batch adversarial loss: 0.606006\n",
      "epoch 63; iter: 0; batch classifier loss: 0.330863; batch adversarial loss: 0.582246\n",
      "epoch 64; iter: 0; batch classifier loss: 0.333326; batch adversarial loss: 0.609095\n",
      "epoch 65; iter: 0; batch classifier loss: 0.328542; batch adversarial loss: 0.618188\n",
      "epoch 66; iter: 0; batch classifier loss: 0.324023; batch adversarial loss: 0.598605\n",
      "epoch 67; iter: 0; batch classifier loss: 0.361408; batch adversarial loss: 0.577168\n",
      "epoch 68; iter: 0; batch classifier loss: 0.309461; batch adversarial loss: 0.598888\n",
      "epoch 69; iter: 0; batch classifier loss: 0.260574; batch adversarial loss: 0.656160\n",
      "epoch 70; iter: 0; batch classifier loss: 0.385597; batch adversarial loss: 0.586548\n",
      "epoch 71; iter: 0; batch classifier loss: 0.308618; batch adversarial loss: 0.603702\n",
      "epoch 72; iter: 0; batch classifier loss: 0.339223; batch adversarial loss: 0.586292\n",
      "epoch 73; iter: 0; batch classifier loss: 0.334246; batch adversarial loss: 0.638848\n",
      "epoch 74; iter: 0; batch classifier loss: 0.352825; batch adversarial loss: 0.584788\n",
      "epoch 75; iter: 0; batch classifier loss: 0.295446; batch adversarial loss: 0.586505\n",
      "epoch 76; iter: 0; batch classifier loss: 0.300569; batch adversarial loss: 0.624552\n",
      "epoch 77; iter: 0; batch classifier loss: 0.356868; batch adversarial loss: 0.621929\n",
      "epoch 78; iter: 0; batch classifier loss: 0.355739; batch adversarial loss: 0.590983\n",
      "epoch 79; iter: 0; batch classifier loss: 0.288144; batch adversarial loss: 0.549413\n",
      "epoch 0; iter: 0; batch classifier loss: 0.769826; batch adversarial loss: 0.819636\n",
      "epoch 1; iter: 0; batch classifier loss: 0.715070; batch adversarial loss: 0.810512\n",
      "epoch 2; iter: 0; batch classifier loss: 0.711994; batch adversarial loss: 0.794458\n",
      "epoch 3; iter: 0; batch classifier loss: 0.649673; batch adversarial loss: 0.806715\n",
      "epoch 4; iter: 0; batch classifier loss: 0.630649; batch adversarial loss: 0.800188\n",
      "epoch 5; iter: 0; batch classifier loss: 0.636689; batch adversarial loss: 0.794679\n",
      "epoch 6; iter: 0; batch classifier loss: 0.574198; batch adversarial loss: 0.804805\n",
      "epoch 7; iter: 0; batch classifier loss: 0.539871; batch adversarial loss: 0.785730\n",
      "epoch 8; iter: 0; batch classifier loss: 0.585680; batch adversarial loss: 0.828393\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567353; batch adversarial loss: 0.790524\n",
      "epoch 10; iter: 0; batch classifier loss: 0.589118; batch adversarial loss: 0.834169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.569851; batch adversarial loss: 0.807343\n",
      "epoch 12; iter: 0; batch classifier loss: 0.517830; batch adversarial loss: 0.807964\n",
      "epoch 13; iter: 0; batch classifier loss: 0.534000; batch adversarial loss: 0.816944\n",
      "epoch 14; iter: 0; batch classifier loss: 0.571108; batch adversarial loss: 0.798928\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484937; batch adversarial loss: 0.830107\n",
      "epoch 16; iter: 0; batch classifier loss: 0.510441; batch adversarial loss: 0.763170\n",
      "epoch 17; iter: 0; batch classifier loss: 0.476454; batch adversarial loss: 0.775441\n",
      "epoch 18; iter: 0; batch classifier loss: 0.426179; batch adversarial loss: 0.881324\n",
      "epoch 19; iter: 0; batch classifier loss: 0.509618; batch adversarial loss: 0.841599\n",
      "epoch 20; iter: 0; batch classifier loss: 0.551413; batch adversarial loss: 0.798520\n",
      "epoch 21; iter: 0; batch classifier loss: 0.453279; batch adversarial loss: 0.799740\n",
      "epoch 22; iter: 0; batch classifier loss: 0.492244; batch adversarial loss: 0.831805\n",
      "epoch 23; iter: 0; batch classifier loss: 0.450809; batch adversarial loss: 0.831530\n",
      "epoch 24; iter: 0; batch classifier loss: 0.454192; batch adversarial loss: 0.803215\n",
      "epoch 25; iter: 0; batch classifier loss: 0.476427; batch adversarial loss: 0.852094\n",
      "epoch 26; iter: 0; batch classifier loss: 0.447573; batch adversarial loss: 0.831630\n",
      "epoch 27; iter: 0; batch classifier loss: 0.395608; batch adversarial loss: 0.849281\n",
      "epoch 28; iter: 0; batch classifier loss: 0.403924; batch adversarial loss: 0.800034\n",
      "epoch 29; iter: 0; batch classifier loss: 0.422650; batch adversarial loss: 0.807074\n",
      "epoch 30; iter: 0; batch classifier loss: 0.435022; batch adversarial loss: 0.812624\n",
      "epoch 31; iter: 0; batch classifier loss: 0.463325; batch adversarial loss: 0.844560\n",
      "epoch 32; iter: 0; batch classifier loss: 0.431933; batch adversarial loss: 0.857399\n",
      "epoch 33; iter: 0; batch classifier loss: 0.352674; batch adversarial loss: 0.827882\n",
      "epoch 34; iter: 0; batch classifier loss: 0.392717; batch adversarial loss: 0.826700\n",
      "epoch 35; iter: 0; batch classifier loss: 0.465764; batch adversarial loss: 0.833879\n",
      "epoch 36; iter: 0; batch classifier loss: 0.436101; batch adversarial loss: 0.851442\n",
      "epoch 37; iter: 0; batch classifier loss: 0.413849; batch adversarial loss: 0.822317\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378651; batch adversarial loss: 0.807606\n",
      "epoch 39; iter: 0; batch classifier loss: 0.418568; batch adversarial loss: 0.777418\n",
      "epoch 40; iter: 0; batch classifier loss: 0.353627; batch adversarial loss: 0.813455\n",
      "epoch 41; iter: 0; batch classifier loss: 0.385490; batch adversarial loss: 0.754055\n",
      "epoch 42; iter: 0; batch classifier loss: 0.411919; batch adversarial loss: 0.785589\n",
      "epoch 43; iter: 0; batch classifier loss: 0.336725; batch adversarial loss: 0.840457\n",
      "epoch 44; iter: 0; batch classifier loss: 0.345328; batch adversarial loss: 0.764488\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368102; batch adversarial loss: 0.781201\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372721; batch adversarial loss: 0.818892\n",
      "epoch 47; iter: 0; batch classifier loss: 0.379915; batch adversarial loss: 0.817410\n",
      "epoch 48; iter: 0; batch classifier loss: 0.411720; batch adversarial loss: 0.822119\n",
      "epoch 49; iter: 0; batch classifier loss: 0.404194; batch adversarial loss: 0.844434\n",
      "epoch 50; iter: 0; batch classifier loss: 0.428859; batch adversarial loss: 0.761351\n",
      "epoch 51; iter: 0; batch classifier loss: 0.414014; batch adversarial loss: 0.855828\n",
      "epoch 52; iter: 0; batch classifier loss: 0.371336; batch adversarial loss: 0.826183\n",
      "epoch 53; iter: 0; batch classifier loss: 0.375646; batch adversarial loss: 0.785752\n",
      "epoch 54; iter: 0; batch classifier loss: 0.379790; batch adversarial loss: 0.832835\n",
      "epoch 55; iter: 0; batch classifier loss: 0.414210; batch adversarial loss: 0.770863\n",
      "epoch 56; iter: 0; batch classifier loss: 0.341803; batch adversarial loss: 0.831080\n",
      "epoch 57; iter: 0; batch classifier loss: 0.329622; batch adversarial loss: 0.766370\n",
      "epoch 58; iter: 0; batch classifier loss: 0.368766; batch adversarial loss: 0.781717\n",
      "epoch 59; iter: 0; batch classifier loss: 0.382844; batch adversarial loss: 0.821798\n",
      "epoch 60; iter: 0; batch classifier loss: 0.355842; batch adversarial loss: 0.748844\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369745; batch adversarial loss: 0.787194\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370096; batch adversarial loss: 0.767789\n",
      "epoch 63; iter: 0; batch classifier loss: 0.319903; batch adversarial loss: 0.770805\n",
      "epoch 64; iter: 0; batch classifier loss: 0.399790; batch adversarial loss: 0.806533\n",
      "epoch 65; iter: 0; batch classifier loss: 0.320522; batch adversarial loss: 0.828786\n",
      "epoch 66; iter: 0; batch classifier loss: 0.366894; batch adversarial loss: 0.766119\n",
      "epoch 67; iter: 0; batch classifier loss: 0.335207; batch adversarial loss: 0.826347\n",
      "epoch 68; iter: 0; batch classifier loss: 0.352310; batch adversarial loss: 0.725166\n",
      "epoch 69; iter: 0; batch classifier loss: 0.321116; batch adversarial loss: 0.763018\n",
      "epoch 70; iter: 0; batch classifier loss: 0.368994; batch adversarial loss: 0.742902\n",
      "epoch 71; iter: 0; batch classifier loss: 0.391632; batch adversarial loss: 0.731158\n",
      "epoch 72; iter: 0; batch classifier loss: 0.363254; batch adversarial loss: 0.749286\n",
      "epoch 73; iter: 0; batch classifier loss: 0.303411; batch adversarial loss: 0.742764\n",
      "epoch 74; iter: 0; batch classifier loss: 0.303609; batch adversarial loss: 0.736566\n",
      "epoch 75; iter: 0; batch classifier loss: 0.321717; batch adversarial loss: 0.753946\n",
      "epoch 76; iter: 0; batch classifier loss: 0.364355; batch adversarial loss: 0.777866\n",
      "epoch 77; iter: 0; batch classifier loss: 0.302214; batch adversarial loss: 0.762147\n",
      "epoch 78; iter: 0; batch classifier loss: 0.330060; batch adversarial loss: 0.764247\n",
      "epoch 79; iter: 0; batch classifier loss: 0.351096; batch adversarial loss: 0.737000\n",
      "epoch 0; iter: 0; batch classifier loss: 0.939332; batch adversarial loss: 0.862209\n",
      "epoch 1; iter: 0; batch classifier loss: 0.758207; batch adversarial loss: 0.846061\n",
      "epoch 2; iter: 0; batch classifier loss: 0.704594; batch adversarial loss: 0.869714\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534173; batch adversarial loss: 0.790525\n",
      "epoch 4; iter: 0; batch classifier loss: 0.640731; batch adversarial loss: 0.761213\n",
      "epoch 5; iter: 0; batch classifier loss: 0.570193; batch adversarial loss: 0.807367\n",
      "epoch 6; iter: 0; batch classifier loss: 0.676886; batch adversarial loss: 0.824473\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517567; batch adversarial loss: 0.808138\n",
      "epoch 8; iter: 0; batch classifier loss: 0.526833; batch adversarial loss: 0.790954\n",
      "epoch 9; iter: 0; batch classifier loss: 0.484040; batch adversarial loss: 0.788352\n",
      "epoch 10; iter: 0; batch classifier loss: 0.546967; batch adversarial loss: 0.784801\n",
      "epoch 11; iter: 0; batch classifier loss: 0.463626; batch adversarial loss: 0.775642\n",
      "epoch 12; iter: 0; batch classifier loss: 0.572659; batch adversarial loss: 0.788144\n",
      "epoch 13; iter: 0; batch classifier loss: 0.489365; batch adversarial loss: 0.734852\n",
      "epoch 14; iter: 0; batch classifier loss: 0.520634; batch adversarial loss: 0.743599\n",
      "epoch 15; iter: 0; batch classifier loss: 0.471557; batch adversarial loss: 0.747730\n",
      "epoch 16; iter: 0; batch classifier loss: 0.446145; batch adversarial loss: 0.723137\n",
      "epoch 17; iter: 0; batch classifier loss: 0.412716; batch adversarial loss: 0.716340\n",
      "epoch 18; iter: 0; batch classifier loss: 0.359954; batch adversarial loss: 0.749546\n",
      "epoch 19; iter: 0; batch classifier loss: 0.427298; batch adversarial loss: 0.726505\n",
      "epoch 20; iter: 0; batch classifier loss: 0.366536; batch adversarial loss: 0.711738\n",
      "epoch 21; iter: 0; batch classifier loss: 0.446319; batch adversarial loss: 0.719236\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359023; batch adversarial loss: 0.710335\n",
      "epoch 23; iter: 0; batch classifier loss: 0.367115; batch adversarial loss: 0.714800\n",
      "epoch 24; iter: 0; batch classifier loss: 0.409634; batch adversarial loss: 0.708928\n",
      "epoch 25; iter: 0; batch classifier loss: 0.360596; batch adversarial loss: 0.692682\n",
      "epoch 26; iter: 0; batch classifier loss: 0.280852; batch adversarial loss: 0.681727\n",
      "epoch 27; iter: 0; batch classifier loss: 0.440638; batch adversarial loss: 0.692446\n",
      "epoch 28; iter: 0; batch classifier loss: 0.334675; batch adversarial loss: 0.663168\n",
      "epoch 29; iter: 0; batch classifier loss: 0.443774; batch adversarial loss: 0.690093\n",
      "epoch 30; iter: 0; batch classifier loss: 0.361562; batch adversarial loss: 0.675811\n",
      "epoch 31; iter: 0; batch classifier loss: 0.376319; batch adversarial loss: 0.661991\n",
      "epoch 32; iter: 0; batch classifier loss: 0.316219; batch adversarial loss: 0.677847\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382425; batch adversarial loss: 0.668449\n",
      "epoch 34; iter: 0; batch classifier loss: 0.356260; batch adversarial loss: 0.671867\n",
      "epoch 35; iter: 0; batch classifier loss: 0.328358; batch adversarial loss: 0.650590\n",
      "epoch 36; iter: 0; batch classifier loss: 0.227684; batch adversarial loss: 0.643463\n",
      "epoch 37; iter: 0; batch classifier loss: 0.343043; batch adversarial loss: 0.646322\n",
      "epoch 38; iter: 0; batch classifier loss: 0.259035; batch adversarial loss: 0.653169\n",
      "epoch 39; iter: 0; batch classifier loss: 0.273704; batch adversarial loss: 0.663227\n",
      "epoch 0; iter: 0; batch classifier loss: 0.781214; batch adversarial loss: 0.718440\n",
      "epoch 1; iter: 0; batch classifier loss: 0.693289; batch adversarial loss: 0.826291\n",
      "epoch 2; iter: 0; batch classifier loss: 0.633301; batch adversarial loss: 0.736929\n",
      "epoch 3; iter: 0; batch classifier loss: 0.682268; batch adversarial loss: 0.786708\n",
      "epoch 4; iter: 0; batch classifier loss: 0.590217; batch adversarial loss: 0.769118\n",
      "epoch 5; iter: 0; batch classifier loss: 0.630329; batch adversarial loss: 0.758280\n",
      "epoch 6; iter: 0; batch classifier loss: 0.632976; batch adversarial loss: 0.759472\n",
      "epoch 7; iter: 0; batch classifier loss: 0.589188; batch adversarial loss: 0.718862\n",
      "epoch 8; iter: 0; batch classifier loss: 0.626936; batch adversarial loss: 0.760997\n",
      "epoch 9; iter: 0; batch classifier loss: 0.640737; batch adversarial loss: 0.769004\n",
      "epoch 10; iter: 0; batch classifier loss: 0.455545; batch adversarial loss: 0.657393\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545788; batch adversarial loss: 0.708638\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484270; batch adversarial loss: 0.702416\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501914; batch adversarial loss: 0.705202\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586851; batch adversarial loss: 0.721312\n",
      "epoch 15; iter: 0; batch classifier loss: 0.453248; batch adversarial loss: 0.698033\n",
      "epoch 16; iter: 0; batch classifier loss: 0.585452; batch adversarial loss: 0.734792\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462515; batch adversarial loss: 0.678975\n",
      "epoch 18; iter: 0; batch classifier loss: 0.578644; batch adversarial loss: 0.744905\n",
      "epoch 19; iter: 0; batch classifier loss: 0.482677; batch adversarial loss: 0.662482\n",
      "epoch 20; iter: 0; batch classifier loss: 0.520829; batch adversarial loss: 0.656770\n",
      "epoch 21; iter: 0; batch classifier loss: 0.478021; batch adversarial loss: 0.734167\n",
      "epoch 22; iter: 0; batch classifier loss: 0.350194; batch adversarial loss: 0.636872\n",
      "epoch 23; iter: 0; batch classifier loss: 0.578450; batch adversarial loss: 0.704351\n",
      "epoch 24; iter: 0; batch classifier loss: 0.406240; batch adversarial loss: 0.648813\n",
      "epoch 25; iter: 0; batch classifier loss: 0.533520; batch adversarial loss: 0.694336\n",
      "epoch 26; iter: 0; batch classifier loss: 0.432962; batch adversarial loss: 0.660918\n",
      "epoch 27; iter: 0; batch classifier loss: 0.363206; batch adversarial loss: 0.616664\n",
      "epoch 28; iter: 0; batch classifier loss: 0.420794; batch adversarial loss: 0.667852\n",
      "epoch 29; iter: 0; batch classifier loss: 0.325424; batch adversarial loss: 0.657058\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365961; batch adversarial loss: 0.663225\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359855; batch adversarial loss: 0.673929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362979; batch adversarial loss: 0.660932\n",
      "epoch 33; iter: 0; batch classifier loss: 0.312808; batch adversarial loss: 0.605796\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310556; batch adversarial loss: 0.629299\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406347; batch adversarial loss: 0.580959\n",
      "epoch 36; iter: 0; batch classifier loss: 0.248081; batch adversarial loss: 0.594651\n",
      "epoch 37; iter: 0; batch classifier loss: 0.354633; batch adversarial loss: 0.605371\n",
      "epoch 38; iter: 0; batch classifier loss: 0.256640; batch adversarial loss: 0.672708\n",
      "epoch 39; iter: 0; batch classifier loss: 0.410737; batch adversarial loss: 0.616371\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685781; batch adversarial loss: 0.703394\n",
      "epoch 1; iter: 0; batch classifier loss: 0.655251; batch adversarial loss: 0.746844\n",
      "epoch 2; iter: 0; batch classifier loss: 0.652165; batch adversarial loss: 0.726714\n",
      "epoch 3; iter: 0; batch classifier loss: 0.617504; batch adversarial loss: 0.740399\n",
      "epoch 4; iter: 0; batch classifier loss: 0.589095; batch adversarial loss: 0.714527\n",
      "epoch 5; iter: 0; batch classifier loss: 0.620318; batch adversarial loss: 0.736239\n",
      "epoch 6; iter: 0; batch classifier loss: 0.600144; batch adversarial loss: 0.731920\n",
      "epoch 7; iter: 0; batch classifier loss: 0.594683; batch adversarial loss: 0.715304\n",
      "epoch 8; iter: 0; batch classifier loss: 0.549723; batch adversarial loss: 0.705717\n",
      "epoch 9; iter: 0; batch classifier loss: 0.567398; batch adversarial loss: 0.716832\n",
      "epoch 10; iter: 0; batch classifier loss: 0.580960; batch adversarial loss: 0.718685\n",
      "epoch 11; iter: 0; batch classifier loss: 0.526564; batch adversarial loss: 0.721388\n",
      "epoch 12; iter: 0; batch classifier loss: 0.506611; batch adversarial loss: 0.708388\n",
      "epoch 13; iter: 0; batch classifier loss: 0.552305; batch adversarial loss: 0.719409\n",
      "epoch 14; iter: 0; batch classifier loss: 0.566346; batch adversarial loss: 0.709998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.515141; batch adversarial loss: 0.688049\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540738; batch adversarial loss: 0.701275\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537594; batch adversarial loss: 0.705528\n",
      "epoch 18; iter: 0; batch classifier loss: 0.482393; batch adversarial loss: 0.693534\n",
      "epoch 19; iter: 0; batch classifier loss: 0.459544; batch adversarial loss: 0.689436\n",
      "epoch 20; iter: 0; batch classifier loss: 0.492715; batch adversarial loss: 0.681340\n",
      "epoch 21; iter: 0; batch classifier loss: 0.500337; batch adversarial loss: 0.679161\n",
      "epoch 22; iter: 0; batch classifier loss: 0.567383; batch adversarial loss: 0.687414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.499456; batch adversarial loss: 0.683402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.453104; batch adversarial loss: 0.683514\n",
      "epoch 25; iter: 0; batch classifier loss: 0.431123; batch adversarial loss: 0.679593\n",
      "epoch 26; iter: 0; batch classifier loss: 0.475566; batch adversarial loss: 0.670367\n",
      "epoch 27; iter: 0; batch classifier loss: 0.458600; batch adversarial loss: 0.677206\n",
      "epoch 28; iter: 0; batch classifier loss: 0.474724; batch adversarial loss: 0.670609\n",
      "epoch 29; iter: 0; batch classifier loss: 0.482153; batch adversarial loss: 0.691546\n",
      "epoch 30; iter: 0; batch classifier loss: 0.448406; batch adversarial loss: 0.692601\n",
      "epoch 31; iter: 0; batch classifier loss: 0.504560; batch adversarial loss: 0.668529\n",
      "epoch 32; iter: 0; batch classifier loss: 0.499274; batch adversarial loss: 0.678803\n",
      "epoch 33; iter: 0; batch classifier loss: 0.476653; batch adversarial loss: 0.672458\n",
      "epoch 34; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.667284\n",
      "epoch 35; iter: 0; batch classifier loss: 0.403650; batch adversarial loss: 0.658053\n",
      "epoch 36; iter: 0; batch classifier loss: 0.427819; batch adversarial loss: 0.663521\n",
      "epoch 37; iter: 0; batch classifier loss: 0.439551; batch adversarial loss: 0.657544\n",
      "epoch 38; iter: 0; batch classifier loss: 0.459663; batch adversarial loss: 0.661301\n",
      "epoch 39; iter: 0; batch classifier loss: 0.342490; batch adversarial loss: 0.658407\n",
      "epoch 0; iter: 0; batch classifier loss: 0.676041; batch adversarial loss: 0.599539\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639505; batch adversarial loss: 0.592636\n",
      "epoch 2; iter: 0; batch classifier loss: 0.624831; batch adversarial loss: 0.598860\n",
      "epoch 3; iter: 0; batch classifier loss: 0.579886; batch adversarial loss: 0.614565\n",
      "epoch 4; iter: 0; batch classifier loss: 0.574267; batch adversarial loss: 0.624885\n",
      "epoch 5; iter: 0; batch classifier loss: 0.550294; batch adversarial loss: 0.608065\n",
      "epoch 6; iter: 0; batch classifier loss: 0.510328; batch adversarial loss: 0.631696\n",
      "epoch 7; iter: 0; batch classifier loss: 0.513850; batch adversarial loss: 0.636753\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489220; batch adversarial loss: 0.612979\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455040; batch adversarial loss: 0.600514\n",
      "epoch 10; iter: 0; batch classifier loss: 0.436498; batch adversarial loss: 0.594550\n",
      "epoch 11; iter: 0; batch classifier loss: 0.441747; batch adversarial loss: 0.631972\n",
      "epoch 12; iter: 0; batch classifier loss: 0.454660; batch adversarial loss: 0.590780\n",
      "epoch 13; iter: 0; batch classifier loss: 0.462132; batch adversarial loss: 0.606471\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442133; batch adversarial loss: 0.546183\n",
      "epoch 15; iter: 0; batch classifier loss: 0.498646; batch adversarial loss: 0.627721\n",
      "epoch 16; iter: 0; batch classifier loss: 0.420199; batch adversarial loss: 0.562529\n",
      "epoch 17; iter: 0; batch classifier loss: 0.392526; batch adversarial loss: 0.607011\n",
      "epoch 18; iter: 0; batch classifier loss: 0.394543; batch adversarial loss: 0.645146\n",
      "epoch 19; iter: 0; batch classifier loss: 0.457682; batch adversarial loss: 0.621285\n",
      "epoch 20; iter: 0; batch classifier loss: 0.381654; batch adversarial loss: 0.596574\n",
      "epoch 21; iter: 0; batch classifier loss: 0.409544; batch adversarial loss: 0.618059\n",
      "epoch 22; iter: 0; batch classifier loss: 0.382236; batch adversarial loss: 0.603424\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411424; batch adversarial loss: 0.584155\n",
      "epoch 24; iter: 0; batch classifier loss: 0.361658; batch adversarial loss: 0.615679\n",
      "epoch 25; iter: 0; batch classifier loss: 0.409264; batch adversarial loss: 0.593230\n",
      "epoch 26; iter: 0; batch classifier loss: 0.348650; batch adversarial loss: 0.633699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.375190; batch adversarial loss: 0.572646\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371664; batch adversarial loss: 0.597297\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323721; batch adversarial loss: 0.575177\n",
      "epoch 30; iter: 0; batch classifier loss: 0.325449; batch adversarial loss: 0.597444\n",
      "epoch 31; iter: 0; batch classifier loss: 0.326599; batch adversarial loss: 0.618914\n",
      "epoch 32; iter: 0; batch classifier loss: 0.360312; batch adversarial loss: 0.606423\n",
      "epoch 33; iter: 0; batch classifier loss: 0.401491; batch adversarial loss: 0.604963\n",
      "epoch 34; iter: 0; batch classifier loss: 0.324313; batch adversarial loss: 0.631874\n",
      "epoch 35; iter: 0; batch classifier loss: 0.354523; batch adversarial loss: 0.570849\n",
      "epoch 36; iter: 0; batch classifier loss: 0.352041; batch adversarial loss: 0.604363\n",
      "epoch 37; iter: 0; batch classifier loss: 0.301044; batch adversarial loss: 0.613263\n",
      "epoch 38; iter: 0; batch classifier loss: 0.328304; batch adversarial loss: 0.560905\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444589; batch adversarial loss: 0.632632\n",
      "epoch 0; iter: 0; batch classifier loss: 0.712831; batch adversarial loss: 0.694238\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670091; batch adversarial loss: 0.727844\n",
      "epoch 2; iter: 0; batch classifier loss: 0.589119; batch adversarial loss: 0.729044\n",
      "epoch 3; iter: 0; batch classifier loss: 0.611603; batch adversarial loss: 0.734509\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583104; batch adversarial loss: 0.703146\n",
      "epoch 5; iter: 0; batch classifier loss: 0.609729; batch adversarial loss: 0.722739\n",
      "epoch 6; iter: 0; batch classifier loss: 0.528482; batch adversarial loss: 0.682759\n",
      "epoch 7; iter: 0; batch classifier loss: 0.536781; batch adversarial loss: 0.724264\n",
      "epoch 8; iter: 0; batch classifier loss: 0.492795; batch adversarial loss: 0.694400\n",
      "epoch 9; iter: 0; batch classifier loss: 0.489194; batch adversarial loss: 0.721712\n",
      "epoch 10; iter: 0; batch classifier loss: 0.486306; batch adversarial loss: 0.723907\n",
      "epoch 11; iter: 0; batch classifier loss: 0.498488; batch adversarial loss: 0.718712\n",
      "epoch 12; iter: 0; batch classifier loss: 0.457693; batch adversarial loss: 0.700375\n",
      "epoch 13; iter: 0; batch classifier loss: 0.493667; batch adversarial loss: 0.683249\n",
      "epoch 14; iter: 0; batch classifier loss: 0.406047; batch adversarial loss: 0.672108\n",
      "epoch 15; iter: 0; batch classifier loss: 0.427282; batch adversarial loss: 0.686034\n",
      "epoch 16; iter: 0; batch classifier loss: 0.458323; batch adversarial loss: 0.654055\n",
      "epoch 17; iter: 0; batch classifier loss: 0.441053; batch adversarial loss: 0.713118\n",
      "epoch 18; iter: 0; batch classifier loss: 0.355259; batch adversarial loss: 0.685898\n",
      "epoch 19; iter: 0; batch classifier loss: 0.433100; batch adversarial loss: 0.697978\n",
      "epoch 20; iter: 0; batch classifier loss: 0.363645; batch adversarial loss: 0.660114\n",
      "epoch 21; iter: 0; batch classifier loss: 0.295440; batch adversarial loss: 0.665543\n",
      "epoch 22; iter: 0; batch classifier loss: 0.398154; batch adversarial loss: 0.662491\n",
      "epoch 23; iter: 0; batch classifier loss: 0.477804; batch adversarial loss: 0.619245\n",
      "epoch 24; iter: 0; batch classifier loss: 0.302831; batch adversarial loss: 0.670235\n",
      "epoch 25; iter: 0; batch classifier loss: 0.381486; batch adversarial loss: 0.641142\n",
      "epoch 26; iter: 0; batch classifier loss: 0.320568; batch adversarial loss: 0.689659\n",
      "epoch 27; iter: 0; batch classifier loss: 0.269971; batch adversarial loss: 0.642690\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424624; batch adversarial loss: 0.652513\n",
      "epoch 29; iter: 0; batch classifier loss: 0.322014; batch adversarial loss: 0.668895\n",
      "epoch 30; iter: 0; batch classifier loss: 0.390158; batch adversarial loss: 0.644149\n",
      "epoch 31; iter: 0; batch classifier loss: 0.310345; batch adversarial loss: 0.627851\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304864; batch adversarial loss: 0.666518\n",
      "epoch 33; iter: 0; batch classifier loss: 0.353840; batch adversarial loss: 0.615307\n",
      "epoch 34; iter: 0; batch classifier loss: 0.338390; batch adversarial loss: 0.625387\n",
      "epoch 35; iter: 0; batch classifier loss: 0.294871; batch adversarial loss: 0.622507\n",
      "epoch 36; iter: 0; batch classifier loss: 0.275848; batch adversarial loss: 0.671398\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438094; batch adversarial loss: 0.608637\n",
      "epoch 38; iter: 0; batch classifier loss: 0.340081; batch adversarial loss: 0.655970\n",
      "epoch 39; iter: 0; batch classifier loss: 0.444819; batch adversarial loss: 0.613251\n",
      "epoch 40; iter: 0; batch classifier loss: 0.254513; batch adversarial loss: 0.596881\n",
      "epoch 41; iter: 0; batch classifier loss: 0.347329; batch adversarial loss: 0.573558\n",
      "epoch 42; iter: 0; batch classifier loss: 0.332517; batch adversarial loss: 0.609833\n",
      "epoch 43; iter: 0; batch classifier loss: 0.228668; batch adversarial loss: 0.636929\n",
      "epoch 44; iter: 0; batch classifier loss: 0.277364; batch adversarial loss: 0.576973\n",
      "epoch 45; iter: 0; batch classifier loss: 0.289402; batch adversarial loss: 0.649381\n",
      "epoch 46; iter: 0; batch classifier loss: 0.295561; batch adversarial loss: 0.636090\n",
      "epoch 47; iter: 0; batch classifier loss: 0.411584; batch adversarial loss: 0.597727\n",
      "epoch 48; iter: 0; batch classifier loss: 0.291713; batch adversarial loss: 0.578364\n",
      "epoch 49; iter: 0; batch classifier loss: 0.332768; batch adversarial loss: 0.617571\n",
      "epoch 50; iter: 0; batch classifier loss: 0.410716; batch adversarial loss: 0.631159\n",
      "epoch 51; iter: 0; batch classifier loss: 0.302061; batch adversarial loss: 0.654491\n",
      "epoch 52; iter: 0; batch classifier loss: 0.343894; batch adversarial loss: 0.585716\n",
      "epoch 53; iter: 0; batch classifier loss: 0.342348; batch adversarial loss: 0.626548\n",
      "epoch 54; iter: 0; batch classifier loss: 0.280222; batch adversarial loss: 0.545096\n",
      "epoch 55; iter: 0; batch classifier loss: 0.412968; batch adversarial loss: 0.556023\n",
      "epoch 56; iter: 0; batch classifier loss: 0.302014; batch adversarial loss: 0.597762\n",
      "epoch 57; iter: 0; batch classifier loss: 0.315359; batch adversarial loss: 0.637053\n",
      "epoch 58; iter: 0; batch classifier loss: 0.265885; batch adversarial loss: 0.552658\n",
      "epoch 59; iter: 0; batch classifier loss: 0.237853; batch adversarial loss: 0.604788\n",
      "epoch 0; iter: 0; batch classifier loss: 0.690060; batch adversarial loss: 0.706558\n",
      "epoch 1; iter: 0; batch classifier loss: 0.603163; batch adversarial loss: 0.701384\n",
      "epoch 2; iter: 0; batch classifier loss: 0.563708; batch adversarial loss: 0.699200\n",
      "epoch 3; iter: 0; batch classifier loss: 0.536362; batch adversarial loss: 0.692633\n",
      "epoch 4; iter: 0; batch classifier loss: 0.495172; batch adversarial loss: 0.688896\n",
      "epoch 5; iter: 0; batch classifier loss: 0.461290; batch adversarial loss: 0.686566\n",
      "epoch 6; iter: 0; batch classifier loss: 0.388844; batch adversarial loss: 0.685157\n",
      "epoch 7; iter: 0; batch classifier loss: 0.434210; batch adversarial loss: 0.679484\n",
      "epoch 8; iter: 0; batch classifier loss: 0.423111; batch adversarial loss: 0.678797\n",
      "epoch 9; iter: 0; batch classifier loss: 0.416707; batch adversarial loss: 0.675619\n",
      "epoch 10; iter: 0; batch classifier loss: 0.376784; batch adversarial loss: 0.673078\n",
      "epoch 11; iter: 0; batch classifier loss: 0.419700; batch adversarial loss: 0.666920\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417187; batch adversarial loss: 0.673143\n",
      "epoch 13; iter: 0; batch classifier loss: 0.397504; batch adversarial loss: 0.655055\n",
      "epoch 14; iter: 0; batch classifier loss: 0.429250; batch adversarial loss: 0.649303\n",
      "epoch 15; iter: 0; batch classifier loss: 0.365424; batch adversarial loss: 0.660628\n",
      "epoch 16; iter: 0; batch classifier loss: 0.462728; batch adversarial loss: 0.654965\n",
      "epoch 17; iter: 0; batch classifier loss: 0.348688; batch adversarial loss: 0.659803\n",
      "epoch 18; iter: 0; batch classifier loss: 0.326494; batch adversarial loss: 0.633262\n",
      "epoch 19; iter: 0; batch classifier loss: 0.354707; batch adversarial loss: 0.632957\n",
      "epoch 20; iter: 0; batch classifier loss: 0.317801; batch adversarial loss: 0.645103\n",
      "epoch 21; iter: 0; batch classifier loss: 0.264328; batch adversarial loss: 0.623031\n",
      "epoch 22; iter: 0; batch classifier loss: 0.301869; batch adversarial loss: 0.654459\n",
      "epoch 23; iter: 0; batch classifier loss: 0.340054; batch adversarial loss: 0.648251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.286974; batch adversarial loss: 0.655958\n",
      "epoch 25; iter: 0; batch classifier loss: 0.269915; batch adversarial loss: 0.606342\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393725; batch adversarial loss: 0.642372\n",
      "epoch 27; iter: 0; batch classifier loss: 0.337193; batch adversarial loss: 0.631096\n",
      "epoch 28; iter: 0; batch classifier loss: 0.368839; batch adversarial loss: 0.659729\n",
      "epoch 29; iter: 0; batch classifier loss: 0.239841; batch adversarial loss: 0.621513\n",
      "epoch 30; iter: 0; batch classifier loss: 0.247290; batch adversarial loss: 0.654166\n",
      "epoch 31; iter: 0; batch classifier loss: 0.307797; batch adversarial loss: 0.652377\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320304; batch adversarial loss: 0.603698\n",
      "epoch 33; iter: 0; batch classifier loss: 0.332592; batch adversarial loss: 0.590844\n",
      "epoch 34; iter: 0; batch classifier loss: 0.310993; batch adversarial loss: 0.604136\n",
      "epoch 35; iter: 0; batch classifier loss: 0.279303; batch adversarial loss: 0.581589\n",
      "epoch 36; iter: 0; batch classifier loss: 0.343292; batch adversarial loss: 0.594178\n",
      "epoch 37; iter: 0; batch classifier loss: 0.239401; batch adversarial loss: 0.591034\n",
      "epoch 38; iter: 0; batch classifier loss: 0.234688; batch adversarial loss: 0.582176\n",
      "epoch 39; iter: 0; batch classifier loss: 0.234579; batch adversarial loss: 0.672406\n",
      "epoch 40; iter: 0; batch classifier loss: 0.219713; batch adversarial loss: 0.578893\n",
      "epoch 41; iter: 0; batch classifier loss: 0.344553; batch adversarial loss: 0.580692\n",
      "epoch 42; iter: 0; batch classifier loss: 0.422628; batch adversarial loss: 0.579398\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287176; batch adversarial loss: 0.624556\n",
      "epoch 44; iter: 0; batch classifier loss: 0.327513; batch adversarial loss: 0.609967\n",
      "epoch 45; iter: 0; batch classifier loss: 0.481509; batch adversarial loss: 0.578809\n",
      "epoch 46; iter: 0; batch classifier loss: 0.368850; batch adversarial loss: 0.594458\n",
      "epoch 47; iter: 0; batch classifier loss: 0.267546; batch adversarial loss: 0.580995\n",
      "epoch 48; iter: 0; batch classifier loss: 0.257017; batch adversarial loss: 0.568098\n",
      "epoch 49; iter: 0; batch classifier loss: 0.228583; batch adversarial loss: 0.613166\n",
      "epoch 50; iter: 0; batch classifier loss: 0.320210; batch adversarial loss: 0.612454\n",
      "epoch 51; iter: 0; batch classifier loss: 0.365281; batch adversarial loss: 0.625049\n",
      "epoch 52; iter: 0; batch classifier loss: 0.238736; batch adversarial loss: 0.607597\n",
      "epoch 53; iter: 0; batch classifier loss: 0.298807; batch adversarial loss: 0.564878\n",
      "epoch 54; iter: 0; batch classifier loss: 0.356545; batch adversarial loss: 0.557525\n",
      "epoch 55; iter: 0; batch classifier loss: 0.223299; batch adversarial loss: 0.624776\n",
      "epoch 56; iter: 0; batch classifier loss: 0.259222; batch adversarial loss: 0.591036\n",
      "epoch 57; iter: 0; batch classifier loss: 0.342919; batch adversarial loss: 0.619963\n",
      "epoch 58; iter: 0; batch classifier loss: 0.390189; batch adversarial loss: 0.639052\n",
      "epoch 59; iter: 0; batch classifier loss: 0.348282; batch adversarial loss: 0.575843\n",
      "epoch 0; iter: 0; batch classifier loss: 0.640149; batch adversarial loss: 0.657748\n",
      "epoch 1; iter: 0; batch classifier loss: 0.621202; batch adversarial loss: 0.630917\n",
      "epoch 2; iter: 0; batch classifier loss: 0.656435; batch adversarial loss: 0.643189\n",
      "epoch 3; iter: 0; batch classifier loss: 0.602438; batch adversarial loss: 0.678021\n",
      "epoch 4; iter: 0; batch classifier loss: 0.538931; batch adversarial loss: 0.687387\n",
      "epoch 5; iter: 0; batch classifier loss: 0.547965; batch adversarial loss: 0.617226\n",
      "epoch 6; iter: 0; batch classifier loss: 0.521390; batch adversarial loss: 0.639785\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498175; batch adversarial loss: 0.645302\n",
      "epoch 8; iter: 0; batch classifier loss: 0.516970; batch adversarial loss: 0.633936\n",
      "epoch 9; iter: 0; batch classifier loss: 0.518776; batch adversarial loss: 0.600978\n",
      "epoch 10; iter: 0; batch classifier loss: 0.487497; batch adversarial loss: 0.628105\n",
      "epoch 11; iter: 0; batch classifier loss: 0.458880; batch adversarial loss: 0.640520\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491551; batch adversarial loss: 0.629518\n",
      "epoch 13; iter: 0; batch classifier loss: 0.457894; batch adversarial loss: 0.607622\n",
      "epoch 14; iter: 0; batch classifier loss: 0.502957; batch adversarial loss: 0.631213\n",
      "epoch 15; iter: 0; batch classifier loss: 0.401445; batch adversarial loss: 0.644184\n",
      "epoch 16; iter: 0; batch classifier loss: 0.489222; batch adversarial loss: 0.642741\n",
      "epoch 17; iter: 0; batch classifier loss: 0.395020; batch adversarial loss: 0.694615\n",
      "epoch 18; iter: 0; batch classifier loss: 0.505171; batch adversarial loss: 0.645341\n",
      "epoch 19; iter: 0; batch classifier loss: 0.465580; batch adversarial loss: 0.666593\n",
      "epoch 20; iter: 0; batch classifier loss: 0.488833; batch adversarial loss: 0.632192\n",
      "epoch 21; iter: 0; batch classifier loss: 0.482699; batch adversarial loss: 0.633111\n",
      "epoch 22; iter: 0; batch classifier loss: 0.447331; batch adversarial loss: 0.621167\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417026; batch adversarial loss: 0.645724\n",
      "epoch 24; iter: 0; batch classifier loss: 0.518830; batch adversarial loss: 0.632154\n",
      "epoch 25; iter: 0; batch classifier loss: 0.438943; batch adversarial loss: 0.626471\n",
      "epoch 26; iter: 0; batch classifier loss: 0.398741; batch adversarial loss: 0.626533\n",
      "epoch 27; iter: 0; batch classifier loss: 0.350745; batch adversarial loss: 0.617453\n",
      "epoch 28; iter: 0; batch classifier loss: 0.371475; batch adversarial loss: 0.663426\n",
      "epoch 29; iter: 0; batch classifier loss: 0.372168; batch adversarial loss: 0.613245\n",
      "epoch 30; iter: 0; batch classifier loss: 0.410134; batch adversarial loss: 0.591383\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368854; batch adversarial loss: 0.629084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.396368; batch adversarial loss: 0.581714\n",
      "epoch 33; iter: 0; batch classifier loss: 0.398825; batch adversarial loss: 0.605632\n",
      "epoch 34; iter: 0; batch classifier loss: 0.427773; batch adversarial loss: 0.616424\n",
      "epoch 35; iter: 0; batch classifier loss: 0.355829; batch adversarial loss: 0.668171\n",
      "epoch 36; iter: 0; batch classifier loss: 0.374883; batch adversarial loss: 0.665475\n",
      "epoch 37; iter: 0; batch classifier loss: 0.364666; batch adversarial loss: 0.643262\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382537; batch adversarial loss: 0.631522\n",
      "epoch 39; iter: 0; batch classifier loss: 0.352722; batch adversarial loss: 0.616257\n",
      "epoch 40; iter: 0; batch classifier loss: 0.340219; batch adversarial loss: 0.654861\n",
      "epoch 41; iter: 0; batch classifier loss: 0.446910; batch adversarial loss: 0.561777\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368883; batch adversarial loss: 0.607811\n",
      "epoch 43; iter: 0; batch classifier loss: 0.405918; batch adversarial loss: 0.600023\n",
      "epoch 44; iter: 0; batch classifier loss: 0.370101; batch adversarial loss: 0.626295\n",
      "epoch 45; iter: 0; batch classifier loss: 0.318818; batch adversarial loss: 0.602797\n",
      "epoch 46; iter: 0; batch classifier loss: 0.322390; batch adversarial loss: 0.615588\n",
      "epoch 47; iter: 0; batch classifier loss: 0.318634; batch adversarial loss: 0.622591\n",
      "epoch 48; iter: 0; batch classifier loss: 0.498221; batch adversarial loss: 0.646945\n",
      "epoch 49; iter: 0; batch classifier loss: 0.329092; batch adversarial loss: 0.633632\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362502; batch adversarial loss: 0.601449\n",
      "epoch 51; iter: 0; batch classifier loss: 0.392245; batch adversarial loss: 0.645316\n",
      "epoch 52; iter: 0; batch classifier loss: 0.380435; batch adversarial loss: 0.656988\n",
      "epoch 53; iter: 0; batch classifier loss: 0.409156; batch adversarial loss: 0.629340\n",
      "epoch 54; iter: 0; batch classifier loss: 0.408096; batch adversarial loss: 0.635363\n",
      "epoch 55; iter: 0; batch classifier loss: 0.403774; batch adversarial loss: 0.618637\n",
      "epoch 56; iter: 0; batch classifier loss: 0.371348; batch adversarial loss: 0.574954\n",
      "epoch 57; iter: 0; batch classifier loss: 0.328386; batch adversarial loss: 0.627838\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358939; batch adversarial loss: 0.636033\n",
      "epoch 59; iter: 0; batch classifier loss: 0.366147; batch adversarial loss: 0.599734\n",
      "epoch 0; iter: 0; batch classifier loss: 0.793253; batch adversarial loss: 0.683794\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780680; batch adversarial loss: 0.634560\n",
      "epoch 2; iter: 0; batch classifier loss: 0.756429; batch adversarial loss: 0.696207\n",
      "epoch 3; iter: 0; batch classifier loss: 0.680530; batch adversarial loss: 0.697525\n",
      "epoch 4; iter: 0; batch classifier loss: 0.645532; batch adversarial loss: 0.693200\n",
      "epoch 5; iter: 0; batch classifier loss: 0.637634; batch adversarial loss: 0.660286\n",
      "epoch 6; iter: 0; batch classifier loss: 0.572736; batch adversarial loss: 0.677470\n",
      "epoch 7; iter: 0; batch classifier loss: 0.541205; batch adversarial loss: 0.668431\n",
      "epoch 8; iter: 0; batch classifier loss: 0.566453; batch adversarial loss: 0.673465\n",
      "epoch 9; iter: 0; batch classifier loss: 0.520355; batch adversarial loss: 0.641140\n",
      "epoch 10; iter: 0; batch classifier loss: 0.485767; batch adversarial loss: 0.637516\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505018; batch adversarial loss: 0.586690\n",
      "epoch 12; iter: 0; batch classifier loss: 0.491666; batch adversarial loss: 0.671755\n",
      "epoch 13; iter: 0; batch classifier loss: 0.500519; batch adversarial loss: 0.663190\n",
      "epoch 14; iter: 0; batch classifier loss: 0.474634; batch adversarial loss: 0.583049\n",
      "epoch 15; iter: 0; batch classifier loss: 0.428909; batch adversarial loss: 0.592515\n",
      "epoch 16; iter: 0; batch classifier loss: 0.376970; batch adversarial loss: 0.638651\n",
      "epoch 17; iter: 0; batch classifier loss: 0.431648; batch adversarial loss: 0.653785\n",
      "epoch 18; iter: 0; batch classifier loss: 0.406433; batch adversarial loss: 0.626822\n",
      "epoch 19; iter: 0; batch classifier loss: 0.396966; batch adversarial loss: 0.677032\n",
      "epoch 20; iter: 0; batch classifier loss: 0.436189; batch adversarial loss: 0.718845\n",
      "epoch 21; iter: 0; batch classifier loss: 0.374267; batch adversarial loss: 0.545437\n",
      "epoch 22; iter: 0; batch classifier loss: 0.395902; batch adversarial loss: 0.587639\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416357; batch adversarial loss: 0.641758\n",
      "epoch 24; iter: 0; batch classifier loss: 0.398813; batch adversarial loss: 0.594911\n",
      "epoch 25; iter: 0; batch classifier loss: 0.377245; batch adversarial loss: 0.697497\n",
      "epoch 26; iter: 0; batch classifier loss: 0.400130; batch adversarial loss: 0.606476\n",
      "epoch 27; iter: 0; batch classifier loss: 0.373194; batch adversarial loss: 0.678936\n",
      "epoch 28; iter: 0; batch classifier loss: 0.402783; batch adversarial loss: 0.746642\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338472; batch adversarial loss: 0.672746\n",
      "epoch 30; iter: 0; batch classifier loss: 0.381792; batch adversarial loss: 0.705531\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390760; batch adversarial loss: 0.671038\n",
      "epoch 32; iter: 0; batch classifier loss: 0.371843; batch adversarial loss: 0.636242\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326312; batch adversarial loss: 0.689447\n",
      "epoch 34; iter: 0; batch classifier loss: 0.336222; batch adversarial loss: 0.682844\n",
      "epoch 35; iter: 0; batch classifier loss: 0.327036; batch adversarial loss: 0.683233\n",
      "epoch 36; iter: 0; batch classifier loss: 0.339988; batch adversarial loss: 0.721848\n",
      "epoch 37; iter: 0; batch classifier loss: 0.460598; batch adversarial loss: 0.540180\n",
      "epoch 38; iter: 0; batch classifier loss: 0.396706; batch adversarial loss: 0.655214\n",
      "epoch 39; iter: 0; batch classifier loss: 0.311030; batch adversarial loss: 0.626880\n",
      "epoch 40; iter: 0; batch classifier loss: 0.345406; batch adversarial loss: 0.670247\n",
      "epoch 41; iter: 0; batch classifier loss: 0.338648; batch adversarial loss: 0.618695\n",
      "epoch 42; iter: 0; batch classifier loss: 0.460442; batch adversarial loss: 0.663158\n",
      "epoch 43; iter: 0; batch classifier loss: 0.277891; batch adversarial loss: 0.613902\n",
      "epoch 44; iter: 0; batch classifier loss: 0.264335; batch adversarial loss: 0.591058\n",
      "epoch 45; iter: 0; batch classifier loss: 0.272014; batch adversarial loss: 0.670736\n",
      "epoch 46; iter: 0; batch classifier loss: 0.340991; batch adversarial loss: 0.672520\n",
      "epoch 47; iter: 0; batch classifier loss: 0.340680; batch adversarial loss: 0.647835\n",
      "epoch 48; iter: 0; batch classifier loss: 0.281321; batch adversarial loss: 0.658670\n",
      "epoch 49; iter: 0; batch classifier loss: 0.282254; batch adversarial loss: 0.596842\n",
      "epoch 50; iter: 0; batch classifier loss: 0.255413; batch adversarial loss: 0.592492\n",
      "epoch 51; iter: 0; batch classifier loss: 0.291335; batch adversarial loss: 0.594457\n",
      "epoch 52; iter: 0; batch classifier loss: 0.376480; batch adversarial loss: 0.616224\n",
      "epoch 53; iter: 0; batch classifier loss: 0.352271; batch adversarial loss: 0.715149\n",
      "epoch 54; iter: 0; batch classifier loss: 0.281351; batch adversarial loss: 0.726202\n",
      "epoch 55; iter: 0; batch classifier loss: 0.286529; batch adversarial loss: 0.685818\n",
      "epoch 56; iter: 0; batch classifier loss: 0.344502; batch adversarial loss: 0.600268\n",
      "epoch 57; iter: 0; batch classifier loss: 0.399969; batch adversarial loss: 0.606904\n",
      "epoch 58; iter: 0; batch classifier loss: 0.287906; batch adversarial loss: 0.666399\n",
      "epoch 59; iter: 0; batch classifier loss: 0.362561; batch adversarial loss: 0.625256\n",
      "epoch 0; iter: 0; batch classifier loss: 0.738450; batch adversarial loss: 0.673622\n",
      "epoch 1; iter: 0; batch classifier loss: 0.720751; batch adversarial loss: 0.646879\n",
      "epoch 2; iter: 0; batch classifier loss: 0.651072; batch adversarial loss: 0.695785\n",
      "epoch 3; iter: 0; batch classifier loss: 0.621252; batch adversarial loss: 0.664384\n",
      "epoch 4; iter: 0; batch classifier loss: 0.670045; batch adversarial loss: 0.647014\n",
      "epoch 5; iter: 0; batch classifier loss: 0.562419; batch adversarial loss: 0.618485\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558154; batch adversarial loss: 0.640685\n",
      "epoch 7; iter: 0; batch classifier loss: 0.481426; batch adversarial loss: 0.669461\n",
      "epoch 8; iter: 0; batch classifier loss: 0.528975; batch adversarial loss: 0.604790\n",
      "epoch 9; iter: 0; batch classifier loss: 0.485051; batch adversarial loss: 0.640618\n",
      "epoch 10; iter: 0; batch classifier loss: 0.497819; batch adversarial loss: 0.668686\n",
      "epoch 11; iter: 0; batch classifier loss: 0.528516; batch adversarial loss: 0.615143\n",
      "epoch 12; iter: 0; batch classifier loss: 0.496903; batch adversarial loss: 0.615714\n",
      "epoch 13; iter: 0; batch classifier loss: 0.399778; batch adversarial loss: 0.752483\n",
      "epoch 14; iter: 0; batch classifier loss: 0.348636; batch adversarial loss: 0.629675\n",
      "epoch 15; iter: 0; batch classifier loss: 0.415320; batch adversarial loss: 0.592660\n",
      "epoch 16; iter: 0; batch classifier loss: 0.350769; batch adversarial loss: 0.646475\n",
      "epoch 17; iter: 0; batch classifier loss: 0.426795; batch adversarial loss: 0.568281\n",
      "epoch 18; iter: 0; batch classifier loss: 0.358555; batch adversarial loss: 0.647957\n",
      "epoch 19; iter: 0; batch classifier loss: 0.496915; batch adversarial loss: 0.665118\n",
      "epoch 20; iter: 0; batch classifier loss: 0.294989; batch adversarial loss: 0.659883\n",
      "epoch 21; iter: 0; batch classifier loss: 0.431979; batch adversarial loss: 0.729991\n",
      "epoch 22; iter: 0; batch classifier loss: 0.344913; batch adversarial loss: 0.633801\n",
      "epoch 23; iter: 0; batch classifier loss: 0.349785; batch adversarial loss: 0.574475\n",
      "epoch 24; iter: 0; batch classifier loss: 0.420995; batch adversarial loss: 0.596129\n",
      "epoch 25; iter: 0; batch classifier loss: 0.250384; batch adversarial loss: 0.657996\n",
      "epoch 26; iter: 0; batch classifier loss: 0.275718; batch adversarial loss: 0.656548\n",
      "epoch 27; iter: 0; batch classifier loss: 0.388119; batch adversarial loss: 0.648699\n",
      "epoch 28; iter: 0; batch classifier loss: 0.301659; batch adversarial loss: 0.647966\n",
      "epoch 29; iter: 0; batch classifier loss: 0.324719; batch adversarial loss: 0.611830\n",
      "epoch 30; iter: 0; batch classifier loss: 0.442227; batch adversarial loss: 0.628365\n",
      "epoch 31; iter: 0; batch classifier loss: 0.365195; batch adversarial loss: 0.637078\n",
      "epoch 32; iter: 0; batch classifier loss: 0.373474; batch adversarial loss: 0.596160\n",
      "epoch 33; iter: 0; batch classifier loss: 0.356978; batch adversarial loss: 0.611957\n",
      "epoch 34; iter: 0; batch classifier loss: 0.300668; batch adversarial loss: 0.673486\n",
      "epoch 35; iter: 0; batch classifier loss: 0.320808; batch adversarial loss: 0.634631\n",
      "epoch 36; iter: 0; batch classifier loss: 0.360987; batch adversarial loss: 0.683565\n",
      "epoch 37; iter: 0; batch classifier loss: 0.394631; batch adversarial loss: 0.609784\n",
      "epoch 38; iter: 0; batch classifier loss: 0.355838; batch adversarial loss: 0.658135\n",
      "epoch 39; iter: 0; batch classifier loss: 0.363185; batch adversarial loss: 0.565377\n",
      "epoch 40; iter: 0; batch classifier loss: 0.436818; batch adversarial loss: 0.571648\n",
      "epoch 41; iter: 0; batch classifier loss: 0.448161; batch adversarial loss: 0.635189\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429516; batch adversarial loss: 0.625927\n",
      "epoch 43; iter: 0; batch classifier loss: 0.339888; batch adversarial loss: 0.674537\n",
      "epoch 44; iter: 0; batch classifier loss: 0.213686; batch adversarial loss: 0.569655\n",
      "epoch 45; iter: 0; batch classifier loss: 0.344481; batch adversarial loss: 0.588213\n",
      "epoch 46; iter: 0; batch classifier loss: 0.311177; batch adversarial loss: 0.598740\n",
      "epoch 47; iter: 0; batch classifier loss: 0.402902; batch adversarial loss: 0.537409\n",
      "epoch 48; iter: 0; batch classifier loss: 0.334562; batch adversarial loss: 0.486924\n",
      "epoch 49; iter: 0; batch classifier loss: 0.224166; batch adversarial loss: 0.548472\n",
      "epoch 50; iter: 0; batch classifier loss: 0.251632; batch adversarial loss: 0.589285\n",
      "epoch 51; iter: 0; batch classifier loss: 0.264871; batch adversarial loss: 0.602941\n",
      "epoch 52; iter: 0; batch classifier loss: 0.319070; batch adversarial loss: 0.598000\n",
      "epoch 53; iter: 0; batch classifier loss: 0.293734; batch adversarial loss: 0.532361\n",
      "epoch 54; iter: 0; batch classifier loss: 0.226465; batch adversarial loss: 0.518735\n",
      "epoch 55; iter: 0; batch classifier loss: 0.362825; batch adversarial loss: 0.558295\n",
      "epoch 56; iter: 0; batch classifier loss: 0.241317; batch adversarial loss: 0.578428\n",
      "epoch 57; iter: 0; batch classifier loss: 0.350526; batch adversarial loss: 0.587586\n",
      "epoch 58; iter: 0; batch classifier loss: 0.294126; batch adversarial loss: 0.513688\n",
      "epoch 59; iter: 0; batch classifier loss: 0.250417; batch adversarial loss: 0.670118\n",
      "epoch 60; iter: 0; batch classifier loss: 0.327120; batch adversarial loss: 0.585918\n",
      "epoch 61; iter: 0; batch classifier loss: 0.375481; batch adversarial loss: 0.558593\n",
      "epoch 62; iter: 0; batch classifier loss: 0.377535; batch adversarial loss: 0.548841\n",
      "epoch 63; iter: 0; batch classifier loss: 0.294907; batch adversarial loss: 0.589231\n",
      "epoch 64; iter: 0; batch classifier loss: 0.271060; batch adversarial loss: 0.625561\n",
      "epoch 65; iter: 0; batch classifier loss: 0.373283; batch adversarial loss: 0.540270\n",
      "epoch 66; iter: 0; batch classifier loss: 0.266854; batch adversarial loss: 0.658044\n",
      "epoch 67; iter: 0; batch classifier loss: 0.246341; batch adversarial loss: 0.593078\n",
      "epoch 68; iter: 0; batch classifier loss: 0.187325; batch adversarial loss: 0.625576\n",
      "epoch 69; iter: 0; batch classifier loss: 0.276685; batch adversarial loss: 0.569966\n",
      "epoch 70; iter: 0; batch classifier loss: 0.408613; batch adversarial loss: 0.701830\n",
      "epoch 71; iter: 0; batch classifier loss: 0.310814; batch adversarial loss: 0.631358\n",
      "epoch 72; iter: 0; batch classifier loss: 0.475466; batch adversarial loss: 0.561749\n",
      "epoch 73; iter: 0; batch classifier loss: 0.290736; batch adversarial loss: 0.600807\n",
      "epoch 74; iter: 0; batch classifier loss: 0.252212; batch adversarial loss: 0.548506\n",
      "epoch 75; iter: 0; batch classifier loss: 0.267464; batch adversarial loss: 0.661779\n",
      "epoch 76; iter: 0; batch classifier loss: 0.369388; batch adversarial loss: 0.589785\n",
      "epoch 77; iter: 0; batch classifier loss: 0.337472; batch adversarial loss: 0.535443\n",
      "epoch 78; iter: 0; batch classifier loss: 0.331548; batch adversarial loss: 0.644531\n",
      "epoch 79; iter: 0; batch classifier loss: 0.433719; batch adversarial loss: 0.609958\n",
      "epoch 0; iter: 0; batch classifier loss: 0.627223; batch adversarial loss: 0.992376\n",
      "epoch 1; iter: 0; batch classifier loss: 0.584277; batch adversarial loss: 0.949638\n",
      "epoch 2; iter: 0; batch classifier loss: 0.544100; batch adversarial loss: 0.905914\n",
      "epoch 3; iter: 0; batch classifier loss: 0.469545; batch adversarial loss: 0.963672\n",
      "epoch 4; iter: 0; batch classifier loss: 0.453556; batch adversarial loss: 0.996777\n",
      "epoch 5; iter: 0; batch classifier loss: 0.455775; batch adversarial loss: 0.879889\n",
      "epoch 6; iter: 0; batch classifier loss: 0.439057; batch adversarial loss: 0.911179\n",
      "epoch 7; iter: 0; batch classifier loss: 0.453539; batch adversarial loss: 0.876066\n",
      "epoch 8; iter: 0; batch classifier loss: 0.364336; batch adversarial loss: 0.906582\n",
      "epoch 9; iter: 0; batch classifier loss: 0.342426; batch adversarial loss: 0.932469\n",
      "epoch 10; iter: 0; batch classifier loss: 0.384460; batch adversarial loss: 0.858471\n",
      "epoch 11; iter: 0; batch classifier loss: 0.424836; batch adversarial loss: 0.848228\n",
      "epoch 12; iter: 0; batch classifier loss: 0.329027; batch adversarial loss: 0.855566\n",
      "epoch 13; iter: 0; batch classifier loss: 0.300448; batch adversarial loss: 0.798185\n",
      "epoch 14; iter: 0; batch classifier loss: 0.374973; batch adversarial loss: 0.831262\n",
      "epoch 15; iter: 0; batch classifier loss: 0.355320; batch adversarial loss: 0.893692\n",
      "epoch 16; iter: 0; batch classifier loss: 0.373952; batch adversarial loss: 0.863592\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418837; batch adversarial loss: 0.829192\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419514; batch adversarial loss: 0.879392\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385763; batch adversarial loss: 0.915664\n",
      "epoch 20; iter: 0; batch classifier loss: 0.437310; batch adversarial loss: 0.830108\n",
      "epoch 21; iter: 0; batch classifier loss: 0.355791; batch adversarial loss: 0.813813\n",
      "epoch 22; iter: 0; batch classifier loss: 0.366364; batch adversarial loss: 0.887055\n",
      "epoch 23; iter: 0; batch classifier loss: 0.368203; batch adversarial loss: 0.782560\n",
      "epoch 24; iter: 0; batch classifier loss: 0.354847; batch adversarial loss: 0.763684\n",
      "epoch 25; iter: 0; batch classifier loss: 0.275764; batch adversarial loss: 0.828313\n",
      "epoch 26; iter: 0; batch classifier loss: 0.300762; batch adversarial loss: 0.841861\n",
      "epoch 27; iter: 0; batch classifier loss: 0.313462; batch adversarial loss: 0.803142\n",
      "epoch 28; iter: 0; batch classifier loss: 0.207487; batch adversarial loss: 0.774112\n",
      "epoch 29; iter: 0; batch classifier loss: 0.300813; batch adversarial loss: 0.730113\n",
      "epoch 30; iter: 0; batch classifier loss: 0.387841; batch adversarial loss: 0.789177\n",
      "epoch 31; iter: 0; batch classifier loss: 0.309195; batch adversarial loss: 0.747176\n",
      "epoch 32; iter: 0; batch classifier loss: 0.304581; batch adversarial loss: 0.812477\n",
      "epoch 33; iter: 0; batch classifier loss: 0.366174; batch adversarial loss: 0.758348\n",
      "epoch 34; iter: 0; batch classifier loss: 0.299628; batch adversarial loss: 0.760148\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319325; batch adversarial loss: 0.736354\n",
      "epoch 36; iter: 0; batch classifier loss: 0.320325; batch adversarial loss: 0.772994\n",
      "epoch 37; iter: 0; batch classifier loss: 0.285157; batch adversarial loss: 0.763552\n",
      "epoch 38; iter: 0; batch classifier loss: 0.326158; batch adversarial loss: 0.740184\n",
      "epoch 39; iter: 0; batch classifier loss: 0.336675; batch adversarial loss: 0.661454\n",
      "epoch 40; iter: 0; batch classifier loss: 0.435118; batch adversarial loss: 0.738396\n",
      "epoch 41; iter: 0; batch classifier loss: 0.366166; batch adversarial loss: 0.710065\n",
      "epoch 42; iter: 0; batch classifier loss: 0.347399; batch adversarial loss: 0.716930\n",
      "epoch 43; iter: 0; batch classifier loss: 0.355442; batch adversarial loss: 0.759323\n",
      "epoch 44; iter: 0; batch classifier loss: 0.388624; batch adversarial loss: 0.678163\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317226; batch adversarial loss: 0.704873\n",
      "epoch 46; iter: 0; batch classifier loss: 0.337414; batch adversarial loss: 0.671385\n",
      "epoch 47; iter: 0; batch classifier loss: 0.298926; batch adversarial loss: 0.656000\n",
      "epoch 48; iter: 0; batch classifier loss: 0.466173; batch adversarial loss: 0.709370\n",
      "epoch 49; iter: 0; batch classifier loss: 0.376917; batch adversarial loss: 0.684566\n",
      "epoch 50; iter: 0; batch classifier loss: 0.206498; batch adversarial loss: 0.725750\n",
      "epoch 51; iter: 0; batch classifier loss: 0.285396; batch adversarial loss: 0.699774\n",
      "epoch 52; iter: 0; batch classifier loss: 0.358119; batch adversarial loss: 0.688156\n",
      "epoch 53; iter: 0; batch classifier loss: 0.260437; batch adversarial loss: 0.674783\n",
      "epoch 54; iter: 0; batch classifier loss: 0.362004; batch adversarial loss: 0.674126\n",
      "epoch 55; iter: 0; batch classifier loss: 0.330446; batch adversarial loss: 0.706595\n",
      "epoch 56; iter: 0; batch classifier loss: 0.348454; batch adversarial loss: 0.662071\n",
      "epoch 57; iter: 0; batch classifier loss: 0.315585; batch adversarial loss: 0.646888\n",
      "epoch 58; iter: 0; batch classifier loss: 0.310201; batch adversarial loss: 0.647373\n",
      "epoch 59; iter: 0; batch classifier loss: 0.294423; batch adversarial loss: 0.627585\n",
      "epoch 60; iter: 0; batch classifier loss: 0.344562; batch adversarial loss: 0.646734\n",
      "epoch 61; iter: 0; batch classifier loss: 0.240587; batch adversarial loss: 0.659432\n",
      "epoch 62; iter: 0; batch classifier loss: 0.290608; batch adversarial loss: 0.640894\n",
      "epoch 63; iter: 0; batch classifier loss: 0.313626; batch adversarial loss: 0.631041\n",
      "epoch 64; iter: 0; batch classifier loss: 0.249079; batch adversarial loss: 0.670753\n",
      "epoch 65; iter: 0; batch classifier loss: 0.334030; batch adversarial loss: 0.646580\n",
      "epoch 66; iter: 0; batch classifier loss: 0.347627; batch adversarial loss: 0.632809\n",
      "epoch 67; iter: 0; batch classifier loss: 0.364729; batch adversarial loss: 0.620562\n",
      "epoch 68; iter: 0; batch classifier loss: 0.278492; batch adversarial loss: 0.629470\n",
      "epoch 69; iter: 0; batch classifier loss: 0.320856; batch adversarial loss: 0.586580\n",
      "epoch 70; iter: 0; batch classifier loss: 0.318134; batch adversarial loss: 0.607190\n",
      "epoch 71; iter: 0; batch classifier loss: 0.222772; batch adversarial loss: 0.628233\n",
      "epoch 72; iter: 0; batch classifier loss: 0.318028; batch adversarial loss: 0.653232\n",
      "epoch 73; iter: 0; batch classifier loss: 0.268392; batch adversarial loss: 0.624863\n",
      "epoch 74; iter: 0; batch classifier loss: 0.267595; batch adversarial loss: 0.655239\n",
      "epoch 75; iter: 0; batch classifier loss: 0.308523; batch adversarial loss: 0.631588\n",
      "epoch 76; iter: 0; batch classifier loss: 0.305683; batch adversarial loss: 0.633440\n",
      "epoch 77; iter: 0; batch classifier loss: 0.344138; batch adversarial loss: 0.578699\n",
      "epoch 78; iter: 0; batch classifier loss: 0.337254; batch adversarial loss: 0.605050\n",
      "epoch 79; iter: 0; batch classifier loss: 0.320277; batch adversarial loss: 0.578384\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685517; batch adversarial loss: 0.808640\n",
      "epoch 1; iter: 0; batch classifier loss: 0.639484; batch adversarial loss: 0.762239\n",
      "epoch 2; iter: 0; batch classifier loss: 0.651019; batch adversarial loss: 0.776831\n",
      "epoch 3; iter: 0; batch classifier loss: 0.571097; batch adversarial loss: 0.778152\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607680; batch adversarial loss: 0.761651\n",
      "epoch 5; iter: 0; batch classifier loss: 0.610845; batch adversarial loss: 0.766195\n",
      "epoch 6; iter: 0; batch classifier loss: 0.567326; batch adversarial loss: 0.768695\n",
      "epoch 7; iter: 0; batch classifier loss: 0.547199; batch adversarial loss: 0.770658\n",
      "epoch 8; iter: 0; batch classifier loss: 0.520994; batch adversarial loss: 0.753097\n",
      "epoch 9; iter: 0; batch classifier loss: 0.505127; batch adversarial loss: 0.763471\n",
      "epoch 10; iter: 0; batch classifier loss: 0.536285; batch adversarial loss: 0.742885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.490063; batch adversarial loss: 0.734094\n",
      "epoch 12; iter: 0; batch classifier loss: 0.502843; batch adversarial loss: 0.733855\n",
      "epoch 13; iter: 0; batch classifier loss: 0.556261; batch adversarial loss: 0.738364\n",
      "epoch 14; iter: 0; batch classifier loss: 0.461448; batch adversarial loss: 0.727815\n",
      "epoch 15; iter: 0; batch classifier loss: 0.425515; batch adversarial loss: 0.725709\n",
      "epoch 16; iter: 0; batch classifier loss: 0.443006; batch adversarial loss: 0.743378\n",
      "epoch 17; iter: 0; batch classifier loss: 0.422276; batch adversarial loss: 0.721069\n",
      "epoch 18; iter: 0; batch classifier loss: 0.469795; batch adversarial loss: 0.724849\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406941; batch adversarial loss: 0.718059\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433500; batch adversarial loss: 0.739939\n",
      "epoch 21; iter: 0; batch classifier loss: 0.424293; batch adversarial loss: 0.715498\n",
      "epoch 22; iter: 0; batch classifier loss: 0.497297; batch adversarial loss: 0.716795\n",
      "epoch 23; iter: 0; batch classifier loss: 0.392231; batch adversarial loss: 0.705660\n",
      "epoch 24; iter: 0; batch classifier loss: 0.465373; batch adversarial loss: 0.717690\n",
      "epoch 25; iter: 0; batch classifier loss: 0.454338; batch adversarial loss: 0.713699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.386749; batch adversarial loss: 0.713338\n",
      "epoch 27; iter: 0; batch classifier loss: 0.464250; batch adversarial loss: 0.694993\n",
      "epoch 28; iter: 0; batch classifier loss: 0.391827; batch adversarial loss: 0.700766\n",
      "epoch 29; iter: 0; batch classifier loss: 0.454879; batch adversarial loss: 0.711968\n",
      "epoch 30; iter: 0; batch classifier loss: 0.371590; batch adversarial loss: 0.702834\n",
      "epoch 31; iter: 0; batch classifier loss: 0.398927; batch adversarial loss: 0.707032\n",
      "epoch 32; iter: 0; batch classifier loss: 0.360606; batch adversarial loss: 0.706603\n",
      "epoch 33; iter: 0; batch classifier loss: 0.434858; batch adversarial loss: 0.700361\n",
      "epoch 34; iter: 0; batch classifier loss: 0.363663; batch adversarial loss: 0.702175\n",
      "epoch 35; iter: 0; batch classifier loss: 0.398144; batch adversarial loss: 0.705246\n",
      "epoch 36; iter: 0; batch classifier loss: 0.368766; batch adversarial loss: 0.700645\n",
      "epoch 37; iter: 0; batch classifier loss: 0.319576; batch adversarial loss: 0.698659\n",
      "epoch 38; iter: 0; batch classifier loss: 0.350459; batch adversarial loss: 0.691782\n",
      "epoch 39; iter: 0; batch classifier loss: 0.380782; batch adversarial loss: 0.688769\n",
      "epoch 40; iter: 0; batch classifier loss: 0.407292; batch adversarial loss: 0.691780\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325250; batch adversarial loss: 0.684666\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365489; batch adversarial loss: 0.685077\n",
      "epoch 43; iter: 0; batch classifier loss: 0.421746; batch adversarial loss: 0.675964\n",
      "epoch 44; iter: 0; batch classifier loss: 0.318687; batch adversarial loss: 0.697365\n",
      "epoch 45; iter: 0; batch classifier loss: 0.308868; batch adversarial loss: 0.685471\n",
      "epoch 46; iter: 0; batch classifier loss: 0.293073; batch adversarial loss: 0.683041\n",
      "epoch 47; iter: 0; batch classifier loss: 0.393166; batch adversarial loss: 0.673092\n",
      "epoch 48; iter: 0; batch classifier loss: 0.344471; batch adversarial loss: 0.672586\n",
      "epoch 49; iter: 0; batch classifier loss: 0.347290; batch adversarial loss: 0.663280\n",
      "epoch 50; iter: 0; batch classifier loss: 0.349669; batch adversarial loss: 0.674733\n",
      "epoch 51; iter: 0; batch classifier loss: 0.303996; batch adversarial loss: 0.687869\n",
      "epoch 52; iter: 0; batch classifier loss: 0.295440; batch adversarial loss: 0.679124\n",
      "epoch 53; iter: 0; batch classifier loss: 0.390214; batch adversarial loss: 0.669015\n",
      "epoch 54; iter: 0; batch classifier loss: 0.410798; batch adversarial loss: 0.673274\n",
      "epoch 55; iter: 0; batch classifier loss: 0.349715; batch adversarial loss: 0.676077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.278704; batch adversarial loss: 0.662745\n",
      "epoch 57; iter: 0; batch classifier loss: 0.316851; batch adversarial loss: 0.672812\n",
      "epoch 58; iter: 0; batch classifier loss: 0.295715; batch adversarial loss: 0.666235\n",
      "epoch 59; iter: 0; batch classifier loss: 0.322025; batch adversarial loss: 0.667239\n",
      "epoch 60; iter: 0; batch classifier loss: 0.243045; batch adversarial loss: 0.667336\n",
      "epoch 61; iter: 0; batch classifier loss: 0.393383; batch adversarial loss: 0.669914\n",
      "epoch 62; iter: 0; batch classifier loss: 0.310883; batch adversarial loss: 0.658711\n",
      "epoch 63; iter: 0; batch classifier loss: 0.313345; batch adversarial loss: 0.661267\n",
      "epoch 64; iter: 0; batch classifier loss: 0.306180; batch adversarial loss: 0.660694\n",
      "epoch 65; iter: 0; batch classifier loss: 0.290235; batch adversarial loss: 0.646791\n",
      "epoch 66; iter: 0; batch classifier loss: 0.324355; batch adversarial loss: 0.663721\n",
      "epoch 67; iter: 0; batch classifier loss: 0.311336; batch adversarial loss: 0.646924\n",
      "epoch 68; iter: 0; batch classifier loss: 0.285064; batch adversarial loss: 0.657169\n",
      "epoch 69; iter: 0; batch classifier loss: 0.332192; batch adversarial loss: 0.645861\n",
      "epoch 70; iter: 0; batch classifier loss: 0.287894; batch adversarial loss: 0.651897\n",
      "epoch 71; iter: 0; batch classifier loss: 0.304749; batch adversarial loss: 0.658457\n",
      "epoch 72; iter: 0; batch classifier loss: 0.328135; batch adversarial loss: 0.646864\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318681; batch adversarial loss: 0.649565\n",
      "epoch 74; iter: 0; batch classifier loss: 0.247730; batch adversarial loss: 0.638155\n",
      "epoch 75; iter: 0; batch classifier loss: 0.385017; batch adversarial loss: 0.652837\n",
      "epoch 76; iter: 0; batch classifier loss: 0.384513; batch adversarial loss: 0.637151\n",
      "epoch 77; iter: 0; batch classifier loss: 0.363314; batch adversarial loss: 0.634698\n",
      "epoch 78; iter: 0; batch classifier loss: 0.286338; batch adversarial loss: 0.644356\n",
      "epoch 79; iter: 0; batch classifier loss: 0.349840; batch adversarial loss: 0.648593\n",
      "epoch 0; iter: 0; batch classifier loss: 0.695633; batch adversarial loss: 0.722652\n",
      "epoch 1; iter: 0; batch classifier loss: 0.674388; batch adversarial loss: 0.748478\n",
      "epoch 2; iter: 0; batch classifier loss: 0.621698; batch adversarial loss: 0.713629\n",
      "epoch 3; iter: 0; batch classifier loss: 0.632368; batch adversarial loss: 0.745969\n",
      "epoch 4; iter: 0; batch classifier loss: 0.598224; batch adversarial loss: 0.740739\n",
      "epoch 5; iter: 0; batch classifier loss: 0.556226; batch adversarial loss: 0.731684\n",
      "epoch 6; iter: 0; batch classifier loss: 0.591658; batch adversarial loss: 0.737779\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529118; batch adversarial loss: 0.722128\n",
      "epoch 8; iter: 0; batch classifier loss: 0.506269; batch adversarial loss: 0.728600\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470055; batch adversarial loss: 0.724551\n",
      "epoch 10; iter: 0; batch classifier loss: 0.507387; batch adversarial loss: 0.720376\n",
      "epoch 11; iter: 0; batch classifier loss: 0.460641; batch adversarial loss: 0.716015\n",
      "epoch 12; iter: 0; batch classifier loss: 0.428245; batch adversarial loss: 0.721591\n",
      "epoch 13; iter: 0; batch classifier loss: 0.418628; batch adversarial loss: 0.722155\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459054; batch adversarial loss: 0.717742\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390476; batch adversarial loss: 0.708092\n",
      "epoch 16; iter: 0; batch classifier loss: 0.429601; batch adversarial loss: 0.714704\n",
      "epoch 17; iter: 0; batch classifier loss: 0.439443; batch adversarial loss: 0.716398\n",
      "epoch 18; iter: 0; batch classifier loss: 0.410461; batch adversarial loss: 0.704141\n",
      "epoch 19; iter: 0; batch classifier loss: 0.390190; batch adversarial loss: 0.702545\n",
      "epoch 20; iter: 0; batch classifier loss: 0.433810; batch adversarial loss: 0.700821\n",
      "epoch 21; iter: 0; batch classifier loss: 0.366226; batch adversarial loss: 0.686193\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446571; batch adversarial loss: 0.710129\n",
      "epoch 23; iter: 0; batch classifier loss: 0.431309; batch adversarial loss: 0.685288\n",
      "epoch 24; iter: 0; batch classifier loss: 0.362170; batch adversarial loss: 0.700063\n",
      "epoch 25; iter: 0; batch classifier loss: 0.373303; batch adversarial loss: 0.694361\n",
      "epoch 26; iter: 0; batch classifier loss: 0.450224; batch adversarial loss: 0.692731\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424134; batch adversarial loss: 0.683537\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387533; batch adversarial loss: 0.687990\n",
      "epoch 29; iter: 0; batch classifier loss: 0.320040; batch adversarial loss: 0.691076\n",
      "epoch 30; iter: 0; batch classifier loss: 0.347038; batch adversarial loss: 0.686979\n",
      "epoch 31; iter: 0; batch classifier loss: 0.473030; batch adversarial loss: 0.671922\n",
      "epoch 32; iter: 0; batch classifier loss: 0.407375; batch adversarial loss: 0.685208\n",
      "epoch 33; iter: 0; batch classifier loss: 0.380178; batch adversarial loss: 0.680057\n",
      "epoch 34; iter: 0; batch classifier loss: 0.412426; batch adversarial loss: 0.685706\n",
      "epoch 35; iter: 0; batch classifier loss: 0.420759; batch adversarial loss: 0.684912\n",
      "epoch 36; iter: 0; batch classifier loss: 0.353423; batch adversarial loss: 0.678532\n",
      "epoch 37; iter: 0; batch classifier loss: 0.357549; batch adversarial loss: 0.678395\n",
      "epoch 38; iter: 0; batch classifier loss: 0.341948; batch adversarial loss: 0.675706\n",
      "epoch 39; iter: 0; batch classifier loss: 0.255902; batch adversarial loss: 0.665384\n",
      "epoch 40; iter: 0; batch classifier loss: 0.278216; batch adversarial loss: 0.672829\n",
      "epoch 41; iter: 0; batch classifier loss: 0.321518; batch adversarial loss: 0.669936\n",
      "epoch 42; iter: 0; batch classifier loss: 0.368376; batch adversarial loss: 0.674817\n",
      "epoch 43; iter: 0; batch classifier loss: 0.360961; batch adversarial loss: 0.664814\n",
      "epoch 44; iter: 0; batch classifier loss: 0.330147; batch adversarial loss: 0.676286\n",
      "epoch 45; iter: 0; batch classifier loss: 0.294247; batch adversarial loss: 0.660207\n",
      "epoch 46; iter: 0; batch classifier loss: 0.266265; batch adversarial loss: 0.663093\n",
      "epoch 47; iter: 0; batch classifier loss: 0.399992; batch adversarial loss: 0.663771\n",
      "epoch 48; iter: 0; batch classifier loss: 0.372818; batch adversarial loss: 0.653118\n",
      "epoch 49; iter: 0; batch classifier loss: 0.264041; batch adversarial loss: 0.656187\n",
      "epoch 50; iter: 0; batch classifier loss: 0.332338; batch adversarial loss: 0.653181\n",
      "epoch 51; iter: 0; batch classifier loss: 0.343390; batch adversarial loss: 0.642213\n",
      "epoch 52; iter: 0; batch classifier loss: 0.270339; batch adversarial loss: 0.654054\n",
      "epoch 53; iter: 0; batch classifier loss: 0.389125; batch adversarial loss: 0.647518\n",
      "epoch 54; iter: 0; batch classifier loss: 0.275223; batch adversarial loss: 0.642386\n",
      "epoch 55; iter: 0; batch classifier loss: 0.283856; batch adversarial loss: 0.659477\n",
      "epoch 56; iter: 0; batch classifier loss: 0.270518; batch adversarial loss: 0.657514\n",
      "epoch 57; iter: 0; batch classifier loss: 0.290223; batch adversarial loss: 0.641076\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328892; batch adversarial loss: 0.641558\n",
      "epoch 59; iter: 0; batch classifier loss: 0.287998; batch adversarial loss: 0.638342\n",
      "epoch 60; iter: 0; batch classifier loss: 0.358961; batch adversarial loss: 0.633661\n",
      "epoch 61; iter: 0; batch classifier loss: 0.371733; batch adversarial loss: 0.651997\n",
      "epoch 62; iter: 0; batch classifier loss: 0.304759; batch adversarial loss: 0.642227\n",
      "epoch 63; iter: 0; batch classifier loss: 0.352939; batch adversarial loss: 0.633628\n",
      "epoch 64; iter: 0; batch classifier loss: 0.348038; batch adversarial loss: 0.643143\n",
      "epoch 65; iter: 0; batch classifier loss: 0.360387; batch adversarial loss: 0.633423\n",
      "epoch 66; iter: 0; batch classifier loss: 0.321545; batch adversarial loss: 0.648154\n",
      "epoch 67; iter: 0; batch classifier loss: 0.251104; batch adversarial loss: 0.637795\n",
      "epoch 68; iter: 0; batch classifier loss: 0.260722; batch adversarial loss: 0.621128\n",
      "epoch 69; iter: 0; batch classifier loss: 0.360901; batch adversarial loss: 0.643137\n",
      "epoch 70; iter: 0; batch classifier loss: 0.323817; batch adversarial loss: 0.622790\n",
      "epoch 71; iter: 0; batch classifier loss: 0.366188; batch adversarial loss: 0.618203\n",
      "epoch 72; iter: 0; batch classifier loss: 0.269149; batch adversarial loss: 0.633564\n",
      "epoch 73; iter: 0; batch classifier loss: 0.282775; batch adversarial loss: 0.625018\n",
      "epoch 74; iter: 0; batch classifier loss: 0.222298; batch adversarial loss: 0.630710\n",
      "epoch 75; iter: 0; batch classifier loss: 0.285544; batch adversarial loss: 0.627280\n",
      "epoch 76; iter: 0; batch classifier loss: 0.344388; batch adversarial loss: 0.639595\n",
      "epoch 77; iter: 0; batch classifier loss: 0.256335; batch adversarial loss: 0.600463\n",
      "epoch 78; iter: 0; batch classifier loss: 0.292048; batch adversarial loss: 0.614373\n",
      "epoch 79; iter: 0; batch classifier loss: 0.281855; batch adversarial loss: 0.633665\n",
      "epoch 0; iter: 0; batch classifier loss: 0.731102; batch adversarial loss: 0.667601\n",
      "epoch 1; iter: 0; batch classifier loss: 0.699058; batch adversarial loss: 0.638027\n",
      "epoch 2; iter: 0; batch classifier loss: 0.672310; batch adversarial loss: 0.670735\n",
      "epoch 3; iter: 0; batch classifier loss: 0.637566; batch adversarial loss: 0.655789\n",
      "epoch 4; iter: 0; batch classifier loss: 0.532619; batch adversarial loss: 0.645641\n",
      "epoch 5; iter: 0; batch classifier loss: 0.565380; batch adversarial loss: 0.710498\n",
      "epoch 6; iter: 0; batch classifier loss: 0.423210; batch adversarial loss: 0.635526\n",
      "epoch 7; iter: 0; batch classifier loss: 0.432395; batch adversarial loss: 0.731336\n",
      "epoch 8; iter: 0; batch classifier loss: 0.481696; batch adversarial loss: 0.675508\n",
      "epoch 9; iter: 0; batch classifier loss: 0.462599; batch adversarial loss: 0.640152\n",
      "epoch 10; iter: 0; batch classifier loss: 0.501931; batch adversarial loss: 0.712652\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414471; batch adversarial loss: 0.601473\n",
      "epoch 12; iter: 0; batch classifier loss: 0.566903; batch adversarial loss: 0.664738\n",
      "epoch 13; iter: 0; batch classifier loss: 0.555878; batch adversarial loss: 0.592076\n",
      "epoch 14; iter: 0; batch classifier loss: 0.359736; batch adversarial loss: 0.660615\n",
      "epoch 15; iter: 0; batch classifier loss: 0.390982; batch adversarial loss: 0.539855\n",
      "epoch 16; iter: 0; batch classifier loss: 0.356078; batch adversarial loss: 0.678545\n",
      "epoch 17; iter: 0; batch classifier loss: 0.436693; batch adversarial loss: 0.704128\n",
      "epoch 18; iter: 0; batch classifier loss: 0.434431; batch adversarial loss: 0.667668\n",
      "epoch 19; iter: 0; batch classifier loss: 0.325623; batch adversarial loss: 0.658649\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361382; batch adversarial loss: 0.620100\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336997; batch adversarial loss: 0.656305\n",
      "epoch 22; iter: 0; batch classifier loss: 0.291810; batch adversarial loss: 0.657947\n",
      "epoch 23; iter: 0; batch classifier loss: 0.292486; batch adversarial loss: 0.646111\n",
      "epoch 24; iter: 0; batch classifier loss: 0.379238; batch adversarial loss: 0.656567\n",
      "epoch 25; iter: 0; batch classifier loss: 0.303753; batch adversarial loss: 0.588140\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393079; batch adversarial loss: 0.567714\n",
      "epoch 27; iter: 0; batch classifier loss: 0.329184; batch adversarial loss: 0.649217\n",
      "epoch 28; iter: 0; batch classifier loss: 0.314762; batch adversarial loss: 0.643739\n",
      "epoch 29; iter: 0; batch classifier loss: 0.297307; batch adversarial loss: 0.679430\n",
      "epoch 30; iter: 0; batch classifier loss: 0.380203; batch adversarial loss: 0.626229\n",
      "epoch 31; iter: 0; batch classifier loss: 0.296916; batch adversarial loss: 0.622202\n",
      "epoch 32; iter: 0; batch classifier loss: 0.376669; batch adversarial loss: 0.611273\n",
      "epoch 33; iter: 0; batch classifier loss: 0.195437; batch adversarial loss: 0.544906\n",
      "epoch 34; iter: 0; batch classifier loss: 0.380010; batch adversarial loss: 0.612583\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365338; batch adversarial loss: 0.589796\n",
      "epoch 36; iter: 0; batch classifier loss: 0.381351; batch adversarial loss: 0.686457\n",
      "epoch 37; iter: 0; batch classifier loss: 0.403656; batch adversarial loss: 0.529937\n",
      "epoch 38; iter: 0; batch classifier loss: 0.284299; batch adversarial loss: 0.523260\n",
      "epoch 39; iter: 0; batch classifier loss: 0.395851; batch adversarial loss: 0.679949\n",
      "epoch 0; iter: 0; batch classifier loss: 0.766396; batch adversarial loss: 0.684307\n",
      "epoch 1; iter: 0; batch classifier loss: 0.741156; batch adversarial loss: 0.666873\n",
      "epoch 2; iter: 0; batch classifier loss: 0.631768; batch adversarial loss: 0.672118\n",
      "epoch 3; iter: 0; batch classifier loss: 0.612066; batch adversarial loss: 0.655803\n",
      "epoch 4; iter: 0; batch classifier loss: 0.625175; batch adversarial loss: 0.658165\n",
      "epoch 5; iter: 0; batch classifier loss: 0.494756; batch adversarial loss: 0.661932\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546543; batch adversarial loss: 0.672286\n",
      "epoch 7; iter: 0; batch classifier loss: 0.529807; batch adversarial loss: 0.649885\n",
      "epoch 8; iter: 0; batch classifier loss: 0.462990; batch adversarial loss: 0.651072\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501230; batch adversarial loss: 0.652098\n",
      "epoch 10; iter: 0; batch classifier loss: 0.462081; batch adversarial loss: 0.642465\n",
      "epoch 11; iter: 0; batch classifier loss: 0.534007; batch adversarial loss: 0.618871\n",
      "epoch 12; iter: 0; batch classifier loss: 0.407204; batch adversarial loss: 0.648876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.512636; batch adversarial loss: 0.634929\n",
      "epoch 14; iter: 0; batch classifier loss: 0.444528; batch adversarial loss: 0.651203\n",
      "epoch 15; iter: 0; batch classifier loss: 0.366081; batch adversarial loss: 0.641377\n",
      "epoch 16; iter: 0; batch classifier loss: 0.331070; batch adversarial loss: 0.631093\n",
      "epoch 17; iter: 0; batch classifier loss: 0.495812; batch adversarial loss: 0.635792\n",
      "epoch 18; iter: 0; batch classifier loss: 0.438051; batch adversarial loss: 0.626847\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365099; batch adversarial loss: 0.623347\n",
      "epoch 20; iter: 0; batch classifier loss: 0.195856; batch adversarial loss: 0.615559\n",
      "epoch 21; iter: 0; batch classifier loss: 0.421880; batch adversarial loss: 0.584811\n",
      "epoch 22; iter: 0; batch classifier loss: 0.399130; batch adversarial loss: 0.635862\n",
      "epoch 23; iter: 0; batch classifier loss: 0.411069; batch adversarial loss: 0.618603\n",
      "epoch 24; iter: 0; batch classifier loss: 0.298200; batch adversarial loss: 0.614478\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428782; batch adversarial loss: 0.675625\n",
      "epoch 26; iter: 0; batch classifier loss: 0.495573; batch adversarial loss: 0.581371\n",
      "epoch 27; iter: 0; batch classifier loss: 0.293011; batch adversarial loss: 0.609671\n",
      "epoch 28; iter: 0; batch classifier loss: 0.397224; batch adversarial loss: 0.656877\n",
      "epoch 29; iter: 0; batch classifier loss: 0.292347; batch adversarial loss: 0.625115\n",
      "epoch 30; iter: 0; batch classifier loss: 0.318127; batch adversarial loss: 0.602950\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431164; batch adversarial loss: 0.590369\n",
      "epoch 32; iter: 0; batch classifier loss: 0.291071; batch adversarial loss: 0.608575\n",
      "epoch 33; iter: 0; batch classifier loss: 0.319612; batch adversarial loss: 0.573292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.341525; batch adversarial loss: 0.597639\n",
      "epoch 35; iter: 0; batch classifier loss: 0.305442; batch adversarial loss: 0.560996\n",
      "epoch 36; iter: 0; batch classifier loss: 0.336626; batch adversarial loss: 0.596048\n",
      "epoch 37; iter: 0; batch classifier loss: 0.440233; batch adversarial loss: 0.601422\n",
      "epoch 38; iter: 0; batch classifier loss: 0.453173; batch adversarial loss: 0.585139\n",
      "epoch 39; iter: 0; batch classifier loss: 0.310815; batch adversarial loss: 0.600164\n",
      "epoch 0; iter: 0; batch classifier loss: 0.772271; batch adversarial loss: 0.803264\n",
      "epoch 1; iter: 0; batch classifier loss: 0.780080; batch adversarial loss: 0.807427\n",
      "epoch 2; iter: 0; batch classifier loss: 0.687838; batch adversarial loss: 0.766219\n",
      "epoch 3; iter: 0; batch classifier loss: 0.696666; batch adversarial loss: 0.791376\n",
      "epoch 4; iter: 0; batch classifier loss: 0.675431; batch adversarial loss: 0.783884\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633037; batch adversarial loss: 0.774755\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617566; batch adversarial loss: 0.774131\n",
      "epoch 7; iter: 0; batch classifier loss: 0.596760; batch adversarial loss: 0.782013\n",
      "epoch 8; iter: 0; batch classifier loss: 0.560197; batch adversarial loss: 0.777785\n",
      "epoch 9; iter: 0; batch classifier loss: 0.576533; batch adversarial loss: 0.778303\n",
      "epoch 10; iter: 0; batch classifier loss: 0.591108; batch adversarial loss: 0.772728\n",
      "epoch 11; iter: 0; batch classifier loss: 0.537078; batch adversarial loss: 0.796765\n",
      "epoch 12; iter: 0; batch classifier loss: 0.490791; batch adversarial loss: 0.765637\n",
      "epoch 13; iter: 0; batch classifier loss: 0.477155; batch adversarial loss: 0.753723\n",
      "epoch 14; iter: 0; batch classifier loss: 0.568003; batch adversarial loss: 0.771672\n",
      "epoch 15; iter: 0; batch classifier loss: 0.520681; batch adversarial loss: 0.785056\n",
      "epoch 16; iter: 0; batch classifier loss: 0.422563; batch adversarial loss: 0.785834\n",
      "epoch 17; iter: 0; batch classifier loss: 0.449825; batch adversarial loss: 0.788687\n",
      "epoch 18; iter: 0; batch classifier loss: 0.513587; batch adversarial loss: 0.756588\n",
      "epoch 19; iter: 0; batch classifier loss: 0.382679; batch adversarial loss: 0.761065\n",
      "epoch 20; iter: 0; batch classifier loss: 0.480119; batch adversarial loss: 0.756909\n",
      "epoch 21; iter: 0; batch classifier loss: 0.454303; batch adversarial loss: 0.752259\n",
      "epoch 22; iter: 0; batch classifier loss: 0.451132; batch adversarial loss: 0.759263\n",
      "epoch 23; iter: 0; batch classifier loss: 0.430583; batch adversarial loss: 0.756779\n",
      "epoch 24; iter: 0; batch classifier loss: 0.399358; batch adversarial loss: 0.740492\n",
      "epoch 25; iter: 0; batch classifier loss: 0.417174; batch adversarial loss: 0.751771\n",
      "epoch 26; iter: 0; batch classifier loss: 0.404866; batch adversarial loss: 0.746080\n",
      "epoch 27; iter: 0; batch classifier loss: 0.371250; batch adversarial loss: 0.748680\n",
      "epoch 28; iter: 0; batch classifier loss: 0.424895; batch adversarial loss: 0.731753\n",
      "epoch 29; iter: 0; batch classifier loss: 0.513900; batch adversarial loss: 0.731896\n",
      "epoch 30; iter: 0; batch classifier loss: 0.384645; batch adversarial loss: 0.750157\n",
      "epoch 31; iter: 0; batch classifier loss: 0.415355; batch adversarial loss: 0.721127\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386743; batch adversarial loss: 0.726207\n",
      "epoch 33; iter: 0; batch classifier loss: 0.412500; batch adversarial loss: 0.728236\n",
      "epoch 34; iter: 0; batch classifier loss: 0.352549; batch adversarial loss: 0.718289\n",
      "epoch 35; iter: 0; batch classifier loss: 0.370918; batch adversarial loss: 0.726073\n",
      "epoch 36; iter: 0; batch classifier loss: 0.358143; batch adversarial loss: 0.725262\n",
      "epoch 37; iter: 0; batch classifier loss: 0.363293; batch adversarial loss: 0.701897\n",
      "epoch 38; iter: 0; batch classifier loss: 0.419965; batch adversarial loss: 0.732853\n",
      "epoch 39; iter: 0; batch classifier loss: 0.321527; batch adversarial loss: 0.737131\n",
      "epoch 0; iter: 0; batch classifier loss: 0.715251; batch adversarial loss: 0.757030\n",
      "epoch 1; iter: 0; batch classifier loss: 0.735651; batch adversarial loss: 0.777803\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620971; batch adversarial loss: 0.780298\n",
      "epoch 3; iter: 0; batch classifier loss: 0.672361; batch adversarial loss: 0.782417\n",
      "epoch 4; iter: 0; batch classifier loss: 0.633380; batch adversarial loss: 0.752011\n",
      "epoch 5; iter: 0; batch classifier loss: 0.595633; batch adversarial loss: 0.792304\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547206; batch adversarial loss: 0.771091\n",
      "epoch 7; iter: 0; batch classifier loss: 0.545326; batch adversarial loss: 0.758273\n",
      "epoch 8; iter: 0; batch classifier loss: 0.535940; batch adversarial loss: 0.750002\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544951; batch adversarial loss: 0.761054\n",
      "epoch 10; iter: 0; batch classifier loss: 0.535979; batch adversarial loss: 0.758027\n",
      "epoch 11; iter: 0; batch classifier loss: 0.510402; batch adversarial loss: 0.772493\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492948; batch adversarial loss: 0.727839\n",
      "epoch 13; iter: 0; batch classifier loss: 0.466763; batch adversarial loss: 0.752429\n",
      "epoch 14; iter: 0; batch classifier loss: 0.509260; batch adversarial loss: 0.744621\n",
      "epoch 15; iter: 0; batch classifier loss: 0.481606; batch adversarial loss: 0.724771\n",
      "epoch 16; iter: 0; batch classifier loss: 0.514468; batch adversarial loss: 0.757143\n",
      "epoch 17; iter: 0; batch classifier loss: 0.418805; batch adversarial loss: 0.757098\n",
      "epoch 18; iter: 0; batch classifier loss: 0.499202; batch adversarial loss: 0.732971\n",
      "epoch 19; iter: 0; batch classifier loss: 0.485863; batch adversarial loss: 0.750752\n",
      "epoch 20; iter: 0; batch classifier loss: 0.471660; batch adversarial loss: 0.761384\n",
      "epoch 21; iter: 0; batch classifier loss: 0.399217; batch adversarial loss: 0.757464\n",
      "epoch 22; iter: 0; batch classifier loss: 0.421259; batch adversarial loss: 0.742186\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422640; batch adversarial loss: 0.730473\n",
      "epoch 24; iter: 0; batch classifier loss: 0.392599; batch adversarial loss: 0.776869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.422542; batch adversarial loss: 0.739136\n",
      "epoch 26; iter: 0; batch classifier loss: 0.368733; batch adversarial loss: 0.751321\n",
      "epoch 27; iter: 0; batch classifier loss: 0.406628; batch adversarial loss: 0.737794\n",
      "epoch 28; iter: 0; batch classifier loss: 0.390125; batch adversarial loss: 0.774174\n",
      "epoch 29; iter: 0; batch classifier loss: 0.439147; batch adversarial loss: 0.737963\n",
      "epoch 30; iter: 0; batch classifier loss: 0.400507; batch adversarial loss: 0.731995\n",
      "epoch 31; iter: 0; batch classifier loss: 0.311178; batch adversarial loss: 0.760608\n",
      "epoch 32; iter: 0; batch classifier loss: 0.436721; batch adversarial loss: 0.739352\n",
      "epoch 33; iter: 0; batch classifier loss: 0.361784; batch adversarial loss: 0.738852\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404882; batch adversarial loss: 0.743827\n",
      "epoch 35; iter: 0; batch classifier loss: 0.410480; batch adversarial loss: 0.765635\n",
      "epoch 36; iter: 0; batch classifier loss: 0.365426; batch adversarial loss: 0.755577\n",
      "epoch 37; iter: 0; batch classifier loss: 0.438257; batch adversarial loss: 0.734034\n",
      "epoch 38; iter: 0; batch classifier loss: 0.407406; batch adversarial loss: 0.744647\n",
      "epoch 39; iter: 0; batch classifier loss: 0.291152; batch adversarial loss: 0.738241\n",
      "epoch 0; iter: 0; batch classifier loss: 0.790629; batch adversarial loss: 0.624870\n",
      "epoch 1; iter: 0; batch classifier loss: 0.712243; batch adversarial loss: 0.650910\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686917; batch adversarial loss: 0.658405\n",
      "epoch 3; iter: 0; batch classifier loss: 0.607681; batch adversarial loss: 0.638006\n",
      "epoch 4; iter: 0; batch classifier loss: 0.607239; batch adversarial loss: 0.627596\n",
      "epoch 5; iter: 0; batch classifier loss: 0.569745; batch adversarial loss: 0.616722\n",
      "epoch 6; iter: 0; batch classifier loss: 0.532336; batch adversarial loss: 0.602334\n",
      "epoch 7; iter: 0; batch classifier loss: 0.602003; batch adversarial loss: 0.636232\n",
      "epoch 8; iter: 0; batch classifier loss: 0.476166; batch adversarial loss: 0.625957\n",
      "epoch 9; iter: 0; batch classifier loss: 0.420114; batch adversarial loss: 0.623604\n",
      "epoch 10; iter: 0; batch classifier loss: 0.476407; batch adversarial loss: 0.598010\n",
      "epoch 11; iter: 0; batch classifier loss: 0.429162; batch adversarial loss: 0.615632\n",
      "epoch 12; iter: 0; batch classifier loss: 0.385178; batch adversarial loss: 0.633574\n",
      "epoch 13; iter: 0; batch classifier loss: 0.420859; batch adversarial loss: 0.627595\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459863; batch adversarial loss: 0.612266\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344155; batch adversarial loss: 0.587222\n",
      "epoch 16; iter: 0; batch classifier loss: 0.386432; batch adversarial loss: 0.647121\n",
      "epoch 17; iter: 0; batch classifier loss: 0.321176; batch adversarial loss: 0.578840\n",
      "epoch 18; iter: 0; batch classifier loss: 0.383740; batch adversarial loss: 0.637280\n",
      "epoch 19; iter: 0; batch classifier loss: 0.311651; batch adversarial loss: 0.612377\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387018; batch adversarial loss: 0.625561\n",
      "epoch 21; iter: 0; batch classifier loss: 0.402866; batch adversarial loss: 0.584265\n",
      "epoch 22; iter: 0; batch classifier loss: 0.417000; batch adversarial loss: 0.618242\n",
      "epoch 23; iter: 0; batch classifier loss: 0.409142; batch adversarial loss: 0.615815\n",
      "epoch 24; iter: 0; batch classifier loss: 0.329145; batch adversarial loss: 0.574350\n",
      "epoch 25; iter: 0; batch classifier loss: 0.357130; batch adversarial loss: 0.580067\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334856; batch adversarial loss: 0.611699\n",
      "epoch 27; iter: 0; batch classifier loss: 0.352256; batch adversarial loss: 0.583291\n",
      "epoch 28; iter: 0; batch classifier loss: 0.286887; batch adversarial loss: 0.621733\n",
      "epoch 29; iter: 0; batch classifier loss: 0.326944; batch adversarial loss: 0.586083\n",
      "epoch 30; iter: 0; batch classifier loss: 0.357702; batch adversarial loss: 0.587921\n",
      "epoch 31; iter: 0; batch classifier loss: 0.233018; batch adversarial loss: 0.592051\n",
      "epoch 32; iter: 0; batch classifier loss: 0.301676; batch adversarial loss: 0.631383\n",
      "epoch 33; iter: 0; batch classifier loss: 0.336465; batch adversarial loss: 0.576848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.260766; batch adversarial loss: 0.549004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.303682; batch adversarial loss: 0.640851\n",
      "epoch 36; iter: 0; batch classifier loss: 0.369504; batch adversarial loss: 0.662000\n",
      "epoch 37; iter: 0; batch classifier loss: 0.249218; batch adversarial loss: 0.557485\n",
      "epoch 38; iter: 0; batch classifier loss: 0.452994; batch adversarial loss: 0.672096\n",
      "epoch 39; iter: 0; batch classifier loss: 0.328974; batch adversarial loss: 0.695490\n",
      "epoch 40; iter: 0; batch classifier loss: 0.370472; batch adversarial loss: 0.596352\n",
      "epoch 41; iter: 0; batch classifier loss: 0.318718; batch adversarial loss: 0.544825\n",
      "epoch 42; iter: 0; batch classifier loss: 0.455461; batch adversarial loss: 0.512161\n",
      "epoch 43; iter: 0; batch classifier loss: 0.329532; batch adversarial loss: 0.671350\n",
      "epoch 44; iter: 0; batch classifier loss: 0.314771; batch adversarial loss: 0.590844\n",
      "epoch 45; iter: 0; batch classifier loss: 0.390523; batch adversarial loss: 0.579351\n",
      "epoch 46; iter: 0; batch classifier loss: 0.314801; batch adversarial loss: 0.558436\n",
      "epoch 47; iter: 0; batch classifier loss: 0.357514; batch adversarial loss: 0.601064\n",
      "epoch 48; iter: 0; batch classifier loss: 0.376792; batch adversarial loss: 0.604962\n",
      "epoch 49; iter: 0; batch classifier loss: 0.253296; batch adversarial loss: 0.623551\n",
      "epoch 50; iter: 0; batch classifier loss: 0.362874; batch adversarial loss: 0.615261\n",
      "epoch 51; iter: 0; batch classifier loss: 0.248378; batch adversarial loss: 0.595404\n",
      "epoch 52; iter: 0; batch classifier loss: 0.260262; batch adversarial loss: 0.524075\n",
      "epoch 53; iter: 0; batch classifier loss: 0.379890; batch adversarial loss: 0.597189\n",
      "epoch 54; iter: 0; batch classifier loss: 0.239582; batch adversarial loss: 0.626659\n",
      "epoch 55; iter: 0; batch classifier loss: 0.318431; batch adversarial loss: 0.570324\n",
      "epoch 56; iter: 0; batch classifier loss: 0.299728; batch adversarial loss: 0.534168\n",
      "epoch 57; iter: 0; batch classifier loss: 0.344728; batch adversarial loss: 0.628317\n",
      "epoch 58; iter: 0; batch classifier loss: 0.264073; batch adversarial loss: 0.515104\n",
      "epoch 59; iter: 0; batch classifier loss: 0.339012; batch adversarial loss: 0.580735\n",
      "epoch 0; iter: 0; batch classifier loss: 0.685243; batch adversarial loss: 0.643596\n",
      "epoch 1; iter: 0; batch classifier loss: 0.628788; batch adversarial loss: 0.664403\n",
      "epoch 2; iter: 0; batch classifier loss: 0.591298; batch adversarial loss: 0.660694\n",
      "epoch 3; iter: 0; batch classifier loss: 0.522116; batch adversarial loss: 0.640164\n",
      "epoch 4; iter: 0; batch classifier loss: 0.548541; batch adversarial loss: 0.697693\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524975; batch adversarial loss: 0.638449\n",
      "epoch 6; iter: 0; batch classifier loss: 0.476261; batch adversarial loss: 0.666533\n",
      "epoch 7; iter: 0; batch classifier loss: 0.462916; batch adversarial loss: 0.660514\n",
      "epoch 8; iter: 0; batch classifier loss: 0.421820; batch adversarial loss: 0.639446\n",
      "epoch 9; iter: 0; batch classifier loss: 0.349809; batch adversarial loss: 0.625090\n",
      "epoch 10; iter: 0; batch classifier loss: 0.338873; batch adversarial loss: 0.654130\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413779; batch adversarial loss: 0.644855\n",
      "epoch 12; iter: 0; batch classifier loss: 0.327250; batch adversarial loss: 0.676223\n",
      "epoch 13; iter: 0; batch classifier loss: 0.484217; batch adversarial loss: 0.655398\n",
      "epoch 14; iter: 0; batch classifier loss: 0.330221; batch adversarial loss: 0.631123\n",
      "epoch 15; iter: 0; batch classifier loss: 0.377996; batch adversarial loss: 0.678708\n",
      "epoch 16; iter: 0; batch classifier loss: 0.281937; batch adversarial loss: 0.670723\n",
      "epoch 17; iter: 0; batch classifier loss: 0.430165; batch adversarial loss: 0.643784\n",
      "epoch 18; iter: 0; batch classifier loss: 0.305056; batch adversarial loss: 0.652736\n",
      "epoch 19; iter: 0; batch classifier loss: 0.327795; batch adversarial loss: 0.638111\n",
      "epoch 20; iter: 0; batch classifier loss: 0.362382; batch adversarial loss: 0.648590\n",
      "epoch 21; iter: 0; batch classifier loss: 0.380868; batch adversarial loss: 0.644895\n",
      "epoch 22; iter: 0; batch classifier loss: 0.303233; batch adversarial loss: 0.693416\n",
      "epoch 23; iter: 0; batch classifier loss: 0.479017; batch adversarial loss: 0.614756\n",
      "epoch 24; iter: 0; batch classifier loss: 0.256319; batch adversarial loss: 0.619031\n",
      "epoch 25; iter: 0; batch classifier loss: 0.304808; batch adversarial loss: 0.703052\n",
      "epoch 26; iter: 0; batch classifier loss: 0.465511; batch adversarial loss: 0.623738\n",
      "epoch 27; iter: 0; batch classifier loss: 0.390517; batch adversarial loss: 0.626737\n",
      "epoch 28; iter: 0; batch classifier loss: 0.480405; batch adversarial loss: 0.610248\n",
      "epoch 29; iter: 0; batch classifier loss: 0.307606; batch adversarial loss: 0.613134\n",
      "epoch 30; iter: 0; batch classifier loss: 0.331694; batch adversarial loss: 0.646617\n",
      "epoch 31; iter: 0; batch classifier loss: 0.331021; batch adversarial loss: 0.598394\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415164; batch adversarial loss: 0.690280\n",
      "epoch 33; iter: 0; batch classifier loss: 0.185767; batch adversarial loss: 0.634292\n",
      "epoch 34; iter: 0; batch classifier loss: 0.318366; batch adversarial loss: 0.578044\n",
      "epoch 35; iter: 0; batch classifier loss: 0.319765; batch adversarial loss: 0.676776\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282213; batch adversarial loss: 0.582155\n",
      "epoch 37; iter: 0; batch classifier loss: 0.352724; batch adversarial loss: 0.588364\n",
      "epoch 38; iter: 0; batch classifier loss: 0.225215; batch adversarial loss: 0.591870\n",
      "epoch 39; iter: 0; batch classifier loss: 0.181451; batch adversarial loss: 0.623190\n",
      "epoch 40; iter: 0; batch classifier loss: 0.271773; batch adversarial loss: 0.570984\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373366; batch adversarial loss: 0.638017\n",
      "epoch 42; iter: 0; batch classifier loss: 0.390111; batch adversarial loss: 0.615779\n",
      "epoch 43; iter: 0; batch classifier loss: 0.239607; batch adversarial loss: 0.615949\n",
      "epoch 44; iter: 0; batch classifier loss: 0.273917; batch adversarial loss: 0.650977\n",
      "epoch 45; iter: 0; batch classifier loss: 0.238826; batch adversarial loss: 0.573915\n",
      "epoch 46; iter: 0; batch classifier loss: 0.281736; batch adversarial loss: 0.566139\n",
      "epoch 47; iter: 0; batch classifier loss: 0.348045; batch adversarial loss: 0.547314\n",
      "epoch 48; iter: 0; batch classifier loss: 0.260340; batch adversarial loss: 0.550123\n",
      "epoch 49; iter: 0; batch classifier loss: 0.270320; batch adversarial loss: 0.622322\n",
      "epoch 50; iter: 0; batch classifier loss: 0.215449; batch adversarial loss: 0.611416\n",
      "epoch 51; iter: 0; batch classifier loss: 0.294495; batch adversarial loss: 0.626094\n",
      "epoch 52; iter: 0; batch classifier loss: 0.439868; batch adversarial loss: 0.574546\n",
      "epoch 53; iter: 0; batch classifier loss: 0.290219; batch adversarial loss: 0.633005\n",
      "epoch 54; iter: 0; batch classifier loss: 0.351767; batch adversarial loss: 0.572932\n",
      "epoch 55; iter: 0; batch classifier loss: 0.279080; batch adversarial loss: 0.620064\n",
      "epoch 56; iter: 0; batch classifier loss: 0.233622; batch adversarial loss: 0.569008\n",
      "epoch 57; iter: 0; batch classifier loss: 0.242594; batch adversarial loss: 0.540667\n",
      "epoch 58; iter: 0; batch classifier loss: 0.240074; batch adversarial loss: 0.574988\n",
      "epoch 59; iter: 0; batch classifier loss: 0.253325; batch adversarial loss: 0.634717\n",
      "epoch 0; iter: 0; batch classifier loss: 0.793250; batch adversarial loss: 0.731403\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691392; batch adversarial loss: 0.753038\n",
      "epoch 2; iter: 0; batch classifier loss: 0.746965; batch adversarial loss: 0.736592\n",
      "epoch 3; iter: 0; batch classifier loss: 0.784208; batch adversarial loss: 0.721188\n",
      "epoch 4; iter: 0; batch classifier loss: 0.751397; batch adversarial loss: 0.721713\n",
      "epoch 5; iter: 0; batch classifier loss: 0.700912; batch adversarial loss: 0.749616\n",
      "epoch 6; iter: 0; batch classifier loss: 0.680527; batch adversarial loss: 0.707498\n",
      "epoch 7; iter: 0; batch classifier loss: 0.609984; batch adversarial loss: 0.725462\n",
      "epoch 8; iter: 0; batch classifier loss: 0.569145; batch adversarial loss: 0.735106\n",
      "epoch 9; iter: 0; batch classifier loss: 0.577832; batch adversarial loss: 0.710997\n",
      "epoch 10; iter: 0; batch classifier loss: 0.551284; batch adversarial loss: 0.721288\n",
      "epoch 11; iter: 0; batch classifier loss: 0.543878; batch adversarial loss: 0.724590\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536500; batch adversarial loss: 0.716195\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518190; batch adversarial loss: 0.710492\n",
      "epoch 14; iter: 0; batch classifier loss: 0.442472; batch adversarial loss: 0.718302\n",
      "epoch 15; iter: 0; batch classifier loss: 0.486053; batch adversarial loss: 0.696183\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523502; batch adversarial loss: 0.730533\n",
      "epoch 17; iter: 0; batch classifier loss: 0.461984; batch adversarial loss: 0.715584\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437684; batch adversarial loss: 0.694641\n",
      "epoch 19; iter: 0; batch classifier loss: 0.474995; batch adversarial loss: 0.712536\n",
      "epoch 20; iter: 0; batch classifier loss: 0.448983; batch adversarial loss: 0.709495\n",
      "epoch 21; iter: 0; batch classifier loss: 0.421516; batch adversarial loss: 0.692523\n",
      "epoch 22; iter: 0; batch classifier loss: 0.487115; batch adversarial loss: 0.708772\n",
      "epoch 23; iter: 0; batch classifier loss: 0.420686; batch adversarial loss: 0.717607\n",
      "epoch 24; iter: 0; batch classifier loss: 0.390474; batch adversarial loss: 0.694845\n",
      "epoch 25; iter: 0; batch classifier loss: 0.428795; batch adversarial loss: 0.717506\n",
      "epoch 26; iter: 0; batch classifier loss: 0.384014; batch adversarial loss: 0.683253\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394863; batch adversarial loss: 0.703343\n",
      "epoch 28; iter: 0; batch classifier loss: 0.387884; batch adversarial loss: 0.702304\n",
      "epoch 29; iter: 0; batch classifier loss: 0.455568; batch adversarial loss: 0.715153\n",
      "epoch 30; iter: 0; batch classifier loss: 0.411969; batch adversarial loss: 0.673447\n",
      "epoch 31; iter: 0; batch classifier loss: 0.430811; batch adversarial loss: 0.683931\n",
      "epoch 32; iter: 0; batch classifier loss: 0.454053; batch adversarial loss: 0.678088\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386790; batch adversarial loss: 0.683581\n",
      "epoch 34; iter: 0; batch classifier loss: 0.467470; batch adversarial loss: 0.722897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.432285; batch adversarial loss: 0.691799\n",
      "epoch 36; iter: 0; batch classifier loss: 0.391798; batch adversarial loss: 0.678949\n",
      "epoch 37; iter: 0; batch classifier loss: 0.368918; batch adversarial loss: 0.675972\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436664; batch adversarial loss: 0.701368\n",
      "epoch 39; iter: 0; batch classifier loss: 0.286340; batch adversarial loss: 0.642357\n",
      "epoch 40; iter: 0; batch classifier loss: 0.399485; batch adversarial loss: 0.682535\n",
      "epoch 41; iter: 0; batch classifier loss: 0.343489; batch adversarial loss: 0.678357\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365369; batch adversarial loss: 0.679805\n",
      "epoch 43; iter: 0; batch classifier loss: 0.380839; batch adversarial loss: 0.680090\n",
      "epoch 44; iter: 0; batch classifier loss: 0.414076; batch adversarial loss: 0.671855\n",
      "epoch 45; iter: 0; batch classifier loss: 0.433322; batch adversarial loss: 0.685044\n",
      "epoch 46; iter: 0; batch classifier loss: 0.324427; batch adversarial loss: 0.631778\n",
      "epoch 47; iter: 0; batch classifier loss: 0.339214; batch adversarial loss: 0.643889\n",
      "epoch 48; iter: 0; batch classifier loss: 0.435504; batch adversarial loss: 0.679236\n",
      "epoch 49; iter: 0; batch classifier loss: 0.432993; batch adversarial loss: 0.683419\n",
      "epoch 50; iter: 0; batch classifier loss: 0.455960; batch adversarial loss: 0.672825\n",
      "epoch 51; iter: 0; batch classifier loss: 0.342295; batch adversarial loss: 0.653262\n",
      "epoch 52; iter: 0; batch classifier loss: 0.366388; batch adversarial loss: 0.654744\n",
      "epoch 53; iter: 0; batch classifier loss: 0.360602; batch adversarial loss: 0.665655\n",
      "epoch 54; iter: 0; batch classifier loss: 0.329953; batch adversarial loss: 0.657407\n",
      "epoch 55; iter: 0; batch classifier loss: 0.340810; batch adversarial loss: 0.674601\n",
      "epoch 56; iter: 0; batch classifier loss: 0.325580; batch adversarial loss: 0.653620\n",
      "epoch 57; iter: 0; batch classifier loss: 0.393810; batch adversarial loss: 0.657212\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395261; batch adversarial loss: 0.683366\n",
      "epoch 59; iter: 0; batch classifier loss: 0.365087; batch adversarial loss: 0.653052\n",
      "epoch 0; iter: 0; batch classifier loss: 0.635001; batch adversarial loss: 0.720362\n",
      "epoch 1; iter: 0; batch classifier loss: 0.614452; batch adversarial loss: 0.727390\n",
      "epoch 2; iter: 0; batch classifier loss: 0.550733; batch adversarial loss: 0.715755\n",
      "epoch 3; iter: 0; batch classifier loss: 0.572771; batch adversarial loss: 0.715571\n",
      "epoch 4; iter: 0; batch classifier loss: 0.573357; batch adversarial loss: 0.711264\n",
      "epoch 5; iter: 0; batch classifier loss: 0.487465; batch adversarial loss: 0.708561\n",
      "epoch 6; iter: 0; batch classifier loss: 0.487070; batch adversarial loss: 0.712627\n",
      "epoch 7; iter: 0; batch classifier loss: 0.549373; batch adversarial loss: 0.707994\n",
      "epoch 8; iter: 0; batch classifier loss: 0.474591; batch adversarial loss: 0.703512\n",
      "epoch 9; iter: 0; batch classifier loss: 0.438415; batch adversarial loss: 0.701553\n",
      "epoch 10; iter: 0; batch classifier loss: 0.461140; batch adversarial loss: 0.701936\n",
      "epoch 11; iter: 0; batch classifier loss: 0.492566; batch adversarial loss: 0.697924\n",
      "epoch 12; iter: 0; batch classifier loss: 0.463599; batch adversarial loss: 0.698026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.436789; batch adversarial loss: 0.694134\n",
      "epoch 14; iter: 0; batch classifier loss: 0.410550; batch adversarial loss: 0.690827\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480651; batch adversarial loss: 0.689217\n",
      "epoch 16; iter: 0; batch classifier loss: 0.445371; batch adversarial loss: 0.685238\n",
      "epoch 17; iter: 0; batch classifier loss: 0.420772; batch adversarial loss: 0.682213\n",
      "epoch 18; iter: 0; batch classifier loss: 0.473312; batch adversarial loss: 0.680134\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425338; batch adversarial loss: 0.683251\n",
      "epoch 20; iter: 0; batch classifier loss: 0.426305; batch adversarial loss: 0.673356\n",
      "epoch 21; iter: 0; batch classifier loss: 0.439653; batch adversarial loss: 0.680340\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462650; batch adversarial loss: 0.677941\n",
      "epoch 23; iter: 0; batch classifier loss: 0.373587; batch adversarial loss: 0.663773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.500870; batch adversarial loss: 0.668756\n",
      "epoch 25; iter: 0; batch classifier loss: 0.453182; batch adversarial loss: 0.670110\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418583; batch adversarial loss: 0.655463\n",
      "epoch 27; iter: 0; batch classifier loss: 0.442281; batch adversarial loss: 0.665498\n",
      "epoch 28; iter: 0; batch classifier loss: 0.404869; batch adversarial loss: 0.657098\n",
      "epoch 29; iter: 0; batch classifier loss: 0.462517; batch adversarial loss: 0.666794\n",
      "epoch 30; iter: 0; batch classifier loss: 0.378850; batch adversarial loss: 0.655934\n",
      "epoch 31; iter: 0; batch classifier loss: 0.425778; batch adversarial loss: 0.662110\n",
      "epoch 32; iter: 0; batch classifier loss: 0.333808; batch adversarial loss: 0.650488\n",
      "epoch 33; iter: 0; batch classifier loss: 0.389137; batch adversarial loss: 0.639278\n",
      "epoch 34; iter: 0; batch classifier loss: 0.372809; batch adversarial loss: 0.654034\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396395; batch adversarial loss: 0.656498\n",
      "epoch 36; iter: 0; batch classifier loss: 0.246830; batch adversarial loss: 0.653505\n",
      "epoch 37; iter: 0; batch classifier loss: 0.332532; batch adversarial loss: 0.649597\n",
      "epoch 38; iter: 0; batch classifier loss: 0.384624; batch adversarial loss: 0.645286\n",
      "epoch 39; iter: 0; batch classifier loss: 0.317814; batch adversarial loss: 0.657063\n",
      "epoch 40; iter: 0; batch classifier loss: 0.351862; batch adversarial loss: 0.652848\n",
      "epoch 41; iter: 0; batch classifier loss: 0.306366; batch adversarial loss: 0.645368\n",
      "epoch 42; iter: 0; batch classifier loss: 0.358689; batch adversarial loss: 0.641548\n",
      "epoch 43; iter: 0; batch classifier loss: 0.396261; batch adversarial loss: 0.635351\n",
      "epoch 44; iter: 0; batch classifier loss: 0.358956; batch adversarial loss: 0.636219\n",
      "epoch 45; iter: 0; batch classifier loss: 0.286931; batch adversarial loss: 0.655022\n",
      "epoch 46; iter: 0; batch classifier loss: 0.303204; batch adversarial loss: 0.654706\n",
      "epoch 47; iter: 0; batch classifier loss: 0.277356; batch adversarial loss: 0.629459\n",
      "epoch 48; iter: 0; batch classifier loss: 0.326231; batch adversarial loss: 0.653019\n",
      "epoch 49; iter: 0; batch classifier loss: 0.302524; batch adversarial loss: 0.639873\n",
      "epoch 50; iter: 0; batch classifier loss: 0.277681; batch adversarial loss: 0.636420\n",
      "epoch 51; iter: 0; batch classifier loss: 0.346423; batch adversarial loss: 0.630835\n",
      "epoch 52; iter: 0; batch classifier loss: 0.307756; batch adversarial loss: 0.624230\n",
      "epoch 53; iter: 0; batch classifier loss: 0.241942; batch adversarial loss: 0.630084\n",
      "epoch 54; iter: 0; batch classifier loss: 0.330133; batch adversarial loss: 0.625208\n",
      "epoch 55; iter: 0; batch classifier loss: 0.257747; batch adversarial loss: 0.643070\n",
      "epoch 56; iter: 0; batch classifier loss: 0.295114; batch adversarial loss: 0.639142\n",
      "epoch 57; iter: 0; batch classifier loss: 0.270461; batch adversarial loss: 0.621854\n",
      "epoch 58; iter: 0; batch classifier loss: 0.322888; batch adversarial loss: 0.609814\n",
      "epoch 59; iter: 0; batch classifier loss: 0.272498; batch adversarial loss: 0.627967\n",
      "epoch 0; iter: 0; batch classifier loss: 0.683750; batch adversarial loss: 0.769662\n",
      "epoch 1; iter: 0; batch classifier loss: 0.620196; batch adversarial loss: 0.767749\n",
      "epoch 2; iter: 0; batch classifier loss: 0.599527; batch adversarial loss: 0.758183\n",
      "epoch 3; iter: 0; batch classifier loss: 0.534320; batch adversarial loss: 0.743647\n",
      "epoch 4; iter: 0; batch classifier loss: 0.495999; batch adversarial loss: 0.760970\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633414; batch adversarial loss: 0.750175\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481421; batch adversarial loss: 0.720633\n",
      "epoch 7; iter: 0; batch classifier loss: 0.548203; batch adversarial loss: 0.739449\n",
      "epoch 8; iter: 0; batch classifier loss: 0.431682; batch adversarial loss: 0.718262\n",
      "epoch 9; iter: 0; batch classifier loss: 0.488881; batch adversarial loss: 0.731704\n",
      "epoch 10; iter: 0; batch classifier loss: 0.429356; batch adversarial loss: 0.711330\n",
      "epoch 11; iter: 0; batch classifier loss: 0.393628; batch adversarial loss: 0.712733\n",
      "epoch 12; iter: 0; batch classifier loss: 0.460580; batch adversarial loss: 0.708692\n",
      "epoch 13; iter: 0; batch classifier loss: 0.372340; batch adversarial loss: 0.695199\n",
      "epoch 14; iter: 0; batch classifier loss: 0.390174; batch adversarial loss: 0.676650\n",
      "epoch 15; iter: 0; batch classifier loss: 0.411933; batch adversarial loss: 0.688064\n",
      "epoch 16; iter: 0; batch classifier loss: 0.316297; batch adversarial loss: 0.677796\n",
      "epoch 17; iter: 0; batch classifier loss: 0.425615; batch adversarial loss: 0.683866\n",
      "epoch 18; iter: 0; batch classifier loss: 0.409984; batch adversarial loss: 0.682525\n",
      "epoch 19; iter: 0; batch classifier loss: 0.441015; batch adversarial loss: 0.677108\n",
      "epoch 20; iter: 0; batch classifier loss: 0.406907; batch adversarial loss: 0.657020\n",
      "epoch 21; iter: 0; batch classifier loss: 0.336091; batch adversarial loss: 0.648538\n",
      "epoch 22; iter: 0; batch classifier loss: 0.401934; batch adversarial loss: 0.664016\n",
      "epoch 23; iter: 0; batch classifier loss: 0.422823; batch adversarial loss: 0.661565\n",
      "epoch 24; iter: 0; batch classifier loss: 0.311643; batch adversarial loss: 0.636379\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429570; batch adversarial loss: 0.670311\n",
      "epoch 26; iter: 0; batch classifier loss: 0.283454; batch adversarial loss: 0.633838\n",
      "epoch 27; iter: 0; batch classifier loss: 0.304902; batch adversarial loss: 0.661464\n",
      "epoch 28; iter: 0; batch classifier loss: 0.347059; batch adversarial loss: 0.630749\n",
      "epoch 29; iter: 0; batch classifier loss: 0.417122; batch adversarial loss: 0.639163\n",
      "epoch 30; iter: 0; batch classifier loss: 0.305655; batch adversarial loss: 0.610639\n",
      "epoch 31; iter: 0; batch classifier loss: 0.290572; batch adversarial loss: 0.649929\n",
      "epoch 32; iter: 0; batch classifier loss: 0.256294; batch adversarial loss: 0.599869\n",
      "epoch 33; iter: 0; batch classifier loss: 0.202445; batch adversarial loss: 0.604148\n",
      "epoch 34; iter: 0; batch classifier loss: 0.404811; batch adversarial loss: 0.647750\n",
      "epoch 35; iter: 0; batch classifier loss: 0.405773; batch adversarial loss: 0.594991\n",
      "epoch 36; iter: 0; batch classifier loss: 0.292222; batch adversarial loss: 0.603711\n",
      "epoch 37; iter: 0; batch classifier loss: 0.248034; batch adversarial loss: 0.606414\n",
      "epoch 38; iter: 0; batch classifier loss: 0.325587; batch adversarial loss: 0.657816\n",
      "epoch 39; iter: 0; batch classifier loss: 0.311090; batch adversarial loss: 0.615510\n",
      "epoch 40; iter: 0; batch classifier loss: 0.386428; batch adversarial loss: 0.633371\n",
      "epoch 41; iter: 0; batch classifier loss: 0.282377; batch adversarial loss: 0.652167\n",
      "epoch 42; iter: 0; batch classifier loss: 0.363162; batch adversarial loss: 0.585877\n",
      "epoch 43; iter: 0; batch classifier loss: 0.267142; batch adversarial loss: 0.647906\n",
      "epoch 44; iter: 0; batch classifier loss: 0.261782; batch adversarial loss: 0.621197\n",
      "epoch 45; iter: 0; batch classifier loss: 0.285388; batch adversarial loss: 0.602480\n",
      "epoch 46; iter: 0; batch classifier loss: 0.292327; batch adversarial loss: 0.549530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.346410; batch adversarial loss: 0.591398\n",
      "epoch 48; iter: 0; batch classifier loss: 0.404448; batch adversarial loss: 0.639544\n",
      "epoch 49; iter: 0; batch classifier loss: 0.334700; batch adversarial loss: 0.661854\n",
      "epoch 50; iter: 0; batch classifier loss: 0.327676; batch adversarial loss: 0.600117\n",
      "epoch 51; iter: 0; batch classifier loss: 0.390338; batch adversarial loss: 0.593662\n",
      "epoch 52; iter: 0; batch classifier loss: 0.255639; batch adversarial loss: 0.561995\n",
      "epoch 53; iter: 0; batch classifier loss: 0.348590; batch adversarial loss: 0.596890\n",
      "epoch 54; iter: 0; batch classifier loss: 0.322585; batch adversarial loss: 0.597952\n",
      "epoch 55; iter: 0; batch classifier loss: 0.282755; batch adversarial loss: 0.627325\n",
      "epoch 56; iter: 0; batch classifier loss: 0.246125; batch adversarial loss: 0.654986\n",
      "epoch 57; iter: 0; batch classifier loss: 0.243636; batch adversarial loss: 0.645626\n",
      "epoch 58; iter: 0; batch classifier loss: 0.369757; batch adversarial loss: 0.598466\n",
      "epoch 59; iter: 0; batch classifier loss: 0.317373; batch adversarial loss: 0.535236\n",
      "epoch 60; iter: 0; batch classifier loss: 0.189760; batch adversarial loss: 0.602231\n",
      "epoch 61; iter: 0; batch classifier loss: 0.392225; batch adversarial loss: 0.631190\n",
      "epoch 62; iter: 0; batch classifier loss: 0.328869; batch adversarial loss: 0.612406\n",
      "epoch 63; iter: 0; batch classifier loss: 0.204897; batch adversarial loss: 0.575411\n",
      "epoch 64; iter: 0; batch classifier loss: 0.414143; batch adversarial loss: 0.591963\n",
      "epoch 65; iter: 0; batch classifier loss: 0.218390; batch adversarial loss: 0.569537\n",
      "epoch 66; iter: 0; batch classifier loss: 0.338463; batch adversarial loss: 0.562018\n",
      "epoch 67; iter: 0; batch classifier loss: 0.343687; batch adversarial loss: 0.569209\n",
      "epoch 68; iter: 0; batch classifier loss: 0.223388; batch adversarial loss: 0.597014\n",
      "epoch 69; iter: 0; batch classifier loss: 0.358281; batch adversarial loss: 0.586653\n",
      "epoch 70; iter: 0; batch classifier loss: 0.397434; batch adversarial loss: 0.556613\n",
      "epoch 71; iter: 0; batch classifier loss: 0.360303; batch adversarial loss: 0.627016\n",
      "epoch 72; iter: 0; batch classifier loss: 0.255234; batch adversarial loss: 0.574271\n",
      "epoch 73; iter: 0; batch classifier loss: 0.264930; batch adversarial loss: 0.603587\n",
      "epoch 74; iter: 0; batch classifier loss: 0.209151; batch adversarial loss: 0.534955\n",
      "epoch 75; iter: 0; batch classifier loss: 0.276028; batch adversarial loss: 0.600778\n",
      "epoch 76; iter: 0; batch classifier loss: 0.302936; batch adversarial loss: 0.678044\n",
      "epoch 77; iter: 0; batch classifier loss: 0.341401; batch adversarial loss: 0.649385\n",
      "epoch 78; iter: 0; batch classifier loss: 0.291363; batch adversarial loss: 0.644851\n",
      "epoch 79; iter: 0; batch classifier loss: 0.246776; batch adversarial loss: 0.504772\n",
      "epoch 0; iter: 0; batch classifier loss: 0.702321; batch adversarial loss: 0.716657\n",
      "epoch 1; iter: 0; batch classifier loss: 0.616942; batch adversarial loss: 0.783554\n",
      "epoch 2; iter: 0; batch classifier loss: 0.645334; batch adversarial loss: 0.825908\n",
      "epoch 3; iter: 0; batch classifier loss: 0.650069; batch adversarial loss: 0.776669\n",
      "epoch 4; iter: 0; batch classifier loss: 0.557965; batch adversarial loss: 0.751037\n",
      "epoch 5; iter: 0; batch classifier loss: 0.435016; batch adversarial loss: 0.742491\n",
      "epoch 6; iter: 0; batch classifier loss: 0.580519; batch adversarial loss: 0.807314\n",
      "epoch 7; iter: 0; batch classifier loss: 0.569861; batch adversarial loss: 0.778681\n",
      "epoch 8; iter: 0; batch classifier loss: 0.525100; batch adversarial loss: 0.726323\n",
      "epoch 9; iter: 0; batch classifier loss: 0.571828; batch adversarial loss: 0.786187\n",
      "epoch 10; iter: 0; batch classifier loss: 0.615550; batch adversarial loss: 0.762183\n",
      "epoch 11; iter: 0; batch classifier loss: 0.627892; batch adversarial loss: 0.796787\n",
      "epoch 12; iter: 0; batch classifier loss: 0.492617; batch adversarial loss: 0.741035\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558438; batch adversarial loss: 0.777696\n",
      "epoch 14; iter: 0; batch classifier loss: 0.540271; batch adversarial loss: 0.760044\n",
      "epoch 15; iter: 0; batch classifier loss: 0.459183; batch adversarial loss: 0.710489\n",
      "epoch 16; iter: 0; batch classifier loss: 0.594931; batch adversarial loss: 0.814399\n",
      "epoch 17; iter: 0; batch classifier loss: 0.615761; batch adversarial loss: 0.805648\n",
      "epoch 18; iter: 0; batch classifier loss: 0.596649; batch adversarial loss: 0.769687\n",
      "epoch 19; iter: 0; batch classifier loss: 0.545438; batch adversarial loss: 0.700367\n",
      "epoch 20; iter: 0; batch classifier loss: 0.449714; batch adversarial loss: 0.654543\n",
      "epoch 21; iter: 0; batch classifier loss: 0.561177; batch adversarial loss: 0.710244\n",
      "epoch 22; iter: 0; batch classifier loss: 0.462089; batch adversarial loss: 0.642649\n",
      "epoch 23; iter: 0; batch classifier loss: 0.489216; batch adversarial loss: 0.635237\n",
      "epoch 24; iter: 0; batch classifier loss: 0.620726; batch adversarial loss: 0.698756\n",
      "epoch 25; iter: 0; batch classifier loss: 0.518718; batch adversarial loss: 0.670917\n",
      "epoch 26; iter: 0; batch classifier loss: 0.472587; batch adversarial loss: 0.743868\n",
      "epoch 27; iter: 0; batch classifier loss: 0.448967; batch adversarial loss: 0.608889\n",
      "epoch 28; iter: 0; batch classifier loss: 0.532103; batch adversarial loss: 0.705530\n",
      "epoch 29; iter: 0; batch classifier loss: 0.458150; batch adversarial loss: 0.696968\n",
      "epoch 30; iter: 0; batch classifier loss: 0.466113; batch adversarial loss: 0.693512\n",
      "epoch 31; iter: 0; batch classifier loss: 0.441782; batch adversarial loss: 0.725743\n",
      "epoch 32; iter: 0; batch classifier loss: 0.470297; batch adversarial loss: 0.683077\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477702; batch adversarial loss: 0.687305\n",
      "epoch 34; iter: 0; batch classifier loss: 0.366785; batch adversarial loss: 0.690488\n",
      "epoch 35; iter: 0; batch classifier loss: 0.427322; batch adversarial loss: 0.621777\n",
      "epoch 36; iter: 0; batch classifier loss: 0.495790; batch adversarial loss: 0.674934\n",
      "epoch 37; iter: 0; batch classifier loss: 0.383747; batch adversarial loss: 0.656781\n",
      "epoch 38; iter: 0; batch classifier loss: 0.368597; batch adversarial loss: 0.626999\n",
      "epoch 39; iter: 0; batch classifier loss: 0.364779; batch adversarial loss: 0.579160\n",
      "epoch 40; iter: 0; batch classifier loss: 0.366885; batch adversarial loss: 0.673403\n",
      "epoch 41; iter: 0; batch classifier loss: 0.337772; batch adversarial loss: 0.640928\n",
      "epoch 42; iter: 0; batch classifier loss: 0.381401; batch adversarial loss: 0.591774\n",
      "epoch 43; iter: 0; batch classifier loss: 0.319979; batch adversarial loss: 0.641731\n",
      "epoch 44; iter: 0; batch classifier loss: 0.424998; batch adversarial loss: 0.592256\n",
      "epoch 45; iter: 0; batch classifier loss: 0.256943; batch adversarial loss: 0.603382\n",
      "epoch 46; iter: 0; batch classifier loss: 0.302817; batch adversarial loss: 0.662582\n",
      "epoch 47; iter: 0; batch classifier loss: 0.247016; batch adversarial loss: 0.642944\n",
      "epoch 48; iter: 0; batch classifier loss: 0.219503; batch adversarial loss: 0.705607\n",
      "epoch 49; iter: 0; batch classifier loss: 0.253160; batch adversarial loss: 0.553605\n",
      "epoch 50; iter: 0; batch classifier loss: 0.294785; batch adversarial loss: 0.604528\n",
      "epoch 51; iter: 0; batch classifier loss: 0.368585; batch adversarial loss: 0.567609\n",
      "epoch 52; iter: 0; batch classifier loss: 0.353887; batch adversarial loss: 0.564453\n",
      "epoch 53; iter: 0; batch classifier loss: 0.303027; batch adversarial loss: 0.624584\n",
      "epoch 54; iter: 0; batch classifier loss: 0.226219; batch adversarial loss: 0.572678\n",
      "epoch 55; iter: 0; batch classifier loss: 0.378343; batch adversarial loss: 0.515200\n",
      "epoch 56; iter: 0; batch classifier loss: 0.247548; batch adversarial loss: 0.592082\n",
      "epoch 57; iter: 0; batch classifier loss: 0.336267; batch adversarial loss: 0.602802\n",
      "epoch 58; iter: 0; batch classifier loss: 0.262068; batch adversarial loss: 0.523364\n",
      "epoch 59; iter: 0; batch classifier loss: 0.225456; batch adversarial loss: 0.558967\n",
      "epoch 60; iter: 0; batch classifier loss: 0.281647; batch adversarial loss: 0.701695\n",
      "epoch 61; iter: 0; batch classifier loss: 0.258777; batch adversarial loss: 0.553616\n",
      "epoch 62; iter: 0; batch classifier loss: 0.291251; batch adversarial loss: 0.524792\n",
      "epoch 63; iter: 0; batch classifier loss: 0.226056; batch adversarial loss: 0.589058\n",
      "epoch 64; iter: 0; batch classifier loss: 0.294619; batch adversarial loss: 0.598507\n",
      "epoch 65; iter: 0; batch classifier loss: 0.233950; batch adversarial loss: 0.543009\n",
      "epoch 66; iter: 0; batch classifier loss: 0.372202; batch adversarial loss: 0.603819\n",
      "epoch 67; iter: 0; batch classifier loss: 0.374917; batch adversarial loss: 0.625466\n",
      "epoch 68; iter: 0; batch classifier loss: 0.275435; batch adversarial loss: 0.663925\n",
      "epoch 69; iter: 0; batch classifier loss: 0.185596; batch adversarial loss: 0.579228\n",
      "epoch 70; iter: 0; batch classifier loss: 0.218823; batch adversarial loss: 0.599819\n",
      "epoch 71; iter: 0; batch classifier loss: 0.182423; batch adversarial loss: 0.741639\n",
      "epoch 72; iter: 0; batch classifier loss: 0.190837; batch adversarial loss: 0.636206\n",
      "epoch 73; iter: 0; batch classifier loss: 0.196798; batch adversarial loss: 0.643024\n",
      "epoch 74; iter: 0; batch classifier loss: 0.307649; batch adversarial loss: 0.524445\n",
      "epoch 75; iter: 0; batch classifier loss: 0.164982; batch adversarial loss: 0.593809\n",
      "epoch 76; iter: 0; batch classifier loss: 0.285412; batch adversarial loss: 0.581624\n",
      "epoch 77; iter: 0; batch classifier loss: 0.246730; batch adversarial loss: 0.686624\n",
      "epoch 78; iter: 0; batch classifier loss: 0.279489; batch adversarial loss: 0.648338\n",
      "epoch 79; iter: 0; batch classifier loss: 0.219157; batch adversarial loss: 0.642192\n",
      "epoch 0; iter: 0; batch classifier loss: 0.653474; batch adversarial loss: 0.687634\n",
      "epoch 1; iter: 0; batch classifier loss: 0.643493; batch adversarial loss: 0.655542\n",
      "epoch 2; iter: 0; batch classifier loss: 0.576896; batch adversarial loss: 0.565422\n",
      "epoch 3; iter: 0; batch classifier loss: 0.594456; batch adversarial loss: 0.637338\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594145; batch adversarial loss: 0.599445\n",
      "epoch 5; iter: 0; batch classifier loss: 0.524816; batch adversarial loss: 0.680319\n",
      "epoch 6; iter: 0; batch classifier loss: 0.511002; batch adversarial loss: 0.648444\n",
      "epoch 7; iter: 0; batch classifier loss: 0.505020; batch adversarial loss: 0.674449\n",
      "epoch 8; iter: 0; batch classifier loss: 0.500757; batch adversarial loss: 0.644497\n",
      "epoch 9; iter: 0; batch classifier loss: 0.471945; batch adversarial loss: 0.682687\n",
      "epoch 10; iter: 0; batch classifier loss: 0.492798; batch adversarial loss: 0.620802\n",
      "epoch 11; iter: 0; batch classifier loss: 0.448668; batch adversarial loss: 0.612788\n",
      "epoch 12; iter: 0; batch classifier loss: 0.433685; batch adversarial loss: 0.690876\n",
      "epoch 13; iter: 0; batch classifier loss: 0.435623; batch adversarial loss: 0.580453\n",
      "epoch 14; iter: 0; batch classifier loss: 0.503613; batch adversarial loss: 0.578078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.412176; batch adversarial loss: 0.655645\n",
      "epoch 16; iter: 0; batch classifier loss: 0.491659; batch adversarial loss: 0.635375\n",
      "epoch 17; iter: 0; batch classifier loss: 0.470577; batch adversarial loss: 0.633951\n",
      "epoch 18; iter: 0; batch classifier loss: 0.452074; batch adversarial loss: 0.678511\n",
      "epoch 19; iter: 0; batch classifier loss: 0.414580; batch adversarial loss: 0.639349\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417163; batch adversarial loss: 0.673733\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364674; batch adversarial loss: 0.719220\n",
      "epoch 22; iter: 0; batch classifier loss: 0.392919; batch adversarial loss: 0.661877\n",
      "epoch 23; iter: 0; batch classifier loss: 0.390400; batch adversarial loss: 0.655773\n",
      "epoch 24; iter: 0; batch classifier loss: 0.387087; batch adversarial loss: 0.700622\n",
      "epoch 25; iter: 0; batch classifier loss: 0.401479; batch adversarial loss: 0.617608\n",
      "epoch 26; iter: 0; batch classifier loss: 0.356980; batch adversarial loss: 0.626396\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424010; batch adversarial loss: 0.681241\n",
      "epoch 28; iter: 0; batch classifier loss: 0.421333; batch adversarial loss: 0.639613\n",
      "epoch 29; iter: 0; batch classifier loss: 0.386803; batch adversarial loss: 0.659304\n",
      "epoch 30; iter: 0; batch classifier loss: 0.396303; batch adversarial loss: 0.612903\n",
      "epoch 31; iter: 0; batch classifier loss: 0.352915; batch adversarial loss: 0.659652\n",
      "epoch 32; iter: 0; batch classifier loss: 0.400599; batch adversarial loss: 0.665477\n",
      "epoch 33; iter: 0; batch classifier loss: 0.477529; batch adversarial loss: 0.603971\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293428; batch adversarial loss: 0.606318\n",
      "epoch 35; iter: 0; batch classifier loss: 0.365965; batch adversarial loss: 0.630726\n",
      "epoch 36; iter: 0; batch classifier loss: 0.390202; batch adversarial loss: 0.677370\n",
      "epoch 37; iter: 0; batch classifier loss: 0.367623; batch adversarial loss: 0.559343\n",
      "epoch 38; iter: 0; batch classifier loss: 0.380903; batch adversarial loss: 0.575875\n",
      "epoch 39; iter: 0; batch classifier loss: 0.416139; batch adversarial loss: 0.573931\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367412; batch adversarial loss: 0.656768\n",
      "epoch 41; iter: 0; batch classifier loss: 0.349660; batch adversarial loss: 0.619606\n",
      "epoch 42; iter: 0; batch classifier loss: 0.308117; batch adversarial loss: 0.690433\n",
      "epoch 43; iter: 0; batch classifier loss: 0.435134; batch adversarial loss: 0.622811\n",
      "epoch 44; iter: 0; batch classifier loss: 0.374132; batch adversarial loss: 0.697105\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317015; batch adversarial loss: 0.668089\n",
      "epoch 46; iter: 0; batch classifier loss: 0.357498; batch adversarial loss: 0.621596\n",
      "epoch 47; iter: 0; batch classifier loss: 0.280855; batch adversarial loss: 0.616821\n",
      "epoch 48; iter: 0; batch classifier loss: 0.332301; batch adversarial loss: 0.638734\n",
      "epoch 49; iter: 0; batch classifier loss: 0.403850; batch adversarial loss: 0.595008\n",
      "epoch 50; iter: 0; batch classifier loss: 0.355375; batch adversarial loss: 0.615356\n",
      "epoch 51; iter: 0; batch classifier loss: 0.247840; batch adversarial loss: 0.607679\n",
      "epoch 52; iter: 0; batch classifier loss: 0.342728; batch adversarial loss: 0.658453\n",
      "epoch 53; iter: 0; batch classifier loss: 0.367459; batch adversarial loss: 0.622947\n",
      "epoch 54; iter: 0; batch classifier loss: 0.397810; batch adversarial loss: 0.606763\n",
      "epoch 55; iter: 0; batch classifier loss: 0.324417; batch adversarial loss: 0.587429\n",
      "epoch 56; iter: 0; batch classifier loss: 0.330761; batch adversarial loss: 0.607440\n",
      "epoch 57; iter: 0; batch classifier loss: 0.374705; batch adversarial loss: 0.657090\n",
      "epoch 58; iter: 0; batch classifier loss: 0.290569; batch adversarial loss: 0.593965\n",
      "epoch 59; iter: 0; batch classifier loss: 0.426065; batch adversarial loss: 0.598909\n",
      "epoch 60; iter: 0; batch classifier loss: 0.282297; batch adversarial loss: 0.610291\n",
      "epoch 61; iter: 0; batch classifier loss: 0.323156; batch adversarial loss: 0.606349\n",
      "epoch 62; iter: 0; batch classifier loss: 0.307851; batch adversarial loss: 0.607268\n",
      "epoch 63; iter: 0; batch classifier loss: 0.348249; batch adversarial loss: 0.627478\n",
      "epoch 64; iter: 0; batch classifier loss: 0.376689; batch adversarial loss: 0.623971\n",
      "epoch 65; iter: 0; batch classifier loss: 0.339135; batch adversarial loss: 0.557200\n",
      "epoch 66; iter: 0; batch classifier loss: 0.389671; batch adversarial loss: 0.595115\n",
      "epoch 67; iter: 0; batch classifier loss: 0.297754; batch adversarial loss: 0.620614\n",
      "epoch 68; iter: 0; batch classifier loss: 0.298174; batch adversarial loss: 0.570404\n",
      "epoch 69; iter: 0; batch classifier loss: 0.367447; batch adversarial loss: 0.640436\n",
      "epoch 70; iter: 0; batch classifier loss: 0.418244; batch adversarial loss: 0.645755\n",
      "epoch 71; iter: 0; batch classifier loss: 0.290653; batch adversarial loss: 0.538921\n",
      "epoch 72; iter: 0; batch classifier loss: 0.293385; batch adversarial loss: 0.596218\n",
      "epoch 73; iter: 0; batch classifier loss: 0.272675; batch adversarial loss: 0.660403\n",
      "epoch 74; iter: 0; batch classifier loss: 0.316384; batch adversarial loss: 0.598173\n",
      "epoch 75; iter: 0; batch classifier loss: 0.341191; batch adversarial loss: 0.580577\n",
      "epoch 76; iter: 0; batch classifier loss: 0.324335; batch adversarial loss: 0.579504\n",
      "epoch 77; iter: 0; batch classifier loss: 0.307890; batch adversarial loss: 0.670461\n",
      "epoch 78; iter: 0; batch classifier loss: 0.358542; batch adversarial loss: 0.585746\n",
      "epoch 79; iter: 0; batch classifier loss: 0.377582; batch adversarial loss: 0.577279\n",
      "epoch 0; iter: 0; batch classifier loss: 0.830300; batch adversarial loss: 0.633488\n",
      "epoch 1; iter: 0; batch classifier loss: 0.777504; batch adversarial loss: 0.653974\n",
      "epoch 2; iter: 0; batch classifier loss: 0.720562; batch adversarial loss: 0.636623\n",
      "epoch 3; iter: 0; batch classifier loss: 0.708516; batch adversarial loss: 0.639172\n",
      "epoch 4; iter: 0; batch classifier loss: 0.663484; batch adversarial loss: 0.640731\n",
      "epoch 5; iter: 0; batch classifier loss: 0.641223; batch adversarial loss: 0.647797\n",
      "epoch 6; iter: 0; batch classifier loss: 0.613770; batch adversarial loss: 0.649584\n",
      "epoch 7; iter: 0; batch classifier loss: 0.624455; batch adversarial loss: 0.646542\n",
      "epoch 8; iter: 0; batch classifier loss: 0.564011; batch adversarial loss: 0.659192\n",
      "epoch 9; iter: 0; batch classifier loss: 0.538756; batch adversarial loss: 0.620097\n",
      "epoch 10; iter: 0; batch classifier loss: 0.574682; batch adversarial loss: 0.621754\n",
      "epoch 11; iter: 0; batch classifier loss: 0.548355; batch adversarial loss: 0.631386\n",
      "epoch 12; iter: 0; batch classifier loss: 0.503733; batch adversarial loss: 0.642174\n",
      "epoch 13; iter: 0; batch classifier loss: 0.483905; batch adversarial loss: 0.667174\n",
      "epoch 14; iter: 0; batch classifier loss: 0.524791; batch adversarial loss: 0.637035\n",
      "epoch 15; iter: 0; batch classifier loss: 0.483159; batch adversarial loss: 0.613784\n",
      "epoch 16; iter: 0; batch classifier loss: 0.455523; batch adversarial loss: 0.613180\n",
      "epoch 17; iter: 0; batch classifier loss: 0.462079; batch adversarial loss: 0.629870\n",
      "epoch 18; iter: 0; batch classifier loss: 0.432344; batch adversarial loss: 0.633864\n",
      "epoch 19; iter: 0; batch classifier loss: 0.484870; batch adversarial loss: 0.597678\n",
      "epoch 20; iter: 0; batch classifier loss: 0.504463; batch adversarial loss: 0.667835\n",
      "epoch 21; iter: 0; batch classifier loss: 0.403257; batch adversarial loss: 0.656434\n",
      "epoch 22; iter: 0; batch classifier loss: 0.354527; batch adversarial loss: 0.642021\n",
      "epoch 23; iter: 0; batch classifier loss: 0.402323; batch adversarial loss: 0.643507\n",
      "epoch 24; iter: 0; batch classifier loss: 0.477422; batch adversarial loss: 0.659260\n",
      "epoch 25; iter: 0; batch classifier loss: 0.362661; batch adversarial loss: 0.642730\n",
      "epoch 26; iter: 0; batch classifier loss: 0.392022; batch adversarial loss: 0.638378\n",
      "epoch 27; iter: 0; batch classifier loss: 0.377646; batch adversarial loss: 0.611093\n",
      "epoch 28; iter: 0; batch classifier loss: 0.352343; batch adversarial loss: 0.615510\n",
      "epoch 29; iter: 0; batch classifier loss: 0.355144; batch adversarial loss: 0.608630\n",
      "epoch 30; iter: 0; batch classifier loss: 0.414960; batch adversarial loss: 0.703616\n",
      "epoch 31; iter: 0; batch classifier loss: 0.340283; batch adversarial loss: 0.613639\n",
      "epoch 32; iter: 0; batch classifier loss: 0.362668; batch adversarial loss: 0.614371\n",
      "epoch 33; iter: 0; batch classifier loss: 0.444521; batch adversarial loss: 0.634209\n",
      "epoch 34; iter: 0; batch classifier loss: 0.403030; batch adversarial loss: 0.616987\n",
      "epoch 35; iter: 0; batch classifier loss: 0.361902; batch adversarial loss: 0.677176\n",
      "epoch 36; iter: 0; batch classifier loss: 0.413682; batch adversarial loss: 0.653373\n",
      "epoch 37; iter: 0; batch classifier loss: 0.285000; batch adversarial loss: 0.621915\n",
      "epoch 38; iter: 0; batch classifier loss: 0.382416; batch adversarial loss: 0.615256\n",
      "epoch 39; iter: 0; batch classifier loss: 0.412892; batch adversarial loss: 0.605345\n",
      "epoch 40; iter: 0; batch classifier loss: 0.328609; batch adversarial loss: 0.612979\n",
      "epoch 41; iter: 0; batch classifier loss: 0.305701; batch adversarial loss: 0.628639\n",
      "epoch 42; iter: 0; batch classifier loss: 0.358366; batch adversarial loss: 0.651333\n",
      "epoch 43; iter: 0; batch classifier loss: 0.383527; batch adversarial loss: 0.628701\n",
      "epoch 44; iter: 0; batch classifier loss: 0.442599; batch adversarial loss: 0.640865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.326282; batch adversarial loss: 0.570488\n",
      "epoch 46; iter: 0; batch classifier loss: 0.302130; batch adversarial loss: 0.615781\n",
      "epoch 47; iter: 0; batch classifier loss: 0.366235; batch adversarial loss: 0.629082\n",
      "epoch 48; iter: 0; batch classifier loss: 0.341103; batch adversarial loss: 0.559317\n",
      "epoch 49; iter: 0; batch classifier loss: 0.269624; batch adversarial loss: 0.643958\n",
      "epoch 50; iter: 0; batch classifier loss: 0.322681; batch adversarial loss: 0.647239\n",
      "epoch 51; iter: 0; batch classifier loss: 0.358595; batch adversarial loss: 0.582855\n",
      "epoch 52; iter: 0; batch classifier loss: 0.300906; batch adversarial loss: 0.652357\n",
      "epoch 53; iter: 0; batch classifier loss: 0.293214; batch adversarial loss: 0.656773\n",
      "epoch 54; iter: 0; batch classifier loss: 0.335388; batch adversarial loss: 0.680883\n",
      "epoch 55; iter: 0; batch classifier loss: 0.325826; batch adversarial loss: 0.639311\n",
      "epoch 56; iter: 0; batch classifier loss: 0.294079; batch adversarial loss: 0.621390\n",
      "epoch 57; iter: 0; batch classifier loss: 0.334533; batch adversarial loss: 0.652982\n",
      "epoch 58; iter: 0; batch classifier loss: 0.258353; batch adversarial loss: 0.585193\n",
      "epoch 59; iter: 0; batch classifier loss: 0.371123; batch adversarial loss: 0.606804\n",
      "epoch 60; iter: 0; batch classifier loss: 0.359644; batch adversarial loss: 0.627328\n",
      "epoch 61; iter: 0; batch classifier loss: 0.290680; batch adversarial loss: 0.600789\n",
      "epoch 62; iter: 0; batch classifier loss: 0.370177; batch adversarial loss: 0.592420\n",
      "epoch 63; iter: 0; batch classifier loss: 0.290252; batch adversarial loss: 0.634681\n",
      "epoch 64; iter: 0; batch classifier loss: 0.223636; batch adversarial loss: 0.639979\n",
      "epoch 65; iter: 0; batch classifier loss: 0.291355; batch adversarial loss: 0.617197\n",
      "epoch 66; iter: 0; batch classifier loss: 0.302570; batch adversarial loss: 0.604696\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351949; batch adversarial loss: 0.635104\n",
      "epoch 68; iter: 0; batch classifier loss: 0.385898; batch adversarial loss: 0.617440\n",
      "epoch 69; iter: 0; batch classifier loss: 0.310382; batch adversarial loss: 0.589901\n",
      "epoch 70; iter: 0; batch classifier loss: 0.413750; batch adversarial loss: 0.591963\n",
      "epoch 71; iter: 0; batch classifier loss: 0.296953; batch adversarial loss: 0.668785\n",
      "epoch 72; iter: 0; batch classifier loss: 0.344657; batch adversarial loss: 0.561464\n",
      "epoch 73; iter: 0; batch classifier loss: 0.270603; batch adversarial loss: 0.616543\n",
      "epoch 74; iter: 0; batch classifier loss: 0.308704; batch adversarial loss: 0.578764\n",
      "epoch 75; iter: 0; batch classifier loss: 0.309751; batch adversarial loss: 0.657642\n",
      "epoch 76; iter: 0; batch classifier loss: 0.275492; batch adversarial loss: 0.606982\n",
      "epoch 77; iter: 0; batch classifier loss: 0.323217; batch adversarial loss: 0.629318\n",
      "epoch 78; iter: 0; batch classifier loss: 0.315271; batch adversarial loss: 0.631951\n",
      "epoch 79; iter: 0; batch classifier loss: 0.271412; batch adversarial loss: 0.623271\n",
      "epoch 0; iter: 0; batch classifier loss: 0.730249; batch adversarial loss: 1.104195\n",
      "epoch 1; iter: 0; batch classifier loss: 0.694934; batch adversarial loss: 1.030860\n",
      "epoch 2; iter: 0; batch classifier loss: 0.678076; batch adversarial loss: 0.933217\n",
      "epoch 3; iter: 0; batch classifier loss: 0.583286; batch adversarial loss: 0.996094\n",
      "epoch 4; iter: 0; batch classifier loss: 0.566626; batch adversarial loss: 1.060820\n",
      "epoch 5; iter: 0; batch classifier loss: 0.532959; batch adversarial loss: 0.908902\n",
      "epoch 6; iter: 0; batch classifier loss: 0.617560; batch adversarial loss: 0.934436\n",
      "epoch 7; iter: 0; batch classifier loss: 0.517509; batch adversarial loss: 0.866592\n",
      "epoch 8; iter: 0; batch classifier loss: 0.428770; batch adversarial loss: 0.937530\n",
      "epoch 9; iter: 0; batch classifier loss: 0.455093; batch adversarial loss: 0.883354\n",
      "epoch 10; iter: 0; batch classifier loss: 0.542673; batch adversarial loss: 0.946975\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567591; batch adversarial loss: 0.904512\n",
      "epoch 12; iter: 0; batch classifier loss: 0.405476; batch adversarial loss: 0.866818\n",
      "epoch 13; iter: 0; batch classifier loss: 0.546055; batch adversarial loss: 0.941673\n",
      "epoch 14; iter: 0; batch classifier loss: 0.432612; batch adversarial loss: 0.902006\n",
      "epoch 15; iter: 0; batch classifier loss: 0.490885; batch adversarial loss: 0.865491\n",
      "epoch 16; iter: 0; batch classifier loss: 0.311259; batch adversarial loss: 0.936284\n",
      "epoch 17; iter: 0; batch classifier loss: 0.412260; batch adversarial loss: 0.949416\n",
      "epoch 18; iter: 0; batch classifier loss: 0.268608; batch adversarial loss: 0.918776\n",
      "epoch 19; iter: 0; batch classifier loss: 0.437171; batch adversarial loss: 0.847431\n",
      "epoch 20; iter: 0; batch classifier loss: 0.440574; batch adversarial loss: 0.808950\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382561; batch adversarial loss: 0.919850\n",
      "epoch 22; iter: 0; batch classifier loss: 0.522530; batch adversarial loss: 0.858544\n",
      "epoch 23; iter: 0; batch classifier loss: 0.303606; batch adversarial loss: 0.806713\n",
      "epoch 24; iter: 0; batch classifier loss: 0.455863; batch adversarial loss: 0.798027\n",
      "epoch 25; iter: 0; batch classifier loss: 0.387676; batch adversarial loss: 0.846934\n",
      "epoch 26; iter: 0; batch classifier loss: 0.322303; batch adversarial loss: 0.791553\n",
      "epoch 27; iter: 0; batch classifier loss: 0.339134; batch adversarial loss: 0.811915\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315996; batch adversarial loss: 0.822866\n",
      "epoch 29; iter: 0; batch classifier loss: 0.416106; batch adversarial loss: 0.773121\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366714; batch adversarial loss: 0.776369\n",
      "epoch 31; iter: 0; batch classifier loss: 0.358892; batch adversarial loss: 0.735021\n",
      "epoch 32; iter: 0; batch classifier loss: 0.356147; batch adversarial loss: 0.727346\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346911; batch adversarial loss: 0.826445\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436092; batch adversarial loss: 0.775688\n",
      "epoch 35; iter: 0; batch classifier loss: 0.345233; batch adversarial loss: 0.743421\n",
      "epoch 36; iter: 0; batch classifier loss: 0.243289; batch adversarial loss: 0.727361\n",
      "epoch 37; iter: 0; batch classifier loss: 0.346039; batch adversarial loss: 0.792271\n",
      "epoch 38; iter: 0; batch classifier loss: 0.316040; batch adversarial loss: 0.751619\n",
      "epoch 39; iter: 0; batch classifier loss: 0.366861; batch adversarial loss: 0.748886\n",
      "epoch 0; iter: 0; batch classifier loss: 0.714959; batch adversarial loss: 0.707344\n",
      "epoch 1; iter: 0; batch classifier loss: 0.657107; batch adversarial loss: 0.707278\n",
      "epoch 2; iter: 0; batch classifier loss: 0.611664; batch adversarial loss: 0.709732\n",
      "epoch 3; iter: 0; batch classifier loss: 0.578721; batch adversarial loss: 0.691642\n",
      "epoch 4; iter: 0; batch classifier loss: 0.599214; batch adversarial loss: 0.695497\n",
      "epoch 5; iter: 0; batch classifier loss: 0.548508; batch adversarial loss: 0.692627\n",
      "epoch 6; iter: 0; batch classifier loss: 0.538939; batch adversarial loss: 0.687815\n",
      "epoch 7; iter: 0; batch classifier loss: 0.482432; batch adversarial loss: 0.682090\n",
      "epoch 8; iter: 0; batch classifier loss: 0.450485; batch adversarial loss: 0.687119\n",
      "epoch 9; iter: 0; batch classifier loss: 0.523197; batch adversarial loss: 0.680593\n",
      "epoch 10; iter: 0; batch classifier loss: 0.468983; batch adversarial loss: 0.671371\n",
      "epoch 11; iter: 0; batch classifier loss: 0.496510; batch adversarial loss: 0.678069\n",
      "epoch 12; iter: 0; batch classifier loss: 0.337336; batch adversarial loss: 0.671291\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408835; batch adversarial loss: 0.674635\n",
      "epoch 14; iter: 0; batch classifier loss: 0.389783; batch adversarial loss: 0.657078\n",
      "epoch 15; iter: 0; batch classifier loss: 0.403896; batch adversarial loss: 0.664133\n",
      "epoch 16; iter: 0; batch classifier loss: 0.424375; batch adversarial loss: 0.677202\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365702; batch adversarial loss: 0.654363\n",
      "epoch 18; iter: 0; batch classifier loss: 0.345787; batch adversarial loss: 0.636293\n",
      "epoch 19; iter: 0; batch classifier loss: 0.369792; batch adversarial loss: 0.633814\n",
      "epoch 20; iter: 0; batch classifier loss: 0.409510; batch adversarial loss: 0.640451\n",
      "epoch 21; iter: 0; batch classifier loss: 0.321643; batch adversarial loss: 0.658891\n",
      "epoch 22; iter: 0; batch classifier loss: 0.483471; batch adversarial loss: 0.618647\n",
      "epoch 23; iter: 0; batch classifier loss: 0.417212; batch adversarial loss: 0.645769\n",
      "epoch 24; iter: 0; batch classifier loss: 0.303708; batch adversarial loss: 0.614579\n",
      "epoch 25; iter: 0; batch classifier loss: 0.300819; batch adversarial loss: 0.611950\n",
      "epoch 26; iter: 0; batch classifier loss: 0.335402; batch adversarial loss: 0.641436\n",
      "epoch 27; iter: 0; batch classifier loss: 0.278244; batch adversarial loss: 0.647600\n",
      "epoch 28; iter: 0; batch classifier loss: 0.311041; batch adversarial loss: 0.666166\n",
      "epoch 29; iter: 0; batch classifier loss: 0.370352; batch adversarial loss: 0.606977\n",
      "epoch 30; iter: 0; batch classifier loss: 0.394269; batch adversarial loss: 0.609070\n",
      "epoch 31; iter: 0; batch classifier loss: 0.394910; batch adversarial loss: 0.591935\n",
      "epoch 32; iter: 0; batch classifier loss: 0.329368; batch adversarial loss: 0.605591\n",
      "epoch 33; iter: 0; batch classifier loss: 0.323999; batch adversarial loss: 0.617880\n",
      "epoch 34; iter: 0; batch classifier loss: 0.437101; batch adversarial loss: 0.633107\n",
      "epoch 35; iter: 0; batch classifier loss: 0.321151; batch adversarial loss: 0.613234\n",
      "epoch 36; iter: 0; batch classifier loss: 0.256070; batch adversarial loss: 0.653350\n",
      "epoch 37; iter: 0; batch classifier loss: 0.404831; batch adversarial loss: 0.639664\n",
      "epoch 38; iter: 0; batch classifier loss: 0.307554; batch adversarial loss: 0.596339\n",
      "epoch 39; iter: 0; batch classifier loss: 0.196747; batch adversarial loss: 0.579362\n",
      "epoch 0; iter: 0; batch classifier loss: 0.720633; batch adversarial loss: 0.661082\n",
      "epoch 1; iter: 0; batch classifier loss: 0.717677; batch adversarial loss: 0.669868\n",
      "epoch 2; iter: 0; batch classifier loss: 0.708888; batch adversarial loss: 0.647265\n",
      "epoch 3; iter: 0; batch classifier loss: 0.661773; batch adversarial loss: 0.631508\n",
      "epoch 4; iter: 0; batch classifier loss: 0.654508; batch adversarial loss: 0.621271\n",
      "epoch 5; iter: 0; batch classifier loss: 0.663217; batch adversarial loss: 0.656714\n",
      "epoch 6; iter: 0; batch classifier loss: 0.610553; batch adversarial loss: 0.633473\n",
      "epoch 7; iter: 0; batch classifier loss: 0.618262; batch adversarial loss: 0.618994\n",
      "epoch 8; iter: 0; batch classifier loss: 0.581766; batch adversarial loss: 0.677745\n",
      "epoch 9; iter: 0; batch classifier loss: 0.512609; batch adversarial loss: 0.650391\n",
      "epoch 10; iter: 0; batch classifier loss: 0.585795; batch adversarial loss: 0.660885\n",
      "epoch 11; iter: 0; batch classifier loss: 0.553333; batch adversarial loss: 0.643535\n",
      "epoch 12; iter: 0; batch classifier loss: 0.497732; batch adversarial loss: 0.670972\n",
      "epoch 13; iter: 0; batch classifier loss: 0.518331; batch adversarial loss: 0.616263\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501110; batch adversarial loss: 0.708167\n",
      "epoch 15; iter: 0; batch classifier loss: 0.485167; batch adversarial loss: 0.627458\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478633; batch adversarial loss: 0.636849\n",
      "epoch 17; iter: 0; batch classifier loss: 0.409569; batch adversarial loss: 0.637663\n",
      "epoch 18; iter: 0; batch classifier loss: 0.419911; batch adversarial loss: 0.637589\n",
      "epoch 19; iter: 0; batch classifier loss: 0.412848; batch adversarial loss: 0.664321\n",
      "epoch 20; iter: 0; batch classifier loss: 0.434995; batch adversarial loss: 0.603053\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459011; batch adversarial loss: 0.651012\n",
      "epoch 22; iter: 0; batch classifier loss: 0.407616; batch adversarial loss: 0.671039\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398231; batch adversarial loss: 0.649835\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416739; batch adversarial loss: 0.614196\n",
      "epoch 25; iter: 0; batch classifier loss: 0.377001; batch adversarial loss: 0.636895\n",
      "epoch 26; iter: 0; batch classifier loss: 0.337268; batch adversarial loss: 0.641685\n",
      "epoch 27; iter: 0; batch classifier loss: 0.325569; batch adversarial loss: 0.582619\n",
      "epoch 28; iter: 0; batch classifier loss: 0.395250; batch adversarial loss: 0.616347\n",
      "epoch 29; iter: 0; batch classifier loss: 0.394629; batch adversarial loss: 0.618106\n",
      "epoch 30; iter: 0; batch classifier loss: 0.418015; batch adversarial loss: 0.599818\n",
      "epoch 31; iter: 0; batch classifier loss: 0.438822; batch adversarial loss: 0.605874\n",
      "epoch 32; iter: 0; batch classifier loss: 0.386957; batch adversarial loss: 0.657916\n",
      "epoch 33; iter: 0; batch classifier loss: 0.307780; batch adversarial loss: 0.638696\n",
      "epoch 34; iter: 0; batch classifier loss: 0.334575; batch adversarial loss: 0.643426\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396484; batch adversarial loss: 0.635193\n",
      "epoch 36; iter: 0; batch classifier loss: 0.333976; batch adversarial loss: 0.640847\n",
      "epoch 37; iter: 0; batch classifier loss: 0.298546; batch adversarial loss: 0.686095\n",
      "epoch 38; iter: 0; batch classifier loss: 0.398953; batch adversarial loss: 0.626046\n",
      "epoch 39; iter: 0; batch classifier loss: 0.342497; batch adversarial loss: 0.604243\n",
      "epoch 0; iter: 0; batch classifier loss: 0.700629; batch adversarial loss: 0.583376\n",
      "epoch 1; iter: 0; batch classifier loss: 0.647489; batch adversarial loss: 0.605645\n",
      "epoch 2; iter: 0; batch classifier loss: 0.631700; batch adversarial loss: 0.618193\n",
      "epoch 3; iter: 0; batch classifier loss: 0.615015; batch adversarial loss: 0.612293\n",
      "epoch 4; iter: 0; batch classifier loss: 0.595073; batch adversarial loss: 0.612879\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555242; batch adversarial loss: 0.581578\n",
      "epoch 6; iter: 0; batch classifier loss: 0.550998; batch adversarial loss: 0.626287\n",
      "epoch 7; iter: 0; batch classifier loss: 0.498006; batch adversarial loss: 0.611294\n",
      "epoch 8; iter: 0; batch classifier loss: 0.491818; batch adversarial loss: 0.627542\n",
      "epoch 9; iter: 0; batch classifier loss: 0.501673; batch adversarial loss: 0.619405\n",
      "epoch 10; iter: 0; batch classifier loss: 0.505940; batch adversarial loss: 0.627376\n",
      "epoch 11; iter: 0; batch classifier loss: 0.414566; batch adversarial loss: 0.592695\n",
      "epoch 12; iter: 0; batch classifier loss: 0.426965; batch adversarial loss: 0.643523\n",
      "epoch 13; iter: 0; batch classifier loss: 0.466666; batch adversarial loss: 0.606412\n",
      "epoch 14; iter: 0; batch classifier loss: 0.444847; batch adversarial loss: 0.625131\n",
      "epoch 15; iter: 0; batch classifier loss: 0.379022; batch adversarial loss: 0.597058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.380854; batch adversarial loss: 0.590970\n",
      "epoch 17; iter: 0; batch classifier loss: 0.379814; batch adversarial loss: 0.638330\n",
      "epoch 18; iter: 0; batch classifier loss: 0.431786; batch adversarial loss: 0.594139\n",
      "epoch 19; iter: 0; batch classifier loss: 0.456599; batch adversarial loss: 0.611421\n",
      "epoch 20; iter: 0; batch classifier loss: 0.361552; batch adversarial loss: 0.603780\n",
      "epoch 21; iter: 0; batch classifier loss: 0.367528; batch adversarial loss: 0.604309\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361785; batch adversarial loss: 0.633672\n",
      "epoch 23; iter: 0; batch classifier loss: 0.412151; batch adversarial loss: 0.626356\n",
      "epoch 24; iter: 0; batch classifier loss: 0.397607; batch adversarial loss: 0.572738\n",
      "epoch 25; iter: 0; batch classifier loss: 0.396764; batch adversarial loss: 0.591796\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340550; batch adversarial loss: 0.588558\n",
      "epoch 27; iter: 0; batch classifier loss: 0.386785; batch adversarial loss: 0.612278\n",
      "epoch 28; iter: 0; batch classifier loss: 0.360440; batch adversarial loss: 0.622342\n",
      "epoch 29; iter: 0; batch classifier loss: 0.363027; batch adversarial loss: 0.616604\n",
      "epoch 30; iter: 0; batch classifier loss: 0.425371; batch adversarial loss: 0.613364\n",
      "epoch 31; iter: 0; batch classifier loss: 0.339188; batch adversarial loss: 0.621195\n",
      "epoch 32; iter: 0; batch classifier loss: 0.410794; batch adversarial loss: 0.593359\n",
      "epoch 33; iter: 0; batch classifier loss: 0.386602; batch adversarial loss: 0.613102\n",
      "epoch 34; iter: 0; batch classifier loss: 0.410764; batch adversarial loss: 0.612227\n",
      "epoch 35; iter: 0; batch classifier loss: 0.303505; batch adversarial loss: 0.636794\n",
      "epoch 36; iter: 0; batch classifier loss: 0.377009; batch adversarial loss: 0.638124\n",
      "epoch 37; iter: 0; batch classifier loss: 0.373642; batch adversarial loss: 0.623515\n",
      "epoch 38; iter: 0; batch classifier loss: 0.329587; batch adversarial loss: 0.635181\n",
      "epoch 39; iter: 0; batch classifier loss: 0.335592; batch adversarial loss: 0.613055\n",
      "epoch 0; iter: 0; batch classifier loss: 0.751594; batch adversarial loss: 0.737543\n",
      "epoch 1; iter: 0; batch classifier loss: 0.708672; batch adversarial loss: 0.721456\n",
      "epoch 2; iter: 0; batch classifier loss: 0.692416; batch adversarial loss: 0.702797\n",
      "epoch 3; iter: 0; batch classifier loss: 0.630750; batch adversarial loss: 0.788460\n",
      "epoch 4; iter: 0; batch classifier loss: 0.622055; batch adversarial loss: 0.771657\n",
      "epoch 5; iter: 0; batch classifier loss: 0.552764; batch adversarial loss: 0.768848\n",
      "epoch 6; iter: 0; batch classifier loss: 0.564134; batch adversarial loss: 0.724715\n",
      "epoch 7; iter: 0; batch classifier loss: 0.486124; batch adversarial loss: 0.734934\n",
      "epoch 8; iter: 0; batch classifier loss: 0.497390; batch adversarial loss: 0.728889\n",
      "epoch 9; iter: 0; batch classifier loss: 0.470435; batch adversarial loss: 0.712788\n",
      "epoch 10; iter: 0; batch classifier loss: 0.456884; batch adversarial loss: 0.729569\n",
      "epoch 11; iter: 0; batch classifier loss: 0.483237; batch adversarial loss: 0.780037\n",
      "epoch 12; iter: 0; batch classifier loss: 0.481515; batch adversarial loss: 0.779620\n",
      "epoch 13; iter: 0; batch classifier loss: 0.402907; batch adversarial loss: 0.821681\n",
      "epoch 14; iter: 0; batch classifier loss: 0.459824; batch adversarial loss: 0.744396\n",
      "epoch 15; iter: 0; batch classifier loss: 0.420913; batch adversarial loss: 0.779798\n",
      "epoch 16; iter: 0; batch classifier loss: 0.388727; batch adversarial loss: 0.718802\n",
      "epoch 17; iter: 0; batch classifier loss: 0.377954; batch adversarial loss: 0.780722\n",
      "epoch 18; iter: 0; batch classifier loss: 0.361899; batch adversarial loss: 0.717319\n",
      "epoch 19; iter: 0; batch classifier loss: 0.316786; batch adversarial loss: 0.741613\n",
      "epoch 20; iter: 0; batch classifier loss: 0.402081; batch adversarial loss: 0.726791\n",
      "epoch 21; iter: 0; batch classifier loss: 0.484993; batch adversarial loss: 0.718234\n",
      "epoch 22; iter: 0; batch classifier loss: 0.332491; batch adversarial loss: 0.708414\n",
      "epoch 23; iter: 0; batch classifier loss: 0.387215; batch adversarial loss: 0.724665\n",
      "epoch 24; iter: 0; batch classifier loss: 0.284195; batch adversarial loss: 0.730848\n",
      "epoch 25; iter: 0; batch classifier loss: 0.277610; batch adversarial loss: 0.711293\n",
      "epoch 26; iter: 0; batch classifier loss: 0.340780; batch adversarial loss: 0.706337\n",
      "epoch 27; iter: 0; batch classifier loss: 0.367439; batch adversarial loss: 0.729329\n",
      "epoch 28; iter: 0; batch classifier loss: 0.266283; batch adversarial loss: 0.701486\n",
      "epoch 29; iter: 0; batch classifier loss: 0.379407; batch adversarial loss: 0.679599\n",
      "epoch 30; iter: 0; batch classifier loss: 0.288737; batch adversarial loss: 0.682037\n",
      "epoch 31; iter: 0; batch classifier loss: 0.359250; batch adversarial loss: 0.688402\n",
      "epoch 32; iter: 0; batch classifier loss: 0.331540; batch adversarial loss: 0.660241\n",
      "epoch 33; iter: 0; batch classifier loss: 0.233434; batch adversarial loss: 0.684183\n",
      "epoch 34; iter: 0; batch classifier loss: 0.325748; batch adversarial loss: 0.709547\n",
      "epoch 35; iter: 0; batch classifier loss: 0.389798; batch adversarial loss: 0.675403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.371773; batch adversarial loss: 0.640618\n",
      "epoch 37; iter: 0; batch classifier loss: 0.310813; batch adversarial loss: 0.653338\n",
      "epoch 38; iter: 0; batch classifier loss: 0.418183; batch adversarial loss: 0.647916\n",
      "epoch 39; iter: 0; batch classifier loss: 0.385157; batch adversarial loss: 0.612416\n",
      "epoch 40; iter: 0; batch classifier loss: 0.367866; batch adversarial loss: 0.641299\n",
      "epoch 41; iter: 0; batch classifier loss: 0.325743; batch adversarial loss: 0.662490\n",
      "epoch 42; iter: 0; batch classifier loss: 0.429408; batch adversarial loss: 0.671859\n",
      "epoch 43; iter: 0; batch classifier loss: 0.302086; batch adversarial loss: 0.666838\n",
      "epoch 44; iter: 0; batch classifier loss: 0.349478; batch adversarial loss: 0.700866\n",
      "epoch 45; iter: 0; batch classifier loss: 0.321215; batch adversarial loss: 0.646149\n",
      "epoch 46; iter: 0; batch classifier loss: 0.354730; batch adversarial loss: 0.650282\n",
      "epoch 47; iter: 0; batch classifier loss: 0.309254; batch adversarial loss: 0.633817\n",
      "epoch 48; iter: 0; batch classifier loss: 0.261969; batch adversarial loss: 0.620052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.384010; batch adversarial loss: 0.650814\n",
      "epoch 50; iter: 0; batch classifier loss: 0.272725; batch adversarial loss: 0.594135\n",
      "epoch 51; iter: 0; batch classifier loss: 0.285778; batch adversarial loss: 0.628807\n",
      "epoch 52; iter: 0; batch classifier loss: 0.350557; batch adversarial loss: 0.609118\n",
      "epoch 53; iter: 0; batch classifier loss: 0.279389; batch adversarial loss: 0.638192\n",
      "epoch 54; iter: 0; batch classifier loss: 0.256440; batch adversarial loss: 0.603568\n",
      "epoch 55; iter: 0; batch classifier loss: 0.304015; batch adversarial loss: 0.657077\n",
      "epoch 56; iter: 0; batch classifier loss: 0.253575; batch adversarial loss: 0.605679\n",
      "epoch 57; iter: 0; batch classifier loss: 0.274179; batch adversarial loss: 0.639346\n",
      "epoch 58; iter: 0; batch classifier loss: 0.287189; batch adversarial loss: 0.605200\n",
      "epoch 59; iter: 0; batch classifier loss: 0.356443; batch adversarial loss: 0.588403\n",
      "epoch 0; iter: 0; batch classifier loss: 0.732230; batch adversarial loss: 0.731148\n",
      "epoch 1; iter: 0; batch classifier loss: 0.655735; batch adversarial loss: 0.755334\n",
      "epoch 2; iter: 0; batch classifier loss: 0.617405; batch adversarial loss: 0.741125\n",
      "epoch 3; iter: 0; batch classifier loss: 0.538279; batch adversarial loss: 0.748406\n",
      "epoch 4; iter: 0; batch classifier loss: 0.537930; batch adversarial loss: 0.746176\n",
      "epoch 5; iter: 0; batch classifier loss: 0.514586; batch adversarial loss: 0.730854\n",
      "epoch 6; iter: 0; batch classifier loss: 0.488621; batch adversarial loss: 0.740848\n",
      "epoch 7; iter: 0; batch classifier loss: 0.434051; batch adversarial loss: 0.731306\n",
      "epoch 8; iter: 0; batch classifier loss: 0.438036; batch adversarial loss: 0.734795\n",
      "epoch 9; iter: 0; batch classifier loss: 0.430091; batch adversarial loss: 0.740651\n",
      "epoch 10; iter: 0; batch classifier loss: 0.428417; batch adversarial loss: 0.735331\n",
      "epoch 11; iter: 0; batch classifier loss: 0.335067; batch adversarial loss: 0.729112\n",
      "epoch 12; iter: 0; batch classifier loss: 0.403007; batch adversarial loss: 0.693423\n",
      "epoch 13; iter: 0; batch classifier loss: 0.528884; batch adversarial loss: 0.700277\n",
      "epoch 14; iter: 0; batch classifier loss: 0.363984; batch adversarial loss: 0.708353\n",
      "epoch 15; iter: 0; batch classifier loss: 0.385633; batch adversarial loss: 0.729108\n",
      "epoch 16; iter: 0; batch classifier loss: 0.408496; batch adversarial loss: 0.693384\n",
      "epoch 17; iter: 0; batch classifier loss: 0.349939; batch adversarial loss: 0.700731\n",
      "epoch 18; iter: 0; batch classifier loss: 0.286619; batch adversarial loss: 0.664455\n",
      "epoch 19; iter: 0; batch classifier loss: 0.344011; batch adversarial loss: 0.687793\n",
      "epoch 20; iter: 0; batch classifier loss: 0.378411; batch adversarial loss: 0.690522\n",
      "epoch 21; iter: 0; batch classifier loss: 0.281320; batch adversarial loss: 0.670986\n",
      "epoch 22; iter: 0; batch classifier loss: 0.319162; batch adversarial loss: 0.681901\n",
      "epoch 23; iter: 0; batch classifier loss: 0.416098; batch adversarial loss: 0.698402\n",
      "epoch 24; iter: 0; batch classifier loss: 0.339590; batch adversarial loss: 0.664115\n",
      "epoch 25; iter: 0; batch classifier loss: 0.258114; batch adversarial loss: 0.678574\n",
      "epoch 26; iter: 0; batch classifier loss: 0.276100; batch adversarial loss: 0.673778\n",
      "epoch 27; iter: 0; batch classifier loss: 0.229945; batch adversarial loss: 0.666896\n",
      "epoch 28; iter: 0; batch classifier loss: 0.346034; batch adversarial loss: 0.663740\n",
      "epoch 29; iter: 0; batch classifier loss: 0.290993; batch adversarial loss: 0.664649\n",
      "epoch 30; iter: 0; batch classifier loss: 0.296793; batch adversarial loss: 0.644342\n",
      "epoch 31; iter: 0; batch classifier loss: 0.207150; batch adversarial loss: 0.666015\n",
      "epoch 32; iter: 0; batch classifier loss: 0.418710; batch adversarial loss: 0.665698\n",
      "epoch 33; iter: 0; batch classifier loss: 0.275819; batch adversarial loss: 0.655531\n",
      "epoch 34; iter: 0; batch classifier loss: 0.256410; batch adversarial loss: 0.648631\n",
      "epoch 35; iter: 0; batch classifier loss: 0.314615; batch adversarial loss: 0.631971\n",
      "epoch 36; iter: 0; batch classifier loss: 0.247274; batch adversarial loss: 0.621164\n",
      "epoch 37; iter: 0; batch classifier loss: 0.378212; batch adversarial loss: 0.634090\n",
      "epoch 38; iter: 0; batch classifier loss: 0.441133; batch adversarial loss: 0.618609\n",
      "epoch 39; iter: 0; batch classifier loss: 0.326000; batch adversarial loss: 0.652523\n",
      "epoch 40; iter: 0; batch classifier loss: 0.339171; batch adversarial loss: 0.617734\n",
      "epoch 41; iter: 0; batch classifier loss: 0.340380; batch adversarial loss: 0.636697\n",
      "epoch 42; iter: 0; batch classifier loss: 0.339394; batch adversarial loss: 0.596054\n",
      "epoch 43; iter: 0; batch classifier loss: 0.243341; batch adversarial loss: 0.612471\n",
      "epoch 44; iter: 0; batch classifier loss: 0.246173; batch adversarial loss: 0.629567\n",
      "epoch 45; iter: 0; batch classifier loss: 0.222608; batch adversarial loss: 0.577490\n",
      "epoch 46; iter: 0; batch classifier loss: 0.293909; batch adversarial loss: 0.622744\n",
      "epoch 47; iter: 0; batch classifier loss: 0.297080; batch adversarial loss: 0.619081\n",
      "epoch 48; iter: 0; batch classifier loss: 0.223370; batch adversarial loss: 0.602103\n",
      "epoch 49; iter: 0; batch classifier loss: 0.311226; batch adversarial loss: 0.619103\n",
      "epoch 50; iter: 0; batch classifier loss: 0.392687; batch adversarial loss: 0.622763\n",
      "epoch 51; iter: 0; batch classifier loss: 0.280633; batch adversarial loss: 0.555036\n",
      "epoch 52; iter: 0; batch classifier loss: 0.221593; batch adversarial loss: 0.575355\n",
      "epoch 53; iter: 0; batch classifier loss: 0.322147; batch adversarial loss: 0.651688\n",
      "epoch 54; iter: 0; batch classifier loss: 0.262194; batch adversarial loss: 0.613915\n",
      "epoch 55; iter: 0; batch classifier loss: 0.346247; batch adversarial loss: 0.597714\n",
      "epoch 56; iter: 0; batch classifier loss: 0.240845; batch adversarial loss: 0.612571\n",
      "epoch 57; iter: 0; batch classifier loss: 0.235974; batch adversarial loss: 0.606573\n",
      "epoch 58; iter: 0; batch classifier loss: 0.349883; batch adversarial loss: 0.654331\n",
      "epoch 59; iter: 0; batch classifier loss: 0.253919; batch adversarial loss: 0.604307\n",
      "epoch 0; iter: 0; batch classifier loss: 0.800577; batch adversarial loss: 0.702971\n",
      "epoch 1; iter: 0; batch classifier loss: 0.752999; batch adversarial loss: 0.702994\n",
      "epoch 2; iter: 0; batch classifier loss: 0.715721; batch adversarial loss: 0.700943\n",
      "epoch 3; iter: 0; batch classifier loss: 0.674886; batch adversarial loss: 0.698880\n",
      "epoch 4; iter: 0; batch classifier loss: 0.665943; batch adversarial loss: 0.698595\n",
      "epoch 5; iter: 0; batch classifier loss: 0.633599; batch adversarial loss: 0.695580\n",
      "epoch 6; iter: 0; batch classifier loss: 0.583495; batch adversarial loss: 0.692817\n",
      "epoch 7; iter: 0; batch classifier loss: 0.653872; batch adversarial loss: 0.691507\n",
      "epoch 8; iter: 0; batch classifier loss: 0.575379; batch adversarial loss: 0.688170\n",
      "epoch 9; iter: 0; batch classifier loss: 0.641318; batch adversarial loss: 0.689343\n",
      "epoch 10; iter: 0; batch classifier loss: 0.569895; batch adversarial loss: 0.684502\n",
      "epoch 11; iter: 0; batch classifier loss: 0.573396; batch adversarial loss: 0.688131\n",
      "epoch 12; iter: 0; batch classifier loss: 0.513917; batch adversarial loss: 0.679502\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501986; batch adversarial loss: 0.681498\n",
      "epoch 14; iter: 0; batch classifier loss: 0.528945; batch adversarial loss: 0.680770\n",
      "epoch 15; iter: 0; batch classifier loss: 0.495067; batch adversarial loss: 0.678241\n",
      "epoch 16; iter: 0; batch classifier loss: 0.540843; batch adversarial loss: 0.681035\n",
      "epoch 17; iter: 0; batch classifier loss: 0.517945; batch adversarial loss: 0.676885\n",
      "epoch 18; iter: 0; batch classifier loss: 0.501074; batch adversarial loss: 0.668677\n",
      "epoch 19; iter: 0; batch classifier loss: 0.500529; batch adversarial loss: 0.671364\n",
      "epoch 20; iter: 0; batch classifier loss: 0.495109; batch adversarial loss: 0.666525\n",
      "epoch 21; iter: 0; batch classifier loss: 0.451534; batch adversarial loss: 0.667336\n",
      "epoch 22; iter: 0; batch classifier loss: 0.477830; batch adversarial loss: 0.658037\n",
      "epoch 23; iter: 0; batch classifier loss: 0.472956; batch adversarial loss: 0.664843\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430148; batch adversarial loss: 0.651376\n",
      "epoch 25; iter: 0; batch classifier loss: 0.391931; batch adversarial loss: 0.652373\n",
      "epoch 26; iter: 0; batch classifier loss: 0.418922; batch adversarial loss: 0.652447\n",
      "epoch 27; iter: 0; batch classifier loss: 0.484807; batch adversarial loss: 0.646352\n",
      "epoch 28; iter: 0; batch classifier loss: 0.486569; batch adversarial loss: 0.653645\n",
      "epoch 29; iter: 0; batch classifier loss: 0.420473; batch adversarial loss: 0.649548\n",
      "epoch 30; iter: 0; batch classifier loss: 0.408838; batch adversarial loss: 0.629751\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416353; batch adversarial loss: 0.639590\n",
      "epoch 32; iter: 0; batch classifier loss: 0.385550; batch adversarial loss: 0.658786\n",
      "epoch 33; iter: 0; batch classifier loss: 0.346164; batch adversarial loss: 0.644633\n",
      "epoch 34; iter: 0; batch classifier loss: 0.388669; batch adversarial loss: 0.654586\n",
      "epoch 35; iter: 0; batch classifier loss: 0.386751; batch adversarial loss: 0.629629\n",
      "epoch 36; iter: 0; batch classifier loss: 0.376518; batch adversarial loss: 0.657081\n",
      "epoch 37; iter: 0; batch classifier loss: 0.412743; batch adversarial loss: 0.655282\n",
      "epoch 38; iter: 0; batch classifier loss: 0.359563; batch adversarial loss: 0.635741\n",
      "epoch 39; iter: 0; batch classifier loss: 0.448190; batch adversarial loss: 0.654854\n",
      "epoch 40; iter: 0; batch classifier loss: 0.344546; batch adversarial loss: 0.633111\n",
      "epoch 41; iter: 0; batch classifier loss: 0.439737; batch adversarial loss: 0.635179\n",
      "epoch 42; iter: 0; batch classifier loss: 0.364789; batch adversarial loss: 0.631180\n",
      "epoch 43; iter: 0; batch classifier loss: 0.369416; batch adversarial loss: 0.625037\n",
      "epoch 44; iter: 0; batch classifier loss: 0.365096; batch adversarial loss: 0.639118\n",
      "epoch 45; iter: 0; batch classifier loss: 0.436024; batch adversarial loss: 0.632430\n",
      "epoch 46; iter: 0; batch classifier loss: 0.413960; batch adversarial loss: 0.643006\n",
      "epoch 47; iter: 0; batch classifier loss: 0.287491; batch adversarial loss: 0.633643\n",
      "epoch 48; iter: 0; batch classifier loss: 0.390511; batch adversarial loss: 0.638665\n",
      "epoch 49; iter: 0; batch classifier loss: 0.450806; batch adversarial loss: 0.626625\n",
      "epoch 50; iter: 0; batch classifier loss: 0.322777; batch adversarial loss: 0.644400\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397548; batch adversarial loss: 0.628232\n",
      "epoch 52; iter: 0; batch classifier loss: 0.300756; batch adversarial loss: 0.607233\n",
      "epoch 53; iter: 0; batch classifier loss: 0.332534; batch adversarial loss: 0.641643\n",
      "epoch 54; iter: 0; batch classifier loss: 0.340177; batch adversarial loss: 0.656701\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387945; batch adversarial loss: 0.618569\n",
      "epoch 56; iter: 0; batch classifier loss: 0.324666; batch adversarial loss: 0.633129\n",
      "epoch 57; iter: 0; batch classifier loss: 0.405140; batch adversarial loss: 0.631064\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366615; batch adversarial loss: 0.634126\n",
      "epoch 59; iter: 0; batch classifier loss: 0.308977; batch adversarial loss: 0.619905\n",
      "epoch 0; iter: 0; batch classifier loss: 0.673247; batch adversarial loss: 0.954838\n",
      "epoch 1; iter: 0; batch classifier loss: 0.664367; batch adversarial loss: 0.997905\n",
      "epoch 2; iter: 0; batch classifier loss: 0.614125; batch adversarial loss: 1.021920\n",
      "epoch 3; iter: 0; batch classifier loss: 0.626872; batch adversarial loss: 1.036078\n",
      "epoch 4; iter: 0; batch classifier loss: 0.616487; batch adversarial loss: 1.008889\n",
      "epoch 5; iter: 0; batch classifier loss: 0.579720; batch adversarial loss: 1.032872\n",
      "epoch 6; iter: 0; batch classifier loss: 0.558940; batch adversarial loss: 1.060140\n",
      "epoch 7; iter: 0; batch classifier loss: 0.566327; batch adversarial loss: 1.043222\n",
      "epoch 8; iter: 0; batch classifier loss: 0.614090; batch adversarial loss: 1.069947\n",
      "epoch 9; iter: 0; batch classifier loss: 0.570066; batch adversarial loss: 1.048936\n",
      "epoch 10; iter: 0; batch classifier loss: 0.635132; batch adversarial loss: 1.138774\n",
      "epoch 11; iter: 0; batch classifier loss: 0.614251; batch adversarial loss: 1.101344\n",
      "epoch 12; iter: 0; batch classifier loss: 0.550754; batch adversarial loss: 1.041025\n",
      "epoch 13; iter: 0; batch classifier loss: 0.578587; batch adversarial loss: 1.073930\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586465; batch adversarial loss: 1.138626\n",
      "epoch 15; iter: 0; batch classifier loss: 0.583818; batch adversarial loss: 1.111809\n",
      "epoch 16; iter: 0; batch classifier loss: 0.620519; batch adversarial loss: 1.142437\n",
      "epoch 17; iter: 0; batch classifier loss: 0.664816; batch adversarial loss: 1.188056\n",
      "epoch 18; iter: 0; batch classifier loss: 0.689283; batch adversarial loss: 1.178782\n",
      "epoch 19; iter: 0; batch classifier loss: 0.664408; batch adversarial loss: 1.110873\n",
      "epoch 20; iter: 0; batch classifier loss: 0.785984; batch adversarial loss: 1.161090\n",
      "epoch 21; iter: 0; batch classifier loss: 0.711008; batch adversarial loss: 1.192958\n",
      "epoch 22; iter: 0; batch classifier loss: 0.643452; batch adversarial loss: 1.088051\n",
      "epoch 23; iter: 0; batch classifier loss: 0.807926; batch adversarial loss: 1.151644\n",
      "epoch 24; iter: 0; batch classifier loss: 0.595428; batch adversarial loss: 1.040223\n",
      "epoch 25; iter: 0; batch classifier loss: 0.666939; batch adversarial loss: 1.146140\n",
      "epoch 26; iter: 0; batch classifier loss: 0.704565; batch adversarial loss: 1.151456\n",
      "epoch 27; iter: 0; batch classifier loss: 0.606463; batch adversarial loss: 1.091621\n",
      "epoch 28; iter: 0; batch classifier loss: 0.850412; batch adversarial loss: 1.173063\n",
      "epoch 29; iter: 0; batch classifier loss: 0.766577; batch adversarial loss: 1.133107\n",
      "epoch 30; iter: 0; batch classifier loss: 0.650934; batch adversarial loss: 1.096773\n",
      "epoch 31; iter: 0; batch classifier loss: 0.780202; batch adversarial loss: 1.190685\n",
      "epoch 32; iter: 0; batch classifier loss: 0.637152; batch adversarial loss: 1.059892\n",
      "epoch 33; iter: 0; batch classifier loss: 0.738087; batch adversarial loss: 1.097469\n",
      "epoch 34; iter: 0; batch classifier loss: 0.656506; batch adversarial loss: 1.050478\n",
      "epoch 35; iter: 0; batch classifier loss: 0.667349; batch adversarial loss: 1.076674\n",
      "epoch 36; iter: 0; batch classifier loss: 0.788153; batch adversarial loss: 1.149178\n",
      "epoch 37; iter: 0; batch classifier loss: 0.705621; batch adversarial loss: 1.118584\n",
      "epoch 38; iter: 0; batch classifier loss: 0.738138; batch adversarial loss: 1.097206\n",
      "epoch 39; iter: 0; batch classifier loss: 0.791590; batch adversarial loss: 1.147220\n",
      "epoch 40; iter: 0; batch classifier loss: 0.856031; batch adversarial loss: 1.142076\n",
      "epoch 41; iter: 0; batch classifier loss: 0.859573; batch adversarial loss: 1.134420\n",
      "epoch 42; iter: 0; batch classifier loss: 0.698415; batch adversarial loss: 1.047118\n",
      "epoch 43; iter: 0; batch classifier loss: 0.834213; batch adversarial loss: 1.129446\n",
      "epoch 44; iter: 0; batch classifier loss: 0.765029; batch adversarial loss: 1.083192\n",
      "epoch 45; iter: 0; batch classifier loss: 0.798552; batch adversarial loss: 1.088760\n",
      "epoch 46; iter: 0; batch classifier loss: 0.780102; batch adversarial loss: 1.064749\n",
      "epoch 47; iter: 0; batch classifier loss: 0.816131; batch adversarial loss: 1.088331\n",
      "epoch 48; iter: 0; batch classifier loss: 0.753618; batch adversarial loss: 1.077768\n",
      "epoch 49; iter: 0; batch classifier loss: 0.842175; batch adversarial loss: 1.063521\n",
      "epoch 50; iter: 0; batch classifier loss: 0.824637; batch adversarial loss: 1.084507\n",
      "epoch 51; iter: 0; batch classifier loss: 0.865286; batch adversarial loss: 1.065232\n",
      "epoch 52; iter: 0; batch classifier loss: 0.806828; batch adversarial loss: 1.055166\n",
      "epoch 53; iter: 0; batch classifier loss: 0.889276; batch adversarial loss: 1.076207\n",
      "epoch 54; iter: 0; batch classifier loss: 0.804317; batch adversarial loss: 1.042057\n",
      "epoch 55; iter: 0; batch classifier loss: 0.851372; batch adversarial loss: 1.027215\n",
      "epoch 56; iter: 0; batch classifier loss: 1.010677; batch adversarial loss: 1.079218\n",
      "epoch 57; iter: 0; batch classifier loss: 0.906737; batch adversarial loss: 1.052319\n",
      "epoch 58; iter: 0; batch classifier loss: 0.892488; batch adversarial loss: 1.038929\n",
      "epoch 59; iter: 0; batch classifier loss: 0.853560; batch adversarial loss: 1.015991\n",
      "epoch 0; iter: 0; batch classifier loss: 0.736651; batch adversarial loss: 0.729225\n",
      "epoch 1; iter: 0; batch classifier loss: 0.694330; batch adversarial loss: 0.696293\n",
      "epoch 2; iter: 0; batch classifier loss: 0.696882; batch adversarial loss: 0.741607\n",
      "epoch 3; iter: 0; batch classifier loss: 0.656186; batch adversarial loss: 0.687963\n",
      "epoch 4; iter: 0; batch classifier loss: 0.627339; batch adversarial loss: 0.724517\n",
      "epoch 5; iter: 0; batch classifier loss: 0.589922; batch adversarial loss: 0.700019\n",
      "epoch 6; iter: 0; batch classifier loss: 0.584557; batch adversarial loss: 0.678120\n",
      "epoch 7; iter: 0; batch classifier loss: 0.562368; batch adversarial loss: 0.666925\n",
      "epoch 8; iter: 0; batch classifier loss: 0.595521; batch adversarial loss: 0.668037\n",
      "epoch 9; iter: 0; batch classifier loss: 0.542259; batch adversarial loss: 0.627326\n",
      "epoch 10; iter: 0; batch classifier loss: 0.537659; batch adversarial loss: 0.675298\n",
      "epoch 11; iter: 0; batch classifier loss: 0.519195; batch adversarial loss: 0.684769\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488220; batch adversarial loss: 0.605108\n",
      "epoch 13; iter: 0; batch classifier loss: 0.520384; batch adversarial loss: 0.638232\n",
      "epoch 14; iter: 0; batch classifier loss: 0.527335; batch adversarial loss: 0.596696\n",
      "epoch 15; iter: 0; batch classifier loss: 0.489289; batch adversarial loss: 0.612202\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475438; batch adversarial loss: 0.626176\n",
      "epoch 17; iter: 0; batch classifier loss: 0.481660; batch adversarial loss: 0.619979\n",
      "epoch 18; iter: 0; batch classifier loss: 0.471817; batch adversarial loss: 0.669935\n",
      "epoch 19; iter: 0; batch classifier loss: 0.366442; batch adversarial loss: 0.655597\n",
      "epoch 20; iter: 0; batch classifier loss: 0.474257; batch adversarial loss: 0.630042\n",
      "epoch 21; iter: 0; batch classifier loss: 0.374504; batch adversarial loss: 0.637505\n",
      "epoch 22; iter: 0; batch classifier loss: 0.446286; batch adversarial loss: 0.603836\n",
      "epoch 23; iter: 0; batch classifier loss: 0.425395; batch adversarial loss: 0.613113\n",
      "epoch 24; iter: 0; batch classifier loss: 0.449702; batch adversarial loss: 0.666050\n",
      "epoch 25; iter: 0; batch classifier loss: 0.359229; batch adversarial loss: 0.635011\n",
      "epoch 26; iter: 0; batch classifier loss: 0.440107; batch adversarial loss: 0.668151\n",
      "epoch 27; iter: 0; batch classifier loss: 0.394702; batch adversarial loss: 0.594335\n",
      "epoch 28; iter: 0; batch classifier loss: 0.259326; batch adversarial loss: 0.586343\n",
      "epoch 29; iter: 0; batch classifier loss: 0.280250; batch adversarial loss: 0.595480\n",
      "epoch 30; iter: 0; batch classifier loss: 0.399972; batch adversarial loss: 0.627168\n",
      "epoch 31; iter: 0; batch classifier loss: 0.241230; batch adversarial loss: 0.581318\n",
      "epoch 32; iter: 0; batch classifier loss: 0.358681; batch adversarial loss: 0.647542\n",
      "epoch 33; iter: 0; batch classifier loss: 0.340240; batch adversarial loss: 0.584071\n",
      "epoch 34; iter: 0; batch classifier loss: 0.262449; batch adversarial loss: 0.575897\n",
      "epoch 35; iter: 0; batch classifier loss: 0.435795; batch adversarial loss: 0.653453\n",
      "epoch 36; iter: 0; batch classifier loss: 0.443528; batch adversarial loss: 0.642514\n",
      "epoch 37; iter: 0; batch classifier loss: 0.312857; batch adversarial loss: 0.610774\n",
      "epoch 38; iter: 0; batch classifier loss: 0.282189; batch adversarial loss: 0.577159\n",
      "epoch 39; iter: 0; batch classifier loss: 0.375362; batch adversarial loss: 0.599615\n",
      "epoch 40; iter: 0; batch classifier loss: 0.280160; batch adversarial loss: 0.625070\n",
      "epoch 41; iter: 0; batch classifier loss: 0.476762; batch adversarial loss: 0.586512\n",
      "epoch 42; iter: 0; batch classifier loss: 0.200533; batch adversarial loss: 0.659645\n",
      "epoch 43; iter: 0; batch classifier loss: 0.415968; batch adversarial loss: 0.579551\n",
      "epoch 44; iter: 0; batch classifier loss: 0.393324; batch adversarial loss: 0.569243\n",
      "epoch 45; iter: 0; batch classifier loss: 0.395192; batch adversarial loss: 0.604331\n",
      "epoch 46; iter: 0; batch classifier loss: 0.220725; batch adversarial loss: 0.611530\n",
      "epoch 47; iter: 0; batch classifier loss: 0.215478; batch adversarial loss: 0.497685\n",
      "epoch 48; iter: 0; batch classifier loss: 0.257816; batch adversarial loss: 0.623866\n",
      "epoch 49; iter: 0; batch classifier loss: 0.245096; batch adversarial loss: 0.635264\n",
      "epoch 50; iter: 0; batch classifier loss: 0.330839; batch adversarial loss: 0.637253\n",
      "epoch 51; iter: 0; batch classifier loss: 0.449662; batch adversarial loss: 0.635745\n",
      "epoch 52; iter: 0; batch classifier loss: 0.325670; batch adversarial loss: 0.588349\n",
      "epoch 53; iter: 0; batch classifier loss: 0.295534; batch adversarial loss: 0.588274\n",
      "epoch 54; iter: 0; batch classifier loss: 0.429245; batch adversarial loss: 0.564541\n",
      "epoch 55; iter: 0; batch classifier loss: 0.392821; batch adversarial loss: 0.576730\n",
      "epoch 56; iter: 0; batch classifier loss: 0.263917; batch adversarial loss: 0.589634\n",
      "epoch 57; iter: 0; batch classifier loss: 0.369971; batch adversarial loss: 0.627031\n",
      "epoch 58; iter: 0; batch classifier loss: 0.253728; batch adversarial loss: 0.651507\n",
      "epoch 59; iter: 0; batch classifier loss: 0.363768; batch adversarial loss: 0.584456\n",
      "epoch 60; iter: 0; batch classifier loss: 0.272388; batch adversarial loss: 0.624383\n",
      "epoch 61; iter: 0; batch classifier loss: 0.315412; batch adversarial loss: 0.584093\n",
      "epoch 62; iter: 0; batch classifier loss: 0.131072; batch adversarial loss: 0.603388\n",
      "epoch 63; iter: 0; batch classifier loss: 0.367795; batch adversarial loss: 0.550147\n",
      "epoch 64; iter: 0; batch classifier loss: 0.350806; batch adversarial loss: 0.593740\n",
      "epoch 65; iter: 0; batch classifier loss: 0.303381; batch adversarial loss: 0.585715\n",
      "epoch 66; iter: 0; batch classifier loss: 0.283783; batch adversarial loss: 0.620242\n",
      "epoch 67; iter: 0; batch classifier loss: 0.336299; batch adversarial loss: 0.685388\n",
      "epoch 68; iter: 0; batch classifier loss: 0.386537; batch adversarial loss: 0.602825\n",
      "epoch 69; iter: 0; batch classifier loss: 0.342303; batch adversarial loss: 0.608290\n",
      "epoch 70; iter: 0; batch classifier loss: 0.285535; batch adversarial loss: 0.502245\n",
      "epoch 71; iter: 0; batch classifier loss: 0.256089; batch adversarial loss: 0.552163\n",
      "epoch 72; iter: 0; batch classifier loss: 0.429012; batch adversarial loss: 0.651064\n",
      "epoch 73; iter: 0; batch classifier loss: 0.216722; batch adversarial loss: 0.571432\n",
      "epoch 74; iter: 0; batch classifier loss: 0.332394; batch adversarial loss: 0.608922\n",
      "epoch 75; iter: 0; batch classifier loss: 0.288982; batch adversarial loss: 0.617820\n",
      "epoch 76; iter: 0; batch classifier loss: 0.256548; batch adversarial loss: 0.553506\n",
      "epoch 77; iter: 0; batch classifier loss: 0.256849; batch adversarial loss: 0.518535\n",
      "epoch 78; iter: 0; batch classifier loss: 0.170672; batch adversarial loss: 0.569257\n",
      "epoch 79; iter: 0; batch classifier loss: 0.233898; batch adversarial loss: 0.558669\n",
      "epoch 0; iter: 0; batch classifier loss: 0.708456; batch adversarial loss: 0.600424\n",
      "epoch 1; iter: 0; batch classifier loss: 0.679159; batch adversarial loss: 0.594729\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647132; batch adversarial loss: 0.602292\n",
      "epoch 3; iter: 0; batch classifier loss: 0.543067; batch adversarial loss: 0.619778\n",
      "epoch 4; iter: 0; batch classifier loss: 0.594537; batch adversarial loss: 0.623992\n",
      "epoch 5; iter: 0; batch classifier loss: 0.515033; batch adversarial loss: 0.619402\n",
      "epoch 6; iter: 0; batch classifier loss: 0.516277; batch adversarial loss: 0.638937\n",
      "epoch 7; iter: 0; batch classifier loss: 0.452707; batch adversarial loss: 0.610992\n",
      "epoch 8; iter: 0; batch classifier loss: 0.381504; batch adversarial loss: 0.624223\n",
      "epoch 9; iter: 0; batch classifier loss: 0.442918; batch adversarial loss: 0.571768\n",
      "epoch 10; iter: 0; batch classifier loss: 0.333977; batch adversarial loss: 0.616169\n",
      "epoch 11; iter: 0; batch classifier loss: 0.426025; batch adversarial loss: 0.613382\n",
      "epoch 12; iter: 0; batch classifier loss: 0.484016; batch adversarial loss: 0.590944\n",
      "epoch 13; iter: 0; batch classifier loss: 0.408113; batch adversarial loss: 0.608523\n",
      "epoch 14; iter: 0; batch classifier loss: 0.395884; batch adversarial loss: 0.635796\n",
      "epoch 15; iter: 0; batch classifier loss: 0.307231; batch adversarial loss: 0.625926\n",
      "epoch 16; iter: 0; batch classifier loss: 0.216608; batch adversarial loss: 0.641445\n",
      "epoch 17; iter: 0; batch classifier loss: 0.291414; batch adversarial loss: 0.610599\n",
      "epoch 18; iter: 0; batch classifier loss: 0.211657; batch adversarial loss: 0.613310\n",
      "epoch 19; iter: 0; batch classifier loss: 0.286072; batch adversarial loss: 0.658288\n",
      "epoch 20; iter: 0; batch classifier loss: 0.344540; batch adversarial loss: 0.592353\n",
      "epoch 21; iter: 0; batch classifier loss: 0.358987; batch adversarial loss: 0.596533\n",
      "epoch 22; iter: 0; batch classifier loss: 0.280952; batch adversarial loss: 0.595144\n",
      "epoch 23; iter: 0; batch classifier loss: 0.321801; batch adversarial loss: 0.555272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.240446; batch adversarial loss: 0.636146\n",
      "epoch 25; iter: 0; batch classifier loss: 0.342249; batch adversarial loss: 0.585685\n",
      "epoch 26; iter: 0; batch classifier loss: 0.272867; batch adversarial loss: 0.575935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.292343; batch adversarial loss: 0.592155\n",
      "epoch 28; iter: 0; batch classifier loss: 0.327827; batch adversarial loss: 0.637392\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338063; batch adversarial loss: 0.610646\n",
      "epoch 30; iter: 0; batch classifier loss: 0.261558; batch adversarial loss: 0.579355\n",
      "epoch 31; iter: 0; batch classifier loss: 0.413232; batch adversarial loss: 0.662162\n",
      "epoch 32; iter: 0; batch classifier loss: 0.306370; batch adversarial loss: 0.662818\n",
      "epoch 33; iter: 0; batch classifier loss: 0.382363; batch adversarial loss: 0.582230\n",
      "epoch 34; iter: 0; batch classifier loss: 0.317816; batch adversarial loss: 0.611947\n",
      "epoch 35; iter: 0; batch classifier loss: 0.325048; batch adversarial loss: 0.581979\n",
      "epoch 36; iter: 0; batch classifier loss: 0.267085; batch adversarial loss: 0.648533\n",
      "epoch 37; iter: 0; batch classifier loss: 0.272214; batch adversarial loss: 0.601912\n",
      "epoch 38; iter: 0; batch classifier loss: 0.244121; batch adversarial loss: 0.591445\n",
      "epoch 39; iter: 0; batch classifier loss: 0.209239; batch adversarial loss: 0.647553\n",
      "epoch 40; iter: 0; batch classifier loss: 0.287704; batch adversarial loss: 0.661252\n",
      "epoch 41; iter: 0; batch classifier loss: 0.276310; batch adversarial loss: 0.618949\n",
      "epoch 42; iter: 0; batch classifier loss: 0.327402; batch adversarial loss: 0.643837\n",
      "epoch 43; iter: 0; batch classifier loss: 0.267334; batch adversarial loss: 0.580441\n",
      "epoch 44; iter: 0; batch classifier loss: 0.321189; batch adversarial loss: 0.638591\n",
      "epoch 45; iter: 0; batch classifier loss: 0.259922; batch adversarial loss: 0.633301\n",
      "epoch 46; iter: 0; batch classifier loss: 0.245742; batch adversarial loss: 0.563954\n",
      "epoch 47; iter: 0; batch classifier loss: 0.268964; batch adversarial loss: 0.648633\n",
      "epoch 48; iter: 0; batch classifier loss: 0.219823; batch adversarial loss: 0.585633\n",
      "epoch 49; iter: 0; batch classifier loss: 0.345740; batch adversarial loss: 0.613192\n",
      "epoch 50; iter: 0; batch classifier loss: 0.336526; batch adversarial loss: 0.578901\n",
      "epoch 51; iter: 0; batch classifier loss: 0.264722; batch adversarial loss: 0.551944\n",
      "epoch 52; iter: 0; batch classifier loss: 0.293170; batch adversarial loss: 0.629661\n",
      "epoch 53; iter: 0; batch classifier loss: 0.304461; batch adversarial loss: 0.622538\n",
      "epoch 54; iter: 0; batch classifier loss: 0.352459; batch adversarial loss: 0.656305\n",
      "epoch 55; iter: 0; batch classifier loss: 0.310341; batch adversarial loss: 0.561826\n",
      "epoch 56; iter: 0; batch classifier loss: 0.259703; batch adversarial loss: 0.565256\n",
      "epoch 57; iter: 0; batch classifier loss: 0.361603; batch adversarial loss: 0.647065\n",
      "epoch 58; iter: 0; batch classifier loss: 0.242148; batch adversarial loss: 0.518301\n",
      "epoch 59; iter: 0; batch classifier loss: 0.333236; batch adversarial loss: 0.615638\n",
      "epoch 60; iter: 0; batch classifier loss: 0.183700; batch adversarial loss: 0.579826\n",
      "epoch 61; iter: 0; batch classifier loss: 0.262562; batch adversarial loss: 0.565190\n",
      "epoch 62; iter: 0; batch classifier loss: 0.349304; batch adversarial loss: 0.651402\n",
      "epoch 63; iter: 0; batch classifier loss: 0.352573; batch adversarial loss: 0.638995\n",
      "epoch 64; iter: 0; batch classifier loss: 0.226036; batch adversarial loss: 0.642765\n",
      "epoch 65; iter: 0; batch classifier loss: 0.226789; batch adversarial loss: 0.612934\n",
      "epoch 66; iter: 0; batch classifier loss: 0.223175; batch adversarial loss: 0.588719\n",
      "epoch 67; iter: 0; batch classifier loss: 0.264228; batch adversarial loss: 0.675120\n",
      "epoch 68; iter: 0; batch classifier loss: 0.188352; batch adversarial loss: 0.690523\n",
      "epoch 69; iter: 0; batch classifier loss: 0.270886; batch adversarial loss: 0.586901\n",
      "epoch 70; iter: 0; batch classifier loss: 0.201470; batch adversarial loss: 0.561844\n",
      "epoch 71; iter: 0; batch classifier loss: 0.274368; batch adversarial loss: 0.548416\n",
      "epoch 72; iter: 0; batch classifier loss: 0.237834; batch adversarial loss: 0.677218\n",
      "epoch 73; iter: 0; batch classifier loss: 0.257492; batch adversarial loss: 0.598499\n",
      "epoch 74; iter: 0; batch classifier loss: 0.242988; batch adversarial loss: 0.670067\n",
      "epoch 75; iter: 0; batch classifier loss: 0.430500; batch adversarial loss: 0.584845\n",
      "epoch 76; iter: 0; batch classifier loss: 0.202317; batch adversarial loss: 0.595094\n",
      "epoch 77; iter: 0; batch classifier loss: 0.280270; batch adversarial loss: 0.560175\n",
      "epoch 78; iter: 0; batch classifier loss: 0.352082; batch adversarial loss: 0.505988\n",
      "epoch 79; iter: 0; batch classifier loss: 0.288278; batch adversarial loss: 0.585295\n",
      "epoch 0; iter: 0; batch classifier loss: 0.815830; batch adversarial loss: 0.681624\n",
      "epoch 1; iter: 0; batch classifier loss: 0.911938; batch adversarial loss: 0.667340\n",
      "epoch 2; iter: 0; batch classifier loss: 0.847840; batch adversarial loss: 0.667834\n",
      "epoch 3; iter: 0; batch classifier loss: 0.772744; batch adversarial loss: 0.664775\n",
      "epoch 4; iter: 0; batch classifier loss: 0.714949; batch adversarial loss: 0.660950\n",
      "epoch 5; iter: 0; batch classifier loss: 0.781839; batch adversarial loss: 0.667110\n",
      "epoch 6; iter: 0; batch classifier loss: 0.707141; batch adversarial loss: 0.673362\n",
      "epoch 7; iter: 0; batch classifier loss: 0.696505; batch adversarial loss: 0.673161\n",
      "epoch 8; iter: 0; batch classifier loss: 0.641429; batch adversarial loss: 0.662742\n",
      "epoch 9; iter: 0; batch classifier loss: 0.678533; batch adversarial loss: 0.651122\n",
      "epoch 10; iter: 0; batch classifier loss: 0.565700; batch adversarial loss: 0.669555\n",
      "epoch 11; iter: 0; batch classifier loss: 0.609180; batch adversarial loss: 0.642950\n",
      "epoch 12; iter: 0; batch classifier loss: 0.596448; batch adversarial loss: 0.651134\n",
      "epoch 13; iter: 0; batch classifier loss: 0.558793; batch adversarial loss: 0.655642\n",
      "epoch 14; iter: 0; batch classifier loss: 0.582976; batch adversarial loss: 0.660036\n",
      "epoch 15; iter: 0; batch classifier loss: 0.611062; batch adversarial loss: 0.648841\n",
      "epoch 16; iter: 0; batch classifier loss: 0.593005; batch adversarial loss: 0.647825\n",
      "epoch 17; iter: 0; batch classifier loss: 0.569084; batch adversarial loss: 0.642080\n",
      "epoch 18; iter: 0; batch classifier loss: 0.586492; batch adversarial loss: 0.634305\n",
      "epoch 19; iter: 0; batch classifier loss: 0.506983; batch adversarial loss: 0.626748\n",
      "epoch 20; iter: 0; batch classifier loss: 0.490731; batch adversarial loss: 0.632831\n",
      "epoch 21; iter: 0; batch classifier loss: 0.585623; batch adversarial loss: 0.637568\n",
      "epoch 22; iter: 0; batch classifier loss: 0.389416; batch adversarial loss: 0.634459\n",
      "epoch 23; iter: 0; batch classifier loss: 0.511729; batch adversarial loss: 0.622486\n",
      "epoch 24; iter: 0; batch classifier loss: 0.535690; batch adversarial loss: 0.612551\n",
      "epoch 25; iter: 0; batch classifier loss: 0.497757; batch adversarial loss: 0.622699\n",
      "epoch 26; iter: 0; batch classifier loss: 0.611202; batch adversarial loss: 0.619935\n",
      "epoch 27; iter: 0; batch classifier loss: 0.504244; batch adversarial loss: 0.629517\n",
      "epoch 28; iter: 0; batch classifier loss: 0.553137; batch adversarial loss: 0.620208\n",
      "epoch 29; iter: 0; batch classifier loss: 0.486961; batch adversarial loss: 0.618073\n",
      "epoch 30; iter: 0; batch classifier loss: 0.458397; batch adversarial loss: 0.620709\n",
      "epoch 31; iter: 0; batch classifier loss: 0.401932; batch adversarial loss: 0.611773\n",
      "epoch 32; iter: 0; batch classifier loss: 0.415045; batch adversarial loss: 0.622079\n",
      "epoch 33; iter: 0; batch classifier loss: 0.494039; batch adversarial loss: 0.628260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.452224; batch adversarial loss: 0.621742\n",
      "epoch 35; iter: 0; batch classifier loss: 0.488443; batch adversarial loss: 0.606863\n",
      "epoch 36; iter: 0; batch classifier loss: 0.432720; batch adversarial loss: 0.622578\n",
      "epoch 37; iter: 0; batch classifier loss: 0.385268; batch adversarial loss: 0.616684\n",
      "epoch 38; iter: 0; batch classifier loss: 0.478177; batch adversarial loss: 0.618255\n",
      "epoch 39; iter: 0; batch classifier loss: 0.451571; batch adversarial loss: 0.615072\n",
      "epoch 40; iter: 0; batch classifier loss: 0.440685; batch adversarial loss: 0.596863\n",
      "epoch 41; iter: 0; batch classifier loss: 0.378704; batch adversarial loss: 0.624210\n",
      "epoch 42; iter: 0; batch classifier loss: 0.387013; batch adversarial loss: 0.634892\n",
      "epoch 43; iter: 0; batch classifier loss: 0.440157; batch adversarial loss: 0.601412\n",
      "epoch 44; iter: 0; batch classifier loss: 0.406246; batch adversarial loss: 0.610546\n",
      "epoch 45; iter: 0; batch classifier loss: 0.349545; batch adversarial loss: 0.602986\n",
      "epoch 46; iter: 0; batch classifier loss: 0.372518; batch adversarial loss: 0.617922\n",
      "epoch 47; iter: 0; batch classifier loss: 0.354080; batch adversarial loss: 0.614326\n",
      "epoch 48; iter: 0; batch classifier loss: 0.384537; batch adversarial loss: 0.621922\n",
      "epoch 49; iter: 0; batch classifier loss: 0.391079; batch adversarial loss: 0.576250\n",
      "epoch 50; iter: 0; batch classifier loss: 0.386970; batch adversarial loss: 0.610805\n",
      "epoch 51; iter: 0; batch classifier loss: 0.372915; batch adversarial loss: 0.628419\n",
      "epoch 52; iter: 0; batch classifier loss: 0.375193; batch adversarial loss: 0.595247\n",
      "epoch 53; iter: 0; batch classifier loss: 0.376351; batch adversarial loss: 0.632282\n",
      "epoch 54; iter: 0; batch classifier loss: 0.399567; batch adversarial loss: 0.615689\n",
      "epoch 55; iter: 0; batch classifier loss: 0.387108; batch adversarial loss: 0.592703\n",
      "epoch 56; iter: 0; batch classifier loss: 0.398723; batch adversarial loss: 0.631801\n",
      "epoch 57; iter: 0; batch classifier loss: 0.396713; batch adversarial loss: 0.630778\n",
      "epoch 58; iter: 0; batch classifier loss: 0.395583; batch adversarial loss: 0.612700\n",
      "epoch 59; iter: 0; batch classifier loss: 0.346253; batch adversarial loss: 0.630992\n",
      "epoch 60; iter: 0; batch classifier loss: 0.398761; batch adversarial loss: 0.604068\n",
      "epoch 61; iter: 0; batch classifier loss: 0.379187; batch adversarial loss: 0.595828\n",
      "epoch 62; iter: 0; batch classifier loss: 0.413770; batch adversarial loss: 0.592997\n",
      "epoch 63; iter: 0; batch classifier loss: 0.394081; batch adversarial loss: 0.567570\n",
      "epoch 64; iter: 0; batch classifier loss: 0.436040; batch adversarial loss: 0.599881\n",
      "epoch 65; iter: 0; batch classifier loss: 0.408206; batch adversarial loss: 0.594312\n",
      "epoch 66; iter: 0; batch classifier loss: 0.373359; batch adversarial loss: 0.596596\n",
      "epoch 67; iter: 0; batch classifier loss: 0.366480; batch adversarial loss: 0.615264\n",
      "epoch 68; iter: 0; batch classifier loss: 0.262950; batch adversarial loss: 0.600900\n",
      "epoch 69; iter: 0; batch classifier loss: 0.338053; batch adversarial loss: 0.594921\n",
      "epoch 70; iter: 0; batch classifier loss: 0.295541; batch adversarial loss: 0.599565\n",
      "epoch 71; iter: 0; batch classifier loss: 0.367639; batch adversarial loss: 0.602986\n",
      "epoch 72; iter: 0; batch classifier loss: 0.288333; batch adversarial loss: 0.601026\n",
      "epoch 73; iter: 0; batch classifier loss: 0.438679; batch adversarial loss: 0.580666\n",
      "epoch 74; iter: 0; batch classifier loss: 0.402507; batch adversarial loss: 0.618129\n",
      "epoch 75; iter: 0; batch classifier loss: 0.322078; batch adversarial loss: 0.578410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.405644; batch adversarial loss: 0.610073\n",
      "epoch 77; iter: 0; batch classifier loss: 0.327321; batch adversarial loss: 0.610557\n",
      "epoch 78; iter: 0; batch classifier loss: 0.232850; batch adversarial loss: 0.616530\n",
      "epoch 79; iter: 0; batch classifier loss: 0.409263; batch adversarial loss: 0.594080\n",
      "epoch 0; iter: 0; batch classifier loss: 0.740975; batch adversarial loss: 0.732536\n",
      "epoch 1; iter: 0; batch classifier loss: 0.689321; batch adversarial loss: 0.728690\n",
      "epoch 2; iter: 0; batch classifier loss: 0.677366; batch adversarial loss: 0.712211\n",
      "epoch 3; iter: 0; batch classifier loss: 0.666598; batch adversarial loss: 0.697378\n",
      "epoch 4; iter: 0; batch classifier loss: 0.671579; batch adversarial loss: 0.712816\n",
      "epoch 5; iter: 0; batch classifier loss: 0.612756; batch adversarial loss: 0.697743\n",
      "epoch 6; iter: 0; batch classifier loss: 0.606200; batch adversarial loss: 0.744075\n",
      "epoch 7; iter: 0; batch classifier loss: 0.574877; batch adversarial loss: 0.741025\n",
      "epoch 8; iter: 0; batch classifier loss: 0.572595; batch adversarial loss: 0.717355\n",
      "epoch 9; iter: 0; batch classifier loss: 0.543496; batch adversarial loss: 0.724713\n",
      "epoch 10; iter: 0; batch classifier loss: 0.513879; batch adversarial loss: 0.709561\n",
      "epoch 11; iter: 0; batch classifier loss: 0.545268; batch adversarial loss: 0.714413\n",
      "epoch 12; iter: 0; batch classifier loss: 0.488133; batch adversarial loss: 0.732107\n",
      "epoch 13; iter: 0; batch classifier loss: 0.480019; batch adversarial loss: 0.738124\n",
      "epoch 14; iter: 0; batch classifier loss: 0.477892; batch adversarial loss: 0.713310\n",
      "epoch 15; iter: 0; batch classifier loss: 0.480327; batch adversarial loss: 0.751506\n",
      "epoch 16; iter: 0; batch classifier loss: 0.469455; batch adversarial loss: 0.721457\n",
      "epoch 17; iter: 0; batch classifier loss: 0.443183; batch adversarial loss: 0.709284\n",
      "epoch 18; iter: 0; batch classifier loss: 0.397640; batch adversarial loss: 0.717819\n",
      "epoch 19; iter: 0; batch classifier loss: 0.475128; batch adversarial loss: 0.711586\n",
      "epoch 20; iter: 0; batch classifier loss: 0.456945; batch adversarial loss: 0.728607\n",
      "epoch 21; iter: 0; batch classifier loss: 0.416652; batch adversarial loss: 0.686272\n",
      "epoch 22; iter: 0; batch classifier loss: 0.410387; batch adversarial loss: 0.717620\n",
      "epoch 23; iter: 0; batch classifier loss: 0.379569; batch adversarial loss: 0.721699\n",
      "epoch 24; iter: 0; batch classifier loss: 0.391321; batch adversarial loss: 0.749000\n",
      "epoch 25; iter: 0; batch classifier loss: 0.418040; batch adversarial loss: 0.700949\n",
      "epoch 26; iter: 0; batch classifier loss: 0.375062; batch adversarial loss: 0.729893\n",
      "epoch 27; iter: 0; batch classifier loss: 0.378086; batch adversarial loss: 0.712654\n",
      "epoch 28; iter: 0; batch classifier loss: 0.400674; batch adversarial loss: 0.688344\n",
      "epoch 29; iter: 0; batch classifier loss: 0.323408; batch adversarial loss: 0.722528\n",
      "epoch 30; iter: 0; batch classifier loss: 0.341796; batch adversarial loss: 0.711225\n",
      "epoch 31; iter: 0; batch classifier loss: 0.332817; batch adversarial loss: 0.737525\n",
      "epoch 32; iter: 0; batch classifier loss: 0.402151; batch adversarial loss: 0.697420\n",
      "epoch 33; iter: 0; batch classifier loss: 0.349617; batch adversarial loss: 0.693848\n",
      "epoch 34; iter: 0; batch classifier loss: 0.379526; batch adversarial loss: 0.709923\n",
      "epoch 35; iter: 0; batch classifier loss: 0.297490; batch adversarial loss: 0.705632\n",
      "epoch 36; iter: 0; batch classifier loss: 0.328449; batch adversarial loss: 0.694154\n",
      "epoch 37; iter: 0; batch classifier loss: 0.336693; batch adversarial loss: 0.676622\n",
      "epoch 38; iter: 0; batch classifier loss: 0.378650; batch adversarial loss: 0.685623\n",
      "epoch 39; iter: 0; batch classifier loss: 0.307367; batch adversarial loss: 0.685389\n",
      "epoch 40; iter: 0; batch classifier loss: 0.319129; batch adversarial loss: 0.688550\n",
      "epoch 41; iter: 0; batch classifier loss: 0.310018; batch adversarial loss: 0.691029\n",
      "epoch 42; iter: 0; batch classifier loss: 0.289713; batch adversarial loss: 0.673992\n",
      "epoch 43; iter: 0; batch classifier loss: 0.287843; batch adversarial loss: 0.702098\n",
      "epoch 44; iter: 0; batch classifier loss: 0.282440; batch adversarial loss: 0.690192\n",
      "epoch 45; iter: 0; batch classifier loss: 0.288997; batch adversarial loss: 0.679375\n",
      "epoch 46; iter: 0; batch classifier loss: 0.288964; batch adversarial loss: 0.690942\n",
      "epoch 47; iter: 0; batch classifier loss: 0.369740; batch adversarial loss: 0.684349\n",
      "epoch 48; iter: 0; batch classifier loss: 0.313713; batch adversarial loss: 0.693232\n",
      "epoch 49; iter: 0; batch classifier loss: 0.310867; batch adversarial loss: 0.674639\n",
      "epoch 50; iter: 0; batch classifier loss: 0.298868; batch adversarial loss: 0.699516\n",
      "epoch 51; iter: 0; batch classifier loss: 0.274943; batch adversarial loss: 0.664738\n",
      "epoch 52; iter: 0; batch classifier loss: 0.281671; batch adversarial loss: 0.657979\n",
      "epoch 53; iter: 0; batch classifier loss: 0.370673; batch adversarial loss: 0.648449\n",
      "epoch 54; iter: 0; batch classifier loss: 0.345136; batch adversarial loss: 0.673293\n",
      "epoch 55; iter: 0; batch classifier loss: 0.304217; batch adversarial loss: 0.654520\n",
      "epoch 56; iter: 0; batch classifier loss: 0.339984; batch adversarial loss: 0.664548\n",
      "epoch 57; iter: 0; batch classifier loss: 0.282088; batch adversarial loss: 0.665486\n",
      "epoch 58; iter: 0; batch classifier loss: 0.263136; batch adversarial loss: 0.654374\n",
      "epoch 59; iter: 0; batch classifier loss: 0.322369; batch adversarial loss: 0.649448\n",
      "epoch 60; iter: 0; batch classifier loss: 0.345553; batch adversarial loss: 0.674021\n",
      "epoch 61; iter: 0; batch classifier loss: 0.264470; batch adversarial loss: 0.644691\n",
      "epoch 62; iter: 0; batch classifier loss: 0.320721; batch adversarial loss: 0.649141\n",
      "epoch 63; iter: 0; batch classifier loss: 0.309252; batch adversarial loss: 0.648793\n",
      "epoch 64; iter: 0; batch classifier loss: 0.303964; batch adversarial loss: 0.647700\n",
      "epoch 65; iter: 0; batch classifier loss: 0.274315; batch adversarial loss: 0.665336\n",
      "epoch 66; iter: 0; batch classifier loss: 0.239204; batch adversarial loss: 0.635270\n",
      "epoch 67; iter: 0; batch classifier loss: 0.338269; batch adversarial loss: 0.665586\n",
      "epoch 68; iter: 0; batch classifier loss: 0.302324; batch adversarial loss: 0.634716\n",
      "epoch 69; iter: 0; batch classifier loss: 0.315161; batch adversarial loss: 0.653511\n",
      "epoch 70; iter: 0; batch classifier loss: 0.382444; batch adversarial loss: 0.676360\n",
      "epoch 71; iter: 0; batch classifier loss: 0.308834; batch adversarial loss: 0.652827\n",
      "epoch 72; iter: 0; batch classifier loss: 0.310461; batch adversarial loss: 0.625119\n",
      "epoch 73; iter: 0; batch classifier loss: 0.318039; batch adversarial loss: 0.652568\n",
      "epoch 74; iter: 0; batch classifier loss: 0.433134; batch adversarial loss: 0.633674\n",
      "epoch 75; iter: 0; batch classifier loss: 0.266908; batch adversarial loss: 0.645410\n",
      "epoch 76; iter: 0; batch classifier loss: 0.316109; batch adversarial loss: 0.656075\n",
      "epoch 77; iter: 0; batch classifier loss: 0.252912; batch adversarial loss: 0.638734\n",
      "epoch 78; iter: 0; batch classifier loss: 0.245118; batch adversarial loss: 0.637562\n",
      "epoch 79; iter: 0; batch classifier loss: 0.276313; batch adversarial loss: 0.633817\n",
      "epoch 0; iter: 0; batch classifier loss: 0.652387; batch adversarial loss: 0.827716\n",
      "epoch 1; iter: 0; batch classifier loss: 0.631080; batch adversarial loss: 0.852128\n",
      "epoch 2; iter: 0; batch classifier loss: 0.574583; batch adversarial loss: 0.845822\n",
      "epoch 3; iter: 0; batch classifier loss: 0.539267; batch adversarial loss: 0.887901\n",
      "epoch 4; iter: 0; batch classifier loss: 0.517485; batch adversarial loss: 0.854771\n",
      "epoch 5; iter: 0; batch classifier loss: 0.538703; batch adversarial loss: 0.986030\n",
      "epoch 6; iter: 0; batch classifier loss: 0.547003; batch adversarial loss: 0.906869\n",
      "epoch 7; iter: 0; batch classifier loss: 0.420225; batch adversarial loss: 0.877823\n",
      "epoch 8; iter: 0; batch classifier loss: 0.413169; batch adversarial loss: 0.985241\n",
      "epoch 9; iter: 0; batch classifier loss: 0.371025; batch adversarial loss: 1.036778\n",
      "epoch 10; iter: 0; batch classifier loss: 0.445206; batch adversarial loss: 0.919643\n",
      "epoch 11; iter: 0; batch classifier loss: 0.413089; batch adversarial loss: 0.996805\n",
      "epoch 12; iter: 0; batch classifier loss: 0.558010; batch adversarial loss: 0.967606\n",
      "epoch 13; iter: 0; batch classifier loss: 0.450209; batch adversarial loss: 0.974743\n",
      "epoch 14; iter: 0; batch classifier loss: 0.586422; batch adversarial loss: 0.999177\n",
      "epoch 15; iter: 0; batch classifier loss: 0.448055; batch adversarial loss: 0.945955\n",
      "epoch 16; iter: 0; batch classifier loss: 0.428716; batch adversarial loss: 0.906119\n",
      "epoch 17; iter: 0; batch classifier loss: 0.473467; batch adversarial loss: 0.999192\n",
      "epoch 18; iter: 0; batch classifier loss: 0.413397; batch adversarial loss: 0.973876\n",
      "epoch 19; iter: 0; batch classifier loss: 0.581667; batch adversarial loss: 1.000870\n",
      "epoch 20; iter: 0; batch classifier loss: 0.491845; batch adversarial loss: 0.981637\n",
      "epoch 21; iter: 0; batch classifier loss: 0.611612; batch adversarial loss: 0.977596\n",
      "epoch 22; iter: 0; batch classifier loss: 0.461938; batch adversarial loss: 1.007132\n",
      "epoch 23; iter: 0; batch classifier loss: 0.654761; batch adversarial loss: 0.960182\n",
      "epoch 24; iter: 0; batch classifier loss: 0.532940; batch adversarial loss: 0.964643\n",
      "epoch 25; iter: 0; batch classifier loss: 0.596477; batch adversarial loss: 0.994485\n",
      "epoch 26; iter: 0; batch classifier loss: 0.449981; batch adversarial loss: 0.966093\n",
      "epoch 27; iter: 0; batch classifier loss: 0.761482; batch adversarial loss: 0.907340\n",
      "epoch 28; iter: 0; batch classifier loss: 0.513560; batch adversarial loss: 0.903612\n",
      "epoch 29; iter: 0; batch classifier loss: 0.672891; batch adversarial loss: 0.897572\n",
      "epoch 30; iter: 0; batch classifier loss: 0.606272; batch adversarial loss: 0.895566\n",
      "epoch 31; iter: 0; batch classifier loss: 0.684031; batch adversarial loss: 0.912538\n",
      "epoch 32; iter: 0; batch classifier loss: 0.718040; batch adversarial loss: 0.895342\n",
      "epoch 33; iter: 0; batch classifier loss: 0.548436; batch adversarial loss: 0.886590\n",
      "epoch 34; iter: 0; batch classifier loss: 0.661716; batch adversarial loss: 0.876855\n",
      "epoch 35; iter: 0; batch classifier loss: 0.544378; batch adversarial loss: 0.888719\n",
      "epoch 36; iter: 0; batch classifier loss: 0.717104; batch adversarial loss: 0.861969\n",
      "epoch 37; iter: 0; batch classifier loss: 0.555830; batch adversarial loss: 0.821079\n",
      "epoch 38; iter: 0; batch classifier loss: 0.590370; batch adversarial loss: 0.865489\n",
      "epoch 39; iter: 0; batch classifier loss: 0.724729; batch adversarial loss: 0.845990\n",
      "epoch 0; iter: 0; batch classifier loss: 0.787318; batch adversarial loss: 0.613558\n",
      "epoch 1; iter: 0; batch classifier loss: 0.645326; batch adversarial loss: 0.575283\n",
      "epoch 2; iter: 0; batch classifier loss: 0.577186; batch adversarial loss: 0.671476\n",
      "epoch 3; iter: 0; batch classifier loss: 0.512961; batch adversarial loss: 0.636670\n",
      "epoch 4; iter: 0; batch classifier loss: 0.521337; batch adversarial loss: 0.662928\n",
      "epoch 5; iter: 0; batch classifier loss: 0.482115; batch adversarial loss: 0.609381\n",
      "epoch 6; iter: 0; batch classifier loss: 0.481540; batch adversarial loss: 0.620690\n",
      "epoch 7; iter: 0; batch classifier loss: 0.463549; batch adversarial loss: 0.629475\n",
      "epoch 8; iter: 0; batch classifier loss: 0.418807; batch adversarial loss: 0.590759\n",
      "epoch 9; iter: 0; batch classifier loss: 0.444645; batch adversarial loss: 0.570307\n",
      "epoch 10; iter: 0; batch classifier loss: 0.394998; batch adversarial loss: 0.702838\n",
      "epoch 11; iter: 0; batch classifier loss: 0.364068; batch adversarial loss: 0.624951\n",
      "epoch 12; iter: 0; batch classifier loss: 0.417162; batch adversarial loss: 0.621931\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340181; batch adversarial loss: 0.702572\n",
      "epoch 14; iter: 0; batch classifier loss: 0.396195; batch adversarial loss: 0.681550\n",
      "epoch 15; iter: 0; batch classifier loss: 0.357534; batch adversarial loss: 0.680095\n",
      "epoch 16; iter: 0; batch classifier loss: 0.475453; batch adversarial loss: 0.637737\n",
      "epoch 17; iter: 0; batch classifier loss: 0.391430; batch adversarial loss: 0.722139\n",
      "epoch 18; iter: 0; batch classifier loss: 0.362509; batch adversarial loss: 0.648225\n",
      "epoch 19; iter: 0; batch classifier loss: 0.406566; batch adversarial loss: 0.662900\n",
      "epoch 20; iter: 0; batch classifier loss: 0.331355; batch adversarial loss: 0.637362\n",
      "epoch 21; iter: 0; batch classifier loss: 0.459248; batch adversarial loss: 0.616096\n",
      "epoch 22; iter: 0; batch classifier loss: 0.309915; batch adversarial loss: 0.667332\n",
      "epoch 23; iter: 0; batch classifier loss: 0.441359; batch adversarial loss: 0.598839\n",
      "epoch 24; iter: 0; batch classifier loss: 0.305994; batch adversarial loss: 0.779897\n",
      "epoch 25; iter: 0; batch classifier loss: 0.333176; batch adversarial loss: 0.730412\n",
      "epoch 26; iter: 0; batch classifier loss: 0.410534; batch adversarial loss: 0.729062\n",
      "epoch 27; iter: 0; batch classifier loss: 0.245889; batch adversarial loss: 0.676197\n",
      "epoch 28; iter: 0; batch classifier loss: 0.361222; batch adversarial loss: 0.630031\n",
      "epoch 29; iter: 0; batch classifier loss: 0.345837; batch adversarial loss: 0.605573\n",
      "epoch 30; iter: 0; batch classifier loss: 0.395416; batch adversarial loss: 0.643211\n",
      "epoch 31; iter: 0; batch classifier loss: 0.306471; batch adversarial loss: 0.655889\n",
      "epoch 32; iter: 0; batch classifier loss: 0.320154; batch adversarial loss: 0.674090\n",
      "epoch 33; iter: 0; batch classifier loss: 0.291390; batch adversarial loss: 0.683260\n",
      "epoch 34; iter: 0; batch classifier loss: 0.414102; batch adversarial loss: 0.592257\n",
      "epoch 35; iter: 0; batch classifier loss: 0.394232; batch adversarial loss: 0.588913\n",
      "epoch 36; iter: 0; batch classifier loss: 0.407972; batch adversarial loss: 0.698792\n",
      "epoch 37; iter: 0; batch classifier loss: 0.344613; batch adversarial loss: 0.582117\n",
      "epoch 38; iter: 0; batch classifier loss: 0.420315; batch adversarial loss: 0.654010\n",
      "epoch 39; iter: 0; batch classifier loss: 0.315622; batch adversarial loss: 0.638930\n",
      "epoch 0; iter: 0; batch classifier loss: 0.747316; batch adversarial loss: 0.614411\n",
      "epoch 1; iter: 0; batch classifier loss: 0.691339; batch adversarial loss: 0.640325\n",
      "epoch 2; iter: 0; batch classifier loss: 0.672229; batch adversarial loss: 0.628261\n",
      "epoch 3; iter: 0; batch classifier loss: 0.659175; batch adversarial loss: 0.618887\n",
      "epoch 4; iter: 0; batch classifier loss: 0.670274; batch adversarial loss: 0.632899\n",
      "epoch 5; iter: 0; batch classifier loss: 0.662008; batch adversarial loss: 0.650914\n",
      "epoch 6; iter: 0; batch classifier loss: 0.657563; batch adversarial loss: 0.644588\n",
      "epoch 7; iter: 0; batch classifier loss: 0.582440; batch adversarial loss: 0.622355\n",
      "epoch 8; iter: 0; batch classifier loss: 0.573706; batch adversarial loss: 0.665578\n",
      "epoch 9; iter: 0; batch classifier loss: 0.580031; batch adversarial loss: 0.638471\n",
      "epoch 10; iter: 0; batch classifier loss: 0.538716; batch adversarial loss: 0.641993\n",
      "epoch 11; iter: 0; batch classifier loss: 0.567970; batch adversarial loss: 0.647268\n",
      "epoch 12; iter: 0; batch classifier loss: 0.526602; batch adversarial loss: 0.652325\n",
      "epoch 13; iter: 0; batch classifier loss: 0.526932; batch adversarial loss: 0.621077\n",
      "epoch 14; iter: 0; batch classifier loss: 0.523489; batch adversarial loss: 0.627376\n",
      "epoch 15; iter: 0; batch classifier loss: 0.484069; batch adversarial loss: 0.651866\n",
      "epoch 16; iter: 0; batch classifier loss: 0.478844; batch adversarial loss: 0.613759\n",
      "epoch 17; iter: 0; batch classifier loss: 0.537205; batch adversarial loss: 0.669236\n",
      "epoch 18; iter: 0; batch classifier loss: 0.486815; batch adversarial loss: 0.635760\n",
      "epoch 19; iter: 0; batch classifier loss: 0.518338; batch adversarial loss: 0.664569\n",
      "epoch 20; iter: 0; batch classifier loss: 0.417152; batch adversarial loss: 0.649485\n",
      "epoch 21; iter: 0; batch classifier loss: 0.495614; batch adversarial loss: 0.607617\n",
      "epoch 22; iter: 0; batch classifier loss: 0.439119; batch adversarial loss: 0.643537\n",
      "epoch 23; iter: 0; batch classifier loss: 0.470493; batch adversarial loss: 0.588450\n",
      "epoch 24; iter: 0; batch classifier loss: 0.508410; batch adversarial loss: 0.648869\n",
      "epoch 25; iter: 0; batch classifier loss: 0.405469; batch adversarial loss: 0.644548\n",
      "epoch 26; iter: 0; batch classifier loss: 0.460055; batch adversarial loss: 0.664033\n",
      "epoch 27; iter: 0; batch classifier loss: 0.424626; batch adversarial loss: 0.614115\n",
      "epoch 28; iter: 0; batch classifier loss: 0.433280; batch adversarial loss: 0.609725\n",
      "epoch 29; iter: 0; batch classifier loss: 0.433856; batch adversarial loss: 0.664708\n",
      "epoch 30; iter: 0; batch classifier loss: 0.477424; batch adversarial loss: 0.630682\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459041; batch adversarial loss: 0.643140\n",
      "epoch 32; iter: 0; batch classifier loss: 0.409919; batch adversarial loss: 0.674838\n",
      "epoch 33; iter: 0; batch classifier loss: 0.403119; batch adversarial loss: 0.625692\n",
      "epoch 34; iter: 0; batch classifier loss: 0.435808; batch adversarial loss: 0.640799\n",
      "epoch 35; iter: 0; batch classifier loss: 0.408479; batch adversarial loss: 0.650767\n",
      "epoch 36; iter: 0; batch classifier loss: 0.309016; batch adversarial loss: 0.685415\n",
      "epoch 37; iter: 0; batch classifier loss: 0.450512; batch adversarial loss: 0.612511\n",
      "epoch 38; iter: 0; batch classifier loss: 0.445061; batch adversarial loss: 0.609191\n",
      "epoch 39; iter: 0; batch classifier loss: 0.424541; batch adversarial loss: 0.664396\n",
      "epoch 0; iter: 0; batch classifier loss: 0.768207; batch adversarial loss: 0.657018\n",
      "epoch 1; iter: 0; batch classifier loss: 0.736569; batch adversarial loss: 0.603844\n",
      "epoch 2; iter: 0; batch classifier loss: 0.686327; batch adversarial loss: 0.658114\n",
      "epoch 3; iter: 0; batch classifier loss: 0.664888; batch adversarial loss: 0.657279\n",
      "epoch 4; iter: 0; batch classifier loss: 0.581843; batch adversarial loss: 0.654003\n",
      "epoch 5; iter: 0; batch classifier loss: 0.531936; batch adversarial loss: 0.728374\n",
      "epoch 6; iter: 0; batch classifier loss: 0.533553; batch adversarial loss: 0.651898\n",
      "epoch 7; iter: 0; batch classifier loss: 0.528960; batch adversarial loss: 0.637908\n",
      "epoch 8; iter: 0; batch classifier loss: 0.495042; batch adversarial loss: 0.626130\n",
      "epoch 9; iter: 0; batch classifier loss: 0.516832; batch adversarial loss: 0.610674\n",
      "epoch 10; iter: 0; batch classifier loss: 0.459434; batch adversarial loss: 0.631744\n",
      "epoch 11; iter: 0; batch classifier loss: 0.491660; batch adversarial loss: 0.626570\n",
      "epoch 12; iter: 0; batch classifier loss: 0.471029; batch adversarial loss: 0.644843\n",
      "epoch 13; iter: 0; batch classifier loss: 0.402134; batch adversarial loss: 0.626602\n",
      "epoch 14; iter: 0; batch classifier loss: 0.451627; batch adversarial loss: 0.620434\n",
      "epoch 15; iter: 0; batch classifier loss: 0.441875; batch adversarial loss: 0.622299\n",
      "epoch 16; iter: 0; batch classifier loss: 0.402434; batch adversarial loss: 0.680441\n",
      "epoch 17; iter: 0; batch classifier loss: 0.390448; batch adversarial loss: 0.694609\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398861; batch adversarial loss: 0.600460\n",
      "epoch 19; iter: 0; batch classifier loss: 0.423377; batch adversarial loss: 0.684254\n",
      "epoch 20; iter: 0; batch classifier loss: 0.387095; batch adversarial loss: 0.666129\n",
      "epoch 21; iter: 0; batch classifier loss: 0.389928; batch adversarial loss: 0.647501\n",
      "epoch 22; iter: 0; batch classifier loss: 0.359964; batch adversarial loss: 0.679590\n",
      "epoch 23; iter: 0; batch classifier loss: 0.354300; batch adversarial loss: 0.638868\n",
      "epoch 24; iter: 0; batch classifier loss: 0.370816; batch adversarial loss: 0.684445\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371284; batch adversarial loss: 0.681196\n",
      "epoch 26; iter: 0; batch classifier loss: 0.352935; batch adversarial loss: 0.689584\n",
      "epoch 27; iter: 0; batch classifier loss: 0.374242; batch adversarial loss: 0.678550\n",
      "epoch 28; iter: 0; batch classifier loss: 0.356413; batch adversarial loss: 0.690145\n",
      "epoch 29; iter: 0; batch classifier loss: 0.349451; batch adversarial loss: 0.673646\n",
      "epoch 30; iter: 0; batch classifier loss: 0.366840; batch adversarial loss: 0.620560\n",
      "epoch 31; iter: 0; batch classifier loss: 0.379457; batch adversarial loss: 0.597945\n",
      "epoch 32; iter: 0; batch classifier loss: 0.343462; batch adversarial loss: 0.673998\n",
      "epoch 33; iter: 0; batch classifier loss: 0.322462; batch adversarial loss: 0.577722\n",
      "epoch 34; iter: 0; batch classifier loss: 0.393579; batch adversarial loss: 0.625611\n",
      "epoch 35; iter: 0; batch classifier loss: 0.346948; batch adversarial loss: 0.618043\n",
      "epoch 36; iter: 0; batch classifier loss: 0.342153; batch adversarial loss: 0.624957\n",
      "epoch 37; iter: 0; batch classifier loss: 0.386000; batch adversarial loss: 0.599014\n",
      "epoch 38; iter: 0; batch classifier loss: 0.417148; batch adversarial loss: 0.680314\n",
      "epoch 39; iter: 0; batch classifier loss: 0.366454; batch adversarial loss: 0.616724\n",
      "epoch 0; iter: 0; batch classifier loss: 0.780680; batch adversarial loss: 0.667072\n",
      "epoch 1; iter: 0; batch classifier loss: 0.789027; batch adversarial loss: 0.665287\n",
      "epoch 2; iter: 0; batch classifier loss: 0.673841; batch adversarial loss: 0.664318\n",
      "epoch 3; iter: 0; batch classifier loss: 0.584373; batch adversarial loss: 0.653603\n",
      "epoch 4; iter: 0; batch classifier loss: 0.605265; batch adversarial loss: 0.654815\n",
      "epoch 5; iter: 0; batch classifier loss: 0.555493; batch adversarial loss: 0.667805\n",
      "epoch 6; iter: 0; batch classifier loss: 0.546861; batch adversarial loss: 0.659631\n",
      "epoch 7; iter: 0; batch classifier loss: 0.564781; batch adversarial loss: 0.649235\n",
      "epoch 8; iter: 0; batch classifier loss: 0.475737; batch adversarial loss: 0.694849\n",
      "epoch 9; iter: 0; batch classifier loss: 0.513852; batch adversarial loss: 0.640189\n",
      "epoch 10; iter: 0; batch classifier loss: 0.520139; batch adversarial loss: 0.627891\n",
      "epoch 11; iter: 0; batch classifier loss: 0.511381; batch adversarial loss: 0.646087\n",
      "epoch 12; iter: 0; batch classifier loss: 0.441403; batch adversarial loss: 0.633011\n",
      "epoch 13; iter: 0; batch classifier loss: 0.448512; batch adversarial loss: 0.652973\n",
      "epoch 14; iter: 0; batch classifier loss: 0.501358; batch adversarial loss: 0.617725\n",
      "epoch 15; iter: 0; batch classifier loss: 0.545342; batch adversarial loss: 0.623609\n",
      "epoch 16; iter: 0; batch classifier loss: 0.416427; batch adversarial loss: 0.654313\n",
      "epoch 17; iter: 0; batch classifier loss: 0.499341; batch adversarial loss: 0.646433\n",
      "epoch 18; iter: 0; batch classifier loss: 0.475702; batch adversarial loss: 0.614306\n",
      "epoch 19; iter: 0; batch classifier loss: 0.365712; batch adversarial loss: 0.623394\n",
      "epoch 20; iter: 0; batch classifier loss: 0.385957; batch adversarial loss: 0.586757\n",
      "epoch 21; iter: 0; batch classifier loss: 0.364069; batch adversarial loss: 0.681804\n",
      "epoch 22; iter: 0; batch classifier loss: 0.362935; batch adversarial loss: 0.608258\n",
      "epoch 23; iter: 0; batch classifier loss: 0.304507; batch adversarial loss: 0.587964\n",
      "epoch 24; iter: 0; batch classifier loss: 0.324597; batch adversarial loss: 0.586034\n",
      "epoch 25; iter: 0; batch classifier loss: 0.313515; batch adversarial loss: 0.610913\n",
      "epoch 26; iter: 0; batch classifier loss: 0.393283; batch adversarial loss: 0.623135\n",
      "epoch 27; iter: 0; batch classifier loss: 0.517479; batch adversarial loss: 0.623250\n",
      "epoch 28; iter: 0; batch classifier loss: 0.440281; batch adversarial loss: 0.633296\n",
      "epoch 29; iter: 0; batch classifier loss: 0.421955; batch adversarial loss: 0.624432\n",
      "epoch 30; iter: 0; batch classifier loss: 0.361905; batch adversarial loss: 0.606398\n",
      "epoch 31; iter: 0; batch classifier loss: 0.312758; batch adversarial loss: 0.603240\n",
      "epoch 32; iter: 0; batch classifier loss: 0.383728; batch adversarial loss: 0.617162\n",
      "epoch 33; iter: 0; batch classifier loss: 0.326622; batch adversarial loss: 0.636141\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357889; batch adversarial loss: 0.528505\n",
      "epoch 35; iter: 0; batch classifier loss: 0.301499; batch adversarial loss: 0.654497\n",
      "epoch 36; iter: 0; batch classifier loss: 0.309685; batch adversarial loss: 0.662458\n",
      "epoch 37; iter: 0; batch classifier loss: 0.295761; batch adversarial loss: 0.630474\n",
      "epoch 38; iter: 0; batch classifier loss: 0.354996; batch adversarial loss: 0.612793\n",
      "epoch 39; iter: 0; batch classifier loss: 0.290406; batch adversarial loss: 0.603700\n",
      "epoch 40; iter: 0; batch classifier loss: 0.373951; batch adversarial loss: 0.635183\n",
      "epoch 41; iter: 0; batch classifier loss: 0.252007; batch adversarial loss: 0.652702\n",
      "epoch 42; iter: 0; batch classifier loss: 0.295148; batch adversarial loss: 0.617534\n",
      "epoch 43; iter: 0; batch classifier loss: 0.367163; batch adversarial loss: 0.637898\n",
      "epoch 44; iter: 0; batch classifier loss: 0.340076; batch adversarial loss: 0.641213\n",
      "epoch 45; iter: 0; batch classifier loss: 0.408962; batch adversarial loss: 0.655599\n",
      "epoch 46; iter: 0; batch classifier loss: 0.293058; batch adversarial loss: 0.593135\n",
      "epoch 47; iter: 0; batch classifier loss: 0.360711; batch adversarial loss: 0.580599\n",
      "epoch 48; iter: 0; batch classifier loss: 0.251673; batch adversarial loss: 0.562840\n",
      "epoch 49; iter: 0; batch classifier loss: 0.282420; batch adversarial loss: 0.582531\n",
      "epoch 50; iter: 0; batch classifier loss: 0.434557; batch adversarial loss: 0.620441\n",
      "epoch 51; iter: 0; batch classifier loss: 0.359187; batch adversarial loss: 0.567874\n",
      "epoch 52; iter: 0; batch classifier loss: 0.264956; batch adversarial loss: 0.719827\n",
      "epoch 53; iter: 0; batch classifier loss: 0.245699; batch adversarial loss: 0.564747\n",
      "epoch 54; iter: 0; batch classifier loss: 0.431232; batch adversarial loss: 0.628930\n",
      "epoch 55; iter: 0; batch classifier loss: 0.284103; batch adversarial loss: 0.669789\n",
      "epoch 56; iter: 0; batch classifier loss: 0.345093; batch adversarial loss: 0.611148\n",
      "epoch 57; iter: 0; batch classifier loss: 0.334454; batch adversarial loss: 0.629647\n",
      "epoch 58; iter: 0; batch classifier loss: 0.358063; batch adversarial loss: 0.659124\n",
      "epoch 59; iter: 0; batch classifier loss: 0.352984; batch adversarial loss: 0.630781\n",
      "epoch 0; iter: 0; batch classifier loss: 0.799062; batch adversarial loss: 0.763037\n",
      "epoch 1; iter: 0; batch classifier loss: 0.734639; batch adversarial loss: 0.766951\n",
      "epoch 2; iter: 0; batch classifier loss: 0.781570; batch adversarial loss: 0.828285\n",
      "epoch 3; iter: 0; batch classifier loss: 0.652180; batch adversarial loss: 0.757636\n",
      "epoch 4; iter: 0; batch classifier loss: 0.699253; batch adversarial loss: 0.812086\n",
      "epoch 5; iter: 0; batch classifier loss: 0.614050; batch adversarial loss: 0.730116\n",
      "epoch 6; iter: 0; batch classifier loss: 0.652806; batch adversarial loss: 0.771237\n",
      "epoch 7; iter: 0; batch classifier loss: 0.593134; batch adversarial loss: 0.754718\n",
      "epoch 8; iter: 0; batch classifier loss: 0.561907; batch adversarial loss: 0.700288\n",
      "epoch 9; iter: 0; batch classifier loss: 0.561880; batch adversarial loss: 0.711258\n",
      "epoch 10; iter: 0; batch classifier loss: 0.654589; batch adversarial loss: 0.765143\n",
      "epoch 11; iter: 0; batch classifier loss: 0.685119; batch adversarial loss: 0.727775\n",
      "epoch 12; iter: 0; batch classifier loss: 0.602494; batch adversarial loss: 0.720612\n",
      "epoch 13; iter: 0; batch classifier loss: 0.563343; batch adversarial loss: 0.676877\n",
      "epoch 14; iter: 0; batch classifier loss: 0.646932; batch adversarial loss: 0.714885\n",
      "epoch 15; iter: 0; batch classifier loss: 0.523334; batch adversarial loss: 0.658111\n",
      "epoch 16; iter: 0; batch classifier loss: 0.703699; batch adversarial loss: 0.749546\n",
      "epoch 17; iter: 0; batch classifier loss: 0.625871; batch adversarial loss: 0.678551\n",
      "epoch 18; iter: 0; batch classifier loss: 0.526289; batch adversarial loss: 0.686671\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425534; batch adversarial loss: 0.614196\n",
      "epoch 20; iter: 0; batch classifier loss: 0.531829; batch adversarial loss: 0.678294\n",
      "epoch 21; iter: 0; batch classifier loss: 0.450513; batch adversarial loss: 0.676999\n",
      "epoch 22; iter: 0; batch classifier loss: 0.427613; batch adversarial loss: 0.688123\n",
      "epoch 23; iter: 0; batch classifier loss: 0.603199; batch adversarial loss: 0.687494\n",
      "epoch 24; iter: 0; batch classifier loss: 0.531124; batch adversarial loss: 0.680827\n",
      "epoch 25; iter: 0; batch classifier loss: 0.606053; batch adversarial loss: 0.700385\n",
      "epoch 26; iter: 0; batch classifier loss: 0.529087; batch adversarial loss: 0.659331\n",
      "epoch 27; iter: 0; batch classifier loss: 0.528191; batch adversarial loss: 0.688611\n",
      "epoch 28; iter: 0; batch classifier loss: 0.428710; batch adversarial loss: 0.668406\n",
      "epoch 29; iter: 0; batch classifier loss: 0.491591; batch adversarial loss: 0.654395\n",
      "epoch 30; iter: 0; batch classifier loss: 0.361316; batch adversarial loss: 0.641521\n",
      "epoch 31; iter: 0; batch classifier loss: 0.416444; batch adversarial loss: 0.579526\n",
      "epoch 32; iter: 0; batch classifier loss: 0.462460; batch adversarial loss: 0.574997\n",
      "epoch 33; iter: 0; batch classifier loss: 0.360275; batch adversarial loss: 0.664198\n",
      "epoch 34; iter: 0; batch classifier loss: 0.458595; batch adversarial loss: 0.644059\n",
      "epoch 35; iter: 0; batch classifier loss: 0.357997; batch adversarial loss: 0.632606\n",
      "epoch 36; iter: 0; batch classifier loss: 0.468090; batch adversarial loss: 0.590781\n",
      "epoch 37; iter: 0; batch classifier loss: 0.311241; batch adversarial loss: 0.617890\n",
      "epoch 38; iter: 0; batch classifier loss: 0.403911; batch adversarial loss: 0.657332\n",
      "epoch 39; iter: 0; batch classifier loss: 0.307206; batch adversarial loss: 0.566190\n",
      "epoch 40; iter: 0; batch classifier loss: 0.309521; batch adversarial loss: 0.553972\n",
      "epoch 41; iter: 0; batch classifier loss: 0.320369; batch adversarial loss: 0.587758\n",
      "epoch 42; iter: 0; batch classifier loss: 0.326152; batch adversarial loss: 0.635423\n",
      "epoch 43; iter: 0; batch classifier loss: 0.315300; batch adversarial loss: 0.609206\n",
      "epoch 44; iter: 0; batch classifier loss: 0.329145; batch adversarial loss: 0.614449\n",
      "epoch 45; iter: 0; batch classifier loss: 0.285786; batch adversarial loss: 0.651197\n",
      "epoch 46; iter: 0; batch classifier loss: 0.310478; batch adversarial loss: 0.621759\n",
      "epoch 47; iter: 0; batch classifier loss: 0.341403; batch adversarial loss: 0.595581\n",
      "epoch 48; iter: 0; batch classifier loss: 0.298255; batch adversarial loss: 0.646398\n",
      "epoch 49; iter: 0; batch classifier loss: 0.280121; batch adversarial loss: 0.590527\n",
      "epoch 50; iter: 0; batch classifier loss: 0.314606; batch adversarial loss: 0.655021\n",
      "epoch 51; iter: 0; batch classifier loss: 0.344082; batch adversarial loss: 0.569879\n",
      "epoch 52; iter: 0; batch classifier loss: 0.431741; batch adversarial loss: 0.570550\n",
      "epoch 53; iter: 0; batch classifier loss: 0.432043; batch adversarial loss: 0.568025\n",
      "epoch 54; iter: 0; batch classifier loss: 0.262970; batch adversarial loss: 0.566704\n",
      "epoch 55; iter: 0; batch classifier loss: 0.371729; batch adversarial loss: 0.510459\n",
      "epoch 56; iter: 0; batch classifier loss: 0.288785; batch adversarial loss: 0.637288\n",
      "epoch 57; iter: 0; batch classifier loss: 0.325204; batch adversarial loss: 0.631514\n",
      "epoch 58; iter: 0; batch classifier loss: 0.350581; batch adversarial loss: 0.621593\n",
      "epoch 59; iter: 0; batch classifier loss: 0.325071; batch adversarial loss: 0.545880\n",
      "epoch 0; iter: 0; batch classifier loss: 0.735518; batch adversarial loss: 0.922729\n",
      "epoch 1; iter: 0; batch classifier loss: 0.725902; batch adversarial loss: 0.896956\n",
      "epoch 2; iter: 0; batch classifier loss: 0.709754; batch adversarial loss: 0.955076\n",
      "epoch 3; iter: 0; batch classifier loss: 0.702990; batch adversarial loss: 0.894951\n",
      "epoch 4; iter: 0; batch classifier loss: 0.649714; batch adversarial loss: 0.946862\n",
      "epoch 5; iter: 0; batch classifier loss: 0.658751; batch adversarial loss: 0.961477\n",
      "epoch 6; iter: 0; batch classifier loss: 0.648177; batch adversarial loss: 0.998826\n",
      "epoch 7; iter: 0; batch classifier loss: 0.641358; batch adversarial loss: 0.957267\n",
      "epoch 8; iter: 0; batch classifier loss: 0.542518; batch adversarial loss: 0.967203\n",
      "epoch 9; iter: 0; batch classifier loss: 0.584821; batch adversarial loss: 0.956123\n",
      "epoch 10; iter: 0; batch classifier loss: 0.628541; batch adversarial loss: 0.971364\n",
      "epoch 11; iter: 0; batch classifier loss: 0.591940; batch adversarial loss: 1.022104\n",
      "epoch 12; iter: 0; batch classifier loss: 0.555811; batch adversarial loss: 0.990170\n",
      "epoch 13; iter: 0; batch classifier loss: 0.553624; batch adversarial loss: 0.998295\n",
      "epoch 14; iter: 0; batch classifier loss: 0.556174; batch adversarial loss: 0.988689\n",
      "epoch 15; iter: 0; batch classifier loss: 0.537234; batch adversarial loss: 1.047471\n",
      "epoch 16; iter: 0; batch classifier loss: 0.523081; batch adversarial loss: 0.942566\n",
      "epoch 17; iter: 0; batch classifier loss: 0.583164; batch adversarial loss: 1.005545\n",
      "epoch 18; iter: 0; batch classifier loss: 0.569640; batch adversarial loss: 0.975953\n",
      "epoch 19; iter: 0; batch classifier loss: 0.549717; batch adversarial loss: 0.985469\n",
      "epoch 20; iter: 0; batch classifier loss: 0.588151; batch adversarial loss: 0.992479\n",
      "epoch 21; iter: 0; batch classifier loss: 0.581024; batch adversarial loss: 0.978030\n",
      "epoch 22; iter: 0; batch classifier loss: 0.533572; batch adversarial loss: 0.929382\n",
      "epoch 23; iter: 0; batch classifier loss: 0.546606; batch adversarial loss: 0.996112\n",
      "epoch 24; iter: 0; batch classifier loss: 0.470598; batch adversarial loss: 1.000317\n",
      "epoch 25; iter: 0; batch classifier loss: 0.579979; batch adversarial loss: 0.971834\n",
      "epoch 26; iter: 0; batch classifier loss: 0.591340; batch adversarial loss: 0.978720\n",
      "epoch 27; iter: 0; batch classifier loss: 0.558412; batch adversarial loss: 0.993973\n",
      "epoch 28; iter: 0; batch classifier loss: 0.554154; batch adversarial loss: 0.970399\n",
      "epoch 29; iter: 0; batch classifier loss: 0.576938; batch adversarial loss: 0.986737\n",
      "epoch 30; iter: 0; batch classifier loss: 0.565559; batch adversarial loss: 0.909042\n",
      "epoch 31; iter: 0; batch classifier loss: 0.579274; batch adversarial loss: 0.962737\n",
      "epoch 32; iter: 0; batch classifier loss: 0.531031; batch adversarial loss: 0.988365\n",
      "epoch 33; iter: 0; batch classifier loss: 0.683845; batch adversarial loss: 0.956463\n",
      "epoch 34; iter: 0; batch classifier loss: 0.587866; batch adversarial loss: 0.944045\n",
      "epoch 35; iter: 0; batch classifier loss: 0.650473; batch adversarial loss: 0.934229\n",
      "epoch 36; iter: 0; batch classifier loss: 0.644829; batch adversarial loss: 0.944448\n",
      "epoch 37; iter: 0; batch classifier loss: 0.713665; batch adversarial loss: 0.962772\n",
      "epoch 38; iter: 0; batch classifier loss: 0.606115; batch adversarial loss: 0.939157\n",
      "epoch 39; iter: 0; batch classifier loss: 0.571119; batch adversarial loss: 0.937685\n",
      "epoch 40; iter: 0; batch classifier loss: 0.527798; batch adversarial loss: 0.921098\n",
      "epoch 41; iter: 0; batch classifier loss: 0.603540; batch adversarial loss: 0.942497\n",
      "epoch 42; iter: 0; batch classifier loss: 0.696091; batch adversarial loss: 0.906999\n",
      "epoch 43; iter: 0; batch classifier loss: 0.639462; batch adversarial loss: 0.925898\n",
      "epoch 44; iter: 0; batch classifier loss: 0.622965; batch adversarial loss: 0.964083\n",
      "epoch 45; iter: 0; batch classifier loss: 0.616895; batch adversarial loss: 0.921702\n",
      "epoch 46; iter: 0; batch classifier loss: 0.532327; batch adversarial loss: 0.937979\n",
      "epoch 47; iter: 0; batch classifier loss: 0.611832; batch adversarial loss: 0.934343\n",
      "epoch 48; iter: 0; batch classifier loss: 0.585391; batch adversarial loss: 0.944052\n",
      "epoch 49; iter: 0; batch classifier loss: 0.659776; batch adversarial loss: 0.917450\n",
      "epoch 50; iter: 0; batch classifier loss: 0.613272; batch adversarial loss: 0.911481\n",
      "epoch 51; iter: 0; batch classifier loss: 0.545443; batch adversarial loss: 0.907327\n",
      "epoch 52; iter: 0; batch classifier loss: 0.795295; batch adversarial loss: 0.917026\n",
      "epoch 53; iter: 0; batch classifier loss: 0.609258; batch adversarial loss: 0.899067\n",
      "epoch 54; iter: 0; batch classifier loss: 0.579953; batch adversarial loss: 0.890015\n",
      "epoch 55; iter: 0; batch classifier loss: 0.579666; batch adversarial loss: 0.894362\n",
      "epoch 56; iter: 0; batch classifier loss: 0.623175; batch adversarial loss: 0.898431\n",
      "epoch 57; iter: 0; batch classifier loss: 0.674296; batch adversarial loss: 0.880021\n",
      "epoch 58; iter: 0; batch classifier loss: 0.642366; batch adversarial loss: 0.881828\n",
      "epoch 59; iter: 0; batch classifier loss: 0.673038; batch adversarial loss: 0.879395\n",
      "epoch 0; iter: 0; batch classifier loss: 0.661015; batch adversarial loss: 0.794953\n",
      "epoch 1; iter: 0; batch classifier loss: 0.629253; batch adversarial loss: 0.773680\n",
      "epoch 2; iter: 0; batch classifier loss: 0.605659; batch adversarial loss: 0.739154\n",
      "epoch 3; iter: 0; batch classifier loss: 0.562761; batch adversarial loss: 0.669234\n",
      "epoch 4; iter: 0; batch classifier loss: 0.583373; batch adversarial loss: 0.729821\n",
      "epoch 5; iter: 0; batch classifier loss: 0.554887; batch adversarial loss: 0.746997\n",
      "epoch 6; iter: 0; batch classifier loss: 0.589105; batch adversarial loss: 0.768429\n",
      "epoch 7; iter: 0; batch classifier loss: 0.632497; batch adversarial loss: 0.732920\n",
      "epoch 8; iter: 0; batch classifier loss: 0.612325; batch adversarial loss: 0.730494\n",
      "epoch 9; iter: 0; batch classifier loss: 0.610279; batch adversarial loss: 0.779364\n",
      "epoch 10; iter: 0; batch classifier loss: 0.632160; batch adversarial loss: 0.806883\n",
      "epoch 11; iter: 0; batch classifier loss: 0.625617; batch adversarial loss: 0.777294\n",
      "epoch 12; iter: 0; batch classifier loss: 0.634366; batch adversarial loss: 0.755026\n",
      "epoch 13; iter: 0; batch classifier loss: 0.685017; batch adversarial loss: 0.819882\n",
      "epoch 14; iter: 0; batch classifier loss: 0.600521; batch adversarial loss: 0.742514\n",
      "epoch 15; iter: 0; batch classifier loss: 0.655874; batch adversarial loss: 0.829425\n",
      "epoch 16; iter: 0; batch classifier loss: 0.638868; batch adversarial loss: 0.695562\n",
      "epoch 17; iter: 0; batch classifier loss: 0.653084; batch adversarial loss: 0.729689\n",
      "epoch 18; iter: 0; batch classifier loss: 0.635235; batch adversarial loss: 0.793759\n",
      "epoch 19; iter: 0; batch classifier loss: 0.635548; batch adversarial loss: 0.803199\n",
      "epoch 20; iter: 0; batch classifier loss: 0.673970; batch adversarial loss: 0.771136\n",
      "epoch 21; iter: 0; batch classifier loss: 0.631517; batch adversarial loss: 0.774905\n",
      "epoch 22; iter: 0; batch classifier loss: 0.729945; batch adversarial loss: 0.828396\n",
      "epoch 23; iter: 0; batch classifier loss: 0.639551; batch adversarial loss: 0.768230\n",
      "epoch 24; iter: 0; batch classifier loss: 0.561594; batch adversarial loss: 0.751300\n",
      "epoch 25; iter: 0; batch classifier loss: 0.625292; batch adversarial loss: 0.738335\n",
      "epoch 26; iter: 0; batch classifier loss: 0.605043; batch adversarial loss: 0.788431\n",
      "epoch 27; iter: 0; batch classifier loss: 0.616575; batch adversarial loss: 0.808109\n",
      "epoch 28; iter: 0; batch classifier loss: 0.705989; batch adversarial loss: 0.788820\n",
      "epoch 29; iter: 0; batch classifier loss: 0.617707; batch adversarial loss: 0.755967\n",
      "epoch 30; iter: 0; batch classifier loss: 0.591366; batch adversarial loss: 0.747204\n",
      "epoch 31; iter: 0; batch classifier loss: 0.557009; batch adversarial loss: 0.717382\n",
      "epoch 32; iter: 0; batch classifier loss: 0.610490; batch adversarial loss: 0.740063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.661722; batch adversarial loss: 0.781168\n",
      "epoch 34; iter: 0; batch classifier loss: 0.744257; batch adversarial loss: 0.832743\n",
      "epoch 35; iter: 0; batch classifier loss: 0.619763; batch adversarial loss: 0.750567\n",
      "epoch 36; iter: 0; batch classifier loss: 0.669354; batch adversarial loss: 0.711254\n",
      "epoch 37; iter: 0; batch classifier loss: 0.612199; batch adversarial loss: 0.803324\n",
      "epoch 38; iter: 0; batch classifier loss: 0.653638; batch adversarial loss: 0.752279\n",
      "epoch 39; iter: 0; batch classifier loss: 0.518968; batch adversarial loss: 0.709023\n",
      "epoch 40; iter: 0; batch classifier loss: 0.615327; batch adversarial loss: 0.762322\n",
      "epoch 41; iter: 0; batch classifier loss: 0.549030; batch adversarial loss: 0.745785\n",
      "epoch 42; iter: 0; batch classifier loss: 0.607977; batch adversarial loss: 0.705506\n",
      "epoch 43; iter: 0; batch classifier loss: 0.662595; batch adversarial loss: 0.691007\n",
      "epoch 44; iter: 0; batch classifier loss: 0.648727; batch adversarial loss: 0.693634\n",
      "epoch 45; iter: 0; batch classifier loss: 0.583937; batch adversarial loss: 0.741677\n",
      "epoch 46; iter: 0; batch classifier loss: 0.641457; batch adversarial loss: 0.775755\n",
      "epoch 47; iter: 0; batch classifier loss: 0.642170; batch adversarial loss: 0.744545\n",
      "epoch 48; iter: 0; batch classifier loss: 0.571670; batch adversarial loss: 0.769613\n",
      "epoch 49; iter: 0; batch classifier loss: 0.669669; batch adversarial loss: 0.729279\n",
      "epoch 50; iter: 0; batch classifier loss: 0.638609; batch adversarial loss: 0.702542\n",
      "epoch 51; iter: 0; batch classifier loss: 0.584581; batch adversarial loss: 0.674009\n",
      "epoch 52; iter: 0; batch classifier loss: 0.689201; batch adversarial loss: 0.724668\n",
      "epoch 53; iter: 0; batch classifier loss: 0.599690; batch adversarial loss: 0.662487\n",
      "epoch 54; iter: 0; batch classifier loss: 0.666316; batch adversarial loss: 0.766561\n",
      "epoch 55; iter: 0; batch classifier loss: 0.547332; batch adversarial loss: 0.753565\n",
      "epoch 56; iter: 0; batch classifier loss: 0.644621; batch adversarial loss: 0.764529\n",
      "epoch 57; iter: 0; batch classifier loss: 0.589280; batch adversarial loss: 0.732589\n",
      "epoch 58; iter: 0; batch classifier loss: 0.596320; batch adversarial loss: 0.723122\n",
      "epoch 59; iter: 0; batch classifier loss: 0.561695; batch adversarial loss: 0.681739\n",
      "epoch 0; iter: 0; batch classifier loss: 0.822284; batch adversarial loss: 0.838825\n",
      "epoch 1; iter: 0; batch classifier loss: 0.791997; batch adversarial loss: 0.854529\n",
      "epoch 2; iter: 0; batch classifier loss: 0.723372; batch adversarial loss: 0.836212\n",
      "epoch 3; iter: 0; batch classifier loss: 0.658540; batch adversarial loss: 0.852041\n",
      "epoch 4; iter: 0; batch classifier loss: 0.668319; batch adversarial loss: 0.866110\n",
      "epoch 5; iter: 0; batch classifier loss: 0.621853; batch adversarial loss: 0.879027\n",
      "epoch 6; iter: 0; batch classifier loss: 0.543777; batch adversarial loss: 0.855819\n",
      "epoch 7; iter: 0; batch classifier loss: 0.551234; batch adversarial loss: 0.805262\n",
      "epoch 8; iter: 0; batch classifier loss: 0.485654; batch adversarial loss: 0.962826\n",
      "epoch 9; iter: 0; batch classifier loss: 0.575917; batch adversarial loss: 0.820717\n",
      "epoch 10; iter: 0; batch classifier loss: 0.463542; batch adversarial loss: 0.838939\n",
      "epoch 11; iter: 0; batch classifier loss: 0.568943; batch adversarial loss: 0.790832\n",
      "epoch 12; iter: 0; batch classifier loss: 0.515959; batch adversarial loss: 0.788488\n",
      "epoch 13; iter: 0; batch classifier loss: 0.396645; batch adversarial loss: 0.860421\n",
      "epoch 14; iter: 0; batch classifier loss: 0.480004; batch adversarial loss: 0.786027\n",
      "epoch 15; iter: 0; batch classifier loss: 0.466678; batch adversarial loss: 0.816746\n",
      "epoch 16; iter: 0; batch classifier loss: 0.297887; batch adversarial loss: 0.824985\n",
      "epoch 17; iter: 0; batch classifier loss: 0.373776; batch adversarial loss: 0.796764\n",
      "epoch 18; iter: 0; batch classifier loss: 0.416589; batch adversarial loss: 0.818760\n",
      "epoch 19; iter: 0; batch classifier loss: 0.425692; batch adversarial loss: 0.809244\n",
      "epoch 20; iter: 0; batch classifier loss: 0.337586; batch adversarial loss: 0.773498\n",
      "epoch 21; iter: 0; batch classifier loss: 0.422354; batch adversarial loss: 0.790547\n",
      "epoch 22; iter: 0; batch classifier loss: 0.484355; batch adversarial loss: 0.802572\n",
      "epoch 23; iter: 0; batch classifier loss: 0.444247; batch adversarial loss: 0.777647\n",
      "epoch 24; iter: 0; batch classifier loss: 0.430366; batch adversarial loss: 0.737367\n",
      "epoch 25; iter: 0; batch classifier loss: 0.399930; batch adversarial loss: 0.746348\n",
      "epoch 26; iter: 0; batch classifier loss: 0.374632; batch adversarial loss: 0.738679\n",
      "epoch 27; iter: 0; batch classifier loss: 0.460326; batch adversarial loss: 0.705366\n",
      "epoch 28; iter: 0; batch classifier loss: 0.336478; batch adversarial loss: 0.755311\n",
      "epoch 29; iter: 0; batch classifier loss: 0.338497; batch adversarial loss: 0.748114\n",
      "epoch 30; iter: 0; batch classifier loss: 0.299207; batch adversarial loss: 0.720943\n",
      "epoch 31; iter: 0; batch classifier loss: 0.349222; batch adversarial loss: 0.744424\n",
      "epoch 32; iter: 0; batch classifier loss: 0.335919; batch adversarial loss: 0.745377\n",
      "epoch 33; iter: 0; batch classifier loss: 0.318404; batch adversarial loss: 0.699607\n",
      "epoch 34; iter: 0; batch classifier loss: 0.384248; batch adversarial loss: 0.726406\n",
      "epoch 35; iter: 0; batch classifier loss: 0.397563; batch adversarial loss: 0.699580\n",
      "epoch 36; iter: 0; batch classifier loss: 0.467808; batch adversarial loss: 0.722956\n",
      "epoch 37; iter: 0; batch classifier loss: 0.375196; batch adversarial loss: 0.724843\n",
      "epoch 38; iter: 0; batch classifier loss: 0.324749; batch adversarial loss: 0.696992\n",
      "epoch 39; iter: 0; batch classifier loss: 0.355304; batch adversarial loss: 0.712603\n",
      "epoch 40; iter: 0; batch classifier loss: 0.319964; batch adversarial loss: 0.726431\n",
      "epoch 41; iter: 0; batch classifier loss: 0.293643; batch adversarial loss: 0.684828\n",
      "epoch 42; iter: 0; batch classifier loss: 0.355677; batch adversarial loss: 0.656240\n",
      "epoch 43; iter: 0; batch classifier loss: 0.300963; batch adversarial loss: 0.676930\n",
      "epoch 44; iter: 0; batch classifier loss: 0.390968; batch adversarial loss: 0.688422\n",
      "epoch 45; iter: 0; batch classifier loss: 0.368118; batch adversarial loss: 0.663781\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269313; batch adversarial loss: 0.685878\n",
      "epoch 47; iter: 0; batch classifier loss: 0.311502; batch adversarial loss: 0.698923\n",
      "epoch 48; iter: 0; batch classifier loss: 0.375697; batch adversarial loss: 0.656000\n",
      "epoch 49; iter: 0; batch classifier loss: 0.369249; batch adversarial loss: 0.655831\n",
      "epoch 50; iter: 0; batch classifier loss: 0.286029; batch adversarial loss: 0.643201\n",
      "epoch 51; iter: 0; batch classifier loss: 0.382112; batch adversarial loss: 0.645045\n",
      "epoch 52; iter: 0; batch classifier loss: 0.297582; batch adversarial loss: 0.688110\n",
      "epoch 53; iter: 0; batch classifier loss: 0.290156; batch adversarial loss: 0.621342\n",
      "epoch 54; iter: 0; batch classifier loss: 0.245671; batch adversarial loss: 0.643322\n",
      "epoch 55; iter: 0; batch classifier loss: 0.379825; batch adversarial loss: 0.616348\n",
      "epoch 56; iter: 0; batch classifier loss: 0.382004; batch adversarial loss: 0.637308\n",
      "epoch 57; iter: 0; batch classifier loss: 0.340376; batch adversarial loss: 0.646188\n",
      "epoch 58; iter: 0; batch classifier loss: 0.328913; batch adversarial loss: 0.685631\n",
      "epoch 59; iter: 0; batch classifier loss: 0.278729; batch adversarial loss: 0.644935\n",
      "epoch 60; iter: 0; batch classifier loss: 0.363647; batch adversarial loss: 0.621112\n",
      "epoch 61; iter: 0; batch classifier loss: 0.309519; batch adversarial loss: 0.643917\n",
      "epoch 62; iter: 0; batch classifier loss: 0.391720; batch adversarial loss: 0.649066\n",
      "epoch 63; iter: 0; batch classifier loss: 0.221667; batch adversarial loss: 0.613077\n",
      "epoch 64; iter: 0; batch classifier loss: 0.225298; batch adversarial loss: 0.684803\n",
      "epoch 65; iter: 0; batch classifier loss: 0.308270; batch adversarial loss: 0.654161\n",
      "epoch 66; iter: 0; batch classifier loss: 0.274982; batch adversarial loss: 0.634672\n",
      "epoch 67; iter: 0; batch classifier loss: 0.293760; batch adversarial loss: 0.632023\n",
      "epoch 68; iter: 0; batch classifier loss: 0.280222; batch adversarial loss: 0.632702\n",
      "epoch 69; iter: 0; batch classifier loss: 0.314705; batch adversarial loss: 0.624365\n",
      "epoch 70; iter: 0; batch classifier loss: 0.169348; batch adversarial loss: 0.586825\n",
      "epoch 71; iter: 0; batch classifier loss: 0.283838; batch adversarial loss: 0.584400\n",
      "epoch 72; iter: 0; batch classifier loss: 0.328675; batch adversarial loss: 0.634537\n",
      "epoch 73; iter: 0; batch classifier loss: 0.288389; batch adversarial loss: 0.640363\n",
      "epoch 74; iter: 0; batch classifier loss: 0.254077; batch adversarial loss: 0.684379\n",
      "epoch 75; iter: 0; batch classifier loss: 0.358016; batch adversarial loss: 0.581944\n",
      "epoch 76; iter: 0; batch classifier loss: 0.350206; batch adversarial loss: 0.600116\n",
      "epoch 77; iter: 0; batch classifier loss: 0.304045; batch adversarial loss: 0.599845\n",
      "epoch 78; iter: 0; batch classifier loss: 0.323512; batch adversarial loss: 0.569467\n",
      "epoch 79; iter: 0; batch classifier loss: 0.314711; batch adversarial loss: 0.552724\n",
      "epoch 0; iter: 0; batch classifier loss: 0.749575; batch adversarial loss: 0.697125\n",
      "epoch 1; iter: 0; batch classifier loss: 0.670976; batch adversarial loss: 0.691025\n",
      "epoch 2; iter: 0; batch classifier loss: 0.620810; batch adversarial loss: 0.687495\n",
      "epoch 3; iter: 0; batch classifier loss: 0.559607; batch adversarial loss: 0.686544\n",
      "epoch 4; iter: 0; batch classifier loss: 0.520778; batch adversarial loss: 0.677336\n",
      "epoch 5; iter: 0; batch classifier loss: 0.594353; batch adversarial loss: 0.656814\n",
      "epoch 6; iter: 0; batch classifier loss: 0.433359; batch adversarial loss: 0.668937\n",
      "epoch 7; iter: 0; batch classifier loss: 0.371147; batch adversarial loss: 0.660116\n",
      "epoch 8; iter: 0; batch classifier loss: 0.489503; batch adversarial loss: 0.670837\n",
      "epoch 9; iter: 0; batch classifier loss: 0.389049; batch adversarial loss: 0.647359\n",
      "epoch 10; iter: 0; batch classifier loss: 0.500567; batch adversarial loss: 0.642626\n",
      "epoch 11; iter: 0; batch classifier loss: 0.428870; batch adversarial loss: 0.631923\n",
      "epoch 12; iter: 0; batch classifier loss: 0.295377; batch adversarial loss: 0.663473\n",
      "epoch 13; iter: 0; batch classifier loss: 0.592072; batch adversarial loss: 0.642516\n",
      "epoch 14; iter: 0; batch classifier loss: 0.301277; batch adversarial loss: 0.640199\n",
      "epoch 15; iter: 0; batch classifier loss: 0.398110; batch adversarial loss: 0.649066\n",
      "epoch 16; iter: 0; batch classifier loss: 0.460986; batch adversarial loss: 0.636650\n",
      "epoch 17; iter: 0; batch classifier loss: 0.365422; batch adversarial loss: 0.638461\n",
      "epoch 18; iter: 0; batch classifier loss: 0.334841; batch adversarial loss: 0.620844\n",
      "epoch 19; iter: 0; batch classifier loss: 0.410412; batch adversarial loss: 0.615048\n",
      "epoch 20; iter: 0; batch classifier loss: 0.270464; batch adversarial loss: 0.611714\n",
      "epoch 21; iter: 0; batch classifier loss: 0.392946; batch adversarial loss: 0.633997\n",
      "epoch 22; iter: 0; batch classifier loss: 0.347838; batch adversarial loss: 0.639360\n",
      "epoch 23; iter: 0; batch classifier loss: 0.380457; batch adversarial loss: 0.642138\n",
      "epoch 24; iter: 0; batch classifier loss: 0.299057; batch adversarial loss: 0.653333\n",
      "epoch 25; iter: 0; batch classifier loss: 0.345186; batch adversarial loss: 0.635174\n",
      "epoch 26; iter: 0; batch classifier loss: 0.286898; batch adversarial loss: 0.585512\n",
      "epoch 27; iter: 0; batch classifier loss: 0.210845; batch adversarial loss: 0.637384\n",
      "epoch 28; iter: 0; batch classifier loss: 0.407036; batch adversarial loss: 0.617561\n",
      "epoch 29; iter: 0; batch classifier loss: 0.306486; batch adversarial loss: 0.606392\n",
      "epoch 30; iter: 0; batch classifier loss: 0.332456; batch adversarial loss: 0.593539\n",
      "epoch 31; iter: 0; batch classifier loss: 0.266148; batch adversarial loss: 0.653779\n",
      "epoch 32; iter: 0; batch classifier loss: 0.238884; batch adversarial loss: 0.618767\n",
      "epoch 33; iter: 0; batch classifier loss: 0.272466; batch adversarial loss: 0.573062\n",
      "epoch 34; iter: 0; batch classifier loss: 0.350372; batch adversarial loss: 0.603683\n",
      "epoch 35; iter: 0; batch classifier loss: 0.440559; batch adversarial loss: 0.574332\n",
      "epoch 36; iter: 0; batch classifier loss: 0.282618; batch adversarial loss: 0.591165\n",
      "epoch 37; iter: 0; batch classifier loss: 0.324233; batch adversarial loss: 0.643766\n",
      "epoch 38; iter: 0; batch classifier loss: 0.186117; batch adversarial loss: 0.595153\n",
      "epoch 39; iter: 0; batch classifier loss: 0.268817; batch adversarial loss: 0.595922\n",
      "epoch 40; iter: 0; batch classifier loss: 0.229988; batch adversarial loss: 0.606910\n",
      "epoch 41; iter: 0; batch classifier loss: 0.243170; batch adversarial loss: 0.604786\n",
      "epoch 42; iter: 0; batch classifier loss: 0.432737; batch adversarial loss: 0.619269\n",
      "epoch 43; iter: 0; batch classifier loss: 0.317303; batch adversarial loss: 0.581180\n",
      "epoch 44; iter: 0; batch classifier loss: 0.237250; batch adversarial loss: 0.609788\n",
      "epoch 45; iter: 0; batch classifier loss: 0.294734; batch adversarial loss: 0.641100\n",
      "epoch 46; iter: 0; batch classifier loss: 0.269075; batch adversarial loss: 0.520108\n",
      "epoch 47; iter: 0; batch classifier loss: 0.294840; batch adversarial loss: 0.661682\n",
      "epoch 48; iter: 0; batch classifier loss: 0.302000; batch adversarial loss: 0.594110\n",
      "epoch 49; iter: 0; batch classifier loss: 0.233889; batch adversarial loss: 0.579173\n",
      "epoch 50; iter: 0; batch classifier loss: 0.198495; batch adversarial loss: 0.601541\n",
      "epoch 51; iter: 0; batch classifier loss: 0.259812; batch adversarial loss: 0.570772\n",
      "epoch 52; iter: 0; batch classifier loss: 0.307748; batch adversarial loss: 0.609113\n",
      "epoch 53; iter: 0; batch classifier loss: 0.229221; batch adversarial loss: 0.522994\n",
      "epoch 54; iter: 0; batch classifier loss: 0.288176; batch adversarial loss: 0.578466\n",
      "epoch 55; iter: 0; batch classifier loss: 0.329953; batch adversarial loss: 0.558656\n",
      "epoch 56; iter: 0; batch classifier loss: 0.292462; batch adversarial loss: 0.565369\n",
      "epoch 57; iter: 0; batch classifier loss: 0.366424; batch adversarial loss: 0.617450\n",
      "epoch 58; iter: 0; batch classifier loss: 0.233806; batch adversarial loss: 0.642436\n",
      "epoch 59; iter: 0; batch classifier loss: 0.160892; batch adversarial loss: 0.563366\n",
      "epoch 60; iter: 0; batch classifier loss: 0.259735; batch adversarial loss: 0.551913\n",
      "epoch 61; iter: 0; batch classifier loss: 0.369555; batch adversarial loss: 0.543436\n",
      "epoch 62; iter: 0; batch classifier loss: 0.347732; batch adversarial loss: 0.634179\n",
      "epoch 63; iter: 0; batch classifier loss: 0.245132; batch adversarial loss: 0.700848\n",
      "epoch 64; iter: 0; batch classifier loss: 0.263489; batch adversarial loss: 0.557733\n",
      "epoch 65; iter: 0; batch classifier loss: 0.265472; batch adversarial loss: 0.547175\n",
      "epoch 66; iter: 0; batch classifier loss: 0.322036; batch adversarial loss: 0.608968\n",
      "epoch 67; iter: 0; batch classifier loss: 0.353785; batch adversarial loss: 0.635702\n",
      "epoch 68; iter: 0; batch classifier loss: 0.298946; batch adversarial loss: 0.537891\n",
      "epoch 69; iter: 0; batch classifier loss: 0.302319; batch adversarial loss: 0.622139\n",
      "epoch 70; iter: 0; batch classifier loss: 0.369847; batch adversarial loss: 0.564879\n",
      "epoch 71; iter: 0; batch classifier loss: 0.326549; batch adversarial loss: 0.621095\n",
      "epoch 72; iter: 0; batch classifier loss: 0.305747; batch adversarial loss: 0.561423\n",
      "epoch 73; iter: 0; batch classifier loss: 0.308383; batch adversarial loss: 0.628533\n",
      "epoch 74; iter: 0; batch classifier loss: 0.306043; batch adversarial loss: 0.654063\n",
      "epoch 75; iter: 0; batch classifier loss: 0.339330; batch adversarial loss: 0.617991\n",
      "epoch 76; iter: 0; batch classifier loss: 0.265273; batch adversarial loss: 0.656792\n",
      "epoch 77; iter: 0; batch classifier loss: 0.381715; batch adversarial loss: 0.584653\n",
      "epoch 78; iter: 0; batch classifier loss: 0.382262; batch adversarial loss: 0.592100\n",
      "epoch 79; iter: 0; batch classifier loss: 0.350972; batch adversarial loss: 0.573385\n",
      "epoch 0; iter: 0; batch classifier loss: 0.845196; batch adversarial loss: 0.796511\n",
      "epoch 1; iter: 0; batch classifier loss: 0.835346; batch adversarial loss: 0.785008\n",
      "epoch 2; iter: 0; batch classifier loss: 0.801114; batch adversarial loss: 0.809800\n",
      "epoch 3; iter: 0; batch classifier loss: 0.794908; batch adversarial loss: 0.802743\n",
      "epoch 4; iter: 0; batch classifier loss: 0.778179; batch adversarial loss: 0.818929\n",
      "epoch 5; iter: 0; batch classifier loss: 0.702182; batch adversarial loss: 0.812267\n",
      "epoch 6; iter: 0; batch classifier loss: 0.685997; batch adversarial loss: 0.808905\n",
      "epoch 7; iter: 0; batch classifier loss: 0.692094; batch adversarial loss: 0.806558\n",
      "epoch 8; iter: 0; batch classifier loss: 0.691846; batch adversarial loss: 0.807482\n",
      "epoch 9; iter: 0; batch classifier loss: 0.649767; batch adversarial loss: 0.812356\n",
      "epoch 10; iter: 0; batch classifier loss: 0.634297; batch adversarial loss: 0.829062\n",
      "epoch 11; iter: 0; batch classifier loss: 0.636303; batch adversarial loss: 0.817118\n",
      "epoch 12; iter: 0; batch classifier loss: 0.624460; batch adversarial loss: 0.795350\n",
      "epoch 13; iter: 0; batch classifier loss: 0.594674; batch adversarial loss: 0.816406\n",
      "epoch 14; iter: 0; batch classifier loss: 0.587240; batch adversarial loss: 0.773998\n",
      "epoch 15; iter: 0; batch classifier loss: 0.581379; batch adversarial loss: 0.874836\n",
      "epoch 16; iter: 0; batch classifier loss: 0.531435; batch adversarial loss: 0.860821\n",
      "epoch 17; iter: 0; batch classifier loss: 0.542732; batch adversarial loss: 0.855512\n",
      "epoch 18; iter: 0; batch classifier loss: 0.544117; batch adversarial loss: 0.853418\n",
      "epoch 19; iter: 0; batch classifier loss: 0.488755; batch adversarial loss: 0.841799\n",
      "epoch 20; iter: 0; batch classifier loss: 0.556329; batch adversarial loss: 0.848846\n",
      "epoch 21; iter: 0; batch classifier loss: 0.473783; batch adversarial loss: 0.905567\n",
      "epoch 22; iter: 0; batch classifier loss: 0.491727; batch adversarial loss: 0.827605\n",
      "epoch 23; iter: 0; batch classifier loss: 0.456526; batch adversarial loss: 0.861949\n",
      "epoch 24; iter: 0; batch classifier loss: 0.468537; batch adversarial loss: 0.865132\n",
      "epoch 25; iter: 0; batch classifier loss: 0.429790; batch adversarial loss: 0.851887\n",
      "epoch 26; iter: 0; batch classifier loss: 0.437965; batch adversarial loss: 0.860164\n",
      "epoch 27; iter: 0; batch classifier loss: 0.474025; batch adversarial loss: 0.908255\n",
      "epoch 28; iter: 0; batch classifier loss: 0.470701; batch adversarial loss: 0.851873\n",
      "epoch 29; iter: 0; batch classifier loss: 0.461172; batch adversarial loss: 0.938902\n",
      "epoch 30; iter: 0; batch classifier loss: 0.405182; batch adversarial loss: 0.926202\n",
      "epoch 31; iter: 0; batch classifier loss: 0.431577; batch adversarial loss: 0.886046\n",
      "epoch 32; iter: 0; batch classifier loss: 0.379579; batch adversarial loss: 0.880146\n",
      "epoch 33; iter: 0; batch classifier loss: 0.429012; batch adversarial loss: 0.874068\n",
      "epoch 34; iter: 0; batch classifier loss: 0.381819; batch adversarial loss: 0.944909\n",
      "epoch 35; iter: 0; batch classifier loss: 0.433615; batch adversarial loss: 0.891692\n",
      "epoch 36; iter: 0; batch classifier loss: 0.462957; batch adversarial loss: 0.839924\n",
      "epoch 37; iter: 0; batch classifier loss: 0.417869; batch adversarial loss: 0.843872\n",
      "epoch 38; iter: 0; batch classifier loss: 0.374235; batch adversarial loss: 0.886615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.346067; batch adversarial loss: 0.888039\n",
      "epoch 40; iter: 0; batch classifier loss: 0.423006; batch adversarial loss: 0.869348\n",
      "epoch 41; iter: 0; batch classifier loss: 0.396098; batch adversarial loss: 0.848649\n",
      "epoch 42; iter: 0; batch classifier loss: 0.358449; batch adversarial loss: 0.871684\n",
      "epoch 43; iter: 0; batch classifier loss: 0.378762; batch adversarial loss: 0.798115\n",
      "epoch 44; iter: 0; batch classifier loss: 0.402868; batch adversarial loss: 0.858865\n",
      "epoch 45; iter: 0; batch classifier loss: 0.383056; batch adversarial loss: 0.853004\n",
      "epoch 46; iter: 0; batch classifier loss: 0.392726; batch adversarial loss: 0.841795\n",
      "epoch 47; iter: 0; batch classifier loss: 0.391049; batch adversarial loss: 0.867919\n",
      "epoch 48; iter: 0; batch classifier loss: 0.391687; batch adversarial loss: 0.826086\n",
      "epoch 49; iter: 0; batch classifier loss: 0.358743; batch adversarial loss: 0.784820\n",
      "epoch 50; iter: 0; batch classifier loss: 0.340845; batch adversarial loss: 0.842758\n",
      "epoch 51; iter: 0; batch classifier loss: 0.397999; batch adversarial loss: 0.845417\n",
      "epoch 52; iter: 0; batch classifier loss: 0.275585; batch adversarial loss: 0.857615\n",
      "epoch 53; iter: 0; batch classifier loss: 0.349093; batch adversarial loss: 0.850573\n",
      "epoch 54; iter: 0; batch classifier loss: 0.293441; batch adversarial loss: 0.832274\n",
      "epoch 55; iter: 0; batch classifier loss: 0.348295; batch adversarial loss: 0.802427\n",
      "epoch 56; iter: 0; batch classifier loss: 0.346816; batch adversarial loss: 0.811500\n",
      "epoch 57; iter: 0; batch classifier loss: 0.341131; batch adversarial loss: 0.841140\n",
      "epoch 58; iter: 0; batch classifier loss: 0.366201; batch adversarial loss: 0.791729\n",
      "epoch 59; iter: 0; batch classifier loss: 0.316306; batch adversarial loss: 0.775135\n",
      "epoch 60; iter: 0; batch classifier loss: 0.330948; batch adversarial loss: 0.814760\n",
      "epoch 61; iter: 0; batch classifier loss: 0.414264; batch adversarial loss: 0.790208\n",
      "epoch 62; iter: 0; batch classifier loss: 0.341271; batch adversarial loss: 0.819483\n",
      "epoch 63; iter: 0; batch classifier loss: 0.322105; batch adversarial loss: 0.759764\n",
      "epoch 64; iter: 0; batch classifier loss: 0.289750; batch adversarial loss: 0.769737\n",
      "epoch 65; iter: 0; batch classifier loss: 0.339644; batch adversarial loss: 0.797114\n",
      "epoch 66; iter: 0; batch classifier loss: 0.367681; batch adversarial loss: 0.805646\n",
      "epoch 67; iter: 0; batch classifier loss: 0.351742; batch adversarial loss: 0.791910\n",
      "epoch 68; iter: 0; batch classifier loss: 0.332658; batch adversarial loss: 0.767777\n",
      "epoch 69; iter: 0; batch classifier loss: 0.352280; batch adversarial loss: 0.825907\n",
      "epoch 70; iter: 0; batch classifier loss: 0.307338; batch adversarial loss: 0.766017\n",
      "epoch 71; iter: 0; batch classifier loss: 0.257869; batch adversarial loss: 0.776790\n",
      "epoch 72; iter: 0; batch classifier loss: 0.335577; batch adversarial loss: 0.761403\n",
      "epoch 73; iter: 0; batch classifier loss: 0.405681; batch adversarial loss: 0.770100\n",
      "epoch 74; iter: 0; batch classifier loss: 0.321924; batch adversarial loss: 0.783078\n",
      "epoch 75; iter: 0; batch classifier loss: 0.333756; batch adversarial loss: 0.773360\n",
      "epoch 76; iter: 0; batch classifier loss: 0.349824; batch adversarial loss: 0.795354\n",
      "epoch 77; iter: 0; batch classifier loss: 0.298286; batch adversarial loss: 0.735624\n",
      "epoch 78; iter: 0; batch classifier loss: 0.356665; batch adversarial loss: 0.756167\n",
      "epoch 79; iter: 0; batch classifier loss: 0.375578; batch adversarial loss: 0.719701\n",
      "epoch 0; iter: 0; batch classifier loss: 0.768761; batch adversarial loss: 0.669048\n",
      "epoch 1; iter: 0; batch classifier loss: 0.711441; batch adversarial loss: 0.668740\n",
      "epoch 2; iter: 0; batch classifier loss: 0.694881; batch adversarial loss: 0.690154\n",
      "epoch 3; iter: 0; batch classifier loss: 0.665934; batch adversarial loss: 0.673811\n",
      "epoch 4; iter: 0; batch classifier loss: 0.634811; batch adversarial loss: 0.658019\n",
      "epoch 5; iter: 0; batch classifier loss: 0.629223; batch adversarial loss: 0.680384\n",
      "epoch 6; iter: 0; batch classifier loss: 0.628182; batch adversarial loss: 0.674944\n",
      "epoch 7; iter: 0; batch classifier loss: 0.586712; batch adversarial loss: 0.679790\n",
      "epoch 8; iter: 0; batch classifier loss: 0.539828; batch adversarial loss: 0.686780\n",
      "epoch 9; iter: 0; batch classifier loss: 0.526381; batch adversarial loss: 0.683461\n",
      "epoch 10; iter: 0; batch classifier loss: 0.498766; batch adversarial loss: 0.680500\n",
      "epoch 11; iter: 0; batch classifier loss: 0.505912; batch adversarial loss: 0.679348\n",
      "epoch 12; iter: 0; batch classifier loss: 0.536742; batch adversarial loss: 0.700756\n",
      "epoch 13; iter: 0; batch classifier loss: 0.501695; batch adversarial loss: 0.661881\n",
      "epoch 14; iter: 0; batch classifier loss: 0.546293; batch adversarial loss: 0.645014\n",
      "epoch 15; iter: 0; batch classifier loss: 0.474541; batch adversarial loss: 0.690520\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453793; batch adversarial loss: 0.657751\n",
      "epoch 17; iter: 0; batch classifier loss: 0.419020; batch adversarial loss: 0.659247\n",
      "epoch 18; iter: 0; batch classifier loss: 0.500665; batch adversarial loss: 0.657101\n",
      "epoch 19; iter: 0; batch classifier loss: 0.451207; batch adversarial loss: 0.674029\n",
      "epoch 20; iter: 0; batch classifier loss: 0.427688; batch adversarial loss: 0.681005\n",
      "epoch 21; iter: 0; batch classifier loss: 0.441035; batch adversarial loss: 0.652051\n",
      "epoch 22; iter: 0; batch classifier loss: 0.413382; batch adversarial loss: 0.671816\n",
      "epoch 23; iter: 0; batch classifier loss: 0.497683; batch adversarial loss: 0.661272\n",
      "epoch 24; iter: 0; batch classifier loss: 0.378004; batch adversarial loss: 0.677518\n",
      "epoch 25; iter: 0; batch classifier loss: 0.371183; batch adversarial loss: 0.671219\n",
      "epoch 26; iter: 0; batch classifier loss: 0.372707; batch adversarial loss: 0.654158\n",
      "epoch 27; iter: 0; batch classifier loss: 0.411607; batch adversarial loss: 0.668524\n",
      "epoch 28; iter: 0; batch classifier loss: 0.315939; batch adversarial loss: 0.666860\n",
      "epoch 29; iter: 0; batch classifier loss: 0.405100; batch adversarial loss: 0.678733\n",
      "epoch 30; iter: 0; batch classifier loss: 0.365906; batch adversarial loss: 0.656962\n",
      "epoch 31; iter: 0; batch classifier loss: 0.390225; batch adversarial loss: 0.657407\n",
      "epoch 32; iter: 0; batch classifier loss: 0.349270; batch adversarial loss: 0.648063\n",
      "epoch 33; iter: 0; batch classifier loss: 0.307963; batch adversarial loss: 0.687190\n",
      "epoch 34; iter: 0; batch classifier loss: 0.293921; batch adversarial loss: 0.656020\n",
      "epoch 35; iter: 0; batch classifier loss: 0.406562; batch adversarial loss: 0.654101\n",
      "epoch 36; iter: 0; batch classifier loss: 0.346222; batch adversarial loss: 0.658486\n",
      "epoch 37; iter: 0; batch classifier loss: 0.319537; batch adversarial loss: 0.680396\n",
      "epoch 38; iter: 0; batch classifier loss: 0.282719; batch adversarial loss: 0.670709\n",
      "epoch 39; iter: 0; batch classifier loss: 0.347541; batch adversarial loss: 0.643474\n",
      "epoch 40; iter: 0; batch classifier loss: 0.343797; batch adversarial loss: 0.651588\n",
      "epoch 41; iter: 0; batch classifier loss: 0.295521; batch adversarial loss: 0.665921\n",
      "epoch 42; iter: 0; batch classifier loss: 0.335444; batch adversarial loss: 0.681700\n",
      "epoch 43; iter: 0; batch classifier loss: 0.337123; batch adversarial loss: 0.655163\n",
      "epoch 44; iter: 0; batch classifier loss: 0.262878; batch adversarial loss: 0.668639\n",
      "epoch 45; iter: 0; batch classifier loss: 0.293251; batch adversarial loss: 0.670574\n",
      "epoch 46; iter: 0; batch classifier loss: 0.300137; batch adversarial loss: 0.629787\n",
      "epoch 47; iter: 0; batch classifier loss: 0.260005; batch adversarial loss: 0.640233\n",
      "epoch 48; iter: 0; batch classifier loss: 0.293127; batch adversarial loss: 0.641384\n",
      "epoch 49; iter: 0; batch classifier loss: 0.327245; batch adversarial loss: 0.677736\n",
      "epoch 50; iter: 0; batch classifier loss: 0.355789; batch adversarial loss: 0.640958\n",
      "epoch 51; iter: 0; batch classifier loss: 0.322329; batch adversarial loss: 0.640103\n",
      "epoch 52; iter: 0; batch classifier loss: 0.354031; batch adversarial loss: 0.659879\n",
      "epoch 53; iter: 0; batch classifier loss: 0.282078; batch adversarial loss: 0.642848\n",
      "epoch 54; iter: 0; batch classifier loss: 0.343246; batch adversarial loss: 0.666121\n",
      "epoch 55; iter: 0; batch classifier loss: 0.267919; batch adversarial loss: 0.659992\n",
      "epoch 56; iter: 0; batch classifier loss: 0.336314; batch adversarial loss: 0.644221\n",
      "epoch 57; iter: 0; batch classifier loss: 0.276116; batch adversarial loss: 0.651922\n",
      "epoch 58; iter: 0; batch classifier loss: 0.316503; batch adversarial loss: 0.649716\n",
      "epoch 59; iter: 0; batch classifier loss: 0.349679; batch adversarial loss: 0.605892\n",
      "epoch 60; iter: 0; batch classifier loss: 0.245053; batch adversarial loss: 0.646362\n",
      "epoch 61; iter: 0; batch classifier loss: 0.353416; batch adversarial loss: 0.612180\n",
      "epoch 62; iter: 0; batch classifier loss: 0.304415; batch adversarial loss: 0.621112\n",
      "epoch 63; iter: 0; batch classifier loss: 0.224019; batch adversarial loss: 0.660618\n",
      "epoch 64; iter: 0; batch classifier loss: 0.280115; batch adversarial loss: 0.660065\n",
      "epoch 65; iter: 0; batch classifier loss: 0.270041; batch adversarial loss: 0.629794\n",
      "epoch 66; iter: 0; batch classifier loss: 0.228132; batch adversarial loss: 0.623426\n",
      "epoch 67; iter: 0; batch classifier loss: 0.340772; batch adversarial loss: 0.620283\n",
      "epoch 68; iter: 0; batch classifier loss: 0.294775; batch adversarial loss: 0.654562\n",
      "epoch 69; iter: 0; batch classifier loss: 0.274698; batch adversarial loss: 0.643116\n",
      "epoch 70; iter: 0; batch classifier loss: 0.261967; batch adversarial loss: 0.619801\n",
      "epoch 71; iter: 0; batch classifier loss: 0.369551; batch adversarial loss: 0.637096\n",
      "epoch 72; iter: 0; batch classifier loss: 0.358129; batch adversarial loss: 0.637460\n",
      "epoch 73; iter: 0; batch classifier loss: 0.361917; batch adversarial loss: 0.639660\n",
      "epoch 74; iter: 0; batch classifier loss: 0.210367; batch adversarial loss: 0.637089\n",
      "epoch 75; iter: 0; batch classifier loss: 0.411925; batch adversarial loss: 0.638483\n",
      "epoch 76; iter: 0; batch classifier loss: 0.194569; batch adversarial loss: 0.643648\n",
      "epoch 77; iter: 0; batch classifier loss: 0.226499; batch adversarial loss: 0.623852\n",
      "epoch 78; iter: 0; batch classifier loss: 0.392780; batch adversarial loss: 0.614277\n",
      "epoch 79; iter: 0; batch classifier loss: 0.281960; batch adversarial loss: 0.632975\n",
      "\n",
      "=== ADV in-proc (best) w=0.2, e=40, b=128, h=32 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>Recall</th>\n",
       "      <th>SelectionRate</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.864583</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          TPR      FPR    Recall  SelectionRate  Accuracy\n",
       "Sex                                                      \n",
       "0    0.833333  0.15625  0.833333       0.263158  0.842105\n",
       "1    0.864583  0.10000  0.864583       0.602740  0.876712"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall -> Accuracy: 0.8696 | DP diff: 0.3396 | EO diff: 0.0312 | combined gap (DP+EO)=0.3708; acc=0.8696\n"
     ]
    }
   ],
   "source": [
    "# Grid-tune AIF360 AdversarialDebiasing for better DP/EO balance and print with report_model\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
    "\n",
    "# small search over key knobs; widen if needed\n",
    "ADV_GRID = dict(\n",
    "    adversary_loss_weight=[0.02, 0.05, 0.1, 0.2, 0.3],\n",
    "    num_epochs=[40, 60, 80],\n",
    "    batch_size=[64, 128],\n",
    "    classifier_num_hidden_units=[32, 64]  # size of main net\n",
    ")\n",
    "\n",
    "def run_adv(loss_w=0.1, epochs=50, bs=128, hidden=64, seed=42):\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    sess = tf.compat.v1.Session()\n",
    "    with sess.as_default():\n",
    "        adv = AdversarialDebiasing(\n",
    "            privileged_groups=privileged_groups,\n",
    "            unprivileged_groups=unprivileged_groups,\n",
    "            debias=True,\n",
    "            scope_name=f\"adv_w{loss_w}_e{epochs}_b{bs}_h{hidden}\",\n",
    "            adversary_loss_weight=loss_w,\n",
    "            num_epochs=epochs,\n",
    "            batch_size=bs,\n",
    "            classifier_num_hidden_units=hidden,\n",
    "            sess=sess\n",
    "        )\n",
    "        adv.fit(bld_tr)\n",
    "        pred_te = adv.predict(bld_te)\n",
    "        yhat = pred_te.labels.ravel().astype(int)\n",
    "        scores = getattr(pred_te, \"scores\", None)\n",
    "        if scores is None:\n",
    "            scores = yhat.astype(float)\n",
    "    sess.close()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    return yhat, scores\n",
    "\n",
    "# Build once (as you did)\n",
    "bld_tr = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_train_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_train, name=label_name),\n",
    "                  pd.Series(A_train, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "bld_te = BinaryLabelDataset(\n",
    "    df=pd.concat([pd.DataFrame(X_test_ready).reset_index(drop=True),\n",
    "                  pd.Series(y_test, name=label_name),\n",
    "                  pd.Series(A_test, name=protected_attr)], axis=1),\n",
    "    label_names=[label_name], protected_attribute_names=[protected_attr],\n",
    "    favorable_label=favorable_label, unfavorable_label=unfavorable_label\n",
    ")\n",
    "\n",
    "# Search & pick the best by minimizing (DP + EO) with an accuracy floor\n",
    "best = None\n",
    "acc_floor = 0.86  # keep close to your current accuracy; adjust as you like\n",
    "results = []\n",
    "for w in ADV_GRID[\"adversary_loss_weight\"]:\n",
    "    for e in ADV_GRID[\"num_epochs\"]:\n",
    "        for bs in ADV_GRID[\"batch_size\"]:\n",
    "            for h in ADV_GRID[\"classifier_num_hidden_units\"]:\n",
    "                yhat, scores = run_adv(w, e, bs, h)\n",
    "                acc = accuracy_score(y_test, yhat)\n",
    "                dp, eo = fair_metrics(y_test, yhat, A_test, scores, absolute=True)\n",
    "                obj = dp + eo\n",
    "                results.append((obj, acc, dp, eo, w, e, bs, h, yhat, scores))\n",
    "                if (best is None or obj < best[0]) and acc >= acc_floor:\n",
    "                    best = (obj, acc, dp, eo, w, e, bs, h, yhat, scores)\n",
    "\n",
    "# Report best and (optionally) a few runners-up\n",
    "if best is None:\n",
    "    # fallback: take global best even if below floor\n",
    "    best = sorted(results, key=lambda t: t[0])[0]\n",
    "\n",
    "obj, acc, dp, eo, w, e, bs, h, yhat_best, scores_best = best\n",
    "_ = report_model(\n",
    "    f\"ADV in-proc (best) w={w}, e={e}, b={bs}, h={h}\",\n",
    "    y_test, yhat_best, A_test, scores=scores_best,\n",
    "    note=f\"combined gap (DP+EO)={obj:.4f}; acc={acc:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecba251",
   "metadata": {},
   "source": [
    "## ADV In-processing (tuned)\n",
    "\n",
    "### Results overview\n",
    "| Variant            | Accuracy | DP diff | EO diff (TPR gap) | DP+EO |\n",
    "|--------------------|---------:|--------:|------------------:|------:|\n",
    "| ADV in-proc (best) | 0.8696   | 0.3396  | **0.0312**        | **0.3708** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-group behavior (Female → 0, Male → 1)\n",
    "\n",
    "#### ADV in-proc (best, tuned)\n",
    "- **Selection rate:** 0 **0.263**, 1 **0.603** → DP gap **0.340** (moderate).  \n",
    "- **TPR (Recall):** 0 **0.833**, 1 **0.865** → **near parity** (EO gap **0.031**, very small).  \n",
    "- **FPR:** 0 **0.156**, 1 **0.100** (slightly higher for females).  \n",
    "- **Accuracy:** Female **0.842**, Male **0.877** → both groups solid, males a bit higher.  \n",
    "\n",
    "---\n",
    "\n",
    "### Implications\n",
    "- **EO gap is very low (0.031)**, showing the model balances recall well between groups.  \n",
    "- **DP gap (0.340)** is still present but improved compared to earlier ADV results.  \n",
    "- **Accuracy (0.870)** is the highest among ADV runs so far, showing good overall performance.  \n",
    "- **Overall:** This tuned ADV configuration achieves the **best balance so far** — high accuracy, minimal EO gap, and moderate DP disparity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996d7e49",
   "metadata": {},
   "source": [
    "# Overall Comparison of Bias Mitigation Results\n",
    "\n",
    "## Results overview\n",
    "| Model / Variant       | Accuracy | DP diff | EO diff | DP+EO | Key Point                                                      |\n",
    "|------------------------|---------:|--------:|--------:|------:|----------------------------------------------------------------|\n",
    "| **KNN – Baseline**     | 0.8859   | 0.3796  | **0.0521** | **0.4317** | Strong accuracy, small EO, but DP remains high.                |\n",
    "| KNN – Pre: Reweigh     | 0.8641   | **0.3659** | 0.1562 | 0.5221 | Slight DP gain, EO worsens, accuracy lower.                    |\n",
    "| KNN – Post: EqOdds     | 0.8859   | 0.3796  | **0.0521** | **0.4317** | Identical to baseline.                                         |\n",
    "| **DT – Baseline**      | 0.8098   | 0.2549  | **0.0104** | 0.2653 | Very low EO, but DP moderate.                                  |\n",
    "| DT – Pre: Reweigh      | 0.8098   | 0.2138  | 0.1979 | 0.4117 | Best DP, but EO worsens sharply.                               |\n",
    "| DT – Post: EqOdds      | 0.8043   | **0.1896** | 0.0312 | **0.2208** | Best balance (lowest DP+EO), slight accuracy drop.             |\n",
    "| **RF – Baseline**      | 0.8804   | 0.4081  | **0.0833** | 0.4914 | High accuracy, good EO, DP high.                              |\n",
    "| RF – Pre: Reweigh      | 0.8804   | 0.4081  | **0.0833** | 0.4914 | Same as baseline.                                              |\n",
    "| RF – Post: EqOdds      | 0.8750   | **0.3818** | **0.0833** | **0.4651** | Slight DP gain, accuracy small drop.                           |\n",
    "| **MLP – Baseline**     | 0.8587   | **0.3396** | 0.1562 | 0.4958 | Strong accuracy, moderate DP, EO gap.                         |\n",
    "| MLP – Pre: Reweigh     | 0.8587   | 0.3612  | **0.1146** | **0.4758** | Best EO, DP worsens, accuracy stable.                          |\n",
    "| MLP – Post: EqOdds     | 0.8098   | 0.3327  | 0.2083 | 0.5410 | Accuracy loss, EO worsens, DP slightly better.                 |\n",
    "| **ADV in-proc**        | 0.8533   | **0.2859** | 0.1771 | 0.4630 | Best DP among ADV runs, EO worsens.                            |\n",
    "| **ADV in-proc (tuned)**| 0.8696   | 0.3396  | **0.0312** | **0.3708** | Best ADV overall: strong accuracy + minimal EO.                |\n",
    "\n",
    "---\n",
    "\n",
    "## Cross-Model Insights\n",
    "- **Best DP parity:** DT Post (0.1896) → lowest selection gap, with still-low EO (0.031).  \n",
    "- **Best EO parity:** DT Baseline (0.010) and ADV tuned (0.031) → almost perfect recall equality.  \n",
    "- **Best combined (DP+EO):** DT Post (0.221) → best fairness overall, though accuracy is lower.  \n",
    "- **Best accuracy with fairness:** KNN Baseline (0.886, EO 0.052) and ADV tuned (0.870, EO 0.031).  \n",
    "- **Weakest performers:** MLP Post (accuracy down, EO up) and RF Pre (no changes vs baseline).  \n",
    "\n",
    "---\n",
    "\n",
    "## Takeaways\n",
    "- **KNN:** Baseline already the best trade-off — small EO, high accuracy.  \n",
    "- **DT:** Post-processing Equalized Odds clearly dominates, minimizing both DP and EO.  \n",
    "- **RF:** Baseline is strong; mitigation adds little benefit.  \n",
    "- **MLP:** Reweighing best — reduces EO while holding accuracy.  \n",
    "- **ADV (tuned):** Best global balance across models — **high accuracy, excellent EO parity, and moderate DP**.  \n",
    "\n",
    "Overall, **DT Post and ADV tuned** stand out as the strongest fairness strategies:  \n",
    "- DT Post is the **fairest** (lowest DP+EO overall).  \n",
    "- ADV tuned is the **most balanced** (high accuracy + very small EO gap).\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
