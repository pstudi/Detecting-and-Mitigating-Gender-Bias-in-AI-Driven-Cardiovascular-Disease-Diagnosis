{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288d499e",
   "metadata": {},
   "source": [
    "## CVD Prediction - Heart Failure Prediction Dataset (Source: https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/data)\n",
    "Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e647717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>130.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  RestingECG  \\\n",
       "0   33    0              3      100.0        246.0          0           0   \n",
       "1   48    0              1      120.0        284.0          0           0   \n",
       "2   49    0              3      130.0        269.0          0           0   \n",
       "3   62    0              3      140.0        268.0          0           2   \n",
       "4   38    0              3      105.0        236.0          1           0   \n",
       "\n",
       "   MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
       "0  150.0               1      1.0         1             1  \n",
       "1  120.0               0      0.0         2             0  \n",
       "2  163.0               0      0.0         2             0  \n",
       "3  160.0               0      3.6         0             1  \n",
       "4  166.0               0      2.8         2             1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load preprocessed data \n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./data_subsets/train_25M_75F.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"./data_splits/X_test.csv\")\n",
    "y_test = pd.read_csv(\"./data_splits/y_test.csv\")\n",
    "\n",
    "#check out the data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2a2677",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"HeartDisease\"\n",
    "SENSITIVE = \"Sex\"   # 1 = Male, 0 = Female\n",
    "\n",
    "categorical_cols = ['Sex','ChestPainType','FastingBS','RestingECG','ExerciseAngina','ST_Slope']\n",
    "continuous_cols  = ['Age','RestingBP','Cholesterol','MaxHR','Oldpeak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82e252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into X / y and keep sensitive feature for fairness evaluation\n",
    "X_train = train_df.drop(columns=[TARGET])\n",
    "y_train = train_df[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e35ed10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numeric features only, fit on train, transform test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_num_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_train.index\n",
    ")\n",
    "X_test_num_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test[continuous_cols]),\n",
    "    columns=continuous_cols, index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode categoricals; numeric are kept as is \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\", sparse_output=False)\n",
    "ohe.fit(X_train[categorical_cols])\n",
    "\n",
    "X_train_cat = pd.DataFrame(\n",
    "    ohe.transform(X_train[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_train.index\n",
    ")\n",
    "X_test_cat = pd.DataFrame(\n",
    "    ohe.transform(X_test[categorical_cols]),\n",
    "    columns=ohe.get_feature_names_out(categorical_cols),\n",
    "    index=X_test.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7189386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature shapes: (600, 18) (184, 18)\n"
     ]
    }
   ],
   "source": [
    "# Assemble final matrices\n",
    "X_train_ready = pd.concat([X_train_cat, X_train_num_scaled], axis=1)\n",
    "X_test_ready  = pd.concat([X_test_cat,  X_test_num_scaled],  axis=1)\n",
    "\n",
    "print(\"Final feature shapes:\", X_train_ready.shape, X_test_ready.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade7ec1",
   "metadata": {},
   "source": [
    "### Traditional ML Models - Baseline: K-Nearest Neighbors (KNN) & Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf455d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "#define a function for model evaluation\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(\"Accuracy :\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average='binary'))\n",
    "    print(\"Recall   :\", recall_score(y_true, y_pred, average='binary'))\n",
    "    print(\"F1 Score :\", f1_score(y_true, y_pred, average='binary'))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b368dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Evaluation ===\n",
      "Accuracy : 0.782608695652174\n",
      "Precision: 0.8690476190476191\n",
      "Recall   : 0.7156862745098039\n",
      "F1 Score : 0.7849462365591398\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.87      0.78        82\n",
      "           1       0.87      0.72      0.78       102\n",
      "\n",
      "    accuracy                           0.78       184\n",
      "   macro avg       0.79      0.79      0.78       184\n",
      "weighted avg       0.80      0.78      0.78       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [29 73]]\n",
      "\n",
      "========================================\n",
      "\n",
      "=== Decision Tree Evaluation ===\n",
      "Accuracy : 0.7934782608695652\n",
      "Precision: 0.82\n",
      "Recall   : 0.803921568627451\n",
      "F1 Score : 0.8118811881188119\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77        82\n",
      "           1       0.82      0.80      0.81       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.79      0.79      0.79       184\n",
      "weighted avg       0.79      0.79      0.79       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[64 18]\n",
      " [20 82]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_ready, y_train)\n",
    "y_pred_knn = knn.predict(X_test_ready)\n",
    "y_prob_knn = knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Decision Tree\n",
    "baseline_dt = DecisionTreeClassifier(random_state=42)\n",
    "baseline_dt.fit(X_train_ready, y_train)\n",
    "y_pred_dt = baseline_dt.predict(X_test_ready)\n",
    "y_prob_dt = baseline_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d687df",
   "metadata": {},
   "source": [
    "## KNN Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 78.3%  \n",
    "- **Precision**: 86.9%  \n",
    "- **Recall**: 71.6%  \n",
    "- **F1 Score**: 78.5%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 71           | 11           |\n",
    "| **Actual: 1** | 29           | 73           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **high precision (87%)**, meaning its positive predictions are usually correct.  \n",
    "- However, **recall is lower (72%)**, with **29 missed CVD cases (false negatives)**.  \n",
    "- The confusion matrix confirms the model is more conservative: fewer false alarms but more missed cases.  \n",
    "- Overall, this KNN model is **precision-focused**, which may limit its usefulness in medical screening where recall (sensitivity) is critical.  \n",
    "\n",
    "---\n",
    "\n",
    "## Decision Tree Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 79.3%  \n",
    "- **Precision**: 82.0%  \n",
    "- **Recall**: 80.4%  \n",
    "- **F1 Score**: 81.2%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 64           | 18           |\n",
    "| **Actual: 1** | 20           | 82           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves a **balanced trade-off** between precision (82%) and recall (80%).  \n",
    "- **20 CVD cases were missed** (false negatives), while **18 healthy cases were incorrectly flagged** (false positives).  \n",
    "- This indicates the Decision Tree provides **stable, well-rounded performance**, detecting most CVD cases while keeping false alarms at a moderate level.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0bb4c",
   "metadata": {},
   "source": [
    "### KNN Improvement\n",
    "The code improves the KNN model by performing a **grid search** over key hyperparameters (`n_neighbors`, `weights`, and `distance metric`) to find the configuration that yields the best performance. After selecting the optimal model, it further explores **decision threshold tuning** to boost recall, which is critical in medical prediction tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8210c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'metric': 'manhattan', 'n_neighbors': 11, 'weights': 'distance'}\n",
      "Best CV F1: 0.9505663280906125\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8043478260869565\n",
      "Precision: 0.8666666666666667\n",
      "Recall   : 0.7647058823529411\n",
      "F1 Score : 0.8125\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.80        82\n",
      "           1       0.87      0.76      0.81       102\n",
      "\n",
      "    accuracy                           0.80       184\n",
      "   macro avg       0.81      0.81      0.80       184\n",
      "weighted avg       0.81      0.80      0.80       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [24 78]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Hyperparameter tuning for KNN \n",
    "param_grid = {\n",
    "    \"n_neighbors\": list(range(1, 31)),\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\", \"minkowski\"],  # minkowski with p=2 is euclidean\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",        \n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Fit \n",
    "grid.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "best_knn = grid.best_estimator_\n",
    "\n",
    "# 2) Evaluate best KNN on TEST \n",
    "y_pred_knn_best = best_knn.predict(X_test_ready)\n",
    "y_prob_knn_best = best_knn.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_knn_best, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3325fd7a",
   "metadata": {},
   "source": [
    "## KNN (Best Params) Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 80.4%  \n",
    "- **Precision**: 86.7%  \n",
    "- **Recall**: 76.5%  \n",
    "- **F1 Score**: 81.3%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 70           | 12           |\n",
    "| **Actual: 1** | 24           | 78           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **strong precision (87%)**, indicating that predicted CVD cases are usually correct.  \n",
    "- **Recall is moderate (76%)**, with **24 CVD cases missed (false negatives)**.  \n",
    "- For non-CVD patients, performance is solid (85% correctly identified), though some misclassifications remain (**12 false positives**).  \n",
    "- Overall, this KNN configuration provides **reliable precision** but still sacrifices sensitivity, making it more conservative in detecting CVD cases.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f7163",
   "metadata": {},
   "source": [
    "### Further KNN Improvement - Implementing PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e7c94e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA components: 11 | Explained variance retained: 0.952\n",
      "=== KNN (best params) Evaluation ===\n",
      "Accuracy : 0.8315217391304348\n",
      "Precision: 0.9080459770114943\n",
      "Recall   : 0.7745098039215687\n",
      "F1 Score : 0.8359788359788359\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.83        82\n",
      "           1       0.91      0.77      0.84       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.84      0.84      0.83       184\n",
      "weighted avg       0.84      0.83      0.83       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  8]\n",
      " [23 79]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "\n",
    "#1) PCA + KNN pipeline (on one-hot encoded + scaled features)\n",
    "pca_knn = Pipeline([\n",
    "    ('pca', PCA(n_components=0.95, random_state=42)),  # keep 95% variance\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=15, metric='manhattan', weights='distance'\n",
    "    ))\n",
    "])\n",
    "\n",
    "pca_knn.fit(X_train_ready, y_train)\n",
    "\n",
    "# Inspect PCA details\n",
    "n_comp = pca_knn.named_steps['pca'].n_components_\n",
    "expl_var = pca_knn.named_steps['pca'].explained_variance_ratio_.sum()\n",
    "print(f\"PCA components: {n_comp} | Explained variance retained: {expl_var:.3f}\")\n",
    "\n",
    "# 2) Evaluate \n",
    "y_pred_pca_knn = pca_knn.predict(X_test_ready)\n",
    "probs_pca_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "  \n",
    "evaluate_model(y_test, y_pred_pca_knn, \"KNN (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf4120",
   "metadata": {},
   "source": [
    "## KNN Model Comparison (Baseline vs Tuned vs PCA)\n",
    "\n",
    "| Model                     | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline KNN**           | 0.783    | 0.869     | 0.716  | 0.785    | Strong precision, but recall is low (29 missed CVD cases). |\n",
    "| **Tuned KNN**              | 0.804    | 0.867     | 0.765  | 0.813    | Small gains in recall (+5%) and F1; still misses 24 CVD cases. |\n",
    "| **Tuned KNN + PCA (11 comps)** | 0.832 | 0.908     | 0.775  | 0.836    | Best overall: higher accuracy (+5% vs baseline), improved precision (91%), fewer false positives. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline KNN** provides decent precision (87%) but underperforms in recall, missing many true CVD cases.  \n",
    "- **Tuned KNN** improves recall and F1 modestly, reducing false negatives from 29 → 24, but gains are limited.  \n",
    "- **Tuned KNN with PCA** achieves the **best balance**, with the highest accuracy (83.2%) and precision (91%), while maintaining solid recall. False positives drop to **8**, making it more reliable in detecting healthy cases correctly.  \n",
    "\n",
    "➡️ **Conclusion**: Incorporating PCA into the tuned KNN delivers the **strongest and most balanced performance**, outperforming both the baseline and standard tuned models.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3bf66d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PCA+KNN model → pca_knn.pkl\n",
      "Saved predictions → HeartFailureData_75F25M_PCA_KNN_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing KNN Model for fairness evaluation\n",
    "import joblib, pandas as pd, numpy as np\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"pca_knn.pkl\"\n",
    "joblib.dump(pca_knn, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from PCA+KNN\n",
    "y_pred_knn = pca_knn.predict(X_test_ready)\n",
    "y_prob_knn = pca_knn.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_knn,\n",
    "    \"y_pred\": y_pred_knn\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75F25M_PCA_KNN_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "\n",
    "print(f\"Saved PCA+KNN model → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d941cf3a",
   "metadata": {},
   "source": [
    "### Improvement - Decision Tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a66f6420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best CV F1: 0.9336502933840469\n",
      "=== Tuned Decision Tree (best params) Evaluation ===\n",
      "Accuracy : 0.7989130434782609\n",
      "Precision: 0.8735632183908046\n",
      "Recall   : 0.7450980392156863\n",
      "F1 Score : 0.8042328042328042\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79        82\n",
      "           1       0.87      0.75      0.80       102\n",
      "\n",
      "    accuracy                           0.80       184\n",
      "   macro avg       0.80      0.81      0.80       184\n",
      "weighted avg       0.81      0.80      0.80       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [26 76]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "\n",
    "# 1) Base model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 2) Hyperparameter grid \n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 5, 7, 9, None],\n",
    "    \"min_samples_split\": [2, 5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6, 10],\n",
    "}\n",
    "\n",
    "# 3) Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 4) Grid search \n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"f1\",      \n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_dt.best_params_)\n",
    "print(\"Best CV F1:\", grid_dt.best_score_)\n",
    "\n",
    "# 5) Train & evaluate best DT\n",
    "tuned_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_best = tuned_dt.predict(X_test_ready)\n",
    "y_prob_dt_best = tuned_dt.predict_proba(X_test_ready)[:, 1] \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt_best, \"Tuned Decision Tree (best params)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b2a706",
   "metadata": {},
   "source": [
    "### Tuned Decision Tree (best params) Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 79.9%  \n",
    "- **Precision**: 87.4%  \n",
    "- **Recall**: **74.5%**  \n",
    "- **F1 Score**: 80.4%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 71           | 11           |\n",
    "| **Actual: 1** | 26           | 76           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **26**  \n",
    "- **True Positives (correct CVD detections)**: **76**  \n",
    "- **Recall (class 1 / CVD)** = 76 / (76 + 26) = **74.5%**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48e7e686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best simple DT params: {'criterion': 'entropy', 'max_depth': 7, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Stage A — Best CV F1: 0.9433333333333334\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV F1: 0.9433\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.7663043478260869\n",
      "Precision: 0.8641975308641975\n",
      "Recall   : 0.6862745098039216\n",
      "F1 Score : 0.7650273224043715\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.87      0.77        82\n",
      "           1       0.86      0.69      0.77       102\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.78      0.78      0.77       184\n",
      "weighted avg       0.79      0.77      0.77       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[71 11]\n",
      " [32 70]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning: simpler trees + class balancing + cost-complexity pruning\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# bias toward simpler trees with class_weight=\"balanced\" \n",
    "base_dt = DecisionTreeClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [3, 4, 5, 6, 7],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],  # tiny regularization\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",    # balanced focus\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "print(\"Stage A — Best simple DT params:\", grid_simple.best_params_)\n",
    "print(\"Stage A — Best CV F1:\", grid_simple.best_score_)\n",
    "simple_dt = grid_simple.best_estimator_\n",
    "\n",
    "# cost-complexity pruning\n",
    "path = simple_dt.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "unique_alphas = np.unique(np.round(ccp_alphas, 6))\n",
    "candidate_alphas = np.linspace(unique_alphas.min(), unique_alphas.max(), num=min(20, len(unique_alphas)))\n",
    "candidate_alphas = np.unique(np.concatenate([candidate_alphas, [0.0]]))  \n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(\n",
    "        random_state=42,\n",
    "        class_weight=\"balanced\",\n",
    "        criterion=simple_dt.criterion,\n",
    "        max_depth=simple_dt.max_depth,\n",
    "        min_samples_split=simple_dt.min_samples_split,\n",
    "        min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "        min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "        ccp_alpha=alpha\n",
    "    )\n",
    "    f1_cv = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, f1_cv))\n",
    "\n",
    "best_alpha, best_cv_f1 = sorted(cv_scores, key=lambda x: x[1], reverse=True)[0]\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV F1: {best_cv_f1:.4f}\")\n",
    "\n",
    "best_dt = DecisionTreeClassifier(\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\",\n",
    "    criterion=simple_dt.criterion,\n",
    "    max_depth=simple_dt.max_depth,\n",
    "    min_samples_split=simple_dt.min_samples_split,\n",
    "    min_samples_leaf=simple_dt.min_samples_leaf,\n",
    "    min_impurity_decrease=simple_dt.min_impurity_decrease,\n",
    "    ccp_alpha=best_alpha\n",
    ").fit(X_train_ready, y_train)\n",
    "\n",
    "# Evaluate on test set \n",
    "y_pred_dt = best_dt.predict(X_test_ready)\n",
    "y_prob_dt = best_dt.predict_proba(X_test_ready)[:, 1]  \n",
    "\n",
    "evaluate_model(y_test, y_pred_dt, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0735452",
   "metadata": {},
   "source": [
    "### Alternative Tuned & Pruned Decision Tree Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 76.6%  \n",
    "- **Precision**: 86.4%  \n",
    "- **Recall**: **68.6%**  \n",
    "- **F1 Score**: 76.5%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 71           | 11           |\n",
    "| **Actual: 1** | 32           | 70           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **32**  \n",
    "- **True Positives (correct CVD detections)**: **70**  \n",
    "- **Recall (class 1 / CVD)** = 70 / (70 + 32) = **68.6%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The tree is **precision-leaning** for class 1 (CVD): relatively few false alarms (**11 FP**), but **32 FN** lowers sensitivity (**recall 68.6%**).\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8295e555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage A — Best DT params: {'class_weight': {0: 1, 1: 4}, 'criterion': 'entropy', 'max_depth': 4, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 5}\n",
      "Stage A — Best CV Recall: 0.9733\n",
      "Stage B — Best ccp_alpha: 0.000000 | CV Recall: 0.9733\n",
      "=== Alternative Tuned & Pruned Decision Tree Evaluation ===\n",
      "Accuracy : 0.8260869565217391\n",
      "Precision: 0.7966101694915254\n",
      "Recall   : 0.9215686274509803\n",
      "F1 Score : 0.8545454545454545\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78        82\n",
      "           1       0.80      0.92      0.85       102\n",
      "\n",
      "    accuracy                           0.83       184\n",
      "   macro avg       0.84      0.81      0.82       184\n",
      "weighted avg       0.83      0.83      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58 24]\n",
      " [ 8 94]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative DT tuning focused on higher recall\n",
    "# Changes vs previous:\n",
    "#  - Remove calibration (predict uses raw tree probs at 0.5)\n",
    "#  - Tune class_weight (heavier positive weights allowed)\n",
    "#  - Broaden depth a bit but keep regularization via min_samples_* and tiny impurity decrease\n",
    "#  - Prune only with very small ccp_alphas to avoid killing recall\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# Simpler-but-expressive trees + tuned class weights\n",
    "base_dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid_simple = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],                  # add \"log_loss\" if your sklearn supports it\n",
    "    \"max_depth\": [4, 5, 6, 7, 8, 9, 10],               # a bit deeper to help recall\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 6],\n",
    "    \"min_impurity_decrease\": [0.0, 1e-4, 1e-3],\n",
    "    \"class_weight\": [\"balanced\", {0:1,1:2}, {0:1,1:3}, {0:1,1:4}],  # stronger push toward positives\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=42)\n",
    "\n",
    "grid_simple = GridSearchCV(\n",
    "    estimator=base_dt,\n",
    "    param_grid=param_grid_simple,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",      # prioritize sensitivity for class 1\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True\n",
    ")\n",
    "grid_simple.fit(X_train_ready, y_train)\n",
    "\n",
    "best_params = grid_simple.best_params_\n",
    "print(\"Stage A — Best DT params:\", best_params)\n",
    "print(\"Stage A — Best CV Recall:\", round(grid_simple.best_score_, 4))\n",
    "\n",
    "# Train a zero-pruned model with best params to get the pruning path\n",
    "dt0 = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=0.0).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Stage B — Gentle cost-complexity pruning (favor small alphas)\n",
    "path = dt0.cost_complexity_pruning_path(X_train_ready, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# Focus on tiny alphas only + 0.0 to avoid big recall loss\n",
    "small_slice = ccp_alphas[: min(30, len(ccp_alphas))]  # first 30 values are typically the smallest\n",
    "candidate_alphas = np.unique(np.r_[0.0, small_slice])\n",
    "\n",
    "cv_scores = []\n",
    "for alpha in candidate_alphas:\n",
    "    dt_alpha = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=alpha)\n",
    "    rec = cross_val_score(dt_alpha, X_train_ready, y_train, cv=cv, scoring=\"recall\", n_jobs=-1).mean()\n",
    "    cv_scores.append((alpha, rec))\n",
    "\n",
    "best_alpha, best_cv_recall = max(cv_scores, key=lambda x: x[1])\n",
    "print(f\"Stage B — Best ccp_alpha: {best_alpha:.6f} | CV Recall: {best_cv_recall:.4f}\")\n",
    "\n",
    "alt_best_dt = DecisionTreeClassifier(random_state=42, **best_params, ccp_alpha=best_alpha).fit(X_train_ready, y_train)\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "y_pred = alt_best_dt.predict(X_test_ready)               \n",
    "y_prob = alt_best_dt.predict_proba(X_test_ready)[:, 1]   \n",
    "\n",
    "evaluate_model(y_test, y_pred, \"Alternative Tuned & Pruned Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d326c56",
   "metadata": {},
   "source": [
    "## Decision Tree Model Comparison\n",
    "\n",
    "| Model                                | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|--------------------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline DT**                      | 0.793    | 0.820     | 0.804  | 0.812    | Balanced overall; 20 false negatives and 18 false positives. |\n",
    "| **Tuned DT (best params)**           | 0.799    | 0.874     | 0.745  | 0.804    | Precision improves, but recall drops (26 false negatives). |\n",
    "| **Alt. Tuned & Pruned DT (F1-focused)** | 0.766 | 0.864     | 0.686  | 0.765    | Strong precision, but recall is lowest; misses many positives (32). |\n",
    "| **Alt. Tuned & Pruned DT (Recall-focused)** | 0.826 | 0.797 | 0.922  | 0.855    | Highest recall; only 8 false negatives, but more false positives (24). |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline DT** offers a **well-balanced trade-off**, with solid precision and recall (~80% each).  \n",
    "- **Tuned DT** prioritizes **precision (87%)**, but recall suffers (74.5%), leading to more missed CVD cases.  \n",
    "- **Alt. Tuned & Pruned DT (F1-focused)** maintains high precision (86%) but shows the **weakest recall (68.6%)**, missing 32 true CVD patients — problematic in medical contexts.  \n",
    "- **Alt. Tuned & Pruned DT (Recall-focused)** achieves the **best recall (92%)** and also the **highest accuracy among DT variants (82.6%)**, minimizing missed CVD cases (**only 8 false negatives**). The trade-off is a moderate increase in false positives (24 cases).  \n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "The **Alt. Tuned & Pruned DT (Recall-focused)** model was selected as the preferred Decision Tree variant since it provides the **highest accuracy and recall**. This combination ensures strong overall performance while minimizing the number of missed CVD cases, which is especially important in a medical context.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96474437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Alternative DT tuning → alt_tuned_pruned_DT.pkl\n",
      "Saved predictions → HeartFailureData_75F25M_AltTunedDT_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing DT Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"alt_tuned_pruned_DT.pkl\"\n",
    "joblib.dump(alt_best_dt, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from Decision Tree \n",
    "y_pred_dt = alt_best_dt.predict(X_test_ready)\n",
    "y_prob_dt = alt_best_dt.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_dt,\n",
    "    \"y_pred\": y_pred_dt\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75F25M_AltTunedDT_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Alternative DT tuning → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bbe2d4",
   "metadata": {},
   "source": [
    "### Ensemble Model - Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81ec0da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Evaluation ===\n",
      "Accuracy : 0.842391304347826\n",
      "Precision: 0.9101123595505618\n",
      "Recall   : 0.7941176470588235\n",
      "F1 Score : 0.8481675392670157\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        82\n",
      "           1       0.91      0.79      0.85       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.85      0.84       184\n",
      "weighted avg       0.85      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[74  8]\n",
      " [21 81]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test_ready)\n",
    "y_prob_rf = rf.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e4d03",
   "metadata": {},
   "source": [
    "### Random Forest Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Metrics (Test Set)\n",
    "\n",
    "- **Accuracy**: 84.2%  \n",
    "- **Precision**: 91.0%  \n",
    "- **Recall**: **79.4%**  \n",
    "- **F1 Score**: 84.8%  \n",
    "\n",
    "#### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|--------------:|-------------:|-------------:|\n",
    "| **Actual: 0** | 74           | 8            |\n",
    "| **Actual: 1** | 21           | 81           |\n",
    "\n",
    "- **False Negatives (missed CVD cases)**: **21**  \n",
    "- **True Positives (correct CVD detections)**: **81**  \n",
    "- **Recall (class 1 / CVD)** = 81 / (81 + 21) = **79.4%**\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The model is **precision-oriented** for class 1: most positive flags are correct (**91.0%** precision), with only **8 FP**.\n",
    "- **Recall at 79.4%** means **21 positive cases were missed**—a concern if the cost of missing CVD is high.\n",
    "- Overall performance is balanced (**F1 84.8%**, **Accuracy 84.2%**), but there’s a **precision–recall trade-off** tilted toward fewer false alarms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95aaa0d",
   "metadata": {},
   "source": [
    "### Improvement Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e9d56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n",
      "Best RF params: {'class_weight': None, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best CV F1: 0.9566666666666667\n",
      "=== Tuned Random Forest Evaluation ===\n",
      "Accuracy : 0.842391304347826\n",
      "Precision: 0.9010989010989011\n",
      "Recall   : 0.803921568627451\n",
      "F1 Score : 0.8497409326424871\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        82\n",
      "           1       0.90      0.80      0.85       102\n",
      "\n",
      "    accuracy                           0.84       184\n",
      "   macro avg       0.84      0.85      0.84       184\n",
      "weighted avg       0.85      0.84      0.84       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[73  9]\n",
      " [20 82]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: hyperparameter tuning\n",
    "\n",
    "# 1) GridSearchCV over impactful RF params\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [200, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.8],  # 0.8 = 80% of features\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring=\"recall\",          \n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid.fit(X_train_ready, y_train)\n",
    "best_rf = grid.best_estimator_\n",
    "print(\"Best RF params:\", grid.best_params_)\n",
    "print(\"Best CV F1:\", grid.best_score_)\n",
    "\n",
    "# 2) Evaluate best RF \n",
    "y_pred = best_rf.predict(X_test_ready)\n",
    "y_prob = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "evaluate_model(y_test, y_pred, \"Tuned Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c84a0",
   "metadata": {},
   "source": [
    "## Random Forest Model Comparison\n",
    "\n",
    "| Model                | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-----------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline RF**       | 0.842    | 0.910     | 0.794  | 0.848    | Strong precision (91%), fewer false positives (8), but 21 CVD cases missed. |\n",
    "| **Tuned RF**          | 0.842    | 0.901     | 0.804  | 0.850    | Slightly higher recall (+1%), detecting 1 more CVD case, but with 1 extra false positive. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline RF** is more **precision-oriented**, reducing false alarms but missing slightly more CVD cases.  \n",
    "- **Tuned RF** provides a **better recall-precision balance**, sacrificing a little precision to catch more positives.  \n",
    "- Performance differences are **minimal**, but the **tuned RF** may be favored in a medical context, where **recall (sensitivity)** is often prioritized.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34e624bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Tuned RF → tuned_rf.pkl\n",
      "Saved predictions → HeartFailureData_75F25M_RF_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing RF Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"tuned_rf.pkl\"\n",
    "joblib.dump(best_rf, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from Decision Tree \n",
    "y_pred_rf = best_rf.predict(X_test_ready)\n",
    "y_prob_rf = best_rf.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_rf,\n",
    "    \"y_pred\": y_pred_rf\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75F25M_RF_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Tuned RF → {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2c505",
   "metadata": {},
   "source": [
    "### Deep Learning - Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b0d5440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library \n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a011ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multilayer Perceptron (MLP) Evaluation ===\n",
      "Accuracy : 0.7934782608695652\n",
      "Precision: 0.8478260869565217\n",
      "Recall   : 0.7647058823529411\n",
      "F1 Score : 0.8041237113402062\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78        82\n",
      "           1       0.85      0.76      0.80       102\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.79      0.80      0.79       184\n",
      "weighted avg       0.80      0.79      0.79       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[68 14]\n",
      " [24 78]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLP model\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),   # one hidden layer with 100 neurons\n",
    "    activation='relu',           # or 'tanh'\n",
    "    solver='adam',               # optimizer\n",
    "    max_iter=1000,                # increase if convergence warning appears\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "mlp.fit(X_train_ready, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp.predict(X_test_ready)\n",
    "y_prob = mlp.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"Multilayer Perceptron (MLP)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f851634f",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 79.3%  \n",
    "- **Precision**: 84.8%  \n",
    "- **Recall**: 76.5%  \n",
    "- **F1 Score**: 80.4%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 68           | 14           |\n",
    "| **Actual: 1** | 24           | 78           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **good precision (85%)**, meaning most positive (CVD) predictions are correct.  \n",
    "- **Recall is lower (76%)**, with **24 CVD cases missed** (false negatives).  \n",
    "- Non-CVD cases are recognized with solid accuracy (83% recall), though **14 healthy cases** were incorrectly classified as CVD (false positives).  \n",
    "- Overall, the MLP shows **balanced but modest performance**, leaning slightly towards precision while sacrificing sensitivity.  \n",
    "\n",
    "➡️ This suggests the model is reliable for confirming positive cases but may under-detect some true CVD patients, which is a limitation in medical screening tasks.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b2b435",
   "metadata": {},
   "source": [
    "### Improvements - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4cbac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (Adam + EarlyStopping) Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.8709677419354839\n",
      "Recall   : 0.7941176470588235\n",
      "F1 Score : 0.8307692307692308\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        82\n",
      "           1       0.87      0.79      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.82      0.82       184\n",
      "weighted avg       0.83      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [21 81]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adam + Early Stopping \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "adammlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),   # slightly smaller/deeper can help\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=1e-3,       # smaller step can stabilize\n",
    "    alpha=1e-3,                    # L2 regularization to reduce overfitting\n",
    "    batch_size=32,\n",
    "    max_iter=1000,                 # increased max_iter\n",
    "    early_stopping=True,           # use a validation split internally\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=25,          \n",
    "    tol=1e-4,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "adammlp.fit(X_train_ready, y_train)  \n",
    "y_pred_mlp = adammlp.predict(X_test_ready)                     \n",
    "y_prob_mlp = adammlp.predict_proba(X_test_ready)[:, 1]         \n",
    "\n",
    "evaluate_model(y_test, y_pred_mlp, \"(Adam + EarlyStopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3148edf",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – Adam + EarlyStopping) Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 82.1%  \n",
    "- **Precision**: 87.1%  \n",
    "- **Recall**: 79.4%  \n",
    "- **F1 Score**: 83.1%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 70           | 12           |\n",
    "| **Actual: 1** | 21           | 81           |\n",
    "\n",
    "### Interpretation\n",
    "- This model delivers **improved overall performance** compared to the baseline MLP.  \n",
    "- **Precision is high (87%)**, indicating strong reliability in positive (CVD) predictions.  \n",
    "- **Recall (79%)** is slightly better, reducing missed CVD cases to **21 false negatives**.  \n",
    "- Non-CVD detection is also solid, with **85% recall**, though **12 healthy patients** were flagged incorrectly (false positives).  \n",
    "- The addition of **EarlyStopping with Adam** enhances model stability, preventing overfitting and yielding a more balanced trade-off between precision and recall.  \n",
    "\n",
    "➡️ Overall, this is a **stronger and more stable MLP variant**, offering a good balance of sensitivity and precision for CVD detection.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef1b35da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MLP (LBFGS)  Evaluation ===\n",
      "Accuracy : 0.7608695652173914\n",
      "Precision: 0.8085106382978723\n",
      "Recall   : 0.7450980392156863\n",
      "F1 Score : 0.7755102040816326\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74        82\n",
      "           1       0.81      0.75      0.78       102\n",
      "\n",
      "    accuracy                           0.76       184\n",
      "   macro avg       0.76      0.76      0.76       184\n",
      "weighted avg       0.77      0.76      0.76       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[64 18]\n",
      " [26 76]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LBFGS solver - converges fast & well on small datasets\n",
    "# LBFGS ignores batch_size, early_stopping, learning_rate. It optimizes the full-batch loss.\n",
    "mlp_lbfgs = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    activation='tanh',         # tanh + lbfgs often works nicely on tabular data\n",
    "    solver='lbfgs',            # quasi-Newton optimizer\n",
    "    alpha=1e-3,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_lbfgs.fit(X_train_ready, y_train)\n",
    "y_pred_lbfgs = mlp_lbfgs.predict(X_test_ready)\n",
    "y_prob_lbfgs = mlp_lbfgs.predict_proba(X_test_ready)[:, 1]  \n",
    "evaluate_model(y_test, y_pred_lbfgs, \"MLP (LBFGS) \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ade95",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – LBFGS) Evaluation\n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 76.1%  \n",
    "- **Precision**: 80.9%  \n",
    "- **Recall**: 74.5%  \n",
    "- **F1 Score**: 77.6%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 64           | 18           |\n",
    "| **Actual: 1** | 26           | 76           |\n",
    "\n",
    "### Interpretation\n",
    "- The model achieves **moderate precision (81%)** but has a lower **recall (74.5%)**, resulting in **26 missed CVD cases** (false negatives).  \n",
    "- For non-CVD patients, performance is weaker, with **18 false positives** misclassified as CVD.  \n",
    "- Both accuracy (76%) and F1 score (77.6%) are **lower compared to other MLP variants**, indicating reduced reliability.  \n",
    "- The **LBFGS optimizer** appears less effective for this dataset, as it fails to reach the stronger balance between sensitivity and precision achieved by the Adam-based models.  \n",
    "\n",
    "➡️ Overall, this variant shows **the weakest performance among the MLP models**, making it less suitable for CVD detection.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8960261b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best MLP params: {'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'batch_size': 16, 'alpha': 0.001, 'activation': 'relu'}\n",
      "=== Best MLP Evaluation ===\n",
      "Accuracy : 0.8206521739130435\n",
      "Precision: 0.8709677419354839\n",
      "Recall   : 0.7941176470588235\n",
      "F1 Score : 0.8307692307692308\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        82\n",
      "           1       0.87      0.79      0.83       102\n",
      "\n",
      "    accuracy                           0.82       184\n",
      "   macro avg       0.82      0.82      0.82       184\n",
      "weighted avg       0.83      0.82      0.82       184\n",
      "\n",
      "Confusion Matrix:\n",
      " [[70 12]\n",
      " [21 81]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Improved MLP pipeline: recall-first tuning  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, recall_score, fbeta_score, make_scorer\n",
    ")\n",
    "\n",
    "\n",
    "# 1) Recall-first search (Adam + early_stopping)\n",
    "base_mlp = MLPClassifier(\n",
    "    solver=\"adam\",\n",
    "    early_stopping=True,          # uses internal 15% validation\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=20,\n",
    "    max_iter=2000,                # allow convergence\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64, 32), (128, 64)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"alpha\": [1e-5, 1e-4, 3e-4, 1e-3],\n",
    "    \"learning_rate_init\": [1e-3, 5e-4, 3e-4, 1e-4],\n",
    "    \"batch_size\": [16, 32, 64],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# multi-metric scoring; refit on recall-oriented F-beta\n",
    "scoring = {\n",
    "    \"f1\": make_scorer(f1_score),\n",
    "    \"recall\": make_scorer(recall_score),\n",
    "    \"fbeta2\": make_scorer(fbeta_score, beta=2)  # emphasize recall\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "    estimator=base_mlp,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=scoring,\n",
    "    refit=\"fbeta2\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rs.fit(X_train_ready, y_train)\n",
    "recallfirst_best_mlp = rs.best_estimator_\n",
    "print(\"Best MLP params:\", rs.best_params_)\n",
    "\n",
    "# 2) Evaluation\n",
    "y_prob = recallfirst_best_mlp.predict_proba(X_test_ready)[:, 1]\n",
    "y_pred_best_mlp = recallfirst_best_mlp.predict(X_test_ready)\n",
    "evaluate_model(y_test, y_pred_best_mlp, model_name=f\"Best MLP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3913da2f",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP – Best Tuned) Evaluation\n",
    "\n",
    "### Best Parameters\n",
    "- **Hidden layers**: (64, 32)  \n",
    "- **Activation**: ReLU  \n",
    "- **Learning rate**: 0.001  \n",
    "- **Batch size**: 16  \n",
    "- **Alpha (regularization)**: 0.001  \n",
    "\n",
    "### Overall Metrics\n",
    "- **Accuracy**: 82.1%  \n",
    "- **Precision**: 87.1%  \n",
    "- **Recall**: 79.4%  \n",
    "- **F1 Score**: 83.1%  \n",
    "\n",
    "### Confusion Matrix\n",
    "|               | Predicted: 0 | Predicted: 1 |\n",
    "|---------------|--------------|--------------|\n",
    "| **Actual: 0** | 70           | 12           |\n",
    "| **Actual: 1** | 21           | 81           |\n",
    "\n",
    "### Interpretation\n",
    "- The tuned MLP achieves **strong and balanced performance**, with **accuracy of 82.1%** and an **F1 score of 83.1%**.  \n",
    "- **Precision (87%)** indicates reliable positive predictions, while **recall (79%)** shows that most CVD cases are correctly detected, with **21 missed cases** (false negatives).  \n",
    "- Non-CVD cases are also well recognized, with **85% recall** and only **12 false positives**.  \n",
    "- Compared to the baseline and LBFGS variants, this tuned MLP shows clear improvements in both stability and predictive power.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ba838",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP) Model Comparison\n",
    "\n",
    "| Model                      | Accuracy | Precision | Recall | F1 Score | Key Notes |\n",
    "|-----------------------------|----------|-----------|--------|----------|-----------|\n",
    "| **Baseline MLP**            | 0.793    | 0.848     | 0.765  | 0.804    | Decent baseline; 24 false negatives, 14 false positives. |\n",
    "| **MLP (Adam + EarlyStopping)** | 0.821 | 0.871     | 0.794  | 0.831    | Improved stability; fewer false negatives (21) and false positives (12). |\n",
    "| **MLP (LBFGS)**             | 0.761    | 0.809     | 0.745  | 0.776    | Weakest variant; highest error rates (26 FN, 18 FP). |\n",
    "| **Best Tuned MLP**          | 0.821    | 0.871     | 0.794  | 0.831    | Matches EarlyStopping variant; confirms tuning leads to strong balance. |\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "- **Baseline MLP** delivers moderate results, leaning toward precision but missing a notable number of CVD cases.  \n",
    "- **MLP with Adam + EarlyStopping** achieves **the best performance**, with higher accuracy and F1 score, reducing both false positives and false negatives.  \n",
    "- **MLP (LBFGS)** underperforms, showing weaker precision and recall, and thus is less suitable.  \n",
    "- **Best Tuned MLP** replicates the performance of the EarlyStopping model, validating that tuning improves overall robustness.  \n",
    "\n",
    "➡️ **Conclusion**: The **Adam + EarlyStopping** and **Best Tuned MLP** variants are the most effective, offering the strongest balance of accuracy and recall, while the LBFGS version is the weakest.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e478f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Recall First Tuned MLP→ RecallFirstTunedMLP.pkl\n",
      "Saved predictions → HeartFailureData_75F25M_RecallFirstTunedMLP_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#saving best performing MLP Model for fairness evaluation\n",
    "\n",
    "# Ensure y_test is a Series \n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    y_test = y_test.squeeze(\"columns\")\n",
    "\n",
    "# Save model\n",
    "model_filename = \"RecallFirstTunedMLP.pkl\"\n",
    "joblib.dump(recallfirst_best_mlp, model_filename)\n",
    "\n",
    "# Ensure 1D arrays for y_true\n",
    "y_true = y_test.to_numpy() if hasattr(y_test, \"to_numpy\") else np.asarray(y_test)\n",
    "\n",
    "# Predictions from MLP\n",
    "y_pred_mlp = recallfirst_best_mlp.predict(X_test_ready)\n",
    "y_prob_mlp = recallfirst_best_mlp.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "# Optional gender column if present\n",
    "if isinstance(X_test, pd.DataFrame) and \"Sex\" in X_test.columns:\n",
    "    gender_vals = X_test[\"Sex\"].to_numpy()\n",
    "else:\n",
    "    gender_vals = np.full(shape=len(y_true), fill_value=np.nan)\n",
    "\n",
    "# Build and save results\n",
    "results = pd.DataFrame({\n",
    "    \"Sex\": gender_vals,\n",
    "    \"y_true\": y_true,\n",
    "    \"y_prob\": y_prob_mlp,\n",
    "    \"y_pred\": y_pred_mlp\n",
    "})\n",
    "\n",
    "preds_filename = \"HeartFailureData_75F25M_RecallFirstTunedMLP_predictions.csv\"\n",
    "results.to_csv(preds_filename, index=False)\n",
    "\n",
    "print(f\"Saved Recall First Tuned MLP→ {model_filename}\")\n",
    "print(f\"Saved predictions → {preds_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
